---
title: "Variables aleatorias discretas"
output: html_document
---
**Nota: este artículo está en construcción!!**


*Las funciones de probabilidad son los objetos matemáticos que usamos para entender experimentos aletorios. Cuando describimos un tipo de experimento aleatorio por una familia de funciones de probabilidad decimos que modelamos el proceso de medición del experimento. Cuando escogemos una función en particular para unos datos decimos que ajustamos el modelo. Usando R y como ejemplo el error aleatorio cometido al trasmitir los píxeles de de una foto, explico como las distribuciones binomial, binomial negativa y geométrica se obtienen de la distribución de Bernoulli.*

<img src="pixel.jpg" style="width:30%;  margin-right: 20px" align="left"> Imaginemos un sistema de trasmisión de información binaria. Cualquier sistema digital sirve como ejemplo. En particular, imaginemos que el sistema consiste en trasmitir el valor de los pixeles (0:blanco, 1:negro) de una foto digital. El sistema puede consistir simplemente en tomar una foto en blanco y negro y enviarla por correo a una cuenta de email. El receptor de la foto al abrirla observará una perdida de calidad inicial, dada por la acumulación de errores en el almacenamiento, envío, procesamiento y visualización. Nuestro objetivo es analizar teóricamente esta situación para disponer de una herramienta matemática que nos permita describir este proceso aleatorio, es decir del error en la trasmisión que da origen a la pérdida en calidad de la foto. Insisto, lo que presentamos es un construcción analítica, lógica y abstracta de lo que queremos **derivar**; el comportamiento que podríamos esperar de este sistema bajo unas suposiciones razonables. El ejercicio es pues de carácter **deductivo**, sin apelar a datos ni observaciones de un experimento en concreto, sino a unos supuestos y a sus consequencias lógicas. Intentaremos construir un *modelo* de probabilidad para el error en transmisión de una foto en blanco y negro.       

##Función de probabilidad de Bernoulli

¿Qué es un modelo probabilístico? Supongamos la medición de un experimento $X$ que al repetirla bajo las mismas condiciones cada vez nos da un número diferente $\{x_1, x_2, ...\}$. Usamos $X$ mayúscula para la medición y nos referimos a ella como una variable aleatoria. Las letras en minúsculas son los valores que puede tomar $X$ depués de una medición en particular. Consideremos que $X$ sólo pueda tomar valores discretos entonces unos serán mas frecuentes que otros. Podemos calcular la frecuencia de $x_1$ como el número de experimentos que dieron como resultado $x_i$ dividido por el número total de experimentos $N$, o sea $fr(x_i)=N_{x_i}/N$. Si repitieramos infinitas veces el experimento entonces $fr(x_i)$ tiende a un número $P(X=x_i)$ que llamamos la probabilidad de que $X$ tome el valor $x_i$. O sea, $$lim_{N \rightarrow \infty} fr(x_i) =P(X=x_i).$$
La idea de concebir la probabilidad como el límite de una frecuencia ya nos indica su caracter abstracto y su naturaleza no observable, por lo menos de forma directa. Sin embargo, podemos ir a límite y desde allí definir las caracterésticas mas importantes que esperamos sobre la probabilidad y de forma lógica derivar sus consecuencias observables. Pansemos que la probabilidad para cada una de las posibles observaciones de $X$ está dada por una función $f(x_i)$ que llamaremos función de probabilidad y defnimos como 

$$f(x_i)=P(X=x_i).$$        
Lo más básico que le podemos pedir a esta función es que 

1. Sea siempre positiva para cualquier valor de $x_i$: $f(x_i)=P(X=x_i)$. No concebimos frequencias negativas ni que sus límites lo sean
2. Que la suma sobre todos sus valores sea 1: $\sum_{i=1}^{n}f(x_i)=1$. Es claro que las frecuecias relativas deben sumar 1 así como las suma de sus valores límites. 


Estas exigencias completan la definición de una función de probabilidad cualquiera. 

Veamos ahora casos particulares que nos ayuden a describir procesos de medición específicos. El caso mas sencillo de una función de distribución es para un ensayo de Bernoulli donde sólo hay dos posibles resultados $\{x_1=A, x_2=B\}$. Si el resultado A (k=1) tiene una probabilidad $p$, el evento B (k=0) por lo tanto tiene probabilidad $q=1-p$. La función de distribución de Bernoulli se puede escribir como 
$$f(k)=(1-p)^{1-k} p^k $$

El lanzamiendo de una moneda es un ensayo de Bernoulli con $p=1/2$. Dos características importantes de las funciones de probabilidad son su valor medio y su varianza. La media de la distribución es definida como 
$$E(X)=\mu=\sum_{i=1}^{n}f(x_i)x_{i}$$
y nos da su centro gravedad; como si cada $x_i$ fuese un punto con masa $f(x_i)$. La varianza es la distancia cuadrática media de cada uno de los valores de $x_i$ a la media 

$$V(X)=\sum_{i=1}^{n}(x_i-\mu)^2 f(x_i)$$
es decir su momento de inercia que indica cuanto de dispersos son los valores $x_i$.  Para la distribución de Bernulli la media y la varianza son $$E(x)=\mu=p$$ $$V(X)=\sigma^2=p(1-p)$$. La función de probabilidad de Bernoulli es un modelo de probabilidad que define realmente una familia de funciones. Cada función es totalmente definida por el número, o parámtro, $p$. Este número es sucifiente para calcular $f(x_i)$ y por lo tanto $E(X)$ y $V(X)$.  

Pensemos en un ejemplo en concreto. Imaginemos que nuestro sistema para transmitir el valor de un pixel lo hace con un probabilidad $p=0.8$ de transmitirlo correctamente (correcto:k=0) y 0.2 de transmitirlo incorrectamente (error:k=1)  

$$
    f(k)= 
\begin{cases}
    0.8,& \text{si } k=0 \\
    0.2,& \text{si } k=1\\
\end{cases}
$$

Asignemmos $k$ el vector $(0,1)$ y a $fk$ el vector $(0.8,0.2)$ y trasmitamos una foto de 100 pixels blancos. Al pasar la foto por nuestro sistema unos pixeles serán blancos (correcto: k=0) y otros negros (error: k=1). La función **sample** toma 100 valores aletorios entre (0,1) con probabilidad (0.8,0.2); es decir que hace 100 ensayos de Bernoulli

```{r}
k <- c(0,1)
fk <- c(0.8,0.2)
names(fk) <- k

foto <- sample(k, size=100, prob=fk, replace=TRUE)
image(matrix(foto, ncol=10), col=c("white", "black"), 
      main= "Recepción de foto en blanco con 20% de errores aleatorios")

```

En cada pixel tenemos un ensayo de Bernoulli, cuya función de probabilidad se puede representar por las frecuencias de cada resultado $fr(0)=N_0/100$, $fr(1)=N_1/100$, siendo $N=100$ un número suficientemente grande como para pensar que estas frecuencias están cerca de las probabilidades $f(0)$ y $fr(1)$.  

```{r}
hist(foto, freq=FALSE, breaks=seq(-0.5,1.5), ylim=c(0,1), main="Función de probabilidad de Bernoulli")
points(k, fk, pch=16, col="red")
for(i in 1:2) {lines(c(k[i],k[i]), c(0,fk[i]), col="red")}

```

Podemos ver sin embargo que todavía permanecen diferencias entre las frecuencias y la probabilidades definidas para el ensayo de Bernoulli $(p, 1-p)$. El promedio de 100 ensayos de Bernoulli $\bar{X}$ y su desviación estándard $S$ son funciones de [muestreo](https://alejandro-isglobal.github.io/teaching/muestreo.html) que se calculan con $mean$ and $sd$

```{r}
xbar <- mean(foto) 
xbar
s <- sd(foto)
s^2
```
y cuyos valores se acercan a $\mu=p=0.2$ y la varianza $\sigma^2=p*(1-p)=0.16$ de la distribución de Bernoulli.

##Función de probabilidad Binomial

La distribuci\'on Binomial da la probabilidad de observar $x$ eventos de un tipo (A) con probabilidad $p$ en $n$ ensayos de Bernoulli. 

$$Bin(x; n,p)=\binom n x p^x(1-p)^{n-x}$$
x=0,1,...n


- $E(X)=\mu=np$
- $V(X)=\sigma^2=np(1-p)$

Enviemos una foto de 100 pixels y contemos cuantas veces aparece el 1 (x=cuantos errores hay).

```{r}
foto <- sample(x=c(0,1),size=100, prob=fk, replace=TRUE)
foto
```

```{r}
sum(foto)
```

esta foto tuvo x=12 errores. 


Pero cu\'al es la probabilidad de observar fotos con 1 error, 2 errores, ... 12 errores, ... 100 errores?  Pr(x=2), Pr(x=3), ... Pr(x=100)?


Tenemos que enviar muchas fotos de 100 pixeles (p.ej. 1000) y contar cuantas fotos tienen 1 error, 2 errores, .... 100 errores (fr(x=2), fr(x=3), ... fr(x=100))



Hagamos una funci\'on para que simule los errores en eviar fotos de 100 pixels (cuando la probabilidad de error por pixel (k=1) es 0.2 -Bernoulli)

```{r}
enviar <- function(...)
{
   foto <- sample(c(0,1),size=100, 
                  replace=TRUE,prob=fk)
   sum(foto)
}
```


los tres puntos indican que no importa el argumento en la funci\'on, esta siempre hara lo mismo.

```{r}
enviar()
enviar(1)
enviar(1)
enviar("hola")
```


cada vez que llamamos a enviar con cualquier argumento, envía una foto de 100 pixels y cuenta los errores. 

Podemos simular los errores producidos en el env\'io de tres fotos de 100 pixeles  

```{r}
c(enviar(1), enviar(1), enviar(1))
```

en R esto se pueden hacer con la funci\'on {\bf sapply}

```{r}
Tresfotos <- sapply(rep(1,3), enviar)
Tresfotos
```


Simula los errores al enviar mil fotos, as\'ignalo a {\bf Milfotos} y pinta su histograma


puedes conseguir?
- usa {\bf hist} como antes pero a\~nade par\'ametro ylim=c(0,0.15) como l\'imites para el eje y; modifica el par\'ametro breaks de acuerdo al los nuevos valores de x, breaks=seq(1.5, 100.5); usa xlim=c(0,40) como l\'imites para el eje x.

Cuales son la media (mean) y varianza (sd$()^2$) de Milfotos?

Coinciden con los valores de la media y varianza de una distribuci\'on binomial?

- $E(X)=\mu=np=100*0.2=20$
- $V(X)=\sigma=np(1-p)=10*0.3*0.7=16$

Qu\'e tanto coincide el histograma con la distribuci\'on binomial?

Necesitamos los valores de la distribucio\'n binomial para n=100 y p=0.2. Esto se hace con la funci\'on {\bf dbinom}

Bin(x; n,p) en R es {\tt dbinom(x, size=n, prob=p)}


```{r}
x <- 0:100
binomial <- dbinom(x, size=100, prob=0.2)
names(binomial) <- x
head(binomial)
```

```{r}
Milfotos <- sapply(rep(1,1000), enviar)
head(Milfotos)

hist(Milfotos,breaks=seq(1.5,100.5), 
freq=FALSE, ylim=c(0,0.15), xlim=c(0,40))

points(x, binomial, pch= 16, col="red")

for(i in 1:101)
{lines(c(x[i], x[i]), c(0, binomial[i]), 
  col="red")}
```




Usando la funci\'on  {\bf dbinom} responde:

- Cu\'al es la probabilidad de observar {\bf exactamente} 5 errores en la tranmisi\'on de una foto de 50 pixeles cuando la probabilidad de error es 0.1? (R/ 0.1849246) 
- Cu\'al es la probabilidad de que haya {\bf exactamente} un error en una foto de 3.1 mega pixels cuando el error en un pixel es de 1e-6?  (R/ 0.1396525)

En R est\'a la funci\'on {\bf pbinom} que es la funci\'on de acumulaci\'on de probabilidad para una distribuci\'on binomial $F_{bin}(x; n, p)$

$F_{bin}(x; n, p)$ en R es {\tt pbinom(x, size=n, prob=p)}


```{r}
binCum <- pbinom(x, size=100, prob=0.2)
head(binCum)
plot(x, binCum, ylim=c(0,1), type="s",
       col="red", ylab="F(x)", xlab="x")
```


Cu\'al es la probabilidad de que haya {\bf al menos} un error en una foto de 3,1 mega pixels cuando el error en un pixel es de 1e-6?  (R/ 0.1847016)

## Distribuci\'on Geom\'etrica

La distribuci\'on geom\'etrica da la probabilidad de en n\'umero de eventos (x) de un tipo (B) que hay que esperar hasta obtener un evento del otro tipo (A) de probabilidad p

$$P(X=x)=f(x)=(1-p)^{x}p,$$ $x=0,1,2,...$

Su media y varianza muestral son 

$E(X)= \mu =\frac{1-p}{p}$ y $V(X)= \sigma^2 =\frac{1-p}{p^2}$


Cu\'al es la probabilidad de observar fotos con 1 pixel correcto antes del primer error, 2 pixels correctos antes del primer error, ... 100 pixeles correctos (sin error)?  Pr(x=2), Pr(x=3), ... Pr(x=100)?

Tenemos que enviar muchas fotos de 100 pixeles (p.ej. 1000) y contar cuantos ceros hay antes del primer 1.
Hagamos una foto:

- hagamos 100 ensayos de Bernoulli (p=0.2) 
```{r}
foto <- sample(c(0,1),100, replace=TRUE, prob=fk)
foto
```

Ahora identificemos cuantos ceros aparecieron antes del primer 1 (en mi caso hubo 2)

Con la funci\'on {\bf which} tenemos las posiciones de un vector que satisfacen una condici\'on (Qu\'e elemento en foto es igual a 1? usa {\bf ==} )

```{r}
which(foto==1)
```

Si asignamos la variable {\bf ones} al resultado de {\bf which}, Cu\'al ser\'ia la posici\'on del \'ultimo cero?


Pong\'amolo todo junto.

Esta es uan foto con su n\'umero de ceros antes del primer 1, asignado a la variable {\bf lastzero}

```{r}
foto <- sample(c(0,1),100, replace=TRUE, prob=fk)
ones <- which(foto==1)
firstone <- ones[1]  
lastzero <- firstone-1
lastzero
```

Esta es s\'olo una foto, queremos enviar 1000 fotos y hacer un histograma?

- Hay que hacer una funci\'on llam\'emosla ({\bf enviar})

```{r}
enviar <- function(x)
          {
             foto <- sample(c(0,1),100, 
                      replace=TRUE, prob=fk)
             ones <- which(foto==1)
             firstone <- ones[1]  
             lastzero <- firstone-1
             lastzero
          }   
          
enviar()
```

esta funci\'on crea una foto la envía y cuenta el n\'umero de pixels bien trasmitidos hasta el primer error

- Hagamos un bucle de 1000 iteraciones de la funci\'on ({\bf sapply})

```{r}
Milfotos <- sapply(rep(1,1000), enviar)
head(Milfotos)
head(Milfotos)
mean(Milfotos)
sd(Milfotos)^2
```

La media y la varianza de la distribuci\'on geom\'etrica son

$E(X) =\frac{1-p}{p}=4$ y $V(X)= \frac{1-p}{p^2}=20$




```{r}
hist(Milfotos,breaks=seq(-0.5,100.5), 
freq=FALSE, ylim=c(0,0.25), xlim=c(0,40))

geom <- dgeom(x, prob=0.2)

points(x, geom, pch= 16, col="red")

for(i in 1:101)
{lines(c(x[i], x[i]), c(0, geom[i]), 
  col="red")}
```

puedes conseguir?

##Distribución Binomial Negativa 

Enviemos una foto y contemos en qu\'e pixel aparece antes del cuarto error (r=4). Imagina que no queremos fotos con mas de 4 errores. El n\'umero de pixels antes del cuarto error se distribuye bajo una binomial gegativa NegBin(x; r,p) o en R dnbinom(x, size=r, prob=p). 

Enviemos una foto y veamos que pixel tiene el cuarto error

```{r}
fotos <- sample(c(0,1),100, replace=TRUE,prob=fk)
ones <- which(fotos==1)
fourthone <- ones[4]  
lastzero <- fourthone-1
#le quitamos los primeros tres errores
goodpixels <- lastzero-3
```
puedes conseguir?

```{r}
enviar <- function(x)
 {
 foto <- sample(c(0,1),100,
 replace=TRUE, prob=fk)
 ones <- which(foto==1)
 firstone <- ones[4]
 lastzero <- firstone-1
 goodpixels <- lastzero-3
 goodpixels
 }

Milfotos <- sapply(rep(1,1000), enviar)

hist(Milfotos,breaks=seq(-0.5,100.5), 
 freq=FALSE, ylim=c(0,0.25), xlim=c(0,40))

nb <- dnbinom(x, size=4, prob=0.2)

points(x, nb, pch= 16, col="red")

for(i in 1:101)
 {lines(c(x[i], x[i]), c(0, nb[i]), 
   col="red")}
```

