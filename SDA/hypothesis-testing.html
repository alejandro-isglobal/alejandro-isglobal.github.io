<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 14 Hypothesis testing | Statistical Data Analysis</title>
  <meta name="description" content="This is the book for the statistics theory of the BIST master" />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 14 Hypothesis testing | Statistical Data Analysis" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is the book for the statistics theory of the BIST master" />
  <meta name="github-repo" content="alejandro-isglobal/master" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 14 Hypothesis testing | Statistical Data Analysis" />
  
  <meta name="twitter:description" content="This is the book for the statistics theory of the BIST master" />
  

<meta name="author" content="Alejandro Caceres" />


<meta name="date" content="2024-08-05" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="interval-estimation.html"/>
<link rel="next" href="contingency-tables.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">SDA</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> About</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#how"><i class="fa fa-check"></i><b>1.1</b> How</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#schedule"><i class="fa fa-check"></i><b>1.2</b> Schedule</a></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#recommended-reading-list"><i class="fa fa-check"></i><b>1.3</b> Recommended reading list</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-description.html"><a href="data-description.html"><i class="fa fa-check"></i><b>2</b> Data description</a>
<ul>
<li class="chapter" data-level="2.1" data-path="data-description.html"><a href="data-description.html#scientific-method"><i class="fa fa-check"></i><b>2.1</b> Scientific method</a></li>
<li class="chapter" data-level="2.2" data-path="data-description.html"><a href="data-description.html#data"><i class="fa fa-check"></i><b>2.2</b> Data</a></li>
<li class="chapter" data-level="2.3" data-path="data-description.html"><a href="data-description.html#result-types"><i class="fa fa-check"></i><b>2.3</b> Result types</a></li>
<li class="chapter" data-level="2.4" data-path="data-description.html"><a href="data-description.html#random-experiments"><i class="fa fa-check"></i><b>2.4</b> Random experiments</a></li>
<li class="chapter" data-level="2.5" data-path="data-description.html"><a href="data-description.html#absolute-frequencies"><i class="fa fa-check"></i><b>2.5</b> Absolute frequencies</a></li>
<li class="chapter" data-level="2.6" data-path="data-description.html"><a href="data-description.html#relative-frequencies"><i class="fa fa-check"></i><b>2.6</b> Relative frequencies</a></li>
<li class="chapter" data-level="2.7" data-path="data-description.html"><a href="data-description.html#bar-chart"><i class="fa fa-check"></i><b>2.7</b> Bar chart</a></li>
<li class="chapter" data-level="2.8" data-path="data-description.html"><a href="data-description.html#pie-chart-pie"><i class="fa fa-check"></i><b>2.8</b> Pie chart (pie)</a></li>
<li class="chapter" data-level="2.9" data-path="data-description.html"><a href="data-description.html#ordinal-categorical-outcomes"><i class="fa fa-check"></i><b>2.9</b> Ordinal categorical outcomes</a></li>
<li class="chapter" data-level="2.10" data-path="data-description.html"><a href="data-description.html#absolute-and-relative-cumulative-frequencies"><i class="fa fa-check"></i><b>2.10</b> Absolute and relative cumulative frequencies</a></li>
<li class="chapter" data-level="2.11" data-path="data-description.html"><a href="data-description.html#cumulative-frequency-graph"><i class="fa fa-check"></i><b>2.11</b> Cumulative frequency graph</a></li>
<li class="chapter" data-level="2.12" data-path="data-description.html"><a href="data-description.html#numerical-outcomes"><i class="fa fa-check"></i><b>2.12</b> Numerical outcomes</a></li>
<li class="chapter" data-level="2.13" data-path="data-description.html"><a href="data-description.html#transforming-continuous-data"><i class="fa fa-check"></i><b>2.13</b> Transforming continuous data</a></li>
<li class="chapter" data-level="2.14" data-path="data-description.html"><a href="data-description.html#frequency-table-for-a-continuous-variable"><i class="fa fa-check"></i><b>2.14</b> Frequency table for a continuous variable</a></li>
<li class="chapter" data-level="2.15" data-path="data-description.html"><a href="data-description.html#histogram"><i class="fa fa-check"></i><b>2.15</b> Histogram</a></li>
<li class="chapter" data-level="2.16" data-path="data-description.html"><a href="data-description.html#cumulative-frequency-graph-1"><i class="fa fa-check"></i><b>2.16</b> Cumulative frequency graph</a></li>
<li class="chapter" data-level="2.17" data-path="data-description.html"><a href="data-description.html#summary-statistics"><i class="fa fa-check"></i><b>2.17</b> Summary Statistics</a></li>
<li class="chapter" data-level="2.18" data-path="data-description.html"><a href="data-description.html#average-sample-mean"><i class="fa fa-check"></i><b>2.18</b> Average (sample mean)</a></li>
<li class="chapter" data-level="2.19" data-path="data-description.html"><a href="data-description.html#median"><i class="fa fa-check"></i><b>2.19</b> Median</a></li>
<li class="chapter" data-level="2.20" data-path="data-description.html"><a href="data-description.html#dispersion"><i class="fa fa-check"></i><b>2.20</b> Dispersion</a></li>
<li class="chapter" data-level="2.21" data-path="data-description.html"><a href="data-description.html#sample-variance"><i class="fa fa-check"></i><b>2.21</b> Sample variance</a></li>
<li class="chapter" data-level="2.22" data-path="data-description.html"><a href="data-description.html#interquartile-range-iqr"><i class="fa fa-check"></i><b>2.22</b> Interquartile range (IQR)</a></li>
<li class="chapter" data-level="2.23" data-path="data-description.html"><a href="data-description.html#boxplot"><i class="fa fa-check"></i><b>2.23</b> Boxplot</a></li>
<li class="chapter" data-level="2.24" data-path="data-description.html"><a href="data-description.html#questions"><i class="fa fa-check"></i><b>2.24</b> Questions</a></li>
<li class="chapter" data-level="2.25" data-path="data-description.html"><a href="data-description.html#exercises"><i class="fa fa-check"></i><b>2.25</b> Exercises</a></li>
<li class="chapter" data-level="2.26" data-path="data-description.html"><a href="data-description.html#practice"><i class="fa fa-check"></i><b>2.26</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>3</b> Probability</a>
<ul>
<li class="chapter" data-level="3.1" data-path="probability.html"><a href="probability.html#random-experiments-1"><i class="fa fa-check"></i><b>3.1</b> Random experiments</a></li>
<li class="chapter" data-level="3.2" data-path="probability.html"><a href="probability.html#measurement-probability"><i class="fa fa-check"></i><b>3.2</b> Measurement probability</a></li>
<li class="chapter" data-level="3.3" data-path="probability.html"><a href="probability.html#classical-probability"><i class="fa fa-check"></i><b>3.3</b> Classical probability</a></li>
<li class="chapter" data-level="3.4" data-path="probability.html"><a href="probability.html#relative-frequencies-1"><i class="fa fa-check"></i><b>3.4</b> Relative frequencies</a></li>
<li class="chapter" data-level="3.5" data-path="probability.html"><a href="probability.html#relative-frequencies-at-infinity"><i class="fa fa-check"></i><b>3.5</b> Relative frequencies at infinity</a></li>
<li class="chapter" data-level="3.6" data-path="probability.html"><a href="probability.html#frequentist-probability"><i class="fa fa-check"></i><b>3.6</b> Frequentist probability</a></li>
<li class="chapter" data-level="3.7" data-path="probability.html"><a href="probability.html#classical-and-frequentist-probabilities"><i class="fa fa-check"></i><b>3.7</b> Classical and frequentist probabilities</a></li>
<li class="chapter" data-level="3.8" data-path="probability.html"><a href="probability.html#definition-of-probability"><i class="fa fa-check"></i><b>3.8</b> Definition of probability</a></li>
<li class="chapter" data-level="3.9" data-path="probability.html"><a href="probability.html#probabilities-table"><i class="fa fa-check"></i><b>3.9</b> Probabilities Table</a></li>
<li class="chapter" data-level="3.10" data-path="probability.html"><a href="probability.html#sample-space"><i class="fa fa-check"></i><b>3.10</b> Sample space</a></li>
<li class="chapter" data-level="3.11" data-path="probability.html"><a href="probability.html#events"><i class="fa fa-check"></i><b>3.11</b> Events</a></li>
<li class="chapter" data-level="3.12" data-path="probability.html"><a href="probability.html#algebra-of-events"><i class="fa fa-check"></i><b>3.12</b> Algebra of events</a></li>
<li class="chapter" data-level="3.13" data-path="probability.html"><a href="probability.html#mutually-exclusive-results"><i class="fa fa-check"></i><b>3.13</b> Mutually exclusive results</a></li>
<li class="chapter" data-level="3.14" data-path="probability.html"><a href="probability.html#joint-probabilities"><i class="fa fa-check"></i><b>3.14</b> Joint probabilities</a></li>
<li class="chapter" data-level="3.15" data-path="probability.html"><a href="probability.html#contingency-table"><i class="fa fa-check"></i><b>3.15</b> Contingency table</a></li>
<li class="chapter" data-level="3.16" data-path="probability.html"><a href="probability.html#the-addition-rule"><i class="fa fa-check"></i><b>3.16</b> The addition rule:</a></li>
<li class="chapter" data-level="3.17" data-path="probability.html"><a href="probability.html#questions-1"><i class="fa fa-check"></i><b>3.17</b> Questions</a></li>
<li class="chapter" data-level="3.18" data-path="probability.html"><a href="probability.html#exercises-1"><i class="fa fa-check"></i><b>3.18</b> Exercises</a></li>
<li class="chapter" data-level="3.19" data-path="probability.html"><a href="probability.html#practice-1"><i class="fa fa-check"></i><b>3.19</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="conditional-probability.html"><a href="conditional-probability.html"><i class="fa fa-check"></i><b>4</b> Conditional probability</a>
<ul>
<li class="chapter" data-level="4.1" data-path="conditional-probability.html"><a href="conditional-probability.html#joint-probability"><i class="fa fa-check"></i><b>4.1</b> Joint probability</a></li>
<li class="chapter" data-level="4.2" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-independence"><i class="fa fa-check"></i><b>4.2</b> Statistical independence</a></li>
<li class="chapter" data-level="4.3" data-path="conditional-probability.html"><a href="conditional-probability.html#the-conditional-probability"><i class="fa fa-check"></i><b>4.3</b> The conditional probability</a></li>
<li class="chapter" data-level="4.4" data-path="conditional-probability.html"><a href="conditional-probability.html#conditional-contingency-table"><i class="fa fa-check"></i><b>4.4</b> Conditional contingency table</a></li>
<li class="chapter" data-level="4.5" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-independence-1"><i class="fa fa-check"></i><b>4.5</b> Statistical independence</a></li>
<li class="chapter" data-level="4.6" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-dependency"><i class="fa fa-check"></i><b>4.6</b> Statistical dependency</a></li>
<li class="chapter" data-level="4.7" data-path="conditional-probability.html"><a href="conditional-probability.html#diagnostic-test"><i class="fa fa-check"></i><b>4.7</b> Diagnostic test</a></li>
<li class="chapter" data-level="4.8" data-path="conditional-probability.html"><a href="conditional-probability.html#inverse-probabilities"><i class="fa fa-check"></i><b>4.8</b> Inverse probabilities</a></li>
<li class="chapter" data-level="4.9" data-path="conditional-probability.html"><a href="conditional-probability.html#bayes-theorem"><i class="fa fa-check"></i><b>4.9</b> Bayes’ Theorem</a></li>
<li class="chapter" data-level="4.10" data-path="conditional-probability.html"><a href="conditional-probability.html#questions-2"><i class="fa fa-check"></i><b>4.10</b> Questions</a></li>
<li class="chapter" data-level="4.11" data-path="conditional-probability.html"><a href="conditional-probability.html#exercises-2"><i class="fa fa-check"></i><b>4.11</b> Exercises</a></li>
<li class="chapter" data-level="4.12" data-path="conditional-probability.html"><a href="conditional-probability.html#practice-2"><i class="fa fa-check"></i><b>4.12</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html"><i class="fa fa-check"></i><b>5</b> Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="5.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#objective"><i class="fa fa-check"></i><b>5.1</b> Objective</a></li>
<li class="chapter" data-level="5.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#relative-frequencies-2"><i class="fa fa-check"></i><b>5.2</b> Relative frequencies</a></li>
<li class="chapter" data-level="5.3" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#random-variable"><i class="fa fa-check"></i><b>5.3</b> Random variable</a></li>
<li class="chapter" data-level="5.4" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#the-value-of-a-random-variable"><i class="fa fa-check"></i><b>5.4</b> The value of a random variable</a></li>
<li class="chapter" data-level="5.5" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-of-random-variables"><i class="fa fa-check"></i><b>5.5</b> Probability of random variables</a></li>
<li class="chapter" data-level="5.6" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-functions"><i class="fa fa-check"></i><b>5.6</b> Probability functions</a></li>
<li class="chapter" data-level="5.7" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-mass-functions"><i class="fa fa-check"></i><b>5.7</b> Probability mass functions</a></li>
<li class="chapter" data-level="5.8" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probabilities-and-relative-frequencies"><i class="fa fa-check"></i><b>5.8</b> Probabilities and relative frequencies</a></li>
<li class="chapter" data-level="5.9" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#mean-or-expected-value"><i class="fa fa-check"></i><b>5.9</b> Mean or expected value</a></li>
<li class="chapter" data-level="5.10" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#variance"><i class="fa fa-check"></i><b>5.10</b> Variance</a></li>
<li class="chapter" data-level="5.11" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-functions-for-functions-of-x"><i class="fa fa-check"></i><b>5.11</b> Probability functions for functions of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="5.12" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-distribution"><i class="fa fa-check"></i><b>5.12</b> Probability distribution</a></li>
<li class="chapter" data-level="5.13" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-function-and-probability-distribution"><i class="fa fa-check"></i><b>5.13</b> Probability function and probability distribution</a></li>
<li class="chapter" data-level="5.14" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#quantiles"><i class="fa fa-check"></i><b>5.14</b> Quantiles</a></li>
<li class="chapter" data-level="5.15" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#summary"><i class="fa fa-check"></i><b>5.15</b> Summary</a></li>
<li class="chapter" data-level="5.16" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#questions-3"><i class="fa fa-check"></i><b>5.16</b> Questions</a></li>
<li class="chapter" data-level="5.17" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#exercises-3"><i class="fa fa-check"></i><b>5.17</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="continous-random-variables.html"><a href="continous-random-variables.html"><i class="fa fa-check"></i><b>6</b> Continous Random Variables</a>
<ul>
<li class="chapter" data-level="6.1" data-path="continous-random-variables.html"><a href="continous-random-variables.html#objective-1"><i class="fa fa-check"></i><b>6.1</b> Objective</a></li>
<li class="chapter" data-level="6.2" data-path="continous-random-variables.html"><a href="continous-random-variables.html#continuous-random-variables"><i class="fa fa-check"></i><b>6.2</b> Continuous random variables</a></li>
<li class="chapter" data-level="6.3" data-path="continous-random-variables.html"><a href="continous-random-variables.html#relative-frequencies-3"><i class="fa fa-check"></i><b>6.3</b> Relative frequencies</a></li>
<li class="chapter" data-level="6.4" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-density-function"><i class="fa fa-check"></i><b>6.4</b> Probability Density Function</a></li>
<li class="chapter" data-level="6.5" data-path="continous-random-variables.html"><a href="continous-random-variables.html#total-area-under-the-curve"><i class="fa fa-check"></i><b>6.5</b> Total area under the curve</a></li>
<li class="chapter" data-level="6.6" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probabilities-of-continous-variables"><i class="fa fa-check"></i><b>6.6</b> Probabilities of continous variables</a></li>
<li class="chapter" data-level="6.7" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-distribution-1"><i class="fa fa-check"></i><b>6.7</b> Probability distribution</a></li>
<li class="chapter" data-level="6.8" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-plots"><i class="fa fa-check"></i><b>6.8</b> Probability plots</a></li>
<li class="chapter" data-level="6.9" data-path="continous-random-variables.html"><a href="continous-random-variables.html#mean"><i class="fa fa-check"></i><b>6.9</b> Mean</a></li>
<li class="chapter" data-level="6.10" data-path="continous-random-variables.html"><a href="continous-random-variables.html#variance-1"><i class="fa fa-check"></i><b>6.10</b> Variance</a></li>
<li class="chapter" data-level="6.11" data-path="continous-random-variables.html"><a href="continous-random-variables.html#functions-of-x"><i class="fa fa-check"></i><b>6.11</b> Functions of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="6.12" data-path="continous-random-variables.html"><a href="continous-random-variables.html#exercises-4"><i class="fa fa-check"></i><b>6.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html"><i class="fa fa-check"></i><b>7</b> Discrete Probability Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#objective-2"><i class="fa fa-check"></i><b>7.1</b> Objective</a></li>
<li class="chapter" data-level="7.2" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#probability-mass-function"><i class="fa fa-check"></i><b>7.2</b> Probability mass function</a></li>
<li class="chapter" data-level="7.3" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#probability-model"><i class="fa fa-check"></i><b>7.3</b> Probability model</a></li>
<li class="chapter" data-level="7.4" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#parametric-models"><i class="fa fa-check"></i><b>7.4</b> Parametric models</a></li>
<li class="chapter" data-level="7.5" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#uniform-distribution-one-parameter"><i class="fa fa-check"></i><b>7.5</b> Uniform distribution (one parameter)</a></li>
<li class="chapter" data-level="7.6" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#uniform-distribution-two-parameters"><i class="fa fa-check"></i><b>7.6</b> Uniform distribution (two parameters)</a></li>
<li class="chapter" data-level="7.7" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#bernoulli-trial"><i class="fa fa-check"></i><b>7.7</b> Bernoulli trial</a></li>
<li class="chapter" data-level="7.8" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#binomial-experiment"><i class="fa fa-check"></i><b>7.8</b> Binomial experiment</a></li>
<li class="chapter" data-level="7.9" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#binomial-probability-function"><i class="fa fa-check"></i><b>7.9</b> Binomial probability function</a></li>
<li class="chapter" data-level="7.10" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#negative-binomial-probability-function"><i class="fa fa-check"></i><b>7.10</b> Negative binomial probability function</a></li>
<li class="chapter" data-level="7.11" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#geometric-distribution"><i class="fa fa-check"></i><b>7.11</b> Geometric distribution</a></li>
<li class="chapter" data-level="7.12" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#hypergeometric-model"><i class="fa fa-check"></i><b>7.12</b> Hypergeometric model</a></li>
<li class="chapter" data-level="7.13" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#questions-4"><i class="fa fa-check"></i><b>7.13</b> Questions</a></li>
<li class="chapter" data-level="7.14" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#exercises-5"><i class="fa fa-check"></i><b>7.14</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html"><i class="fa fa-check"></i><b>8</b> Poisson and Exponential Models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#objective-3"><i class="fa fa-check"></i><b>8.1</b> Objective</a></li>
<li class="chapter" data-level="8.2" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#discrete-probability-models-1"><i class="fa fa-check"></i><b>8.2</b> Discrete probability models</a></li>
<li class="chapter" data-level="8.3" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#poissson-experiment"><i class="fa fa-check"></i><b>8.3</b> Poissson experiment</a></li>
<li class="chapter" data-level="8.4" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#poisson-probability-mass-function"><i class="fa fa-check"></i><b>8.4</b> Poisson probability mass function</a></li>
<li class="chapter" data-level="8.5" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#continuous-probability-models"><i class="fa fa-check"></i><b>8.5</b> Continuous probability models</a></li>
<li class="chapter" data-level="8.6" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-process"><i class="fa fa-check"></i><b>8.6</b> Exponential process</a></li>
<li class="chapter" data-level="8.7" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-probability-density"><i class="fa fa-check"></i><b>8.7</b> Exponential probability density</a></li>
<li class="chapter" data-level="8.8" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-distribution"><i class="fa fa-check"></i><b>8.8</b> Exponential Distribution</a></li>
<li class="chapter" data-level="8.9" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#questions-5"><i class="fa fa-check"></i><b>8.9</b> Questions</a></li>
<li class="chapter" data-level="8.10" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exercises-6"><i class="fa fa-check"></i><b>8.10</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="normal-distribution.html"><a href="normal-distribution.html"><i class="fa fa-check"></i><b>9</b> Normal Distribution</a>
<ul>
<li class="chapter" data-level="9.1" data-path="normal-distribution.html"><a href="normal-distribution.html#objective-4"><i class="fa fa-check"></i><b>9.1</b> Objective</a></li>
<li class="chapter" data-level="9.2" data-path="normal-distribution.html"><a href="normal-distribution.html#history"><i class="fa fa-check"></i><b>9.2</b> History</a></li>
<li class="chapter" data-level="9.3" data-path="normal-distribution.html"><a href="normal-distribution.html#normal-density"><i class="fa fa-check"></i><b>9.3</b> normal density</a></li>
<li class="chapter" data-level="9.4" data-path="normal-distribution.html"><a href="normal-distribution.html#definition"><i class="fa fa-check"></i><b>9.4</b> Definition</a></li>
<li class="chapter" data-level="9.5" data-path="normal-distribution.html"><a href="normal-distribution.html#probability-distribution-2"><i class="fa fa-check"></i><b>9.5</b> Probability distribution</a></li>
<li class="chapter" data-level="9.6" data-path="normal-distribution.html"><a href="normal-distribution.html#standard-normal-density"><i class="fa fa-check"></i><b>9.6</b> Standard normal density</a></li>
<li class="chapter" data-level="9.7" data-path="normal-distribution.html"><a href="normal-distribution.html#standard-distribution"><i class="fa fa-check"></i><b>9.7</b> Standard distribution</a></li>
<li class="chapter" data-level="9.8" data-path="normal-distribution.html"><a href="normal-distribution.html#standardization"><i class="fa fa-check"></i><b>9.8</b> Standardization</a></li>
<li class="chapter" data-level="9.9" data-path="normal-distribution.html"><a href="normal-distribution.html#summary-of-probability-models"><i class="fa fa-check"></i><b>9.9</b> Summary of probability models</a></li>
<li class="chapter" data-level="9.10" data-path="normal-distribution.html"><a href="normal-distribution.html#python-functions-of-probability-models"><i class="fa fa-check"></i><b>9.10</b> Python functions of probability models</a></li>
<li class="chapter" data-level="9.11" data-path="normal-distribution.html"><a href="normal-distribution.html#questions-6"><i class="fa fa-check"></i><b>9.11</b> Questions</a></li>
<li class="chapter" data-level="9.12" data-path="normal-distribution.html"><a href="normal-distribution.html#exercises-7"><i class="fa fa-check"></i><b>9.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="sampling-distributions.html"><a href="sampling-distributions.html"><i class="fa fa-check"></i><b>10</b> Sampling distributions</a>
<ul>
<li class="chapter" data-level="10.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#objective-5"><i class="fa fa-check"></i><b>10.1</b> Objective</a></li>
<li class="chapter" data-level="10.2" data-path="sampling-distributions.html"><a href="sampling-distributions.html#random-sample"><i class="fa fa-check"></i><b>10.2</b> Random sample</a></li>
<li class="chapter" data-level="10.3" data-path="sampling-distributions.html"><a href="sampling-distributions.html#calculation-of-probabilities"><i class="fa fa-check"></i><b>10.3</b> Calculation of probabilities</a></li>
<li class="chapter" data-level="10.4" data-path="sampling-distributions.html"><a href="sampling-distributions.html#parameter-estimation"><i class="fa fa-check"></i><b>10.4</b> Parameter estimation</a></li>
<li class="chapter" data-level="10.5" data-path="sampling-distributions.html"><a href="sampling-distributions.html#law-of-large-numbers"><i class="fa fa-check"></i><b>10.5</b> Law of large numbers</a></li>
<li class="chapter" data-level="10.6" data-path="sampling-distributions.html"><a href="sampling-distributions.html#inference"><i class="fa fa-check"></i><b>10.6</b> Inference</a></li>
<li class="chapter" data-level="10.7" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-mean"><i class="fa fa-check"></i><b>10.7</b> Sample mean</a></li>
<li class="chapter" data-level="10.8" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-sum"><i class="fa fa-check"></i><b>10.8</b> Sample sum</a></li>
<li class="chapter" data-level="10.9" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-variance-1"><i class="fa fa-check"></i><b>10.9</b> Sample variance</a></li>
<li class="chapter" data-level="10.10" data-path="sampling-distributions.html"><a href="sampling-distributions.html#probabilities-of-the-sample-variance"><i class="fa fa-check"></i><b>10.10</b> Probabilities of the sample variance</a></li>
<li class="chapter" data-level="10.11" data-path="sampling-distributions.html"><a href="sampling-distributions.html#chi2-statistic"><i class="fa fa-check"></i><b>10.11</b> <span class="math inline">\(\chi^2\)</span>-statistic</a></li>
<li class="chapter" data-level="10.12" data-path="sampling-distributions.html"><a href="sampling-distributions.html#questions-7"><i class="fa fa-check"></i><b>10.12</b> Questions</a></li>
<li class="chapter" data-level="10.13" data-path="sampling-distributions.html"><a href="sampling-distributions.html#exercises-8"><i class="fa fa-check"></i><b>10.13</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html"><i class="fa fa-check"></i><b>11</b> Central limit theorem</a>
<ul>
<li class="chapter" data-level="11.1" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#objective-6"><i class="fa fa-check"></i><b>11.1</b> Objective</a></li>
<li class="chapter" data-level="11.2" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#margin-of-error"><i class="fa fa-check"></i><b>11.2</b> Margin of error</a></li>
<li class="chapter" data-level="11.3" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#averages-of-normal-variables"><i class="fa fa-check"></i><b>11.3</b> Averages of normal variables</a></li>
<li class="chapter" data-level="11.4" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#central-limit-theorem-1"><i class="fa fa-check"></i><b>11.4</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="11.5" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#sample-sum-and-clt"><i class="fa fa-check"></i><b>11.5</b> Sample sum and CLT</a></li>
<li class="chapter" data-level="11.6" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#questions-8"><i class="fa fa-check"></i><b>11.6</b> Questions</a></li>
<li class="chapter" data-level="11.7" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#exercises-9"><i class="fa fa-check"></i><b>11.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html"><i class="fa fa-check"></i><b>12</b> Maximum likelihood</a>
<ul>
<li class="chapter" data-level="12.1" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#objective-7"><i class="fa fa-check"></i><b>12.1</b> Objective</a></li>
<li class="chapter" data-level="12.2" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#statistic"><i class="fa fa-check"></i><b>12.2</b> Statistic</a></li>
<li class="chapter" data-level="12.3" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#properties"><i class="fa fa-check"></i><b>12.3</b> Properties</a></li>
<li class="chapter" data-level="12.4" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#maximum-likelihood-1"><i class="fa fa-check"></i><b>12.4</b> Maximum likelihood</a></li>
<li class="chapter" data-level="12.5" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#maximum-likelihood-2"><i class="fa fa-check"></i><b>12.5</b> Maximum likelihood</a></li>
<li class="chapter" data-level="12.6" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#questions-9"><i class="fa fa-check"></i><b>12.6</b> Questions</a></li>
<li class="chapter" data-level="12.7" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#exercises-10"><i class="fa fa-check"></i><b>12.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="interval-estimation.html"><a href="interval-estimation.html"><i class="fa fa-check"></i><b>13</b> Interval estimation</a>
<ul>
<li class="chapter" data-level="13.1" data-path="interval-estimation.html"><a href="interval-estimation.html#objective-8"><i class="fa fa-check"></i><b>13.1</b> Objective</a></li>
<li class="chapter" data-level="13.2" data-path="interval-estimation.html"><a href="interval-estimation.html#estimation-of-the-mean"><i class="fa fa-check"></i><b>13.2</b> Estimation of the mean</a></li>
<li class="chapter" data-level="13.3" data-path="interval-estimation.html"><a href="interval-estimation.html#margin-of-error-1"><i class="fa fa-check"></i><b>13.3</b> Margin of error</a></li>
<li class="chapter" data-level="13.4" data-path="interval-estimation.html"><a href="interval-estimation.html#interval-estimation-for-the-mean"><i class="fa fa-check"></i><b>13.4</b> Interval estimation for the mean</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="interval-estimation.html"><a href="interval-estimation.html#case-1-known-variance"><i class="fa fa-check"></i><b>13.4.1</b> Case 1 (known variance)</a></li>
<li class="chapter" data-level="13.4.2" data-path="interval-estimation.html"><a href="interval-estimation.html#confidence-level"><i class="fa fa-check"></i><b>13.4.2</b> Confidence level</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="interval-estimation.html"><a href="interval-estimation.html#marging-of-error-for-unkown-variance"><i class="fa fa-check"></i><b>13.5</b> Marging of error for unkown variance</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="interval-estimation.html"><a href="interval-estimation.html#theorem-t-statistic"><i class="fa fa-check"></i><b>13.5.1</b> Theorem (T-statistic)</a></li>
<li class="chapter" data-level="13.5.2" data-path="interval-estimation.html"><a href="interval-estimation.html#case-2-unknown-variance"><i class="fa fa-check"></i><b>13.5.2</b> Case 2 (unknown variance)</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="interval-estimation.html"><a href="interval-estimation.html#estimation-of-proportions"><i class="fa fa-check"></i><b>13.6</b> Estimation of proportions</a>
<ul>
<li class="chapter" data-level="13.6.1" data-path="interval-estimation.html"><a href="interval-estimation.html#case-3-proportions"><i class="fa fa-check"></i><b>13.6.1</b> Case 3 (proportions)</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="interval-estimation.html"><a href="interval-estimation.html#estimation-of-the-variance"><i class="fa fa-check"></i><b>13.7</b> Estimation of the variance</a></li>
<li class="chapter" data-level="13.8" data-path="interval-estimation.html"><a href="interval-estimation.html#confidence-interval-for-the-variance"><i class="fa fa-check"></i><b>13.8</b> Confidence interval for the variance</a>
<ul>
<li class="chapter" data-level="13.8.1" data-path="interval-estimation.html"><a href="interval-estimation.html#theorem-chi2"><i class="fa fa-check"></i><b>13.8.1</b> Theorem (<span class="math inline">\(\chi^2\)</span>):</a></li>
<li class="chapter" data-level="13.8.2" data-path="interval-estimation.html"><a href="interval-estimation.html#confidence-interval-for-the-variance-1"><i class="fa fa-check"></i><b>13.8.2</b> Confidence interval for the variance</a></li>
<li class="chapter" data-level="13.8.3" data-path="interval-estimation.html"><a href="interval-estimation.html#case-4-variance"><i class="fa fa-check"></i><b>13.8.3</b> Case 4 (variance)</a></li>
</ul></li>
<li class="chapter" data-level="13.9" data-path="interval-estimation.html"><a href="interval-estimation.html#questions-10"><i class="fa fa-check"></i><b>13.9</b> Questions</a></li>
<li class="chapter" data-level="13.10" data-path="interval-estimation.html"><a href="interval-estimation.html#exercises-11"><i class="fa fa-check"></i><b>13.10</b> Exercises</a></li>
<li class="chapter" data-level="13.11" data-path="interval-estimation.html"><a href="interval-estimation.html#practice-3"><i class="fa fa-check"></i><b>13.11</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>14</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="14.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#objective-9"><i class="fa fa-check"></i><b>14.1</b> Objective</a></li>
<li class="chapter" data-level="14.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis"><i class="fa fa-check"></i><b>14.2</b> Hypothesis</a></li>
<li class="chapter" data-level="14.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-1"><i class="fa fa-check"></i><b>14.3</b> Hypothesis testing</a></li>
<li class="chapter" data-level="14.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#case-1-known-variance-1"><i class="fa fa-check"></i><b>14.4</b> Case 1 (known variance)</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-with-a-confidence-interval"><i class="fa fa-check"></i><b>14.4.1</b> Hypothesis test with a confidence interval</a></li>
<li class="chapter" data-level="14.4.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-with-acceptancerejection-zones"><i class="fa fa-check"></i><b>14.4.2</b> Hypothesis test with acceptance/rejection zones</a></li>
<li class="chapter" data-level="14.4.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-with-a-p-value"><i class="fa fa-check"></i><b>14.4.3</b> Hypothesis test with a P-value</a></li>
<li class="chapter" data-level="14.4.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#upper-tail-hypothesis"><i class="fa fa-check"></i><b>14.4.4</b> Upper tail hypothesis</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#case-2-unknown-variance-1"><i class="fa fa-check"></i><b>14.5</b> Case 2 (unknown variance)</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#lower-tail-hypothesis"><i class="fa fa-check"></i><b>14.5.1</b> Lower tail hypothesis</a></li>
<li class="chapter" data-level="14.5.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-with-large-n-and-any-distribution"><i class="fa fa-check"></i><b>14.5.2</b> Hypothesis testing with large n and any distribution</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#case-3-proportions-1"><i class="fa fa-check"></i><b>14.6</b> Case 3 (proportions)</a></li>
<li class="chapter" data-level="14.7" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#case-4-variances"><i class="fa fa-check"></i><b>14.7</b> Case 4 (variances)</a></li>
<li class="chapter" data-level="14.8" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#errors-in-hypothesis-testing"><i class="fa fa-check"></i><b>14.8</b> Errors in hypothesis testing</a></li>
<li class="chapter" data-level="14.9" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#exercises-12"><i class="fa fa-check"></i><b>14.9</b> Exercises</a></li>
<li class="chapter" data-level="14.10" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#practice-4"><i class="fa fa-check"></i><b>14.10</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="contingency-tables.html"><a href="contingency-tables.html"><i class="fa fa-check"></i><b>15</b> Contingency tables</a>
<ul>
<li class="chapter" data-level="15.1" data-path="contingency-tables.html"><a href="contingency-tables.html#objective-10"><i class="fa fa-check"></i><b>15.1</b> Objective</a></li>
<li class="chapter" data-level="15.2" data-path="contingency-tables.html"><a href="contingency-tables.html#difference-between-proportions"><i class="fa fa-check"></i><b>15.2</b> Difference between proportions</a></li>
<li class="chapter" data-level="15.3" data-path="contingency-tables.html"><a href="contingency-tables.html#difference-between-proportions-1"><i class="fa fa-check"></i><b>15.3</b> Difference between proportions</a></li>
<li class="chapter" data-level="15.4" data-path="contingency-tables.html"><a href="contingency-tables.html#contingency-table-of-conditional-probabilities"><i class="fa fa-check"></i><b>15.4</b> Contingency table of conditional probabilities</a></li>
<li class="chapter" data-level="15.5" data-path="contingency-tables.html"><a href="contingency-tables.html#test-for-the-difference-between-proportions"><i class="fa fa-check"></i><b>15.5</b> Test for the difference between proportions</a></li>
<li class="chapter" data-level="15.6" data-path="contingency-tables.html"><a href="contingency-tables.html#chi2-test"><i class="fa fa-check"></i><b>15.6</b> <span class="math inline">\(\chi^2\)</span> test</a></li>
<li class="chapter" data-level="15.7" data-path="contingency-tables.html"><a href="contingency-tables.html#fishers-exact-test"><i class="fa fa-check"></i><b>15.7</b> Fisher’s exact test</a></li>
<li class="chapter" data-level="15.8" data-path="contingency-tables.html"><a href="contingency-tables.html#hypergeometric-distribution"><i class="fa fa-check"></i><b>15.8</b> Hypergeometric distribution</a></li>
<li class="chapter" data-level="15.9" data-path="contingency-tables.html"><a href="contingency-tables.html#difference-between-several-proportions"><i class="fa fa-check"></i><b>15.9</b> Difference between several proportions</a></li>
<li class="chapter" data-level="15.10" data-path="contingency-tables.html"><a href="contingency-tables.html#questions-11"><i class="fa fa-check"></i><b>15.10</b> Questions</a></li>
<li class="chapter" data-level="15.11" data-path="contingency-tables.html"><a href="contingency-tables.html#practice-5"><i class="fa fa-check"></i><b>15.11</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html"><i class="fa fa-check"></i><b>16</b> Mean differences between two samples</a>
<ul>
<li class="chapter" data-level="16.1" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#objective-11"><i class="fa fa-check"></i><b>16.1</b> Objective</a></li>
<li class="chapter" data-level="16.2" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#differece-in-means-between-two-groups"><i class="fa fa-check"></i><b>16.2</b> Differece in means between two groups</a></li>
<li class="chapter" data-level="16.3" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#data-1"><i class="fa fa-check"></i><b>16.3</b> Data</a></li>
<li class="chapter" data-level="16.4" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#difference-between-means"><i class="fa fa-check"></i><b>16.4</b> Difference between means</a></li>
<li class="chapter" data-level="16.5" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#hypothesis-test"><i class="fa fa-check"></i><b>16.5</b> Hypothesis test</a></li>
<li class="chapter" data-level="16.6" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#estiamtor-of-the-mean-difference"><i class="fa fa-check"></i><b>16.6</b> Estiamtor of the mean difference</a></li>
<li class="chapter" data-level="16.7" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#standardized-error"><i class="fa fa-check"></i><b>16.7</b> Standardized error</a></li>
<li class="chapter" data-level="16.8" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#standardized-error-for-the-null"><i class="fa fa-check"></i><b>16.8</b> Standardized error for the null</a></li>
<li class="chapter" data-level="16.9" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#mean-differences-when-n-is-small"><i class="fa fa-check"></i><b>16.9</b> Mean differences when <span class="math inline">\(n\)</span> is small</a></li>
<li class="chapter" data-level="16.10" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#data-2"><i class="fa fa-check"></i><b>16.10</b> Data</a></li>
<li class="chapter" data-level="16.11" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#difference-between-means-1"><i class="fa fa-check"></i><b>16.11</b> Difference between means</a></li>
<li class="chapter" data-level="16.12" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#hypothesis-test-1"><i class="fa fa-check"></i><b>16.12</b> Hypothesis test</a></li>
<li class="chapter" data-level="16.13" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#estimator-of-the-mean-difference"><i class="fa fa-check"></i><b>16.13</b> Estimator of the mean difference</a></li>
<li class="chapter" data-level="16.14" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#standardized-error-for-the-null-1"><i class="fa fa-check"></i><b>16.14</b> Standardized error for the null</a></li>
<li class="chapter" data-level="16.15" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#unequal-variances"><i class="fa fa-check"></i><b>16.15</b> Unequal variances</a></li>
<li class="chapter" data-level="16.16" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#questions-12"><i class="fa fa-check"></i><b>16.16</b> Questions</a></li>
<li class="chapter" data-level="16.17" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#practice-6"><i class="fa fa-check"></i><b>16.17</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html"><i class="fa fa-check"></i><b>17</b> Mean differences across several groups</a>
<ul>
<li class="chapter" data-level="17.1" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#objective-12"><i class="fa fa-check"></i><b>17.1</b> Objective</a></li>
<li class="chapter" data-level="17.2" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#different-means-among-several-conditions"><i class="fa fa-check"></i><b>17.2</b> Different means among several conditions</a></li>
<li class="chapter" data-level="17.3" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#data-3"><i class="fa fa-check"></i><b>17.3</b> Data</a></li>
<li class="chapter" data-level="17.4" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#difference-between-means-2"><i class="fa fa-check"></i><b>17.4</b> Difference between means</a></li>
<li class="chapter" data-level="17.5" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#hypothesis-test-2"><i class="fa fa-check"></i><b>17.5</b> Hypothesis test</a></li>
<li class="chapter" data-level="17.6" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#analysis-of-variance-anova"><i class="fa fa-check"></i><b>17.6</b> Analysis of variance (ANOVA)</a></li>
<li class="chapter" data-level="17.7" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#anova-for-two-groups"><i class="fa fa-check"></i><b>17.7</b> ANOVA for two groups</a></li>
<li class="chapter" data-level="17.8" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#linear-model"><i class="fa fa-check"></i><b>17.8</b> Linear model</a></li>
<li class="chapter" data-level="17.9" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#way-anova"><i class="fa fa-check"></i><b>17.9</b> 2-way ANOVA</a></li>
<li class="chapter" data-level="17.10" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#data-4"><i class="fa fa-check"></i><b>17.10</b> Data</a></li>
<li class="chapter" data-level="17.11" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#modeling-residuals"><i class="fa fa-check"></i><b>17.11</b> Modeling residuals</a></li>
<li class="chapter" data-level="17.12" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#linear-model-1"><i class="fa fa-check"></i><b>17.12</b> Linear model</a></li>
<li class="chapter" data-level="17.13" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#hypothesis-test-3"><i class="fa fa-check"></i><b>17.13</b> Hypothesis test</a></li>
<li class="chapter" data-level="17.14" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#variance-components"><i class="fa fa-check"></i><b>17.14</b> Variance components</a></li>
<li class="chapter" data-level="17.15" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#way-anova-with-interaction"><i class="fa fa-check"></i><b>17.15</b> 2-way ANOVA with interaction</a></li>
<li class="chapter" data-level="17.16" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#linear-model-2"><i class="fa fa-check"></i><b>17.16</b> Linear model</a></li>
<li class="chapter" data-level="17.17" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#hypothesis-test-4"><i class="fa fa-check"></i><b>17.17</b> Hypothesis test</a></li>
<li class="chapter" data-level="17.18" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#variance-components-1"><i class="fa fa-check"></i><b>17.18</b> Variance components</a></li>
<li class="chapter" data-level="17.19" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#questions-13"><i class="fa fa-check"></i><b>17.19</b> Questions</a></li>
<li class="chapter" data-level="17.20" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#practice-7"><i class="fa fa-check"></i><b>17.20</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html"><i class="fa fa-check"></i><b>18</b> Regression and correlation</a>
<ul>
<li class="chapter" data-level="18.1" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#objective-13"><i class="fa fa-check"></i><b>18.1</b> Objective</a></li>
<li class="chapter" data-level="18.2" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#correlations"><i class="fa fa-check"></i><b>18.2</b> Correlations</a></li>
<li class="chapter" data-level="18.3" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#data-5"><i class="fa fa-check"></i><b>18.3</b> Data</a></li>
<li class="chapter" data-level="18.4" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#normal-bivariate"><i class="fa fa-check"></i><b>18.4</b> Normal bivariate</a></li>
<li class="chapter" data-level="18.5" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#estimators"><i class="fa fa-check"></i><b>18.5</b> Estimators</a></li>
<li class="chapter" data-level="18.6" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#correlation-coefficient"><i class="fa fa-check"></i><b>18.6</b> Correlation coefficient</a></li>
<li class="chapter" data-level="18.7" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#hypothesis-contrast"><i class="fa fa-check"></i><b>18.7</b> Hypothesis contrast</a></li>
<li class="chapter" data-level="18.8" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#regression-analysis"><i class="fa fa-check"></i><b>18.8</b> Regression analysis</a></li>
<li class="chapter" data-level="18.9" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#linear-model-3"><i class="fa fa-check"></i><b>18.9</b> Linear model</a></li>
<li class="chapter" data-level="18.10" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#hypothesis-contrast-1"><i class="fa fa-check"></i><b>18.10</b> Hypothesis contrast</a></li>
<li class="chapter" data-level="18.11" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#estimators-1"><i class="fa fa-check"></i><b>18.11</b> Estimators</a></li>
<li class="chapter" data-level="18.12" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#hypothesis-testing-2"><i class="fa fa-check"></i><b>18.12</b> Hypothesis testing</a></li>
<li class="chapter" data-level="18.13" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#stratified-analysis"><i class="fa fa-check"></i><b>18.13</b> Stratified analysis</a></li>
<li class="chapter" data-level="18.14" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#multiple-regression"><i class="fa fa-check"></i><b>18.14</b> Multiple Regression</a></li>
<li class="chapter" data-level="18.15" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#multiple-regression-interaction"><i class="fa fa-check"></i><b>18.15</b> Multiple Regression interaction</a></li>
<li class="chapter" data-level="18.16" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#model-diagnostics"><i class="fa fa-check"></i><b>18.16</b> Model diagnostics</a></li>
<li class="chapter" data-level="18.17" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#questions-14"><i class="fa fa-check"></i><b>18.17</b> Questions</a></li>
<li class="chapter" data-level="18.18" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#practice-8"><i class="fa fa-check"></i><b>18.18</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="group-work-sessions.html"><a href="group-work-sessions.html"><i class="fa fa-check"></i><b>19</b> Group Work sessions</a>
<ul>
<li class="chapter" data-level="19.1" data-path="group-work-sessions.html"><a href="group-work-sessions.html#objectives"><i class="fa fa-check"></i><b>19.1</b> Objectives</a></li>
<li class="chapter" data-level="19.2" data-path="group-work-sessions.html"><a href="group-work-sessions.html#misophonia-dataset"><i class="fa fa-check"></i><b>19.2</b> Misophonia dataset</a></li>
<li class="chapter" data-level="19.3" data-path="group-work-sessions.html"><a href="group-work-sessions.html#group-work-session-1-data-description"><i class="fa fa-check"></i><b>19.3</b> Group Work session 1: Data description</a></li>
<li class="chapter" data-level="19.4" data-path="group-work-sessions.html"><a href="group-work-sessions.html#group-work-session-2-inference"><i class="fa fa-check"></i><b>19.4</b> Group Work session 2: Inference</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="solutions-to-questions.html"><a href="solutions-to-questions.html"><i class="fa fa-check"></i><b>20</b> Solutions to Questions</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Data Analysis</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hypothesis-testing" class="section level1 hasAnchor" number="14">
<h1><span class="header-section-number">Chapter 14</span> Hypothesis testing<a href="hypothesis-testing.html#hypothesis-testing" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="objective-9" class="section level2 hasAnchor" number="14.1">
<h2><span class="header-section-number">14.1</span> Objective<a href="hypothesis-testing.html#objective-9" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this chapter we will study <strong>hypothesis testing</strong> of means and proportions. We will define the null and the alternative hypotheses and how to use data to choose between both.</p>
<p>We will also introduce hypothesis testing of variances. Finally we will describe the errors that are made when hypotheses are tested. These errors are known as false positives and false negatives.</p>
</div>
<div id="hypothesis" class="section level2 hasAnchor" number="14.2">
<h2><span class="header-section-number">14.2</span> Hypothesis<a href="hypothesis-testing.html#hypothesis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>When we perform an experiment, we often want to test whether the changes we make to the experiment have a real effect. We want, for example, to know if we are able to influence the experiment. Or, if we submit the experiment under a new condition, we want to know if that condition affects the results of the experiment. We usually have an idea of what the data should look like when the new conditions are <strong>not present</strong>. Since the results of the experiment are random in any circumstance, how can we tell the difference in the experiment when changing conditions?</p>
<p>The strategy is to formulate a probability model for the experiment and estimate the change in the model <strong>parameters</strong> between conditions. We then use observations from taking random samples of the experiment under the different conditions to assess the change in the parameters and thus provide evidence about the expected change in the experiment.</p>
<p><strong>Examples (Tyres)</strong></p>
<p>The mean life of a standard tyre is <span class="math inline">\(20,000\)</span> km. A tyre manufacturer wants to know if their improved tyres run longer than the standart type. Let’s try to translate their interest into statistical terms. Imagine a random experiment that consists of measuring how long the life of a particular tyre is. Therefore, the manufacturer is interested in knowing if the mean life of a new tyre is more than <span class="math inline">\(20,000\)</span> km.</p>
<p>Let us formulate two dichotomous statements, that is, two mutually exclusive situations:</p>
<ol style="list-style-type: lower-alpha">
<li>The mean life of the new tyre may be <strong>less</strong> than <span class="math inline">\(20,000\)</span> km</li>
<li>The mean life of the new tyre may be <strong>greater</strong> than <span class="math inline">\(20,000\)</span> km</li>
</ol>
<p>This means that only one can be true. The question is then how we can use data to decide between situation a. or situation b.</p>
<p>Note than when running the experiment several times, some tyres will run for more than <span class="math inline">\(20,000\)</span> km and some for less than <span class="math inline">\(20,000\)</span> km. The question is whether <strong>the mean</strong>, as a parameter, is higher than <span class="math inline">\(20,000\)</span> km, not single observations. The statements a. and b. are general statements.</p>
<p>Let’s consider that <span class="math inline">\(\mu\)</span> is the mean of the random variable that measures the life of a new tyre. Therefore, the statements a. and b. can also be written as</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0: \mu \leq 20000\)</span> km</li>
<li><span class="math inline">\(H_1: \mu &gt; 20000\)</span> km</li>
</ol>
<p>Where the statement <span class="math inline">\(H_0\)</span> states that the mean life of the new tyre is not the desired <span class="math inline">\(20,000\)</span> km while statement <span class="math inline">\(H_1\)</span> is the desired case. <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_1\)</span> are called hypotheses.</p>
<p><strong>Definition</strong></p>
<p>In statistics, a statement (conjecture) about the probability function of a random variable is called a <strong>hypothesis</strong>.</p>
<p>The hypothesis is usually written in two dichotomous statements</p>
<ol style="list-style-type: lower-alpha">
<li><p>The <strong>null</strong> hypothesis: <span class="math inline">\(H_0\)</span> when the conjecture is false usually refers to <strong>status quo</strong>. The data may be explained by the satus quo.</p></li>
<li><p>The <strong>alternative</strong> hypothesis: <span class="math inline">\(H_1\)</span> when the conjecture is true usually refers to <strong>research hypothesis</strong>. The data may be explained by the desired alternative.</p></li>
</ol>
<p><strong>Example (Fertilizer)</strong></p>
<p>What are the null and the alternative hypothesis for the following situation?</p>
<p>Fertilizer developers want to test whether their new product has a real effect on the growth of plants.</p>
<p>Being <span class="math inline">\(\mu_0\)</span> the mean growth of the plants <strong>without</strong> fertilizer (known) and <span class="math inline">\(\mu\)</span> the mean growth of the plants with the fertilizer (unknown)</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu \leq \mu_0\)</span> (The fertilizer may do nothing: status quo)</li>
<li><span class="math inline">\(H_1:\mu &gt; \mu_0\)</span> (The fertilizer may have the desired effect: research interest)</li>
</ol>
<p><strong>Example (chemotherapy)</strong></p>
<p>Pharmaceutical companies need to know if a novel chemotherapy can cure 90% of cancer patients.</p>
<p>Being <span class="math inline">\(p_0\)</span> the proportion of patients that are cured <strong>without</strong> the chemotherapy (known) and <span class="math inline">\(p\)</span> the proportion that are cures <strong>with</strong> the chemotherapy (unknown)</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:p \leq p_0\)</span> (The chemotherapy may do nothing: status quo)</li>
<li><span class="math inline">\(H_1: p &gt; p_0\)</span> (The chemotherapy may have the desired effect: research interest)</li>
</ol>
<p>Note that our new improved experiment has the parameter <span class="math inline">\(p\)</span> and we want to know how it compares to the experiment without <strong>any improvement</strong> that has the parameter <span class="math inline">\(p_0\)</span>.</p>
<p>We want to decide between <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_1\)</span>. There are two options:</p>
<ol style="list-style-type: decimal">
<li><p>We <strong>reject</strong> the alternative hypothesis <span class="math inline">\(H_1\)</span>; that is, we accept the null hypothesis <span class="math inline">\(H_0\)</span>.</p></li>
<li><p>We <strong>accept</strong> the alternative hypothesis <span class="math inline">\(H_1\)</span> (our interest); that is, we reject the null hypothesis <span class="math inline">\(H_0\)</span>.</p></li>
</ol>
<p><strong>Example (Microprocessors)</strong></p>
<p>We want to produce computers with a certain type of microprocessor. The design requires that the <strong>mean width</strong> of a microprocessor is about <span class="math inline">\(26\)</span>mm. We buy <span class="math inline">\(8\)</span> microprocessors for prototypes from a manufacturing company that claims that they produce them with <strong>mean</strong> with of <span class="math inline">\(\mu_0=26\)</span>mm. We are not sure and want to decide on whether the microprocessors of the company do measure <strong>on average</strong> <span class="math inline">\(26\)</span>mm or not. We formulate the hypothesis contrast</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu = \mu_0\)</span> (The manufacturer claim: status quo)</li>
<li><span class="math inline">\(H_1:\mu \neq \mu_0\)</span> (Our doubt that the manufacturer is not right: research interest)</li>
</ol>
<p>To decide between <span class="math inline">\(H_0\)</span> or <span class="math inline">\(H_1\)</span>, we measure the width of the purchased sample of <span class="math inline">\(8\)</span> microprocessors</p>
<pre><code>## [1] 26.69284 26.65240 26.02918 26.21622 25.93998 27.10618 27.51114 25.25494</code></pre>
<p>The idea is simple. The average of the sample width is <span class="math inline">\(\bar{x}=26.42536\)</span> which would make us believe that the microprocessors are too thick. But the manufacturer would argue that <span class="math inline">\(\bar{x}\)</span> is the observation of a random variable and that <span class="math inline">\(\bar{x}&gt;26\)</span> is not a sufficient argument that he is not right (<span class="math inline">\(H_0\)</span> is not true) because sometimes <span class="math inline">\(\bar{X}\)</span> would be higher than <span class="math inline">\(26\)</span> and sometimes it will me lower. Being more technical, he asks us to account for the variability of <span class="math inline">\(\bar{X}\)</span> as an estimator of the <span class="math inline">\(\mu_0=26\)</span>. We would then ask ourselves: Is <span class="math inline">\(\bar{x}=26.42536\)</span> what we would typically observe when we estimate <span class="math inline">\(\mu_0=26\)</span> by <span class="math inline">\(\bar{x}\)</span>? or are those <span class="math inline">\(0.42536\)</span> too high to believe that the microprocessors are build with of expected value of <span class="math inline">\(26\)</span>mm?</p>
<p>To test these ideas, we need a decision process that we describe now.</p>
</div>
<div id="hypothesis-testing-1" class="section level2 hasAnchor" number="14.3">
<h2><span class="header-section-number">14.3</span> Hypothesis testing<a href="hypothesis-testing.html#hypothesis-testing-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let us summarize the different cases, ways and types for testing hypothesis. We will then discuss each case with a particular example.</p>
<p>Hypotheses can be tested, or decided, using confidence intervals. Therefore, we are going to test hypothesis in the four <strong>cases</strong> that we saw for confidence intervals, namely:</p>
<ul>
<li><p><strong>Case 1</strong>: Hypothesis test for the mean <span class="math inline">\(\mu\)</span>, when <span class="math inline">\(X \rightarrow N(\mu, \sigma^2)\)</span> and we know <span class="math inline">\(\sigma\)</span></p></li>
<li><p><strong>Case 2</strong>: Hypothesis test for the mean <span class="math inline">\(\mu\)</span>, when <span class="math inline">\(X \rightarrow N(\mu, \sigma^2)\)</span> and we do not know <span class="math inline">\(\sigma\)</span></p></li>
<li><p><strong>Case 3</strong>: Hypothesis test for the proportion <span class="math inline">\(p\)</span> when <span class="math inline">\(X \rightarrow Bernoulli(p)\)</span> and both <span class="math inline">\(np\)</span> and <span class="math inline">\(n(1-p)\)</span> <span class="math inline">\(&gt; 5\)</span>.</p></li>
<li><p><strong>Case 4</strong>: Hypothesis test for the variance <span class="math inline">\(\sigma^2\)</span>, when <span class="math inline">\(X \rightarrow N(\mu, \sigma^2)\)</span></p></li>
</ul>
<p>There are three <strong>ways</strong> to test the hypotheses:</p>
<ol style="list-style-type: decimal">
<li>Using <strong>confidence intervals</strong></li>
<li>using a <strong>rejection zone</strong></li>
<li>using a <span class="math inline">\(p-value\)</span>.</li>
</ol>
<p>All three options are equivalent. Finally, there are three <strong>types</strong> of hypothesis that we can test:</p>
<ol style="list-style-type: decimal">
<li><strong>Two</strong> tailed</li>
<li><strong>Upper</strong> tailed</li>
<li><strong>Lower</strong> tailed</li>
</ol>
</div>
<div id="case-1-known-variance-1" class="section level2 hasAnchor" number="14.4">
<h2><span class="header-section-number">14.4</span> Case 1 (known variance)<a href="hypothesis-testing.html#case-1-known-variance-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A <strong>tow tailed</strong> hypothesis contrast is of the form</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu = \mu_0\)</span> (status quo)</li>
<li><span class="math inline">\(H_1:\mu \neq \mu_0\)</span> (research interest)</li>
</ol>
<p>This is called two tailed because the alternative hypothesis <span class="math inline">\(H_1\)</span> requires that the mean <span class="math inline">\(\mu\)</span> is either lower or higher than <span class="math inline">\(\mu_0\)</span>. This hypothesis can be tested in different cases. The <strong>case 1</strong> is when</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X\)</span> is a normal variable, and</li>
<li>we <strong>know</strong> the value of <span class="math inline">\(\sigma^2\)</span></li>
</ol>
<div id="hypothesis-test-with-a-confidence-interval" class="section level3 hasAnchor" number="14.4.1">
<h3><span class="header-section-number">14.4.1</span> Hypothesis test with a confidence interval<a href="hypothesis-testing.html#hypothesis-test-with-a-confidence-interval" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For <strong>case 1</strong> the confidence interval at <span class="math inline">\(95\%\)</span> is</p>
<p><span class="math display">\[(l,u)=(\bar{x}-z_{0.025} \frac{\sigma}{\sqrt{n}}, \bar{x}+z_{0.025} \frac{\sigma}{\sqrt{n}})\]</span></p>
<p><strong>Testing Criteria:</strong></p>
<ul>
<li>If the confidence interval <strong>contains</strong> the null hypothesis</li>
</ul>
<p><span class="math display">\[\mu_0\in (l,u)\]</span> then we <strong>accept</strong> <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence.</p>
<ul>
<li>If the confidence interval does <strong>not contain</strong> the null hypothesis<span class="math display">\[\mu_0\notin (l,u)\]</span> then we <strong>reject</strong> <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence.</li>
</ul>
<p><strong>Example (Microprocessors)</strong></p>
<p>We want to know whether the microprocessors on average <span class="math inline">\(26\)</span>mm or not. Therefore, we test the following hypotheses</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu = 26\)</span> (The microprocessors <strong>may</strong> have the width that the manufacturer claim: status quo)</li>
<li><span class="math inline">\(H_1:\mu \neq 26\)</span> (The microprocessors <strong>may not</strong> have the width that the manufacturer claim: research interest)</li>
</ol>
<p>Since we do no know which one is true, let’s start by estimating the mean of our sample (<span class="math inline">\(\mu\)</span>). We then use <span class="math inline">\(\bar{x}=\hat{\mu}\)</span>. We do this as before, and consider <strong>case 1</strong> where the model of the widths are normal</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X \rightarrow N(\mu=26, \sigma^2=0.7^2)\)</span></li>
<li>and, somehow we know <span class="math inline">\(\sigma^2=0.7^2\)</span> (perhaps given by the manufacturer)</li>
</ol>
<p>The confidence interval for the mean of our sample <span class="math inline">\(\mu\)</span> is</p>
<p><span class="math display">\[(l,u)=(\bar{x}-z_{0.025} \frac{\sigma}{\sqrt{n}}, \bar{x}+z_{0.025} \frac{\sigma}{\sqrt{n}})= (25.94, 26.91)\]</span>
The confidence interval tells us that we trust with <span class="math inline">\(95\%\)</span> confidence that the true width <span class="math inline">\(\mu\)</span> is in the interval. We don’t know the true value of <span class="math inline">\(\mu\)</span> but we see that <span class="math inline">\(\mu=26\)</span> mm could be it. Since the interval caught <span class="math inline">\(\mu_0\)</span> (the manufacturer’s claim)</p>
<p><span class="math display">\[\mu_0\in (25.94, 26.91)\]</span></p>
<p>our conclusion is to accept that <span class="math inline">\(H_0\)</span> could have produced our <strong>observed interval</strong>. We also say that that the data supports the manufacturer’s claim. More technically, we say that we <strong>do not reject</strong> <span class="math inline">\(H_0\)</span>.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-99-1.png" width="672" /></p>
</div>
<div id="hypothesis-test-with-acceptancerejection-zones" class="section level3 hasAnchor" number="14.4.2">
<h3><span class="header-section-number">14.4.2</span> Hypothesis test with acceptance/rejection zones<a href="hypothesis-testing.html#hypothesis-test-with-acceptancerejection-zones" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>An equivalent way to test the hypothesis is to see if our set of observations are either common or rare <strong>if</strong> we assume that the <strong>null hypothesis is true</strong>. Let’s remember the hypothesis contrast</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu = \mu_0\)</span> (status quo)</li>
<li><span class="math inline">\(H_1:\mu \neq \mu_0\)</span> (research interest)</li>
</ol>
<p>To test the hypothesis with a <strong>rejection zone</strong> we compute the standardized statistic</p>
<p><span class="math display">\[Z=\frac{\bar{X}-\mu_0}{\frac{\sigma}{\sqrt{n}}}\]</span>
when the null hypothesis is true. Note that we are standardizing with <span class="math inline">\(\mu_0\)</span> (the null hypothesis). We then see if the observed value of <span class="math inline">\(Z\)</span> is within the interval</p>
<p><span class="math display">\[(-z_{0.025}, z_{0.025})\]</span>
Remember that this interval defines the most common values of <span class="math inline">\(Z\)</span> since <span class="math display">\[P(-z_{0.025} \leq Z \leq z_{0.025})=0.95\]</span></p>
<p>The interval <span class="math inline">\((-z_{0.025}, z_{0.025})\)</span> is called <strong>acceptance interval</strong> of <span class="math inline">\(H_0\)</span> at <span class="math inline">\(95\%\)</span> confidence level.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-100-1.png" width="672" /></p>
<p><strong>Testing criteria:</strong></p>
<ul>
<li>If the observed statistics <span class="math inline">\(z_{obs}\)</span> under the null hypothesis <strong>is</strong> in the acceptance region</li>
</ul>
<p><span class="math display">\[z_{obs}=\frac{\bar{x}-\mu_0}{\frac{\sigma}{\sqrt{n}}} \in (-z_{0.025}, z_{0.025})\]</span></p>
<p>then we <strong>accept</strong> <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence.</p>
<ul>
<li>If the observed statistics <span class="math inline">\(z_{obs}\)</span> under the null hypothesis <strong>is not</strong> in the acceptance region</li>
</ul>
<p><span class="math display">\[z_{obs} \notin (-z_{0.025}, z_{0.025})\]</span> then we <strong>reject</strong> <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence.</p>
<p>The region <span class="math inline">\((-z_{0.025}] \cup[z_{0.025})\)</span> is called the <strong>rejection zone</strong>.</p>
<p><strong>Example (Microprocessors)</strong></p>
<p>We want to test whether the manufacturer of microprocessors produce them with mean <span class="math inline">\(\mu_0=26\)</span>. Let’s take the point of view of the manufacturer and ask whether the observation <span class="math inline">\(\bar{x}=26.42536\)</span> is an expected average of a sample of <span class="math inline">\(8\)</span> microprocessors when the expected value of the with of a microprocessor is <span class="math inline">\(\mu=26\)</span>. If <span class="math inline">\(H_0\)</span> is true then <span class="math inline">\(\bar{X}\)</span> is an estimator of <span class="math inline">\(\mu_0\)</span> and therefore <span class="math inline">\(Z\)</span></p>
<p><span class="math display">\[Z=\frac{\bar{X}-26}{\frac{0.7}{\sqrt{8}}}  \rightarrow N(0,1)\]</span></p>
<p>is <strong>the standardized error</strong> that we make when we estimate <span class="math inline">\(\mu_0\)</span> with <span class="math inline">\(\bar{X}\)</span>, as the manufacturer claims. Because we are in <strong>case 1</strong>, <span class="math inline">\(Z\)</span> is standard normal
Since</p>
<p><span class="math display">\[\bar{X} \rightarrow N(26, \frac{0.7^2}{8})\]</span></p>
<p>For <strong>our data</strong> the standardized <strong>observed error</strong> is in the acceptance region</p>
<p><span class="math display">\[z_{obs}=\frac{26.42536-26}{\frac{0.7}{\sqrt{8}}}=1.7187 \in (-z_{0.025}, z_{0.025})\]</span>
Think of this regions as a region of tolerance for the error. Because our observation is within then everything is ok for the manufacturer. Had it not, we would have had have enough evidence to distrust the manufacturer’s claim. We conclude that our observed average is a typical observation of <span class="math inline">\(\bar{x}\)</span> when the null hypothesis <span class="math inline">\(\mu_0\)</span> is true. Therefore, we again accept that the data is consistent with the manufacturer’s claim. We also say that we <strong>do not reject</strong> <span class="math inline">\(H_0\)</span>.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-101-1.png" width="672" /></p>
</div>
<div id="hypothesis-test-with-a-p-value" class="section level3 hasAnchor" number="14.4.3">
<h3><span class="header-section-number">14.4.3</span> Hypothesis test with a P-value<a href="hypothesis-testing.html#hypothesis-test-with-a-p-value" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can also contrast the <strong>two tail</strong> hypothesis by calculating the probability that the average of another sample from the null hypothesis will be even rarer than the average we just observed. Because we are in <strong>case 1</strong>, We know that the standardized statistics <span class="math inline">\(Z\)</span> is standard normal variable then we define the <span class="math inline">\(pvalue\)</span> as</p>
<p><span class="math display">\[pvalue = P(Z \leq -z_{obs}) + P(z_{obs} \geq Z) = 2 (1-\phi(|z_{obs}|))\]</span></p>
<p>That is the probability that when we take another sample of the status quo of the same size, we are able to obtain an even rarer observation. If our observation is rare for the status quo then this value will be small.</p>
<p><strong>Testing criteria:</strong></p>
<ul>
<li>If the observed <span class="math inline">\(pvalue\)</span> is</li>
</ul>
<p><span class="math display">\[pvalue \geq \alpha =1-0.95=0.05\]</span></p>
<p>then we <strong>accept</strong> the status quo <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence.</p>
<ul>
<li>If the observed <span class="math inline">\(pvalue\)</span> is</li>
</ul>
<p><span class="math display">\[pvalue &lt; \alpha =1-0.95=0.05\]</span>
then we <strong>reject</strong> <span class="math inline">\(H_0\)</span> and accept our research question with <span class="math inline">\(95\%\)</span> confidence.</p>
<p><span class="math inline">\(\alpha\)</span> is the significance level. It gives us how much of the distribution we are leaving out, and defines the region that we consider as rare observations.</p>
<p>Remember: We always trust our data. If the null hypothesis says that our data is a <strong>rare</strong> observation we then distrust the null hypothesis, and reject it.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-102-1.png" width="672" /></p>
<p><strong>Example (Microprocessors)</strong></p>
<p>For our data the observed statistic <span class="math inline">\(z_{obs}=1.718714\)</span> and its <strong>p-value</strong> is then</p>
<p><span class="math display">\[pvalue=2 (1-\phi(1.718714))=0.08567\]</span>
Python: <code>2*(1- norm.cdf(1.718714))</code></p>
<p>We conclude that if we purchase other <span class="math inline">\(8\)</span> microprocessors, it is likely, within <span class="math inline">\(8\%\)</span> of the purchases, that we get a higher average width than the one we got; if the manufacturer produces mean widths at <span class="math inline">\(26\)</span>mm. The null hypothesis can then tolerate the observed error with <span class="math inline">\(95\%\)</span> confidence. We, therefore, accept that the status quo could have produced our data and conclude again that the data is consistent with the manufacturer’s claim.</p>
<p>In Python the entire hypothesis testing can be performed with the function ztest from the library bioinfokit (that needs to be previously installed)</p>
<pre echo="FALSE," warning="FALSE," message="FALSE"><code># https://pypi.org/project/bioinfokit/

!pip install bioinfokit
from bioinfokit.analys import stat
import pandas as pd

data = {&#39;x&#39;: [26.69284, 26.65240, 26.02918, 26.21622, 
              25.93998, 27.10618, 27.51114, 25.25494]}

df = pd.DataFrame(data)

res = stat()
res.ztest(df=df, x=&#39;x&#39;, mu=26, x_std=0.7, test_type=1)
print(res.summary)</code></pre>
<pre echo="FALSE," warning="FALSE," message="FALSE"><code>One Sample Z-test 

------------------  ----------
Sample size          8
Mean                26.42536
Z value              1.71871
p value (one-tail)   0.0428332
p value (two-tail)   0.0856665
Lower 95.0%         25.94029
Upper 95.0%         26.91043
------------------  ----------</code></pre>
</div>
<div id="upper-tail-hypothesis" class="section level3 hasAnchor" number="14.4.4">
<h3><span class="header-section-number">14.4.4</span> Upper tail hypothesis<a href="hypothesis-testing.html#upper-tail-hypothesis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We may be interested in only testing for the fact that our experiment’s mean has a higher mean than the null’s mean.</p>
<p>Upper-tailed test:</p>
<ul>
<li><span class="math inline">\(H_0:\mu \leq 26\)</span> (<strong>at most</strong> microprocessors have this mean width)</li>
<li><span class="math inline">\(H_1:\mu &gt; 26\)</span> (microprocessors have <strong>higher</strong> mean width)</li>
</ul>
<p>Perhaps, our design needs an upper limit to the with that the microprocessors can have, such that if it is not stisfy we may look for another provider.</p>
<p>This called <strong>upper-tailed</strong> because the alternative hypothesis <span class="math inline">\(H_1\)</span> requires that the mean <span class="math inline">\(\mu\)</span> is <strong>higher</strong> than <span class="math inline">\(\mu_0\)</span>. This hypothesis can be tested in different cases. The <strong>case 1</strong> is when</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X\)</span> is a normal variable, and</li>
<li>we know the value of <span class="math inline">\(\sigma\)</span></li>
</ol>
<p><strong>Testing criteria:</strong></p>
<ol style="list-style-type: decimal">
<li><em>Confidence interval:</em> If the <strong>upper-tailed</strong> confidence interval <strong>contains</strong> the null hypothesis</li>
</ol>
<p><span class="math display">\[\mu_0\in (l,u)=(\bar{x}-z_{0.05} \frac{\sigma}{\sqrt{n}}, \infty)\]</span>
where <span class="math inline">\(z_{0.05}=\phi^{-1}(0.95)=\)</span><code>norm.ppf(0.95)</code>, then we <strong>accept</strong> <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence. Note that this test is from the point of view of the <strong>data</strong>, we are not centering the confidence interval around <span class="math inline">\(\bar{x}\)</span>, instead we are leaving all the <span class="math inline">\(5\%\)</span> of the rare cases to the left of the average. We are therefore asking if the null hypothesis is lower than the average.</p>
<ol start="2" style="list-style-type: decimal">
<li><em>Rejection/acceptance region:</em> If the observed statistics <span class="math inline">\(z_{obs}\)</span> under the null hypothesis <strong>is</strong> in the acceptance region</li>
</ol>
<p><span class="math display">\[z_{obs}=\frac{\bar{x}-\mu_0}{\frac{\sigma}{\sqrt{n}}} \in (-\infty, z_{0.05})\]</span></p>
<p>then we <strong>accept</strong> <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence. Note that this test is from the point of view of the <strong>null hypothesis</strong>. We are leaving all the <span class="math inline">\(5\%\)</span> of the rare averages to the right of the null hypothesis and therefore ask if the average is higher than the null hypothesis.</p>
<ol start="3" style="list-style-type: decimal">
<li><span class="math inline">\(pvalue\)</span>: If the observed <strong>upper-tailed</strong> <span class="math display">\[pvalue= 1-\phi(z_{obs})\]</span></li>
</ol>
<p><code>1-norm.cdf(zobs)</code> is greater than <span class="math inline">\(\alpha=1-0.95=0.05\)</span></p>
<p><span class="math display">\[pvalue \geq \alpha =0.05\]</span></p>
<p>then we <strong>accept</strong> <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence. Note that this test is again from the point of view of the <strong>null hypothesis</strong>. We are asking: if we were to take another average what is the probability that is higher than the observed one?</p>
<p><strong>Example (Microprocessors)</strong></p>
<p>In the example of the microprocessors, we may be interested to choose another manufacturer only in the case that the mean width is too high. Therefore the upper-tailed hypothesis is</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu \leq 26\)</span> (<strong>at most</strong> microprocessors have this mean width: <strong>status quo</strong>)</li>
<li><span class="math inline">\(H_1:\mu &gt; 26\)</span> (microprocessors have <strong>higher</strong> mean width: <strong>research interest</strong>)</li>
</ol>
<p>We will test the higher tail of the distribution.
For the data that we discussed before, we then <strong>reject</strong> <span class="math inline">\(H_0\)</span> (i.e. the manufacturer’s claim) at <span class="math inline">\(95\%\)</span> confidence because of any of the three equivalent contrasts:</p>
<ol style="list-style-type: decimal">
<li>The <strong>upper tailed</strong> confidence interval does not contain the null hypothesis <span class="math inline">\(\mu_0=13\)</span></li>
</ol>
<p><span class="math display">\[\mu_0=26 \notin (\bar{x}-z_{0.05} \frac{\sigma}{\sqrt{n}}, \infty)=(26.01828, \infty)\]</span>
where <span class="math inline">\(z_{0.05}=\)</span><code>norm.ppf(0.95)=1.644854</code></p>
<ol start="2" style="list-style-type: decimal">
<li>We have that the acceptance region for <span class="math inline">\(H_0\)</span> is:</li>
</ol>
<p><span class="math display">\[(-\infty, z_{0.05})=( -\infty,  1.644854)\]</span></p>
<p>and that the observed standardized error is not in the region
<span class="math display">\[z_{obs} =  \frac{26.42536-26}{\frac{0.7}{\sqrt{8}}}=1.7187 \notin ( -\infty,  1.644854)\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>The upper tail <span class="math inline">\(pvalue\)</span> is lower than <span class="math inline">\(\alpha=0.05\)</span>
<span class="math display">\[pvalue=1-\phi(1.7187)=0.04283451 &lt;0.05\]</span></li>
</ol>
<p>where <span class="math inline">\(pvalue=\)</span><code>1-norm.cdf(1.7187)</code>.</p>
<p>The hypothesis test is performed in Python under the label <code>p value (one-tail)</code></p>
<pre echo="FALSE," warning="FALSE," message="FALSE"><code># https://pypi.org/project/bioinfokit/

!pip install bioinfokit
from bioinfokit.analys import stat
import pandas as pd

data = {&#39;x&#39;: [26.69284, 26.65240, 26.02918, 26.21622, 
              25.93998, 27.10618, 27.51114, 25.25494]}

df = pd.DataFrame(data)

res = stat()
res.ztest(df=df, x=&#39;x&#39;, mu=26, x_std=0.7, test_type=1)
print(res.summary)</code></pre>
<pre echo="FALSE," warning="FALSE," message="FALSE"><code>One Sample Z-test 

------------------  ----------
Sample size          8
Mean                26.42536
Z value              1.71871
p value (one-tail)   0.0428332
p value (two-tail)   0.0856665
Lower 95.0%         25.94029
Upper 95.0%         26.91043
------------------  ----------</code></pre>
<p>The result can be seen in the <span class="math inline">\(pvalue\)</span> for one tail. Note that the <span class="math inline">\(pvalue\)</span> for one tail is half of the <span class="math inline">\(pvalue\)</span> for two tails.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-103-1.png" width="672" /></p>
<p>We then conclude that the microprocessors of the manufacturer are too thick for our specifications and have evidence that support changing from provider.</p>
</div>
</div>
<div id="case-2-unknown-variance-1" class="section level2 hasAnchor" number="14.5">
<h2><span class="header-section-number">14.5</span> Case 2 (unknown variance)<a href="hypothesis-testing.html#case-2-unknown-variance-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A <strong>two tailed</strong> hypothesis contrast of the form</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu = \mu_0\)</span> (status quo)</li>
<li><span class="math inline">\(H_1:\mu \neq \mu_0\)</span> (research interest)</li>
</ol>
<p>can be tested when we do not know <span class="math inline">\(\sigma^2\)</span> using <strong>case 2</strong>, namely when</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X\)</span> is a normal variable, <span class="math inline">\(X \rightarrow N(\mu, \sigma^2)\)</span>, and</li>
<li>we do <strong>not</strong> know the value of <span class="math inline">\(\sigma^2\)</span></li>
</ol>
<p>Let’s remember that in this case, the <strong>standardized error</strong> with respect to the <strong>sample standard deviation</strong> <span class="math inline">\(S\)</span></p>
<p><span class="math display">\[T=\frac{\bar{X}-\mu}{\frac{S}{\sqrt{n}}}\]</span></p>
<p>Follows a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-1\)</span> degrees of freedom. Therefore, we can apply <strong>all three criteria</strong> as in <strong>case 1</strong> but making the substitution of <span class="math inline">\(s\)</span> for <span class="math inline">\(\sigma\)</span> and <span class="math inline">\(Z\)</span> for <span class="math inline">\(T\)</span>.</p>
<p><strong>Testing criteria:</strong></p>
<ol style="list-style-type: decimal">
<li><em>Confidence interval:</em> If the confidence interval <strong>contains</strong> the null hypothesis</li>
</ol>
<p><span class="math display">\[\mu_0\in (l,u)=(\bar{x}-t_{0.025,n-1} \frac{s}{\sqrt{n}}, \bar{x}+t_{0.025,n-1} \frac{s}{\sqrt{n}})\]</span> then we <strong>accept</strong> <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence.</p>
<ol start="2" style="list-style-type: decimal">
<li><em>Rejection/acceptance region:</em> If the observed statistics <span class="math inline">\(t_{obs}\)</span> under the null hypothesis <strong>is</strong> in the acceptance region</li>
</ol>
<p><span class="math display">\[t_{obs}=\frac{\bar{x}-\mu_0}{\frac{s}{\sqrt{n}}} \in (-t_{0.025}, t_{0.025})\]</span></p>
<p>where <span class="math inline">\(t_{0.025}=F_t^{-1}(0.975, n-1)=\)</span><code> t.ppf(0.975, n-1)</code>, then we <strong>accept</strong> <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence.</p>
<ol start="3" style="list-style-type: decimal">
<li><span class="math inline">\(pvalue\)</span>: If the observed <span class="math inline">\(pvalue= 2 (1-F_t(|t_{obs}|))=\)</span><code>2*(1- t.cdf(abs(tobs), n-1))</code> is</li>
</ol>
<p><span class="math display">\[pvalue \geq \alpha =1-0.95=0.05\]</span></p>
<p>then we <strong>accept</strong> <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence.</p>
<p><strong>Example (Microprocessors)</strong></p>
<p>For the hypothesis contrast for the microprocessors width</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu = 26\)</span></li>
<li><span class="math inline">\(H_1:\mu \neq 26\)</span></li>
</ol>
<p>We will only assume that the mean width of a microprocessor is normally distributed</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X \rightarrow N(\mu=26, \sigma^2=?)\)</span></li>
<li>We do not know <span class="math inline">\(\sigma^2\)</span></li>
</ol>
<p>Having obtained the sample</p>
<pre><code>## [1] 26.69284 26.65240 26.02918 26.21622 25.93998 27.10618 27.51114 25.25494</code></pre>
<p>with this data, we accept that <span class="math inline">\(H_0\)</span> (the manufacturer’s claim) at <span class="math inline">\(95\%\)</span> significance because of any of following equivalent contrasts:</p>
<ol style="list-style-type: decimal">
<li>The confidence interval</li>
</ol>
<p><span class="math display">\[(\bar{x}-t_{0.025, n-1} \frac{s}{\sqrt{n}}, \bar{x}+t_{0.025, n-1} \frac{s}{\sqrt{n}})=(25.82818, 27.02254)\]</span></p>
<p>contains <span class="math inline">\(H_0:\mu=26\)</span>.</p>
<ol start="2" style="list-style-type: decimal">
<li>The acceptance region for <span class="math inline">\(H_0\)</span> is:</li>
</ol>
<p><span class="math display">\[(-t_{0.025,7}, t_{0.025,7})=( -2.36,  2.36)\]</span></p>
<p>and the observed standardized error from <span class="math inline">\(H_0\)</span> is
<span class="math display">\[t_{obs} =  \frac{26.42536-26}{\frac{0.714313}{\sqrt{8}}}=1.6843\]</span></p>
<p>within the acceptance region.</p>
<ol start="3" style="list-style-type: decimal">
<li>The <span class="math display">\[pvalue=2(1-F_{t,7}(1.6843))=0.136\]</span></li>
</ol>
<p>is greater then <span class="math inline">\(\alpha=0.05\)</span>. The <span class="math inline">\(pvalue\)</span> is computed R like <code>2*(1- t.cdf(1.6843,7))</code></p>
<p>In Python this contrasts are performed with the function stats.ttest_1samp:</p>
<pre eval="FALSE"><code>from scipy import stats

data = [26.69284, 26.65240, 26.02918, 26.21622, 
        25.93998, 27.10618, 27.51114, 25.25494]

res=stats.ttest_1samp(data, popmean=13)
print (res)</code></pre>
<pre eval="FALSE"><code>TtestResult(statistic=1.68427527723504, pvalue=0.1360005269730744, df=7)</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-105-1.png" width="672" /></p>
<p>If we use an upper tailed hypothesis, we would obtain half of the <span class="math inline">\(pvalue\)</span> for the two tail test, that it <span class="math inline">\(pvalue=0.068\)</span> and, therefore, we still would not reject the manufacturer’s claim. The upper tail <span class="math inline">\(pvalue\)</span> is greater than the significance limit <span class="math inline">\(\alpha=0.05\)</span>. With a t-test we do not look for another manufacturer in any case.</p>
<p>Note that in the case 1, we have <strong>assumed</strong> that <span class="math inline">\(\sigma=0.7\)</span>. In case 2, for the same data we computed <span class="math inline">\(s=0.714313\)</span>. Therefore the data suggest that the widths are more dispersed than what we have assumed, giving more benefit of the doubt to the manufacturer. This difference in dispersion lead to two different decisions for the upper-tail test, to replace the manufacturer (case 1) or not (case 2).</p>
<p><strong>Example (NaCl)</strong></p>
<p><span class="math inline">\(11.6g\)</span> of NaCl is dissolved in <span class="math inline">\(100 g\)</span> of water and has a molar concentration of <span class="math inline">\(1.92 mol/L\)</span></p>
<p>We design a process to remove salt from this concentration and obtain the following results</p>
<pre><code>## [1] 1.716 1.889 1.783 1.849 1.891</code></pre>
<p>We first want to test at <span class="math inline">\(0.95\%\)</span> confidence if the process changes the salt concentration in any direction. Therefore we propose a two-tail hypothesis:</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu=1.92\)</span></li>
<li><span class="math inline">\(H_1:\mu \neq 1.92\)</span></li>
</ol>
<p>We will assume that <span class="math inline">\(X\)</span> is normal and that we do not know the variance <span class="math inline">\(\sigma^2\)</span>. Therefore, we are in <strong>case 2</strong> that we test with a <code>stats.ttest_1samp</code></p>
<pre eval="FALSE"><code>from scipy import stats

data = [1.716, 1.889, 1.783, 1.849, 1.891]

res=stats.ttest_1samp(data, popmean=1.92, alternative=&#39;two-sided&#39;)
print (res)
res.confidence_interval(confidence_level=0.95)</code></pre>
<pre><code>TtestResult(statistic=-2.8038174739802226, pvalue=0.048622042176166516, df=4)
ConfidenceInterval(low=1.7321215833901604, high=1.9190784166098398)</code></pre>
<p>Since <span class="math inline">\(pvalue &lt;0.05\)</span>, we conclude that the molar concentration has <strong>significantly</strong> changed after the process.</p>
<div id="lower-tail-hypothesis" class="section level3 hasAnchor" number="14.5.1">
<h3><span class="header-section-number">14.5.1</span> Lower tail hypothesis<a href="hypothesis-testing.html#lower-tail-hypothesis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If we are interested only in the case that we are able to remove salt from the concentration then we rather propose a <strong>lower tail</strong> hypothesis:</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu \geq 1.92\)</span> (After the desalinization process the concentration o salt is at least the initial one: status quo)</li>
<li><span class="math inline">\(H_1:\mu &lt; 1.92\)</span> (After the desalinization process the concentration is lower the initial one: research interest)</li>
</ol>
<p>Note that the lower tail is given by the alternative <span class="math inline">\(H_1\)</span>. We want to test that the average concentration after the process is lower than the initial concentration. The contrast criteria are the same as for the other types of hypothesis. For this type of hypothesis, we will accept the null hypothesis if</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\mu_0\)</span> is in the confidence interval:
<span class="math display">\[\mu_0\in (l,u)=(-\infty, \bar{x}+t_{0.05,n-1} \frac{s}{\sqrt{n}})\]</span></p></li>
<li><p>or, <span class="math inline">\(t_{obs}\)</span> is in the aceptance region:</p></li>
</ol>
<p><span class="math display">\[t_{obs}\in (t_{0.05,n-1}, \infty)\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>or, the <span class="math inline">\(pvalue\)</span> on the lower tail of the distribution.<br />
<span class="math display">\[pvalue=F_t(t_{obs},n-1)\]</span>
is higher than <span class="math inline">\(\alpha=0.05\)</span></li>
</ol>
<p>In any other case, we reject <span class="math inline">\(H_0\)</span> and accept the alternative hypothesis.</p>
<p><strong>Example (NaCl)</strong></p>
<p>For the lower tail contrast</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu \geq 1.92\)</span></li>
<li><span class="math inline">\(H_1:\mu &lt; 1.92\)</span></li>
</ol>
<p>We can assume that the concentration is normal and that we do not know <span class="math inline">\(\sigma^2\)</span>. Therefore, we are in <strong>case 2</strong> for which we only need to change the argument alternative to less in the function t.test.</p>
<pre eval="FALSE"><code>from scipy import stats

data = [1.716, 1.889, 1.783, 1.849, 1.891]

res=stats.ttest_1samp(data, popmean=1.92, alternative=&#39;less&#39;)
print (res)
res.confidence_interval(confidence_level=0.95)</code></pre>
<pre><code>TtestResult(statistic=-2.8038174739802226, pvalue=0.024311021088083258, df=4)
ConfidenceInterval(low=-inf, high=1.8973758334933486)</code></pre>
<p>We see that the <span class="math inline">\(pvalue\)</span> is reduced in half, and therefore we have more confidence in rejecting the lower tail hypothesis than the two-sided hypothesis.</p>
<p><strong>Example 2 (soporific)</strong></p>
<p>In some cases, we are not sure about the numerical value of the hypothesis to test, but we know that we want to improve the value of a parameter in two different conditions.</p>
<p>In the original paper of Gosset, he analyzed the effect of two soporific medicines.</p>
<ul>
<li>10 individuals were given <strong>soporific 1</strong> and wrote down the additional hours slept under treatment, with a mean <span class="math inline">\(0.75\)</span></li>
</ul>
<pre eval="FALSE"><code>import numpy as np

medicine1 = np.array([0.7,-1.6,-0.2,-1.2,-0.1,3.4,3.7,0.8,0,2])</code></pre>
<ul>
<li>The same 10 individuals were given <strong>soporific 2</strong> and wrote down the additional hours slept under treatment, with a mean <span class="math inline">\(2.33\)</span></li>
</ul>
<pre eval="FALSE"><code>medicine2 = np.array([1.9,0.8,1.1,0.1,-0.1,4.4,5.5,1.6,4.6,3.4])</code></pre>
<p>The scientific hypothesis was that soporific 2 was better than soporific 1. For each individual, Gosset computed the difference between the treatments. Taking <span class="math inline">\(X\)</span> as the <strong>difference</strong> between treatments, this was the sample observed for <span class="math inline">\(X\)</span></p>
<div class="sourceCode" id="cb52"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb52-1"><a href="hypothesis-testing.html#cb52-1" tabindex="-1"></a>x <span class="ot">=</span> medicine2<span class="sc">-</span>medicine1</span>
<span id="cb52-2"><a href="hypothesis-testing.html#cb52-2" tabindex="-1"></a>x</span></code></pre></div>
<pre><code>##  [1] 1.2 2.4 1.3 1.3 0.0 1.0 1.8 0.8 4.6 1.4</code></pre>
<p>The average hours gained by soporific 2 with respect to soporific 1 was <span class="math inline">\(1.58\)</span>, and <span class="math inline">\(s=1.229995\)</span>.</p>
<p>The scientific question can be stated as <strong>upper-tailed</strong> paired t-test:</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu \leq 0\)</span> (no treatment difference: <span class="math inline">\(\mu_2-\mu_1=0\)</span>)</li>
<li><span class="math inline">\(H_1:\mu &gt; 0\)</span> (treatment 2 higher then treatment 1: <span class="math inline">\(\mu_2-\mu_1&gt;0\)</span>)</li>
</ol>
<p>Where <span class="math inline">\(\mu\)</span> is the mean of the <strong>differences</strong> between treatments.</p>
<p>If we suppose that <span class="math inline">\(X\)</span> is normal and we do not know <span class="math inline">\(\sigma^2\)</span> then we are in <strong>case 2</strong>. The <strong>standardized error</strong> is:</p>
<p><span class="math display">\[T=\frac{\bar{X}}{\frac{S}{\sqrt{n}}}\]</span></p>
<p>and its observation</p>
<p><span class="math display">\[t_{obs}=\frac{\bar{x}}{\frac{s}{\sqrt{n}}}\]</span>
which is also known as the <strong>signal</strong> to <strong>noise</strong> ratio.</p>
<p>we can test the hypothesis for the difference <span class="math inline">\(X=medicine_1-medicine_2\)</span></p>
<pre eval="FALSE"><code>from scipy import stats

res=stats.ttest_1samp(x, popmean=0, alternative=&#39;greater&#39;)
print (res)
res.confidence_interval(confidence_level=0.95)</code></pre>
<pre><code>TtestResult(statistic=4.062127683382037, pvalue=0.001416445098692135, df=9)</code></pre>
<p>showing a significant gain by soporific 2 (rejection of the null).</p>
<p>Equivalently we can test the hypothesis using a paired t-test, where we introduce the observation for each separate condition, and state that the observations are paired</p>
<pre><code>t_statistic, p_value = stats.ttest_rel(medicine2, medicine1, alternative=&#39;greater&#39;)</code></pre>
<pre><code>TtestResult(statistic=4.062127683382037, pvalue=0.001416445098692135, df=9)</code></pre>
<p>In this plot, we show all the statistical elements for this example. In red, we show the null hypothesis of no difference between treatments. The <span class="math inline">\(95\%\)</span> confidence interval for the difference is shown in the upper part. The CI does not contain the null. In the second row, we see the data represented in a box plot. The <span class="math inline">\(5\%\)</span>-quantile of the data is on <span class="math inline">\(0\)</span>. At the bottom row, we see the raw data, that is the individual observations for the change in hours for each patient.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-109-1.png" width="672" /></p>
</div>
<div id="hypothesis-testing-with-large-n-and-any-distribution" class="section level3 hasAnchor" number="14.5.2">
<h3><span class="header-section-number">14.5.2</span> Hypothesis testing with large n and any distribution<a href="hypothesis-testing.html#hypothesis-testing-with-large-n-and-any-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>On many occasions, <span class="math inline">\(X\)</span> is not normally distributed but if we can take large samples <span class="math inline">\(n \ge 30\)</span> then we can use the CLT:</p>
<p>Then the <strong>standardized error</strong> from the null hypothesis can be approximated to a standard distribution</p>
<p><span class="math display">\[Z=\frac{\bar{X}-\mu}{\frac{\sigma}{\sqrt{n}}}  \rightarrow N(0,1)\]</span></p>
<p>and then we proceed as in <strong>case 1</strong>. If <span class="math inline">\(\sigma\)</span> is unknown we then replace it with its estimate <span class="math inline">\(s\)</span> and proceed as in <strong>case 2</strong> using the t-statistic</p>
<p><span class="math display">\[T=\frac{\bar{X}-\mu_0}{\frac{S}{\sqrt{n}}}\]</span></p>
</div>
</div>
<div id="case-3-proportions-1" class="section level2 hasAnchor" number="14.6">
<h2><span class="header-section-number">14.6</span> Case 3 (proportions)<a href="hypothesis-testing.html#case-3-proportions-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>If our random experiment is a Bernoulli trial <span class="math inline">\(X \rightarrow Bernoulli(p)\)</span>, we can formulate hypothesis contrasts for the probability <span class="math inline">\(p\)</span> of an event in the trial. Consider an upper tailed hypothesis</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0: p \leq p_0\)</span> (status quo)</li>
<li><span class="math inline">\(H_1: p&gt; p_0\)</span> (research interest)</li>
</ol>
<p>In this <strong>case 3</strong>, we test a hypothesis for the proportion if</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X\)</span> is a Bernoulli trial, and</li>
<li><span class="math inline">\(np\)</span>, <span class="math inline">\(n(1-p)\)</span> are both greater than 5, so we can apply the central limit theorem.</li>
</ol>
<p>Remember that if we take a the sample of <span class="math inline">\(n\)</span> Bernoulli trials <span class="math inline">\((1,0,1,...0)\)</span>, <span class="math display">\[\bar{X}=\frac{1}{n}\sum_{i=1}^n X_i\]</span> is the relative frequency for the ‘’ones’’ in the sample. This is an estimator of <span class="math inline">\(p\)</span>.</p>
<p>If we assume that the null hypothesis is true then <span class="math inline">\(X \rightarrow Bernoulli(p_0)\)</span> and the standardized error that we make when we estimate <span class="math inline">\(p_0\)</span> with <span class="math inline">\(\bar{X}\)</span> is</p>
<p><span class="math display">\[Z=\frac{\bar{X}-p_0}{\frac{\sqrt{p_0(1-p_0)}}{\sqrt{n}}}  \rightarrow N(0,1)\]</span></p>
<p><span class="math inline">\(\sigma=\sqrt{p_0(1-p_0)}\)</span> is the standard deviation of <span class="math inline">\(X\)</span> when the null hypothesis is true: <span class="math inline">\(V(X)=\sigma^2=p_0(1-p_0)\)</span>. With this <span class="math inline">\(Z\)</span> statistic, we can accept or reject the null hypothesis using any of the three testing criteria.</p>
<p><strong>Example (process improvement)</strong></p>
<p>We may be satisfied with a new process if <span class="math inline">\(90\%\)</span> of the times we improve the previous process.</p>
<p>If we run a sample of <span class="math inline">\(200\)</span> new processes and find that <span class="math inline">\(188\)</span> times we improved the previous process, can we be satisfied with the new process at <span class="math inline">\(95\%\)</span> confidence?</p>
<p>We then formulate an upper-tailed hypothesis contrast for the null hypothesis <span class="math inline">\(p_0=0.9\)</span>. Therefore, the null and alternative hypotheses are</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0: p \leq p_0=0.9\)</span> (The new process is not satisfactory: status quo)</li>
<li><span class="math inline">\(H_1: p&gt; p_0=0.9\)</span> (The new process is satisfactory: research interest)</li>
</ol>
<p>We assume that if the null hypothesis is true then</p>
<ol style="list-style-type: decimal">
<li>The probability model of a random experiment is</li>
</ol>
<p><span class="math display">\[X \rightarrow Bernoulli (p_0)\]</span>
2. and check that when <span class="math inline">\(p_0n=180&gt;5\)</span> and <span class="math inline">\((1-p_0)=n=20&gt;5\)</span></p>
<p>Therefore, we can apply <strong>case 3</strong>.</p>
<p>We can use any of the three criteria to test the hypothesis. For this example, we believe that have a satisfactory process because, we <strong>reject</strong> <span class="math inline">\(H_0\)</span> at <span class="math inline">\(95\%\)</span> following</p>
<ol style="list-style-type: decimal">
<li>The upper tail confidence interval for the <span class="math inline">\(p\)</span> does not include <span class="math inline">\(p_0\)</span></li>
</ol>
<p><span class="math inline">\(p_0=0.9 \notin (\bar{x}-z_{0.05}\big[\frac{p_0(1-p_0)}{n} \big]^{1/2},1)= (0.905,1)\)</span></p>
<ol start="2" style="list-style-type: decimal">
<li>The observed standardized error from the null is not in the acceptance region</li>
</ol>
<p><span class="math display">\[z_{obs}= \frac{\bar{X}-p_0}{\big[\frac{p_0(1-p_0)}{n} \big]^{1/2}} =\frac{0.94-0.90}{\sqrt{0.00045}}=1.88563 \notin (-\infty, z_{0.05})=(-\infty, 1.644)\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>The upper tail <span class="math inline">\(pvalue\)</span> is lower than <span class="math inline">\(\alpha=0.05\)</span>:</li>
</ol>
<p><span class="math display">\[pvalue=1-\phi(1.885618)=0.02967323&lt;0.05\]</span></p>
<p>in Python: <code>1-norm.cdf(1.885618)</code></p>
<p><img src="_main_files/figure-html/unnamed-chunk-110-1.png" width="672" /></p>
<p>The test can be performed in Python using the <code>proportions_ztest</code> function</p>
<pre eval="FALSE"><code>from statsmodels.stats.proportion import proportions_ztest
proportions_ztest(count=0.9*200, nobs=200, value=188/200, alternative=&#39;smaller&#39;)</code></pre>
<pre><code>(-1.8856180831641234, 0.029673219395960154)</code></pre>
<p>Note that the function is programmed such that the null hypothesis is in the <code>count</code> argument, which is used to compute the standard deviation of the sample. This is why the value of the statisitcs is negative and the test i <a href="https://www.geeksforgeeks.org/how-to-perform-a-one-proportion-z-test-in-python/">lower tailed</a>.</p>
</div>
<div id="case-4-variances" class="section level2 hasAnchor" number="14.7">
<h2><span class="header-section-number">14.7</span> Case 4 (variances)<a href="hypothesis-testing.html#case-4-variances" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In many cases, experiments are run to test the dispersion of data.</p>
<p>Such as</p>
<ul>
<li><p>when complying with strict design standards where measurements must be between certain values.</p></li>
<li><p>when different treatments are applied to different groups, we want to see the dispersion of outcomes between the groups.</p></li>
</ul>
<p>A <strong>tow tailed</strong> hypothesis contrast for the variance is of the form</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\sigma = \sigma_0\)</span> (status quo)</li>
<li><span class="math inline">\(H_1:\sigma \neq \sigma_0\)</span> (research interest)</li>
</ol>
<p>This hypothesis for <span class="math inline">\(\sigma\)</span> (<strong>case 4</strong>) can be tested when</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X\)</span> is a normal variable</li>
</ol>
<p>Remember that if we take a random sample <span class="math display">\[S^2=\frac{1}{n-1}\sum_{i=1}^n (X_i-\bar{X})^2\]</span> is the sample variance. This is an estimator of <span class="math inline">\(\sigma^2\)</span>.</p>
<p>If we assume that the null hypothesis is true and <span class="math inline">\(X \rightarrow N(\mu, \sigma_0)\)</span> then the <strong>error ratio</strong> that we make when we estimate <span class="math inline">\(\sigma^2\)</span> with <span class="math inline">\(s^2\)</span> is</p>
<p><span class="math display">\[W=\frac{(n-1)S^2}{\sigma_0^2}\]</span></p>
<p>Note that when <span class="math inline">\(W=1\)</span>, we make no error. <span class="math inline">\(W\)</span> follows a <span class="math inline">\(\chi^2\)</span> (chi-squared) distribution with <span class="math inline">\(n-1\)</span> degrees of freedom.</p>
<p><span class="math display">\[W \rightarrow \chi^2(n-1)\]</span></p>
<p>With <span class="math inline">\(W\)</span>, we can accept or reject the null hypothesis using any of the three testing criteria.</p>
<p><strong>Example (Semiconductor)</strong></p>
<p>The production of a semiconductor chip is regulated by a process that requires that the thickness of a particular layer does not vary in more than <span class="math inline">\(\sigma_0=0.6mm\)</span>, from its mean of <span class="math inline">\(25mm\)</span>.</p>
<p>To keep control of the process every so often a sample of <span class="math inline">\(20\)</span> specimens is taken.</p>
<p>On one occasion a sample of the thickness of 20 semiconductors was</p>
<pre><code>##  [1] 24.51239 24.79975 26.35608 25.06134 25.11248 26.49211 25.40100 23.89940
##  [9] 24.40244 24.61227 26.06495 25.31304 25.34867 25.09629 24.51642 26.55461
## [17] 25.43313 23.28904 25.61018 24.58867</code></pre>
<p>The estimated standard deviation for this data is <span class="math inline">\(s=0.8462188\)</span> was the process out of control at <span class="math inline">\(99\%\)</span> confidence and should be stopped?</p>
<p>We therefore want to contrast the upper tail hypotheses</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\sigma^2 \leq \sigma_0^2=0.6^2\)</span> (Process is <strong>under</strong> control)</li>
<li><span class="math inline">\(H_1:\sigma^2 &gt; \sigma_0^2=0.6^2\)</span> (Process is <strong>out of</strong> control)</li>
</ol>
<p>Let’s test the hypothesis using the <strong>acceptance region</strong>.</p>
<p>The contrast statistics is <span class="math display">\[W=\frac{(n-1)S^2}{\sigma_0^2} \rightarrow \chi^2(n-1)\]</span></p>
<p>and the threshold limit <span class="math inline">\(\alpha=0.01=0-0.99\)</span>. Therefore, the acceptance region <span class="math inline">\(P(W\leq \chi^2_{0.01,19})=0.99\)</span> is</p>
<p><span class="math display">\[(0, \chi^2_{0.01,19})=(0,36.19)\]</span></p>
<p>In Python: <span class="math inline">\(\chi^2_{0.01,19}=\)</span><code>chi2.ppf(0.99,19)</code><span class="math inline">\(= 36.19\)</span></p>
<p>For our data, the observed <strong>standardized error ratio</strong> is:</p>
<p><span class="math display">\[w_{obs}=\frac{19 (0.8462188)^2}{0.60^2}=37.79344\]</span></p>
<p>That falls outside the acceptance region</p>
<p><span class="math display">\[w_{obs}=37.79344\notin (0,36.19)\]</span></p>
<p>Therefore, we reject the null hypothesis and conclude that that yes! the process is out of control.</p>
<p>If we, alternativelly, calculate the upper tailed <span class="math inline">\(pvalue\)</span></p>
<p><span class="math display">\[pvalue=1-F_{\chi^2,19}(37.79344)= 0.006\]</span>
we see that it is lower than <span class="math inline">\(\alpha=0.01\)</span> and reject the null hypothesis.</p>
<p>R: <code>1-chi2.cdf(37.79344, 19)</code></p>
<p><img src="_main_files/figure-html/unnamed-chunk-112-1.png" width="672" /></p>
<p>For testing the hypothesis, we can use the following code in Python</p>
<pre eval="FALSE"><code>import numpy as np
from scipy import stats

# Sample data
x = np.array([24.51239, 24.79975, 26.35608, 25.06134, 25.11248, 
              26.49211, 25.40100, 23.89940, 24.40244, 24.61227, 
              26.06495, 25.31304, 25.34867, 25.09629, 24.51642, 
              26.55461, 25.43313, 23.28904, 25.61018, 24.58867])

# Hypothesized variance
hypothesized_variance = 0.6**2

# Degrees of freedom
df = len(x) - 1

# Calculate the test statistic
chi_square = (len(x) - 1) * np.var(x,ddof=1) / hypothesized_variance

# Calculate the critical value from the Chi-square distribution
alpha = 1 - 0.99
critical_value = stats.chi2.ppf(1 - alpha, df)

# Perform the variance test
p_value = 1 - stats.chi2.cdf(chi_square, df)

print(&quot;Variance Test:&quot;)
print(&quot;Chi-Square Statistic:&quot;, chi_square)
print(&quot;Critical Value:&quot;, critical_value)
print(&quot;P-Value:&quot;, p_value)</code></pre>
<pre><code>Variance Test:
Chi-Square Statistic: 37.79345223227778
Critical Value: 36.19086912927004
P-Value: 0.006304215036982974</code></pre>
</div>
<div id="errors-in-hypothesis-testing" class="section level2 hasAnchor" number="14.8">
<h2><span class="header-section-number">14.8</span> Errors in hypothesis testing<a href="hypothesis-testing.html#errors-in-hypothesis-testing" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The result of an upper tail hypothesis test may be to <strong>reject</strong> the null hypothesis:</p>
<p><span class="math display">\[H_0: \mu\leq\mu_0\]</span></p>
<p>when <span class="math inline">\(H_0\)</span> is actually <strong>true</strong>. In the case of the microprocessors, imagine, for example that we rejected the manufacturer’s claim (<span class="math inline">\(H_0\)</span>) when they actually do produce microprocessors of widths with mean <span class="math inline">\(26\)</span>mm. Data made us believe that they produce thick microprocessors. But it was only because we bought a sample of <span class="math inline">\(8\)</span> microprocessors that by chance were too thick.</p>
<p>We must bear in mind that the decision is made based on the data. It may well be that the observed statistic has fallen, by chance, far from the null hypothesis, in the rejection zone of <span class="math inline">\(H_0\)</span> even when this hypothesis is true. The statistic is a random variable and one observation can have a large value by chance.</p>
<p>When we perform the hypothesis test, we don’t know if <span class="math inline">\(H_0\)</span> is true. Let us assume that we found by other means that <span class="math inline">\(H_0\)</span> is really true. The probability of rejecting the truth (<span class="math inline">\(H_0\)</span>) is precisely the level of statistical significance <span class="math inline">\(\alpha\)</span>. We call this probability the probability of making a <strong>type 1</strong> error. Taking the example for <strong>case 1</strong>, an upper tail test, and a confidence of <span class="math inline">\(95\%\)</span> we have that</p>
<p><span class="math display">\[\alpha = P(Z&gt; z_{0.05})=0.05\]</span></p>
<p>where <span class="math inline">\(z_{0.05}=\phi^{-1}(0.95)=\)</span> <code>norm.ppf(0.95)=1.644</code></p>
<p><img src="_main_files/figure-html/unnamed-chunk-113-1.png" width="672" /></p>
<p>A type 1 error is also called a <strong>false positive</strong> because our research interest is in <span class="math inline">\(H_1\)</span>. When we reject <span class="math inline">\(H_0\)</span>, we accept <span class="math inline">\(H_1\)</span> and say that our test is <strong>positive</strong>. Accepting <span class="math inline">\(H_1\)</span> translates to announcing a discovery, so the type 1 error is announcing a discovery that is not true: we falsely claimed a discovery because the data suggested it, we were fooled by it.</p>
<p>There is another type of error. The result of an upper tail hypothesis test can be <strong>accepting</strong> the null hypothesis:</p>
<p><span class="math display">\[H_0: \mu\leq\mu_0\]</span></p>
<p>when this is <strong>not true</strong>. Again for the microprocessors, imagine now that our data made us accept the manufacturer’s claim (<span class="math inline">\(H_0\)</span>) when they actually do produce microprocessors that are too thick. Data made us believe that they produce acceptable microprocessors. But it was only because we bought a sample of <span class="math inline">\(8\)</span> microprocessors that by chance were too thin.</p>
<p>In this case, it may be that the observed statistic has fallen, due to randomness, close to the null hypothesis, in the zone of acceptance of <span class="math inline">\(H_0\)</span>, when really <span class="math inline">\(H_1\)</span> is true. If we found out somehow that, for example, <span class="math inline">\(\mu\)</span> really does have a value of <span class="math inline">\(\mu_1\)</span> then the alternative hypothesis would be exactly:</p>
<p><span class="math display">\[H_1: \mu=\mu_1\]</span></p>
<p><img src="_main_files/figure-html/unnamed-chunk-114-1.png" width="672" /></p>
<p>If <span class="math inline">\(H_1\)</span> is indeed true (red line, which we don’t know when we perform the hypothesis test) then the statistic is <strong>really</strong> a random variable <span class="math inline">\(Y\)</span> that has mean (case 1)</p>
<p><span class="math display">\[E(Y)=\frac{\mu_1-\mu_0}{\frac{\sigma}{\sqrt{n}}}\]</span></p>
<p>and most of them will fall close to this value, therefore, in the rejection area of <span class="math inline">\(H_0\)</span>, validating the hypothesis test. However, there are cases in which the observed statistic falls within the acceptance zone of <span class="math inline">\(H_0\)</span> due to randomness, despite the fact that the statistics are produced by <span class="math inline">\(H_1\)</span>. In these cases we accept <span class="math inline">\(H_0\)</span> when it is not true. This error is called <strong>a type 2 error</strong> or a <strong>false negative</strong>. Since our research interest is in <span class="math inline">\(H_1\)</span> we failed to accept it. rejecting <span class="math inline">\(H_1\)</span> translates to discarding a discovery, so the type 2 error is ignoring a discovery that is actually true.</p>
<p>For case 1, with an upper tailed test and a confidence level of <span class="math inline">\(95\%\)</span>, this is</p>
<p><span class="math display">\[\beta= P(Y &lt; z_{0.05})\]</span>
Where <span class="math inline">\(Y \rightarrow N(\frac{\mu_1-\mu_0}{\sigma/\sqrt{n}},1)\)</span> is the <strong>true distribution</strong> of the observed statistics.</p>
<p><strong>Example (Light bulb)</strong></p>
<p>The energy efficiency of a new light bulb is a normal random variable with a standard deviation of <span class="math inline">\(5\)</span> watts. We consider that the light bulbs we produce are efficient if their average does not exceed <span class="math inline">\(80\)</span> watts, so we propose the hypothesis test</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0 : \mu \geq 80\)</span> (not efficient)</li>
<li><span class="math inline">\(H_1 : \mu &lt; 80\)</span> (efficient)</li>
</ol>
<p>We want to prove that we produce efficient light bulbs and we plan to draw a random sample of size <span class="math inline">\(100\)</span>, with a statistical significance level of <span class="math inline">\(5\%\)</span>. If previous studies have suggested that light bulbs may average <span class="math inline">\(\mu=\mu_1=79\)</span> watts, what type 2 error do we expect?</p>
<p>The contrast is for <strong>case 1</strong> with a <strong>lower tail</strong>. Therefore the probability of accepting the null hypothesis (we do not produce efficient light bulbs) is</p>
<p><span class="math display">\[\alpha = P(Z&lt; z_{0.95})=0.05\]</span>
and <span class="math inline">\(z_{0.95}=\)</span><code>norm.ppf(0.05)</code><span class="math inline">\(=-1.644\)</span>.</p>
<p>The type 2 error is therefore</p>
<p><span class="math display">\[\beta= P(Y &gt; -1.644)\]</span></p>
<p>that is, the probability of accepting that we do not produce efficient light bulbs when in fact we do. Because we are in <strong>case 1</strong>, as we know <span class="math inline">\(\sigma\)</span> and the variable is normal, the observed statistics are actually distributed as</p>
<p><span class="math display">\[Y \rightarrow N(\frac{79-80}{5/\sqrt{100}}=-2,1)\]</span> and the type 2 error is</p>
<p><span class="math display">\[\beta = 1-F(-1.644)=0.36\]</span></p>
<p>computed in Python as <code>1-norm.cdf(-1.644,-2,1)=0.36</code>. Therefore, only <span class="math inline">\(\alpha=5\%\)</span> of the times we would announce that we produce efficient light bulbs when they really are not, while <span class="math inline">\(\beta=36\%\)</span> of the times we would announce that we have a production that is not useful when it really does work.</p>
<p>When we carry out a hypothesis test we have two possibilities for each condition</p>
<ul>
<li><span class="math inline">\(H_1\)</span> is actually : <strong>true</strong> (<span class="math inline">\(\mu=\mu_1\)</span>) or <strong>false</strong> (<span class="math inline">\(\mu=\mu_0\)</span>)</li>
<li>The test for <span class="math inline">\(H_1\)</span> is: <strong>positive</strong> (<span class="math inline">\(z_{obs}\)</span> in the acceptance zone of <span class="math inline">\(H_1\)</span>) or <strong>negative</strong> (<span class="math inline">\(z_{obs}\)</span> in the acceptance zone of <span class="math inline">\(H_0\)</span>)</li>
</ul>
<p><strong>Example (PCR)</strong></p>
<p>We do <strong>a</strong> PCR to test for an infection. The hypothesis test is</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0\)</span> no infection</li>
<li><span class="math inline">\(H_1\)</span> there is infection</li>
</ol>
<p>We do the PCR test and it gives us</p>
<ol style="list-style-type: lower-roman">
<li>negative: we reject the infection (<span class="math inline">\(H_1\)</span>)</li>
<li>positive: we accept the infection (<span class="math inline">\(H_1\)</span>)</li>
</ol>
<p>We can write the contingency table for the probabilities of the results of the hypothesis test as</p>
<table>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center"><span class="math inline">\(H_1\)</span> is true</th>
<th align="center"><span class="math inline">\(H_1\)</span> is false</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>The test on <span class="math inline">\(H_1\)</span> is positive</strong></td>
<td align="center"><span class="math inline">\(1-\beta\)</span></td>
<td align="center"><span class="math inline">\(\alpha\)</span></td>
</tr>
<tr class="even">
<td align="center"><strong>The test on <span class="math inline">\(H_1\)</span> is negative</strong></td>
<td align="center"><span class="math inline">\(\beta\)</span></td>
<td align="center"><span class="math inline">\(1-\alpha\)</span></td>
</tr>
<tr class="odd">
<td align="center"><strong>sum</strong></td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<p>we therefore have</p>
<ol style="list-style-type: decimal">
<li>The <strong>type 2 error</strong> rate: probability of a false negative (ignore a finding when it is true)</li>
</ol>
<p><span class="math display">\[\beta=P(negative|H_1)\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li><p>The <strong>True positive</strong> rate: This is the power or sensitivity of a test (claiming a discovery when it is true, the main objective)
<span class="math display">\[1-\beta=P(positive|H_1)\]</span></p></li>
<li><p>The <strong>Type 1 error</strong> rate: probability of a false positive (state a discovery when it is false)
<span class="math display">\[\alpha=P(positive|H_0)\]</span></p></li>
<li><p>The <strong>True Negative</strong> rate: This is the specificity of a test (ignore a finding when it is false)
<span class="math display">\[1-\alpha=P(negative|H_0)\]</span></p></li>
</ol>
</div>
<div id="exercises-12" class="section level2 hasAnchor" number="14.9">
<h2><span class="header-section-number">14.9</span> Exercises<a href="hypothesis-testing.html#exercises-12" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="exercise-1-11" class="section level4 hasAnchor" number="14.9.0.1">
<h4><span class="header-section-number">14.9.0.1</span> Exercise 1<a href="hypothesis-testing.html#exercise-1-11" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Imagine we take a random sample of size <span class="math inline">\(n = 41\)</span> of a normal random variable <span class="math inline">\(X\)</span>, and find that the sample average is <span class="math inline">\(10\)</span> and the sample variance is <span class="math inline">\(1.5\)</span>.</p>
<ul>
<li>What is then the confidence interval for the mean of <span class="math inline">\(X\)</span> at <span class="math inline">\(95\%\)</span> confidence level?</li>
</ul>
<p>Consider that <span class="math inline">\(t_{0.025,40}=\)</span> <code>t.ppf(0.975, 40)</code> <span class="math inline">\(\sim 2\)</span>.</p>
<ul>
<li><p>Test the hypothesis that the mean of <span class="math inline">\(X\)</span> is <strong>different</strong> than <span class="math inline">\(10.5\)</span>, using a <span class="math inline">\(5\%\)</span> significance threshold.</p></li>
<li><p>Write the code to calculate the P-value to test the hypothesis that the mean of <span class="math inline">\(\mu\)</span> is <strong>lower</strong> than <span class="math inline">\(10.5\)</span>, using a <span class="math inline">\(5\%\)</span> significance threshold.</p></li>
</ul>
<p>Consider that the code for the T probability distribution with <span class="math inline">\(n-1\)</span> degrees of freedom is <code>t.cdf(tobs, n-1)</code>.</p>
</div>
<div id="exercise-2-11" class="section level4 hasAnchor" number="14.9.0.2">
<h4><span class="header-section-number">14.9.0.2</span> Exercise 2<a href="hypothesis-testing.html#exercise-2-11" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><span class="math inline">\(10\)</span> gas condensates showed the following concentrations of mercury (in <span class="math inline">\(ng/ml\)</span>):</p>
<p><span class="math inline">\(23.3\)</span>, <span class="math inline">\(22.5\)</span>, <span class="math inline">\(21.9\)</span>, <span class="math inline">\(21.5\)</span>, <span class="math inline">\(19.9\)</span>, <span class="math inline">\(21.3\)</span>, <span class="math inline">\(21.7\)</span>, <span class="math inline">\(23.8\)</span>, <span class="math inline">\(22.6\)</span>, <span class="math inline">\(24.7\)</span></p>
<p>Assuming that the mercury concentration is distributed normally across gas condensates, test the hypothesis that condensate does not surpass the toxicity limit established at <span class="math inline">\(24 ng/ml\)</span>.</p>
</div>
<div id="exercise-3-8" class="section level4 hasAnchor" number="14.9.0.3">
<h4><span class="header-section-number">14.9.0.3</span> Exercise 3<a href="hypothesis-testing.html#exercise-3-8" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The manufacturer of gene expression microarrays guarantees that at least <span class="math inline">\(97\%\)</span> of the microarrays they produce have high-quality signals. A customer receives a batch of <span class="math inline">\(200\)</span> pieces and finds that <span class="math inline">\(8\)</span> unperformed.</p>
<p>Should the customer return the lot due to poor quality?</p>
</div>
</div>
<div id="practice-4" class="section level2 hasAnchor" number="14.10">
<h2><span class="header-section-number">14.10</span> Practice<a href="hypothesis-testing.html#practice-4" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Load misophonia data <code><a href="https://alejandro-isglobal.github.io/SDA/data/data_0.txt" class="uri">https://alejandro-isglobal.github.io/SDA/data/data_0.txt</a></code></p>
<p>We have four measures of anxiety:</p>
<ul>
<li>Trait: ansiedad.rasgo (are you an anxious person?) continuous:0-100</li>
<li>State: ansiedad.estado (are you currently feeling anxious?) continuous:0-100</li>
<li>Diagnosed: ansiedad.medicada (have you been diagnosed with an anxiety disorder?) binary (si, no)</li>
<li>Excess: ansiedad.dif (difference between State and Trait)</li>
</ul>
<p>We are interested in the variable misofonia.dif, that is the observed <strong>excess</strong> of anxiety from the trait</p>
<p><span class="math inline">\(excess = state - trait\)</span></p>
<p>Test the following hypotheses</p>
<ol style="list-style-type: lower-alpha">
<li><p>Is excess in anxiety different from 0? is it higher?</p></li>
<li><p>Is excess in anxiety higher than 0 for men and women separately?</p></li>
<li><p>Is the proportion of anxious patients different from <span class="math inline">\(0.03\)</span>?</p></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="interval-estimation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="contingency-tables.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/14-HypothesisTesting.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
