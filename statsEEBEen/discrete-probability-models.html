<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Discrete Probability Models | EEBE stats</title>
  <meta name="description" content="EEBE" />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Discrete Probability Models | EEBE stats" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="EEBE" />
  <meta name="github-repo" content="alejandro-isglobal/master" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Discrete Probability Models | EEBE stats" />
  
  <meta name="twitter:description" content="EEBE" />
  

<meta name="author" content="Alejandro Caceres" />


<meta name="date" content="2023-10-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="continous-random-variables.html"/>
<link rel="next" href="poisson-and-exponential-models.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">EEBE</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Objective</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#recommended-reading"><i class="fa fa-check"></i><b>1.1</b> Recommended reading</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-description.html"><a href="data-description.html"><i class="fa fa-check"></i><b>2</b> Data description</a>
<ul>
<li class="chapter" data-level="2.1" data-path="data-description.html"><a href="data-description.html#scientific-method"><i class="fa fa-check"></i><b>2.1</b> Scientific method</a></li>
<li class="chapter" data-level="2.2" data-path="data-description.html"><a href="data-description.html#statistics"><i class="fa fa-check"></i><b>2.2</b> Statistics</a></li>
<li class="chapter" data-level="2.3" data-path="data-description.html"><a href="data-description.html#data"><i class="fa fa-check"></i><b>2.3</b> Data</a></li>
<li class="chapter" data-level="2.4" data-path="data-description.html"><a href="data-description.html#result-types"><i class="fa fa-check"></i><b>2.4</b> Result types</a></li>
<li class="chapter" data-level="2.5" data-path="data-description.html"><a href="data-description.html#random-experiments"><i class="fa fa-check"></i><b>2.5</b> Random experiments</a></li>
<li class="chapter" data-level="2.6" data-path="data-description.html"><a href="data-description.html#absolute-frequencies"><i class="fa fa-check"></i><b>2.6</b> Absolute frequencies</a></li>
<li class="chapter" data-level="2.7" data-path="data-description.html"><a href="data-description.html#relative-frequencies"><i class="fa fa-check"></i><b>2.7</b> Relative frequencies</a></li>
<li class="chapter" data-level="2.8" data-path="data-description.html"><a href="data-description.html#bar-chart"><i class="fa fa-check"></i><b>2.8</b> Bar chart</a></li>
<li class="chapter" data-level="2.9" data-path="data-description.html"><a href="data-description.html#pie-chart-pie"><i class="fa fa-check"></i><b>2.9</b> Pie chart (pie)</a></li>
<li class="chapter" data-level="2.10" data-path="data-description.html"><a href="data-description.html#ordinal-categorical-variables"><i class="fa fa-check"></i><b>2.10</b> Ordinal categorical variables</a></li>
<li class="chapter" data-level="2.11" data-path="data-description.html"><a href="data-description.html#accumulated-absolute-and-relative-frequencies"><i class="fa fa-check"></i><b>2.11</b> Accumulated absolute and relative frequencies</a></li>
<li class="chapter" data-level="2.12" data-path="data-description.html"><a href="data-description.html#cumulative-frequency-graph"><i class="fa fa-check"></i><b>2.12</b> Cumulative frequency graph</a></li>
<li class="chapter" data-level="2.13" data-path="data-description.html"><a href="data-description.html#numeric-variables"><i class="fa fa-check"></i><b>2.13</b> Numeric variables</a></li>
<li class="chapter" data-level="2.14" data-path="data-description.html"><a href="data-description.html#transforming-continuous-data"><i class="fa fa-check"></i><b>2.14</b> Transforming continuous data</a></li>
<li class="chapter" data-level="2.15" data-path="data-description.html"><a href="data-description.html#frequency-table-for-a-continuous-variable"><i class="fa fa-check"></i><b>2.15</b> Frequency table for a continuous variable</a></li>
<li class="chapter" data-level="2.16" data-path="data-description.html"><a href="data-description.html#histogram"><i class="fa fa-check"></i><b>2.16</b> Histogram</a></li>
<li class="chapter" data-level="2.17" data-path="data-description.html"><a href="data-description.html#cumulative-frequency-graph-1"><i class="fa fa-check"></i><b>2.17</b> Cumulative frequency graph</a></li>
<li class="chapter" data-level="2.18" data-path="data-description.html"><a href="data-description.html#summary-statistics"><i class="fa fa-check"></i><b>2.18</b> Summary Statistics</a></li>
<li class="chapter" data-level="2.19" data-path="data-description.html"><a href="data-description.html#average-sample-mean"><i class="fa fa-check"></i><b>2.19</b> Average (sample mean)</a></li>
<li class="chapter" data-level="2.20" data-path="data-description.html"><a href="data-description.html#median"><i class="fa fa-check"></i><b>2.20</b> Median</a></li>
<li class="chapter" data-level="2.21" data-path="data-description.html"><a href="data-description.html#dispersion"><i class="fa fa-check"></i><b>2.21</b> Dispersion</a></li>
<li class="chapter" data-level="2.22" data-path="data-description.html"><a href="data-description.html#sample-variance"><i class="fa fa-check"></i><b>2.22</b> Sample variance</a></li>
<li class="chapter" data-level="2.23" data-path="data-description.html"><a href="data-description.html#interquartile-range-iqr"><i class="fa fa-check"></i><b>2.23</b> Interquartile range (IQR)</a></li>
<li class="chapter" data-level="2.24" data-path="data-description.html"><a href="data-description.html#boxplot"><i class="fa fa-check"></i><b>2.24</b> Boxplot</a></li>
<li class="chapter" data-level="2.25" data-path="data-description.html"><a href="data-description.html#questions"><i class="fa fa-check"></i><b>2.25</b> Questions</a></li>
<li class="chapter" data-level="2.26" data-path="data-description.html"><a href="data-description.html#exercises"><i class="fa fa-check"></i><b>2.26</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>3</b> Probability</a>
<ul>
<li class="chapter" data-level="3.1" data-path="probability.html"><a href="probability.html#random-experiments-1"><i class="fa fa-check"></i><b>3.1</b> Random experiments</a></li>
<li class="chapter" data-level="3.2" data-path="probability.html"><a href="probability.html#measurement-probability"><i class="fa fa-check"></i><b>3.2</b> Measurement probability</a></li>
<li class="chapter" data-level="3.3" data-path="probability.html"><a href="probability.html#classical-probability"><i class="fa fa-check"></i><b>3.3</b> Classical probability</a></li>
<li class="chapter" data-level="3.4" data-path="probability.html"><a href="probability.html#relative-frequencies-1"><i class="fa fa-check"></i><b>3.4</b> Relative frequencies</a></li>
<li class="chapter" data-level="3.5" data-path="probability.html"><a href="probability.html#relative-frequencies-at-infinity"><i class="fa fa-check"></i><b>3.5</b> Relative frequencies at infinity</a></li>
<li class="chapter" data-level="3.6" data-path="probability.html"><a href="probability.html#frequentist-probability"><i class="fa fa-check"></i><b>3.6</b> Frequentist probability</a></li>
<li class="chapter" data-level="3.7" data-path="probability.html"><a href="probability.html#classical-and-frequentist-probabilities"><i class="fa fa-check"></i><b>3.7</b> Classical and frequentist probabilities</a></li>
<li class="chapter" data-level="3.8" data-path="probability.html"><a href="probability.html#definition-of-probability"><i class="fa fa-check"></i><b>3.8</b> Definition of probability</a></li>
<li class="chapter" data-level="3.9" data-path="probability.html"><a href="probability.html#probabilities-table"><i class="fa fa-check"></i><b>3.9</b> Probabilities Table</a></li>
<li class="chapter" data-level="3.10" data-path="probability.html"><a href="probability.html#sample-space"><i class="fa fa-check"></i><b>3.10</b> Sample space</a></li>
<li class="chapter" data-level="3.11" data-path="probability.html"><a href="probability.html#events"><i class="fa fa-check"></i><b>3.11</b> Events</a></li>
<li class="chapter" data-level="3.12" data-path="probability.html"><a href="probability.html#algebra-of-events"><i class="fa fa-check"></i><b>3.12</b> Algebra of events</a></li>
<li class="chapter" data-level="3.13" data-path="probability.html"><a href="probability.html#mutually-exclusive-results"><i class="fa fa-check"></i><b>3.13</b> Mutually exclusive results</a></li>
<li class="chapter" data-level="3.14" data-path="probability.html"><a href="probability.html#joint-probabilities"><i class="fa fa-check"></i><b>3.14</b> Joint probabilities</a></li>
<li class="chapter" data-level="3.15" data-path="probability.html"><a href="probability.html#contingency-table"><i class="fa fa-check"></i><b>3.15</b> Contingency table</a></li>
<li class="chapter" data-level="3.16" data-path="probability.html"><a href="probability.html#the-addition-rule"><i class="fa fa-check"></i><b>3.16</b> The addition rule:</a></li>
<li class="chapter" data-level="3.17" data-path="probability.html"><a href="probability.html#questions-1"><i class="fa fa-check"></i><b>3.17</b> Questions</a></li>
<li class="chapter" data-level="3.18" data-path="probability.html"><a href="probability.html#exercises-1"><i class="fa fa-check"></i><b>3.18</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="conditional-probability.html"><a href="conditional-probability.html"><i class="fa fa-check"></i><b>4</b> Conditional probability</a>
<ul>
<li class="chapter" data-level="4.1" data-path="conditional-probability.html"><a href="conditional-probability.html#joint-probability"><i class="fa fa-check"></i><b>4.1</b> Joint probability</a></li>
<li class="chapter" data-level="4.2" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-independence"><i class="fa fa-check"></i><b>4.2</b> Statistical independence</a></li>
<li class="chapter" data-level="4.3" data-path="conditional-probability.html"><a href="conditional-probability.html#the-conditional-probability"><i class="fa fa-check"></i><b>4.3</b> The conditional probability</a></li>
<li class="chapter" data-level="4.4" data-path="conditional-probability.html"><a href="conditional-probability.html#conditional-contingency-table"><i class="fa fa-check"></i><b>4.4</b> Conditional contingency table</a></li>
<li class="chapter" data-level="4.5" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-independence-1"><i class="fa fa-check"></i><b>4.5</b> Statistical independence</a></li>
<li class="chapter" data-level="4.6" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-dependency"><i class="fa fa-check"></i><b>4.6</b> Statistical dependency</a></li>
<li class="chapter" data-level="4.7" data-path="conditional-probability.html"><a href="conditional-probability.html#diagnostic-test"><i class="fa fa-check"></i><b>4.7</b> Diagnostic test</a></li>
<li class="chapter" data-level="4.8" data-path="conditional-probability.html"><a href="conditional-probability.html#inverse-probabilities"><i class="fa fa-check"></i><b>4.8</b> Inverse probabilities</a></li>
<li class="chapter" data-level="4.9" data-path="conditional-probability.html"><a href="conditional-probability.html#bayes-theorem"><i class="fa fa-check"></i><b>4.9</b> Bayes’ Theorem</a></li>
<li class="chapter" data-level="4.10" data-path="conditional-probability.html"><a href="conditional-probability.html#questions-2"><i class="fa fa-check"></i><b>4.10</b> Questions</a></li>
<li class="chapter" data-level="4.11" data-path="conditional-probability.html"><a href="conditional-probability.html#exercises-2"><i class="fa fa-check"></i><b>4.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html"><i class="fa fa-check"></i><b>5</b> Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="5.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#objective-1"><i class="fa fa-check"></i><b>5.1</b> Objective</a></li>
<li class="chapter" data-level="5.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#relative-frequencies-2"><i class="fa fa-check"></i><b>5.2</b> Relative frequencies</a></li>
<li class="chapter" data-level="5.3" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#random-variable"><i class="fa fa-check"></i><b>5.3</b> Random variable</a></li>
<li class="chapter" data-level="5.4" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#events-of-observing-a-random-variable"><i class="fa fa-check"></i><b>5.4</b> Events of observing a random variable</a></li>
<li class="chapter" data-level="5.5" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-of-random-variables"><i class="fa fa-check"></i><b>5.5</b> Probability of random variables</a></li>
<li class="chapter" data-level="5.6" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-functions"><i class="fa fa-check"></i><b>5.6</b> Probability functions</a></li>
<li class="chapter" data-level="5.7" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-functions-1"><i class="fa fa-check"></i><b>5.7</b> Probability functions</a></li>
<li class="chapter" data-level="5.8" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probabilities-and-relative-frequencies"><i class="fa fa-check"></i><b>5.8</b> Probabilities and relative frequencies</a></li>
<li class="chapter" data-level="5.9" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#mean-or-expected-value"><i class="fa fa-check"></i><b>5.9</b> Mean or expected value</a></li>
<li class="chapter" data-level="5.10" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#variance"><i class="fa fa-check"></i><b>5.10</b> Variance</a></li>
<li class="chapter" data-level="5.11" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-functions-for-functions-of-x"><i class="fa fa-check"></i><b>5.11</b> Probability functions for functions of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="5.12" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-distribution"><i class="fa fa-check"></i><b>5.12</b> Probability distribution</a></li>
<li class="chapter" data-level="5.13" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-function-and-probability-distribution"><i class="fa fa-check"></i><b>5.13</b> Probability function and probability distribution</a></li>
<li class="chapter" data-level="5.14" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#quantiles"><i class="fa fa-check"></i><b>5.14</b> Quantiles</a></li>
<li class="chapter" data-level="5.15" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#summary"><i class="fa fa-check"></i><b>5.15</b> Summary</a></li>
<li class="chapter" data-level="5.16" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#questions-3"><i class="fa fa-check"></i><b>5.16</b> Questions</a></li>
<li class="chapter" data-level="5.17" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#exercises-3"><i class="fa fa-check"></i><b>5.17</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="continous-random-variables.html"><a href="continous-random-variables.html"><i class="fa fa-check"></i><b>6</b> Continous Random Variables</a>
<ul>
<li class="chapter" data-level="6.1" data-path="continous-random-variables.html"><a href="continous-random-variables.html#objective-2"><i class="fa fa-check"></i><b>6.1</b> Objective</a></li>
<li class="chapter" data-level="6.2" data-path="continous-random-variables.html"><a href="continous-random-variables.html#continuous-random-variables"><i class="fa fa-check"></i><b>6.2</b> Continuous random variables</a></li>
<li class="chapter" data-level="6.3" data-path="continous-random-variables.html"><a href="continous-random-variables.html#relative-frequencies-3"><i class="fa fa-check"></i><b>6.3</b> relative frequencies</a></li>
<li class="chapter" data-level="6.4" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-density-function"><i class="fa fa-check"></i><b>6.4</b> probability density function</a></li>
<li class="chapter" data-level="6.5" data-path="continous-random-variables.html"><a href="continous-random-variables.html#total-area-under-the-curve"><i class="fa fa-check"></i><b>6.5</b> Total area under the curve</a></li>
<li class="chapter" data-level="6.6" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probabilities-of-continous-variables"><i class="fa fa-check"></i><b>6.6</b> Probabilities of continous variables</a></li>
<li class="chapter" data-level="6.7" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-distribution-1"><i class="fa fa-check"></i><b>6.7</b> Probability distribution</a></li>
<li class="chapter" data-level="6.8" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-plots"><i class="fa fa-check"></i><b>6.8</b> Probability plots</a></li>
<li class="chapter" data-level="6.9" data-path="continous-random-variables.html"><a href="continous-random-variables.html#mean"><i class="fa fa-check"></i><b>6.9</b> Mean</a></li>
<li class="chapter" data-level="6.10" data-path="continous-random-variables.html"><a href="continous-random-variables.html#variance-1"><i class="fa fa-check"></i><b>6.10</b> Variance</a></li>
<li class="chapter" data-level="6.11" data-path="continous-random-variables.html"><a href="continous-random-variables.html#functions-of-x"><i class="fa fa-check"></i><b>6.11</b> Functions of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="6.12" data-path="continous-random-variables.html"><a href="continous-random-variables.html#exercises-4"><i class="fa fa-check"></i><b>6.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html"><i class="fa fa-check"></i><b>7</b> Discrete Probability Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#objective-3"><i class="fa fa-check"></i><b>7.1</b> Objective</a></li>
<li class="chapter" data-level="7.2" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#probability-mass-function"><i class="fa fa-check"></i><b>7.2</b> Probability mass function</a></li>
<li class="chapter" data-level="7.3" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#probability-model"><i class="fa fa-check"></i><b>7.3</b> Probability model</a></li>
<li class="chapter" data-level="7.4" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#parametric-models"><i class="fa fa-check"></i><b>7.4</b> Parametric models</a></li>
<li class="chapter" data-level="7.5" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#uniform-distribution-one-parameter"><i class="fa fa-check"></i><b>7.5</b> Uniform distribution (one parameter)</a></li>
<li class="chapter" data-level="7.6" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#uniform-distribution-two-parameters"><i class="fa fa-check"></i><b>7.6</b> Uniform distribution (two parameters)</a></li>
<li class="chapter" data-level="7.7" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#bernoulli-trial"><i class="fa fa-check"></i><b>7.7</b> Bernoulli trial</a></li>
<li class="chapter" data-level="7.8" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#binomial-experiment"><i class="fa fa-check"></i><b>7.8</b> Binomial experiment</a></li>
<li class="chapter" data-level="7.9" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#binomial-probability-function"><i class="fa fa-check"></i><b>7.9</b> Binomial probability function</a></li>
<li class="chapter" data-level="7.10" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#negative-binomial-probability-function"><i class="fa fa-check"></i><b>7.10</b> Negative binomial probability function</a></li>
<li class="chapter" data-level="7.11" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#geometric-distribution"><i class="fa fa-check"></i><b>7.11</b> Geometric distribution</a></li>
<li class="chapter" data-level="7.12" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#hypergeometric-model"><i class="fa fa-check"></i><b>7.12</b> Hypergeometric model</a></li>
<li class="chapter" data-level="7.13" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#questions-4"><i class="fa fa-check"></i><b>7.13</b> Questions</a></li>
<li class="chapter" data-level="7.14" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#exercises-5"><i class="fa fa-check"></i><b>7.14</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html"><i class="fa fa-check"></i><b>8</b> Poisson and Exponential Models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#objective-4"><i class="fa fa-check"></i><b>8.1</b> Objective</a></li>
<li class="chapter" data-level="8.2" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#discrete-probability-models-1"><i class="fa fa-check"></i><b>8.2</b> Discrete probability models</a></li>
<li class="chapter" data-level="8.3" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#poissson-experiment"><i class="fa fa-check"></i><b>8.3</b> Poissson experiment</a></li>
<li class="chapter" data-level="8.4" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#poisson-probability-mass-function"><i class="fa fa-check"></i><b>8.4</b> Poisson probability mass function</a></li>
<li class="chapter" data-level="8.5" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#continuous-probability-models"><i class="fa fa-check"></i><b>8.5</b> Continuous probability models</a></li>
<li class="chapter" data-level="8.6" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-process"><i class="fa fa-check"></i><b>8.6</b> Exponential process</a></li>
<li class="chapter" data-level="8.7" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-probability-density"><i class="fa fa-check"></i><b>8.7</b> Exponential probability density</a></li>
<li class="chapter" data-level="8.8" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-distribution"><i class="fa fa-check"></i><b>8.8</b> Exponential Distribution</a></li>
<li class="chapter" data-level="8.9" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#questions-5"><i class="fa fa-check"></i><b>8.9</b> Questions</a></li>
<li class="chapter" data-level="8.10" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exercises-6"><i class="fa fa-check"></i><b>8.10</b> Exercises</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">EEBE stats</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="discrete-probability-models" class="section level1 hasAnchor" number="7">
<h1><span class="header-section-number">Chapter 7</span> Discrete Probability Models<a href="discrete-probability-models.html#discrete-probability-models" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="objective-3" class="section level2 hasAnchor" number="7.1">
<h2><span class="header-section-number">7.1</span> Objective<a href="discrete-probability-models.html#objective-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this chapter we will see some probability mass functions that are used to describe common random experiments.</p>
<p>We will introduce the concept of parameter and thus parametric models.</p>
<p>In particular, we will discuss the uniform and Bernoulli probability functions and how they are used to derive the binomial and negative binomial probability functions.</p>
</div>
<div id="probability-mass-function" class="section level2 hasAnchor" number="7.2">
<h2><span class="header-section-number">7.2</span> Probability mass function<a href="discrete-probability-models.html#probability-mass-function" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let us remenber that a probability mass function of a <strong>discrete random variable</strong> <span class="math inline">\(X\)</span> with possible values <span class="math inline">\(x_1 , x_2 , .. , x_M\)</span> is <strong>any function</strong> such that</p>
<ol style="list-style-type: decimal">
<li>It Allows us to compute probabilities for all outcomes</li>
</ol>
<p><span class="math display">\[f(x_i)=P(X=x_i)\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>It is always positive:</li>
</ol>
<p><span class="math display">\[f(x_i)\geq 0\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>The probability of of obtaining anything in the random experiment is <span class="math inline">\(1\)</span></li>
</ol>
<p><span class="math display">\[\sum_{i=1}^M f(x_i)=1\]</span></p>
<p>We studied two important <strong>properties:</strong></p>
<ol style="list-style-type: decimal">
<li>The mean as a measure of central tendency:</li>
</ol>
<p><span class="math display">\[E(X)= \sum_{i=1}^M x_i f(x_i)\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>The variance as a measure of dispersion:</li>
</ol>
<p><span class="math display">\[V(X)= \sum_{i=1}^M (x_i-\mu)^2 f(x_i)\]</span></p>
</div>
<div id="probability-model" class="section level2 hasAnchor" number="7.3">
<h2><span class="header-section-number">7.3</span> Probability model<a href="discrete-probability-models.html#probability-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A <strong>probability model</strong> is a probability mass function that may represent the probabilities of a random experiment.</p>
<p><strong>Examples:</strong></p>
<ol style="list-style-type: decimal">
<li>The probability mass function defined by</li>
</ol>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(X\)</span></th>
<th align="center"><span class="math inline">\(f(x)\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(-2\)</span></td>
<td align="center"><span class="math inline">\(1/8\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(-1\)</span></td>
<td align="center"><span class="math inline">\(2/8\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(0\)</span></td>
<td align="center"><span class="math inline">\(2/8\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(1\)</span></td>
<td align="center"><span class="math inline">\(2/8\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(2\)</span></td>
<td align="center"><span class="math inline">\(1/8\)</span></td>
</tr>
</tbody>
</table>
<p>Represents the probability of drawing <strong>one</strong> ball from an urn where there are two balls with labels: <span class="math inline">\(-1, 0, 1\)</span> and one ball with labels: <span class="math inline">\(-2, 2\)</span>.</p>
<ol start="2" style="list-style-type: decimal">
<li><span class="math inline">\(f(x)=P(X=x)=1/6\)</span> represents the probability of the outcomes of <strong>one</strong> throw of a dice.</li>
</ol>
</div>
<div id="parametric-models" class="section level2 hasAnchor" number="7.4">
<h2><span class="header-section-number">7.4</span> Parametric models<a href="discrete-probability-models.html#parametric-models" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>When we have a random experiment with <span class="math inline">\(M\)</span> possible outcomes, we need to find <span class="math inline">\(M\)</span> numbers to determine the probability mass function. As in the previous example 1, we needed <span class="math inline">\(5\)</span> values in the column <span class="math inline">\(f(x)\)</span> of the probability table.</p>
<p>However, <strong>in many cases</strong>, we can formulate probability functions <span class="math inline">\(f(x)\)</span> that depend on <strong>very few</strong> numbers only. As in the previous example 2, we only needed to know how many possible outcomes the throw of a dice has.</p>
<p><strong>Example (classical probability):</strong></p>
<p>A random experiment with <span class="math inline">\(M\)</span> equally likely outcomes has a probability mass function:
<span class="math display">\[f(x)=P(X=x)=1/M\]</span></p>
<p>We only need to know <span class="math inline">\(M\)</span>.</p>
<p>The numbers we <strong>need to know</strong> to fully determine a probability function are called <strong>parameters</strong>.</p>
</div>
<div id="uniform-distribution-one-parameter" class="section level2 hasAnchor" number="7.5">
<h2><span class="header-section-number">7.5</span> Uniform distribution (one parameter)<a href="discrete-probability-models.html#uniform-distribution-one-parameter" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The previous example is the classical interpretation of probability, and defines our first parametric model.</p>
<p><strong>Definition</strong></p>
<p>A random variable <span class="math inline">\(X\)</span> with outcomes <span class="math inline">\(\{1,...M\}\)</span> has a discrete <strong>uniform distribution</strong> if all its <span class="math inline">\(M\)</span> outcomes have the same probability</p>
<p><span class="math display">\[f(x)=\frac{1}{M}\]</span></p>
<p><span class="math inline">\(M\)</span> is the natural parameter of the model. Once we define <span class="math inline">\(M\)</span> for an experiment, we choose a particular probability mass function. The function above is really a family of functions that depend on <span class="math inline">\(M\)</span>: <span class="math inline">\(f(x; M)\)</span>.</p>
<p>The mean and variance of a variable that follows a uniform distribution are:</p>
<p><span class="math display">\[E(X)= \frac{M+1}{2}\]</span></p>
<p>and</p>
<p><span class="math display">\[V(X)= \frac{M^2-1}{12}\]</span></p>
<p>Note: <span class="math inline">\(E(X)\)</span> and <span class="math inline">\(V(X)\)</span> are also <strong>parameters</strong>. If we know any of them then we can fully determine the distribution. For instance:</p>
<p><span class="math display">\[f(x)=\frac{1}{2E(X)-1}\]</span>
Let’s look at some probability mass functions in the family of uniform parametric models:</p>
<p><img src="_main_files/figure-html/unnamed-chunk-53-1.png" width="672" /></p>
</div>
<div id="uniform-distribution-two-parameters" class="section level2 hasAnchor" number="7.6">
<h2><span class="header-section-number">7.6</span> Uniform distribution (two parameters)<a href="discrete-probability-models.html#uniform-distribution-two-parameters" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let’s introduce a new <strong>uniform</strong> probability model with <strong>two parameters</strong>: The minimum and maximum outcomes.</p>
<p>If the random variable takes values in <span class="math inline">\(\{a, a+1, ...b\}\)</span>, where <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> are integers and all the outcomes are equally probable then</p>
<p><span class="math display">\[f(x)=\frac{1}{b-a+1}\]</span></p>
<p>as <span class="math inline">\(M=b-a+1\)</span>.</p>
<p>We then say that <span class="math inline">\(X\)</span> distributes uniformly between <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> and write</p>
<p><span class="math display">\[X \rightarrow Unif(a,b)\]</span></p>
<p><strong>Properties:</strong></p>
<p>If <span class="math inline">\(X\)</span> distributes uniformly between <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span></p>
<p><span class="math display">\[X \rightarrow Unif(a,b)\]</span></p>
<ol style="list-style-type: decimal">
<li>Its mean is</li>
</ol>
<p><span class="math display">\[E(X)= \frac{b+a}{2}\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Its variance is</li>
</ol>
<p><span class="math display">\[V(X)= \frac{(b-a+1)^2-1}{12}\]</span></p>
<p>To prove this change variables <span class="math inline">\(X=Y+a-1\)</span>, <span class="math inline">\(y \in \{1,...M\}\)</span>.</p>
<p><strong>Probability mass functions</strong></p>
<p>Let’s look at some probability mass functions in the family of uniform parametric models:</p>
<p><img src="_main_files/figure-html/unnamed-chunk-54-1.png" width="672" /></p>
<p><strong>Example (school classes):</strong></p>
<p>What is the probability of observing a child of a particular age in a primary school (if all classes have the same amount of children)?</p>
<p>From the set up of the experiment we know: <span class="math inline">\(a=6\)</span> and <span class="math inline">\(b=11\)</span> then</p>
<p><span class="math display">\[X \rightarrow Unif(a=6, b=11)\]</span> that is</p>
<p><span class="math display">\[f(x)=\frac{1}{6}\]</span> for <span class="math inline">\(x\in \{6,7,8,9,10,11\}\)</span>, and <span class="math inline">\(0\)</span> otherwise.</p>
<p>The mean and variance for this probability mass function is:</p>
<ul>
<li><span class="math inline">\(E(X)=8.5\)</span></li>
<li><span class="math inline">\(V(X)=2.916667\)</span></li>
</ul>
<p>Remember that</p>
<ul>
<li><p>The expected value is the <strong>mean</strong> <span class="math inline">\(\mu=8.5\)</span></p></li>
<li><p>The <strong>standard deviation</strong> <span class="math inline">\(\sigma=1.707825\)</span> is the average distance from the mean and is computed from the square root of the variance.</p></li>
</ul>
<p><img src="_main_files/figure-html/unnamed-chunk-55-1.png" width="672" /></p>
<p><strong>Parameters and Models:</strong></p>
<p>A <strong>model</strong> is a particular function <span class="math inline">\(f(x)\)</span> that <strong>describes</strong> our experiment.</p>
<p>If the model is a <strong>known</strong> function that depends on a few parameters then changing the value of the parameters we produce a <strong>family of models</strong>: <span class="math inline">\(f(x; a,b)\)</span>.</p>
<p>Knowledge of <span class="math inline">\(f(x)\)</span> is reduced to the knowledge of the value of the parameters <span class="math inline">\(a\)</span>, <span class="math inline">\(b\)</span>.</p>
<p>Ideally, the model and the parameters are <strong>interpretable</strong>.</p>
<p>In our example, <span class="math inline">\(a\)</span> represents the the minimum age at school and <span class="math inline">\(b\)</span> the maximum age. They can be considered as the <strong>physical properties</strong> of the experiment.</p>
</div>
<div id="bernoulli-trial" class="section level2 hasAnchor" number="7.7">
<h2><span class="header-section-number">7.7</span> Bernoulli trial<a href="discrete-probability-models.html#bernoulli-trial" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let’s try to advance from the equal probability case and suppose a model with only two possible outcomes (<span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>) that have <strong>unequal</strong> probabilities</p>
<p><strong>Examples:</strong></p>
<ul>
<li><p>Writing down the sex of a patient who goes into an emergency room of a hospital (<span class="math inline">\(A:male\)</span> and <span class="math inline">\(B:female\)</span>).</p></li>
<li><p>Recording whether a manufactured machine is defective or not (<span class="math inline">\(A:defective\)</span> and <span class="math inline">\(B:not \,\, defective\)</span>).</p></li>
<li><p>Hitting a target (<span class="math inline">\(A:success\)</span> and <span class="math inline">\(B:failure\)</span>).</p></li>
<li><p>Transmitting one pixel correctly (<span class="math inline">\(A:yes\)</span> and <span class="math inline">\(B:no\)</span>).</p></li>
</ul>
<p>In these examples, the probability of outcome <span class="math inline">\(A\)</span> is usually <strong>unknown</strong>.</p>
<p><strong>Probability model:</strong></p>
<p>We will introduce the probability of an outcome (<span class="math inline">\(A\)</span>) as the <strong>parameter</strong> of the model. The model can be written in different forms</p>
<ol style="list-style-type: decimal">
<li>As a probability table:</li>
</ol>
<table>
<thead>
<tr class="header">
<th align="center"><span class="math inline">\(Outcome\)</span></th>
<th align="center"><span class="math inline">\(P_i\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(A\)</span></td>
<td align="center"><span class="math inline">\(p\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(B\)</span></td>
<td align="center"><span class="math inline">\(1-p\)</span></td>
</tr>
</tbody>
</table>
<ul>
<li><span class="math inline">\(i \in \{A,B\}\)</span></li>
<li>outcome A (success): has probability <span class="math inline">\(p\)</span> (parameter)</li>
<li>outcome B (failure): has a probability <span class="math inline">\(1-p\)</span></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>As a probability mass function of the random variable <span class="math inline">\(K\)</span> taking values <span class="math inline">\(\{0, 1\}\)</span> for <span class="math inline">\(B\)</span> and <span class="math inline">\(A\)</span>, respectively.</li>
</ol>
<p><span class="math display">\[
    f(k)=
\begin{cases}
    1-p,&amp;  k=0\, (event\, B)\\
    p,&amp; k=1\, (event\, A)
\end{cases}
\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>As a concise probability mass function</li>
</ol>
<p><span class="math display">\[f(k; p)=p^k(1-p)^{1-k} \]</span></p>
<p>for <span class="math inline">\(k=(0,1)\)</span>.</p>
<p>We then say that <span class="math inline">\(X\)</span> follows a Bernoulli distribution with parameter <span class="math inline">\(p\)</span>
<span class="math display">\[X \rightarrow Bernoulli(p)\]</span></p>
<p><strong>Properties:</strong></p>
<p>If <span class="math inline">\(X\)</span> follows a Bernoulli distribution then</p>
<ol style="list-style-type: decimal">
<li>its mean is</li>
</ol>
<p><span class="math display">\[E(K)=p\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>its variance is</li>
</ol>
<p><span class="math display">\[V(K)=(1-p)p\]</span></p>
<p>Note that the probability of the outcome <span class="math inline">\(A\)</span> is the parameter <span class="math inline">\(p\)</span>
which is the same as its value at <span class="math inline">\(1\)</span>: <span class="math inline">\(f(1)=P(X=1)\)</span>. The parameter fully determines the probability mass function, including its mean and variance.</p>
<p>Let’s look at some probability mass functions in the family of uniform parametric models:</p>
<p><img src="_main_files/figure-html/unnamed-chunk-56-1.png" width="672" /></p>
</div>
<div id="binomial-experiment" class="section level2 hasAnchor" number="7.8">
<h2><span class="header-section-number">7.8</span> Binomial experiment<a href="discrete-probability-models.html#binomial-experiment" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>When we are interested in predicting <strong>absolute frequencies</strong> when we know the parameter <span class="math inline">\(p\)</span> of particular Bernoulli trial, we</p>
<ol style="list-style-type: decimal">
<li><p><strong>repeat</strong> the Bernoulli trial <span class="math inline">\(n\)</span> times and count how many times we obtained <span class="math inline">\(A\)</span> using the absolute frequency of <span class="math inline">\(A\)</span>: <span class="math inline">\(N_A\)</span>.</p></li>
<li><p>define a <strong>random variable</strong> <span class="math inline">\(X=N_A\)</span> taking values <span class="math inline">\(x \in {0,1,...n}\)</span></p></li>
</ol>
<p>When we repeat <span class="math inline">\(n\)</span> times a Bernoulli trial, we obtain one value for <span class="math inline">\(n_A\)</span>. If we perform other <span class="math inline">\(n\)</span> Bernoulli trials then <span class="math inline">\(n_A\)</span> changes its value. Therefore, <span class="math inline">\(X=N_A\)</span> is a random variable and <span class="math inline">\(x=n_A\)</span> is its observation.</p>
<p><strong>Examples (Some binomial experiments):</strong></p>
<ul>
<li><p>Writing down the sex of <span class="math inline">\(n=10\)</span> patients who go into an emergency room of a hospital. What is the probability that <span class="math inline">\(X=9\)</span> patients are men when <span class="math inline">\(p=0.8\)</span>?</p></li>
<li><p>Trying <span class="math inline">\(n=5\)</span> times to hit a target (<span class="math inline">\(A:success\)</span> and <span class="math inline">\(B:failure\)</span>). What is the probability that I hit the target <span class="math inline">\(X=5\)</span> times when I usually hit it <span class="math inline">\(25\%\)</span> of the times (<span class="math inline">\(p=0.25\)</span>)?</p></li>
<li><p>Transmitting <span class="math inline">\(n=100\)</span> pixels correctly (<span class="math inline">\(A:yes\)</span> and <span class="math inline">\(B:no\)</span>). What is the probability that <span class="math inline">\(X=2\)</span> pixels are errors, when the probability of error is <span class="math inline">\(p=0.1\)</span>?</p></li>
</ul>
</div>
<div id="binomial-probability-function" class="section level2 hasAnchor" number="7.9">
<h2><span class="header-section-number">7.9</span> Binomial probability function<a href="discrete-probability-models.html#binomial-probability-function" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let us suppose that <strong>we know</strong> the real value of the parameter of the Bernoulli trial <span class="math inline">\(p\)</span>.</p>
<p>When we repeat a Bernoulli trial and stop at <span class="math inline">\(n\)</span>, is the value <span class="math inline">\(x\)</span> that we obtain common or rare? what is its probability mass function <span class="math inline">\(P(X=x)=f(x)\)</span>?</p>
<p><strong>Example (transmission of pixels):</strong></p>
<p>What is the probability of observing <span class="math inline">\(X=x\)</span> errors when transmitting <span class="math inline">\(n=4\)</span> pixels, if the probability of an error is <span class="math inline">\(p\)</span>?</p>
<p>Let us consider that</p>
<ol style="list-style-type: decimal">
<li><p>A random variable of the <strong>transmission experiment</strong> is the vector <span class="math display">\[(K_1, K_2, K_3, K_4)\]</span> where one observation may be <span class="math inline">\((K_1=0, K_2=1, K_3=0, K_4=1)\)</span> or <span class="math inline">\((0, 1, 0, 1)\)</span>.</p></li>
<li><p>Each <span class="math display">\[K_i \rightarrow Bernoulli(p)\]</span> <span class="math inline">\(k_i \in \{0, 1\}\)</span></p></li>
<li><p><span class="math inline">\(X=N_A\)</span> can be computed as the sum <span class="math display">\[X=\sum_{i=1}^4 K_i\]</span> <span class="math inline">\(x\in \{0,1,2,3,4\}\)</span>. For example <span class="math inline">\(X=2\)</span> for the outcome <span class="math inline">\((0, 1, 0, 1)\)</span>.</p></li>
</ol>
<p>Now let’s see the probabilities of some <strong>error events</strong> and then we will generalize them.</p>
<ol style="list-style-type: decimal">
<li>What is the probability of observing <span class="math inline">\(4\)</span> <strong>errors</strong>?</li>
</ol>
<p>The probability of observing <span class="math inline">\(4\)</span> errors is the probability of observing an error in the <span class="math inline">\(1^{st}\)</span> <strong>and</strong> <span class="math inline">\(2^{nd}\)</span> <strong>and</strong> <span class="math inline">\(3^{rd}\)</span> <strong>and</strong> <span class="math inline">\(4^{th}\)</span> pixel:</p>
<p><span class="math display">\[P(X=4)=P(1,1,1,1)=p*p*p*p=p^4\]</span></p>
<p>because <span class="math inline">\(K_i\)</span> are <strong>independent</strong>.</p>
<ol start="2" style="list-style-type: decimal">
<li>What is the probability of observing <span class="math inline">\(0\)</span> <strong>errors</strong>?</li>
</ol>
<p>The probability of <span class="math inline">\(0\)</span> errors is the joint probability of observing <strong>no error</strong> in <strong>any</strong> transmission:</p>
<p><span class="math display">\[P(X=0)=P(0,0,0,0)=(1-p)(1-p)(1-p)(1-p)=(1-p)^4\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>What is the probability of observing <span class="math inline">\(3\)</span> <strong>errors</strong>?</li>
</ol>
<p>The probability of <span class="math inline">\(3\)</span> errors is the <strong>addition</strong> of probability of observing <span class="math inline">\(3\)</span> errors in <strong>different events</strong>:</p>
<p><span class="math display">\[P(X=3)=P(0,1,1,1)+P(1,0,1,1)+P(1,1,0,1)+P(1,1,1,0)=4p^3(1-p)^1\]</span>
because all off these events are <strong>mutually exclusive</strong>.</p>
<ol start="4" style="list-style-type: decimal">
<li>Therefore the probability of <span class="math inline">\(x\)</span> <strong>errors</strong> is</li>
</ol>
<p><span class="math display">\[
    f(x)=
\begin{cases}
    1*p^0(1-p)^4,&amp;  x=0 \\
    4*p^1(1-p)^3,&amp;  x=1 \\
    6*p^2(1-p)^2,&amp;  x=2 \\
    4*p^3(1-p)^1,&amp;  x=3 \\
    1*p^4(1-p)^0,&amp;  x=4 \\
\end{cases}
\]</span></p>
<p>or more shortly</p>
<p><span class="math display">\[f(x)=\binom 4 x p^x(1-p)^{4-x}\]</span>
for <span class="math inline">\(x=0,1,2,3,4\)</span></p>
<p>where <span class="math inline">\(\binom 4 x\)</span> is the number of <strong>possible outcomes</strong> (transmissions of <span class="math inline">\(4\)</span> pixels) with <span class="math inline">\(x\)</span> errors.</p>
<p><strong>Definition:</strong></p>
<p>The <strong>binomial probability</strong> function is the probability mass function of observing <span class="math inline">\(x\)</span> outcomes of type <span class="math inline">\(A\)</span> in <span class="math inline">\(n\)</span> independent Bernoulli trials, where <span class="math inline">\(A\)</span> has the same probability <span class="math inline">\(p\)</span> in each trial.</p>
<p>The function is given by</p>
<p><span class="math inline">\(f(x)=\binom n x p^x(1-p)^{n-x}\)</span>, <span class="math inline">\(x=0,1,...n\)</span></p>
<p><span class="math inline">\(\binom n x= \frac{n!}{x!(n-x)!}\)</span> is called <strong>the binomial coefficient</strong> and gives the number of ways one can obtain <span class="math inline">\(x\)</span> events of type <span class="math inline">\(A\)</span> in a set of <span class="math inline">\(n\)</span>.</p>
<p>When a variable <span class="math inline">\(X\)</span> has a binomial probability function we say it distributes binomially and write</p>
<p><span class="math display">\[X\rightarrow Bin(n,p)\]</span></p>
<p>where <span class="math inline">\(n\)</span> and <span class="math inline">\(p\)</span> are parameters.</p>
<p>Let’s look at some probability mass functions in the family of binomial parametric models:</p>
<p><img src="_main_files/figure-html/unnamed-chunk-57-1.png" width="672" /></p>
<p><strong>Properties:</strong></p>
<p>If a random variable <span class="math inline">\(X\rightarrow Bin(n,p)\)</span> then</p>
<ol style="list-style-type: decimal">
<li>its mean is</li>
</ol>
<p><span class="math display">\[E(X)=np\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>its variance is</li>
</ol>
<p><span class="math display">\[V(X)=np(1-p)\]</span></p>
<p>These properties can be demonstrated by the fact that <span class="math inline">\(X\)</span> is the sum of <span class="math inline">\(n\)</span> independent Bernoulli variables. Therefore,</p>
<p><span class="math inline">\(E(X)=E(\sum_{i=1}^n K_i)=np\)</span></p>
<p>and</p>
<p><span class="math inline">\(V(X)=V(\sum_{i=1}^n K_i)=n(1-p)p\)</span></p>
<p><strong>Example (transmission of pixels):</strong></p>
<ul>
<li><p>The expected value for the number of errors in the transmission of <span class="math inline">\(4\)</span> pixels is <span class="math inline">\(np=4*0.1=0.4\)</span> when the probability of an error is <span class="math inline">\(0.1\)</span>.</p></li>
<li><p>The variance is <span class="math inline">\(n(1-p)p=0.36\)</span></p></li>
<li><p>What is the probability of observing <span class="math inline">\(4\)</span> errors?</p></li>
</ul>
<p>Since we are repeating a Bernoulli trial <span class="math inline">\(n=4\)</span> times and counting the number of events of type <span class="math inline">\(A\)</span> (errors), when <span class="math inline">\(P(A)=p=0.1\)</span> then</p>
<p><span class="math display">\[X \rightarrow Bin(n=4, p=0.1)\]</span>
That is <span class="math display">\[f(x)=\binom 4 x 0.1^x(1-0.1)^{4-x}\]</span></p>
<p><span class="math inline">\(P(X=4)=f(4)=\binom 4 4 0.1^4 0.9^{0}=0.1^4=10^{-4}\)</span></p>
<p>In R <code>dbinom(4,4,0.1)</code></p>
<ul>
<li>What is the probability of observing <span class="math inline">\(2\)</span> errors?</li>
</ul>
<p><span class="math inline">\(P(X=2)=\binom 4 2 0.1^2 0.9^2=0.0486\)</span></p>
<p>In R <code>dbinom(2,4,0.1)</code></p>
<p><strong>Example (opinion polls):</strong></p>
<ul>
<li>What is the probability of observing <strong>at most</strong> <span class="math inline">\(8\)</span> voters of the ruling party in an election poll of size <span class="math inline">\(10\)</span>, if the probability of a positive vote for the party is <span class="math inline">\(0.9\)</span></li>
</ul>
<p>For this case</p>
<p><span class="math display">\[X \rightarrow Bin(n=10, p=0.9)\]</span></p>
<p>That is <span class="math display">\[f(x)=\binom {10} x 0.9^x(0.1)^{4-x}\]</span></p>
<p>We want to compute:
<span class="math inline">\(P(X\le 8)=F(8)= \sum_{i=1..8} f(x_i)=0.2639011\)</span></p>
<p>in R <code>pbinom(8,10, 0.9)</code></p>
</div>
<div id="negative-binomial-probability-function" class="section level2 hasAnchor" number="7.10">
<h2><span class="header-section-number">7.10</span> Negative binomial probability function<a href="discrete-probability-models.html#negative-binomial-probability-function" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now let us imagine that we are interested in counting the well-transmitted pixels before a <strong>given number</strong> of errors occur. Say we can <strong>tolerate</strong> <span class="math inline">\(r\)</span> errors in transmission.</p>
<p>Our random experiment is now: Repeat Bernoulli trials until we observe the outcome <span class="math inline">\(A\)</span> appears <span class="math inline">\(r\)</span> times.</p>
<p>The outcome of the experiment is the number of events <span class="math inline">\(n_B=y\)</span></p>
<p>We are interested in finding the probability of observing a particular number of events <span class="math inline">\(B\)</span>, <span class="math inline">\(P(Y=y)\)</span>, where <span class="math inline">\(Y=N_B\)</span> is the random variable.</p>
<p><strong>Example (transmission of pixels):</strong></p>
<p>What is the probability of observing <span class="math inline">\(y\)</span> well-transmitted (<span class="math inline">\(B\)</span>) pixels before <span class="math inline">\(r\)</span> errors (<span class="math inline">\(A\)</span>)?</p>
<p>Let’s first find the probability of <strong>one particular</strong> <strong>transmission event</strong> with <span class="math inline">\(y\)</span> number of correct pixels (<span class="math inline">\(B\)</span>) and <span class="math inline">\(r\)</span> number of errors (<span class="math inline">\(A\)</span>).</p>
<p><span class="math display">\[(0,0,1,., 0,1,...0,1)\]</span></p>
<p>where we consider that there are <span class="math inline">\(y\)</span> zeros and <span class="math inline">\(r\)</span> ones. Therefore, we observe <span class="math inline">\(y\)</span> correct pixels in a total of <span class="math inline">\(y + r\)</span> pixels.</p>
<p>The probability of this event is:</p>
<p><span class="math display">\[P(0,0,1,., 0,1,...0,1)=p^r(1-p)^y\]</span></p>
<p>Remember that <span class="math inline">\(p\)</span> is the probability of error (<span class="math inline">\(A\)</span>).</p>
<p>How many <strong>transmissions events</strong> can have <span class="math inline">\(y\)</span> correct pixels (0’s) before <span class="math inline">\(r\)</span> errors (1’s)?</p>
<p>Note that</p>
<ol style="list-style-type: decimal">
<li><p>The last bit is fixed (marks the end of transmission)</p></li>
<li><p>The total number of ways in which <span class="math inline">\(y\)</span> number of zeros can be allocated in <span class="math inline">\(y + r-1\)</span> pixels (the last pixel is fixed with value 1) is: <span class="math inline">\(\binom {y + r-1} y\)</span></p></li>
</ol>
<p>Therefore, the probability of observing <span class="math inline">\(y\)</span> 1’s before <span class="math inline">\(r\)</span> 0’s (each 1 with probability <span class="math inline">\(p\)</span>) is</p>
<p><span class="math display">\[P(Y=y)=f(y)=\binom {y+r-1} y p^r(1-p)^y\]</span></p>
<p>for <span class="math inline">\(y=0,1,...\)</span></p>
<p>We then say that <span class="math inline">\(Y\)</span> follows a negative binomial distribution and we write</p>
<p><span class="math display">\[Y\rightarrow NB(r,p)\]</span></p>
<p>where <span class="math inline">\(r\)</span> and <span class="math inline">\(p\)</span> are parameters representing the tolerance and the probability of a single error (event <span class="math inline">\(A\)</span>).</p>
<p><strong>Properties:</strong></p>
<p>A random variable <span class="math inline">\(Y\rightarrow NB(r,p)\)</span> has</p>
<ol style="list-style-type: decimal">
<li><p>mean <span class="math display">\[E(Y)= r\frac{1-p}{p}\]</span></p></li>
<li><p>and variance <span class="math display">\[V(Y)= r\frac{1-p}{p^2}\]</span></p></li>
</ol>
<p>Let’s look at some probability mass functions in the family of negative binomial parametric models:</p>
<p><img src="_main_files/figure-html/unnamed-chunk-58-1.png" width="672" /></p>
<p><strong>Example (website)</strong></p>
<p>A website has three servers. One server operates at a time and only when a request fails another server is used.</p>
<p>If the probability of failure for a request is known to be <span class="math inline">\(p=0.0005\)</span> then</p>
<ul>
<li>what is the expected number of successful requests before the three computers fail?</li>
</ul>
<p>Since we are repeating a Bernoulli trial until <span class="math inline">\(r=3\)</span> events of type <span class="math inline">\(A\)</span> (failure) are observed (each with <span class="math inline">\(P(A)=p=0.0005\)</span>) and are counting the number of events of type <span class="math inline">\(B\)</span> (successful requests) then</p>
<p><span class="math display">\[Y \rightarrow NB(r=3, p=0.0005)\]</span></p>
<p>Therefore, the expected number of requests before the system fails is:</p>
<p><span class="math inline">\(E(Y)=r\frac{1-p}{p}=3\frac{1-0.0005}{0.0005}=5997\)</span></p>
<p>Note that there are actually <span class="math inline">\(6000\)</span> trials.</p>
<ul>
<li>What is the probability of dealing with at most <span class="math inline">\(5\)</span> successful requests before the system fails?</li>
</ul>
<p>We therefore want to compute the probability distribution at <span class="math inline">\(5\)</span>:</p>
<p><span class="math inline">\(F(5)=P(Y\leq 5)=\Sigma_{y=0}^5 f(y)\)</span></p>
<p><span class="math inline">\(=\sum_{y=0}^5\binom {y+2} y 0.0005^r0.9995^y\)</span></p>
<p><span class="math inline">\(=\binom {2} 0 0.0005^3 0.9995^0 +\binom {3} 1 0.0005^3 0.9995^1\)</span></p>
<p><span class="math inline">\(+\binom {4} 2 0.0005^3 0.9995^2 +\binom {5} 3 0.0005^3 0.9995^3\)</span></p>
<p><span class="math inline">\(+\binom {6} 4 0.0005^3 0.9995^4 +\binom {7} 5 0.0005^3 0.9995^5\)</span></p>
<p><span class="math inline">\(= 6.9\times 10^{-9}\)</span></p>
<p>In R this is computed with <code>pnbinom(5,3,0.0005)</code></p>
<p><strong>Examples</strong></p>
<ul>
<li>What is the probability of observing <span class="math inline">\(10\)</span> correct pixels before <span class="math inline">\(2\)</span> errors, if the probability of an error is <span class="math inline">\(0.1\)</span>?</li>
</ul>
<p><span class="math inline">\(f(10; r=2, p=0.1)=0.03835463\)</span></p>
<p>in R <code>dnbinom(10, 2, 0.1)</code></p>
<ul>
<li>What is the probability that <span class="math inline">\(2\)</span> girls enter the class before <span class="math inline">\(4\)</span> boys if the probability that a girl enters is <span class="math inline">\(0.5\)</span>?</li>
</ul>
<p><span class="math inline">\(f(2; r=4, p=0.5)=0.15625\)</span></p>
<p>in R <code>dnbinom(2, 4, 0.5)</code></p>
</div>
<div id="geometric-distribution" class="section level2 hasAnchor" number="7.11">
<h2><span class="header-section-number">7.11</span> Geometric distribution<a href="discrete-probability-models.html#geometric-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We call <strong>geometric distribution</strong> to the <strong>negative binomial</strong> distribution with <span class="math inline">\(r=1\)</span></p>
<p>The probability of observing <span class="math inline">\(B\)</span> events before observing the <strong>first</strong> event of type <span class="math inline">\(A\)</span> is</p>
<p><span class="math display">\[P(Y=y)=f(y)= p(1-p)^y\]</span></p>
<p><span class="math display">\[Y\rightarrow Geom(p)\]</span>
which has</p>
<ol style="list-style-type: decimal">
<li><p>mean <span class="math display">\[E(Y)= \frac{1-p}{p}\]</span></p></li>
<li><p>and variance <span class="math display">\[V(Y)= \frac{1-p}{p^2}\]</span></p></li>
</ol>
</div>
<div id="hypergeometric-model" class="section level2 hasAnchor" number="7.12">
<h2><span class="header-section-number">7.12</span> Hypergeometric model<a href="discrete-probability-models.html#hypergeometric-model" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The <strong>hypergeometric model</strong> arises when we want to count the number of events of type <span class="math inline">\(A\)</span> that are drawn from a finite population.</p>
<p>The general model is to consider <span class="math inline">\(N\)</span> total balls in a urn. Mark <span class="math inline">\(K\)</span> with label <span class="math inline">\(A\)</span> and <span class="math inline">\(N-K\)</span> with label <span class="math inline">\(B\)</span>. Take out <span class="math inline">\(n\)</span> balls one by one with no replacement in the urn, and then count how many <span class="math inline">\(A\)</span>’s you obtained.</p>
<p>The <strong>Binomial</strong> model can be derived from the <strong>Hypergeometric</strong> model when we consider that either <span class="math inline">\(N\)</span> is infinite, or that every time we draw a ball we replace it back in the urn.</p>
<p><strong>Example (chickenpox):</strong></p>
<p>A school of <span class="math inline">\(N=600\)</span> children has an epidemic of chickenpox. We tested <span class="math inline">\(n=200\)</span> children and observed that <span class="math inline">\(x=17\)</span> were positive. If we knew that a total of <span class="math inline">\(K=64\)</span> were really infected in the school, what is the probability of our observation?</p>
<p><strong>Definition:</strong></p>
<p>The probability of obtaining <span class="math inline">\(x\)</span> cases (type <span class="math inline">\(A\)</span>) in a sample of <span class="math inline">\(n\)</span> drawn from a population of <span class="math inline">\(N\)</span> where <span class="math inline">\(K\)</span> are cases (type <span class="math inline">\(A\)</span>).</p>
<p><span class="math inline">\(P(X=x)=P(one\,sample) \times (Number\, of\, ways\, of\, obtaining\, x)\)</span></p>
<p><span class="math display">\[=\frac{1}{\binom N n}\binom K x \binom {N-K} {n-x}\]</span></p>
<p>where <span class="math inline">\(k \in \{\max(0, n+K-N), ... \min(K, n) \}\)</span></p>
<p>We then say that <span class="math inline">\(X\)</span> follows a hypergeometric distribution and write</p>
<p><span class="math display">\[X \rightarrow Hypergeometric(N,K,n)\]</span>
The hypergeometric model has three parameters.</p>
<p><strong>Properties:</strong></p>
<p>If <span class="math inline">\(X \rightarrow Hypergeometric(N,K,n)\)</span> then it has</p>
<ol style="list-style-type: decimal">
<li><p>mean <span class="math display">\[E(X) =  n  \frac{K}{N} = np\]</span></p></li>
<li><p>and variance <span class="math display">\[V(X) = np(1-p)\frac{N-n}{N-1}\]</span></p></li>
</ol>
<p>when <span class="math inline">\(p=\frac{K}{N}\)</span> is the proportion of hepatitis C in a population of size <span class="math inline">\(N\)</span>. Note that when <span class="math inline">\(N \rightarrow \infty\)</span> then we recover the binomial properties.</p>
<p>Let’s look at some probability mass functions in the family of hypergeometric parametric models:</p>
<p><img src="_main_files/figure-html/unnamed-chunk-59-1.png" width="672" /></p>
<p><img src="_main_files/figure-html/unnamed-chunk-60-1.png" width="672" /></p>
<p><strong>Example (chickenpox):</strong></p>
<ul>
<li>what is the probability of infections less or equal than <span class="math inline">\(17\)</span> in a sample of <span class="math inline">\(200\)</span>, drawn from a population of <span class="math inline">\(600\)</span> where <span class="math inline">\(64\)</span> are infected?</li>
</ul>
<p>The probability that we need to compute is
<span class="math inline">\(P(X \leq 17)=F(17)\)</span></p>
<p>where <span class="math inline">\(X \rightarrow Hypergeometric(N=600,K=64,n=200)\)</span></p>
<p>in R <code>phyper(17, 64, 600-64, 200)=0.140565</code></p>
<p>The solution is the addition of the blue needles in the plot.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-61-1.png" width="672" /></p>
</div>
<div id="questions-4" class="section level2 hasAnchor" number="7.13">
<h2><span class="header-section-number">7.13</span> Questions<a href="discrete-probability-models.html#questions-4" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>1)</strong> What is the expected value and the variance of the number of failures in <span class="math inline">\(100\)</span> prototypes, when the probability of a failure is <span class="math inline">\(0.25\)</span></p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> <span class="math inline">\(0.25\)</span>, <span class="math inline">\(0.1875\)</span>;
<strong><span class="math inline">\(\qquad\)</span>b:</strong> <span class="math inline">\(25\)</span>, <span class="math inline">\(0.1875\)</span>;
<strong><span class="math inline">\(\qquad\)</span>c:</strong> <span class="math inline">\(0.25\)</span>, <span class="math inline">\(18.75\)</span>;<br />
<strong><span class="math inline">\(\qquad\)</span>d:</strong> <span class="math inline">\(25\)</span>, <span class="math inline">\(18.75\)</span></p>
<p><strong>2)</strong> The number of available tables at lunch time in a restaurant is better described by which probability model</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> Binomial;
<strong><span class="math inline">\(\qquad\)</span>b:</strong> Uniform;
<strong><span class="math inline">\(\qquad\)</span>c:</strong> Negative Binomial;<br />
<strong><span class="math inline">\(\qquad\)</span>d:</strong> Hypergeometric</p>
<p><strong>3)</strong> The expected value of a Binomial distribution is not</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> <span class="math inline">\(n\)</span> times the expected value of a Bernoulli;
<strong><span class="math inline">\(\qquad\)</span>b:</strong> the expected value of a Hypergeometric, when the population is very big;
<strong><span class="math inline">\(\qquad\)</span>c:</strong> <span class="math inline">\(np\)</span>;<br />
<strong><span class="math inline">\(\qquad\)</span>d:</strong> the limit of the relative frequency when the number of repetitions is large</p>
<p><strong>4)</strong> Opinion polls for the USA 2022 election give a probability of <span class="math inline">\(0.55\)</span> that a voter favors the republican party. If we conduct our own poll and ask 100 random people on the street, How would you compute the probability that in our poll democrats win the election?</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong><code>pbinom(x=49, n=100, p=0.55)=0.13</code>;
<strong><span class="math inline">\(\qquad\)</span>b:</strong><code>1-pbinom(x=49, n=100, p=0.55)=0.86</code>;
<strong><span class="math inline">\(\qquad\)</span>c:</strong><code>pbinom(x=51, n=100, p=0.45)=0.90</code>; <strong><span class="math inline">\(\qquad\)</span>d:</strong><code>1-pbinom(x=51, n=100, p=0.45)=0.095</code></p>
<p><strong>5)</strong> In an exam a student chooses at random one of the four answers that he does not know. If he doesn’t know <span class="math inline">\(10\)</span> questions what is the probability that more than <span class="math inline">\(5\)</span> (<span class="math inline">\(&gt;5\)</span>) questions are correct?</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong><code>dbinom(x=5, n=10, p=0.25)~ 0.05</code>; <strong><span class="math inline">\(\qquad\)</span>b:</strong><code>pbinom(x=5, n=10, p=0.75)~ 0.07</code>; <strong><span class="math inline">\(\qquad\)</span>c:</strong><code>dbinom(x=5, n=10, p=0.75)~ 0.05</code>; <strong><span class="math inline">\(\qquad\)</span>d:</strong><code>1-pbinom(x=5, n=10, p=0.25)~ 0.02</code></p>
</div>
<div id="exercises-5" class="section level2 hasAnchor" number="7.14">
<h2><span class="header-section-number">7.14</span> Exercises<a href="discrete-probability-models.html#exercises-5" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="exercise-1-4" class="section level4 hasAnchor" number="7.14.0.1">
<h4><span class="header-section-number">7.14.0.1</span> Exercise 1<a href="discrete-probability-models.html#exercise-1-4" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>If 20% of the bolts produced by a machine are defective, determine the probability that, out of
4 bolts chosen at random</p>
<ul>
<li>1 bolts will be defective (R:0:4096)</li>
<li>0 bolts will be defective (R::4096)</li>
<li>at most 2 bolts will be defective (R:0:9728)</li>
</ul>
</div>
<div id="exercise-2-4" class="section level4 hasAnchor" number="7.14.0.2">
<h4><span class="header-section-number">7.14.0.2</span> Exercise 2<a href="discrete-probability-models.html#exercise-2-4" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In a population, the probability that a baby boy is born is <span class="math inline">\(p=0.51\)</span>. Consider a family of 4 children</p>
<ul>
<li>What is the probability that a family has only one boy?(R: 0.240)</li>
<li>What is the probability that a family has only one girl?(R: 0.259)</li>
<li>What is the probability that a family has only one boy or only one girl?(R: 0.4999)</li>
<li>What is the probability that the family has at least two boys?(R: 0.7023)</li>
<li>What is the number of children that a family should have such that the probability of having at least one girl is more than <span class="math inline">\(0.75\)</span>?(R:<span class="math inline">\(n=3&gt;\log(0.25)/\log(0.51)\)</span>)</li>
</ul>
</div>
<div id="exercise-3-4" class="section level4 hasAnchor" number="7.14.0.3">
<h4><span class="header-section-number">7.14.0.3</span> Exercise 3<a href="discrete-probability-models.html#exercise-3-4" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A search engine fails to retrieve information with a probability <span class="math inline">\(0.1\)</span></p>
<ul>
<li><p>If we system receives <span class="math inline">\(50\)</span> search requests, what is the probability that the system fails to answer three of them?(R:0.1385651)</p></li>
<li><p>What is the probability that the engine successfully completes <span class="math inline">\(15\)</span> searches before the first failure?(R:0.020)</p></li>
<li><p>We consider that a search engine works sufficiently well when it is able to find information for moe than <span class="math inline">\(10\)</span> requests for every <span class="math inline">\(2\)</span> failures. What is the probability that in a reliability trial our search engine is satisfactory?(R: 0.697)</p></li>
</ul>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="continous-random-variables.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="poisson-and-exponential-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/06-DiscreteModels.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
