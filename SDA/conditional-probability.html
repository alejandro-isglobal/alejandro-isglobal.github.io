<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Conditional probability | Statistical Data Analysis for Experimental Sciences</title>
  <meta name="description" content="This is a markdown book titled Statistical Data Analysis for Experimental Sciences by Alejandro Caceres" />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Conditional probability | Statistical Data Analysis for Experimental Sciences" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a markdown book titled Statistical Data Analysis for Experimental Sciences by Alejandro Caceres" />
  <meta name="github-repo" content="alejandro-isglobal/master" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Conditional probability | Statistical Data Analysis for Experimental Sciences" />
  
  <meta name="twitter:description" content="This is a markdown book titled Statistical Data Analysis for Experimental Sciences by Alejandro Caceres" />
  

<meta name="author" content="Alejandro CÃ¡ceres" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="probability.html"/>
<link rel="next" href="discrete-random-variables.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">SDA</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#how-to-read-the-book"><i class="fa fa-check"></i><b>1.1</b> How to read the book</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>1.2</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-description.html"><a href="data-description.html"><i class="fa fa-check"></i><b>2</b> Data description</a>
<ul>
<li class="chapter" data-level="2.1" data-path="data-description.html"><a href="data-description.html#scientific-method"><i class="fa fa-check"></i><b>2.1</b> Scientific method</a></li>
<li class="chapter" data-level="2.2" data-path="data-description.html"><a href="data-description.html#data"><i class="fa fa-check"></i><b>2.2</b> Data</a></li>
<li class="chapter" data-level="2.3" data-path="data-description.html"><a href="data-description.html#types-of-outcomes"><i class="fa fa-check"></i><b>2.3</b> Types of outcomes</a></li>
<li class="chapter" data-level="2.4" data-path="data-description.html"><a href="data-description.html#random-experiments"><i class="fa fa-check"></i><b>2.4</b> Random experiments</a></li>
<li class="chapter" data-level="2.5" data-path="data-description.html"><a href="data-description.html#absolute-frequencies"><i class="fa fa-check"></i><b>2.5</b> Absolute frequencies</a></li>
<li class="chapter" data-level="2.6" data-path="data-description.html"><a href="data-description.html#relative-frequencies"><i class="fa fa-check"></i><b>2.6</b> Relative frequencies</a></li>
<li class="chapter" data-level="2.7" data-path="data-description.html"><a href="data-description.html#bar-chart"><i class="fa fa-check"></i><b>2.7</b> Bar chart</a></li>
<li class="chapter" data-level="2.8" data-path="data-description.html"><a href="data-description.html#pie-chart"><i class="fa fa-check"></i><b>2.8</b> Pie chart</a></li>
<li class="chapter" data-level="2.9" data-path="data-description.html"><a href="data-description.html#ordinal-categorical-outcomes"><i class="fa fa-check"></i><b>2.9</b> Ordinal categorical outcomes</a></li>
<li class="chapter" data-level="2.10" data-path="data-description.html"><a href="data-description.html#absolute-and-relative-cumulative-frequencies"><i class="fa fa-check"></i><b>2.10</b> Absolute and relative cumulative frequencies</a></li>
<li class="chapter" data-level="2.11" data-path="data-description.html"><a href="data-description.html#cumulative-frequency-graph"><i class="fa fa-check"></i><b>2.11</b> Cumulative frequency graph</a></li>
<li class="chapter" data-level="2.12" data-path="data-description.html"><a href="data-description.html#numerical-outcomes"><i class="fa fa-check"></i><b>2.12</b> Numerical outcomes</a></li>
<li class="chapter" data-level="2.13" data-path="data-description.html"><a href="data-description.html#transforming-continuous-data"><i class="fa fa-check"></i><b>2.13</b> Transforming continuous data</a></li>
<li class="chapter" data-level="2.14" data-path="data-description.html"><a href="data-description.html#frequency-table-for-a-continuous-variable"><i class="fa fa-check"></i><b>2.14</b> Frequency table for a continuous variable</a></li>
<li class="chapter" data-level="2.15" data-path="data-description.html"><a href="data-description.html#histogram"><i class="fa fa-check"></i><b>2.15</b> Histogram</a></li>
<li class="chapter" data-level="2.16" data-path="data-description.html"><a href="data-description.html#cumulative-frequency-graph-1"><i class="fa fa-check"></i><b>2.16</b> Cumulative frequency graph</a></li>
<li class="chapter" data-level="2.17" data-path="data-description.html"><a href="data-description.html#summary-statistics"><i class="fa fa-check"></i><b>2.17</b> Summary Statistics</a></li>
<li class="chapter" data-level="2.18" data-path="data-description.html"><a href="data-description.html#average-sample-mean"><i class="fa fa-check"></i><b>2.18</b> Average (sample mean)</a></li>
<li class="chapter" data-level="2.19" data-path="data-description.html"><a href="data-description.html#median"><i class="fa fa-check"></i><b>2.19</b> Median</a></li>
<li class="chapter" data-level="2.20" data-path="data-description.html"><a href="data-description.html#dispersion"><i class="fa fa-check"></i><b>2.20</b> Dispersion</a></li>
<li class="chapter" data-level="2.21" data-path="data-description.html"><a href="data-description.html#sample-variance"><i class="fa fa-check"></i><b>2.21</b> Sample variance</a></li>
<li class="chapter" data-level="2.22" data-path="data-description.html"><a href="data-description.html#interquartile-range-iqr"><i class="fa fa-check"></i><b>2.22</b> Interquartile range (IQR)</a></li>
<li class="chapter" data-level="2.23" data-path="data-description.html"><a href="data-description.html#boxplot"><i class="fa fa-check"></i><b>2.23</b> Boxplot</a></li>
<li class="chapter" data-level="2.24" data-path="data-description.html"><a href="data-description.html#questions"><i class="fa fa-check"></i><b>2.24</b> Questions</a></li>
<li class="chapter" data-level="2.25" data-path="data-description.html"><a href="data-description.html#exercises"><i class="fa fa-check"></i><b>2.25</b> Exercises</a></li>
<li class="chapter" data-level="2.26" data-path="data-description.html"><a href="data-description.html#practice"><i class="fa fa-check"></i><b>2.26</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>3</b> Probability</a>
<ul>
<li class="chapter" data-level="3.1" data-path="probability.html"><a href="probability.html#probability-mesurement"><i class="fa fa-check"></i><b>3.1</b> Probability mesurement</a></li>
<li class="chapter" data-level="3.2" data-path="probability.html"><a href="probability.html#classical-probability"><i class="fa fa-check"></i><b>3.2</b> Classical probability</a></li>
<li class="chapter" data-level="3.3" data-path="probability.html"><a href="probability.html#relative-frequencies-1"><i class="fa fa-check"></i><b>3.3</b> Relative frequencies</a></li>
<li class="chapter" data-level="3.4" data-path="probability.html"><a href="probability.html#frequentist-probability"><i class="fa fa-check"></i><b>3.4</b> Frequentist probability</a></li>
<li class="chapter" data-level="3.5" data-path="probability.html"><a href="probability.html#classical-and-frequentist-probabilities"><i class="fa fa-check"></i><b>3.5</b> Classical and frequentist probabilities</a></li>
<li class="chapter" data-level="3.6" data-path="probability.html"><a href="probability.html#sample-space"><i class="fa fa-check"></i><b>3.6</b> Sample space</a></li>
<li class="chapter" data-level="3.7" data-path="probability.html"><a href="probability.html#events"><i class="fa fa-check"></i><b>3.7</b> Events</a></li>
<li class="chapter" data-level="3.8" data-path="probability.html"><a href="probability.html#algebra-of-events"><i class="fa fa-check"></i><b>3.8</b> Algebra of events</a></li>
<li class="chapter" data-level="3.9" data-path="probability.html"><a href="probability.html#mutually-exclusive-events"><i class="fa fa-check"></i><b>3.9</b> Mutually exclusive events</a></li>
<li class="chapter" data-level="3.10" data-path="probability.html"><a href="probability.html#definition-of-probability"><i class="fa fa-check"></i><b>3.10</b> Definition of probability</a></li>
<li class="chapter" data-level="3.11" data-path="probability.html"><a href="probability.html#probability-table"><i class="fa fa-check"></i><b>3.11</b> Probability table</a></li>
<li class="chapter" data-level="3.12" data-path="probability.html"><a href="probability.html#joint-probabilities"><i class="fa fa-check"></i><b>3.12</b> Joint probabilities</a></li>
<li class="chapter" data-level="3.13" data-path="probability.html"><a href="probability.html#contingency-table"><i class="fa fa-check"></i><b>3.13</b> Contingency table</a></li>
<li class="chapter" data-level="3.14" data-path="probability.html"><a href="probability.html#the-addition-rule"><i class="fa fa-check"></i><b>3.14</b> The addition rule</a></li>
<li class="chapter" data-level="3.15" data-path="probability.html"><a href="probability.html#questions-1"><i class="fa fa-check"></i><b>3.15</b> Questions</a></li>
<li class="chapter" data-level="3.16" data-path="probability.html"><a href="probability.html#exercises-1"><i class="fa fa-check"></i><b>3.16</b> Exercises</a></li>
<li class="chapter" data-level="3.17" data-path="probability.html"><a href="probability.html#practice-1"><i class="fa fa-check"></i><b>3.17</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="conditional-probability.html"><a href="conditional-probability.html"><i class="fa fa-check"></i><b>4</b> Conditional probability</a>
<ul>
<li class="chapter" data-level="4.1" data-path="conditional-probability.html"><a href="conditional-probability.html#joint-probability"><i class="fa fa-check"></i><b>4.1</b> Joint probability</a></li>
<li class="chapter" data-level="4.2" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-independence-and-correlation"><i class="fa fa-check"></i><b>4.2</b> Statistical independence and correlation</a></li>
<li class="chapter" data-level="4.3" data-path="conditional-probability.html"><a href="conditional-probability.html#conditional-probability-1"><i class="fa fa-check"></i><b>4.3</b> Conditional probability</a></li>
<li class="chapter" data-level="4.4" data-path="conditional-probability.html"><a href="conditional-probability.html#conditional-contingency-table"><i class="fa fa-check"></i><b>4.4</b> Conditional contingency table</a></li>
<li class="chapter" data-level="4.5" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-independence"><i class="fa fa-check"></i><b>4.5</b> Statistical independence</a></li>
<li class="chapter" data-level="4.6" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-dependency"><i class="fa fa-check"></i><b>4.6</b> Statistical dependency</a></li>
<li class="chapter" data-level="4.7" data-path="conditional-probability.html"><a href="conditional-probability.html#diagnostic-test"><i class="fa fa-check"></i><b>4.7</b> Diagnostic test</a></li>
<li class="chapter" data-level="4.8" data-path="conditional-probability.html"><a href="conditional-probability.html#inverse-probabilities"><i class="fa fa-check"></i><b>4.8</b> Inverse probabilities</a></li>
<li class="chapter" data-level="4.9" data-path="conditional-probability.html"><a href="conditional-probability.html#bayes-theorem"><i class="fa fa-check"></i><b>4.9</b> Bayesâ Theorem</a></li>
<li class="chapter" data-level="4.10" data-path="conditional-probability.html"><a href="conditional-probability.html#questions-2"><i class="fa fa-check"></i><b>4.10</b> Questions</a></li>
<li class="chapter" data-level="4.11" data-path="conditional-probability.html"><a href="conditional-probability.html#exercises-2"><i class="fa fa-check"></i><b>4.11</b> Exercises</a></li>
<li class="chapter" data-level="4.12" data-path="conditional-probability.html"><a href="conditional-probability.html#practice-2"><i class="fa fa-check"></i><b>4.12</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html"><i class="fa fa-check"></i><b>5</b> Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="5.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#definition-of-a-random-variable"><i class="fa fa-check"></i><b>5.1</b> Definition of a Random Variable</a></li>
<li class="chapter" data-level="5.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#the-value-of-a-random-variable"><i class="fa fa-check"></i><b>5.2</b> The value of a random variable</a></li>
<li class="chapter" data-level="5.3" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-of-random-variables"><i class="fa fa-check"></i><b>5.3</b> Probability of random variables</a></li>
<li class="chapter" data-level="5.4" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-functions"><i class="fa fa-check"></i><b>5.4</b> Probability functions</a></li>
<li class="chapter" data-level="5.5" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-mass-functions"><i class="fa fa-check"></i><b>5.5</b> Probability mass functions</a></li>
<li class="chapter" data-level="5.6" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#mean-or-expected-value"><i class="fa fa-check"></i><b>5.6</b> Mean or expected value</a></li>
<li class="chapter" data-level="5.7" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#variance"><i class="fa fa-check"></i><b>5.7</b> Variance</a></li>
<li class="chapter" data-level="5.8" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-functions-for-functions-of-x"><i class="fa fa-check"></i><b>5.8</b> Probability functions for functions of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="5.9" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-distribution"><i class="fa fa-check"></i><b>5.9</b> Probability distribution</a></li>
<li class="chapter" data-level="5.10" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-function-and-probability-distribution"><i class="fa fa-check"></i><b>5.10</b> Probability function and probability distribution</a></li>
<li class="chapter" data-level="5.11" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#quantiles"><i class="fa fa-check"></i><b>5.11</b> Quantiles</a></li>
<li class="chapter" data-level="5.12" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#summary"><i class="fa fa-check"></i><b>5.12</b> Summary</a></li>
<li class="chapter" data-level="5.13" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#questions-3"><i class="fa fa-check"></i><b>5.13</b> Questions</a></li>
<li class="chapter" data-level="5.14" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#exercises-3"><i class="fa fa-check"></i><b>5.14</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="continous-random-variables.html"><a href="continous-random-variables.html"><i class="fa fa-check"></i><b>6</b> Continous Random Variables</a>
<ul>
<li class="chapter" data-level="6.1" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probabilities-of-continuous-random-variables"><i class="fa fa-check"></i><b>6.1</b> Probabilities of continuous random variables</a></li>
<li class="chapter" data-level="6.2" data-path="continous-random-variables.html"><a href="continous-random-variables.html#relative-frequencies-2"><i class="fa fa-check"></i><b>6.2</b> Relative frequencies</a></li>
<li class="chapter" data-level="6.3" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-density-function"><i class="fa fa-check"></i><b>6.3</b> Probability Density Function</a></li>
<li class="chapter" data-level="6.4" data-path="continous-random-variables.html"><a href="continous-random-variables.html#total-area-under-the-curve"><i class="fa fa-check"></i><b>6.4</b> Total area under the curve</a></li>
<li class="chapter" data-level="6.5" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probabilities-of-continous-variables"><i class="fa fa-check"></i><b>6.5</b> Probabilities of continous variables</a></li>
<li class="chapter" data-level="6.6" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-distribution-1"><i class="fa fa-check"></i><b>6.6</b> Probability distribution</a></li>
<li class="chapter" data-level="6.7" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-plots"><i class="fa fa-check"></i><b>6.7</b> Probability plots</a></li>
<li class="chapter" data-level="6.8" data-path="continous-random-variables.html"><a href="continous-random-variables.html#mean"><i class="fa fa-check"></i><b>6.8</b> Mean</a></li>
<li class="chapter" data-level="6.9" data-path="continous-random-variables.html"><a href="continous-random-variables.html#variance-1"><i class="fa fa-check"></i><b>6.9</b> Variance</a></li>
<li class="chapter" data-level="6.10" data-path="continous-random-variables.html"><a href="continous-random-variables.html#functions-of-x"><i class="fa fa-check"></i><b>6.10</b> Functions of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="6.11" data-path="continous-random-variables.html"><a href="continous-random-variables.html#exercises-4"><i class="fa fa-check"></i><b>6.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html"><i class="fa fa-check"></i><b>7</b> Discrete Probability Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#probability-model"><i class="fa fa-check"></i><b>7.1</b> Probability model</a></li>
<li class="chapter" data-level="7.2" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#parametric-models"><i class="fa fa-check"></i><b>7.2</b> Parametric models</a></li>
<li class="chapter" data-level="7.3" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#uniform-probability-mass-function-one-parameter"><i class="fa fa-check"></i><b>7.3</b> Uniform probability mass function (one parameter)</a></li>
<li class="chapter" data-level="7.4" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#uniform-probability-mass-function-two-parameters"><i class="fa fa-check"></i><b>7.4</b> Uniform probability mass function (two parameters)</a></li>
<li class="chapter" data-level="7.5" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#bernoulli-trial"><i class="fa fa-check"></i><b>7.5</b> Bernoulli trial</a></li>
<li class="chapter" data-level="7.6" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#binomial-experiment"><i class="fa fa-check"></i><b>7.6</b> Binomial experiment</a></li>
<li class="chapter" data-level="7.7" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#binomial-probability-function"><i class="fa fa-check"></i><b>7.7</b> Binomial probability function</a></li>
<li class="chapter" data-level="7.8" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#negative-binomial"><i class="fa fa-check"></i><b>7.8</b> Negative binomial</a></li>
<li class="chapter" data-level="7.9" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#geometric-distribution"><i class="fa fa-check"></i><b>7.9</b> Geometric distribution</a></li>
<li class="chapter" data-level="7.10" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#hypergeometric-model"><i class="fa fa-check"></i><b>7.10</b> Hypergeometric model</a></li>
<li class="chapter" data-level="7.11" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#questions-4"><i class="fa fa-check"></i><b>7.11</b> Questions</a></li>
<li class="chapter" data-level="7.12" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#exercises-5"><i class="fa fa-check"></i><b>7.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html"><i class="fa fa-check"></i><b>8</b> Poisson and Exponential Models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#discrete-probability-models-1"><i class="fa fa-check"></i><b>8.1</b> Discrete probability models</a></li>
<li class="chapter" data-level="8.2" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#poissson-experiment"><i class="fa fa-check"></i><b>8.2</b> Poissson experiment</a></li>
<li class="chapter" data-level="8.3" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#poisson-probability-mass-function"><i class="fa fa-check"></i><b>8.3</b> Poisson probability mass function</a></li>
<li class="chapter" data-level="8.4" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#continuous-probability-models"><i class="fa fa-check"></i><b>8.4</b> Continuous probability models</a></li>
<li class="chapter" data-level="8.5" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-process"><i class="fa fa-check"></i><b>8.5</b> Exponential process</a></li>
<li class="chapter" data-level="8.6" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-probability-density"><i class="fa fa-check"></i><b>8.6</b> Exponential probability density</a></li>
<li class="chapter" data-level="8.7" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-distribution"><i class="fa fa-check"></i><b>8.7</b> Exponential Distribution</a></li>
<li class="chapter" data-level="8.8" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#questions-5"><i class="fa fa-check"></i><b>8.8</b> Questions</a></li>
<li class="chapter" data-level="8.9" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exercises-6"><i class="fa fa-check"></i><b>8.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="normal-distribution.html"><a href="normal-distribution.html"><i class="fa fa-check"></i><b>9</b> Normal Distribution</a>
<ul>
<li class="chapter" data-level="9.1" data-path="normal-distribution.html"><a href="normal-distribution.html#history"><i class="fa fa-check"></i><b>9.1</b> History</a></li>
<li class="chapter" data-level="9.2" data-path="normal-distribution.html"><a href="normal-distribution.html#normal-density"><i class="fa fa-check"></i><b>9.2</b> normal density</a></li>
<li class="chapter" data-level="9.3" data-path="normal-distribution.html"><a href="normal-distribution.html#definition"><i class="fa fa-check"></i><b>9.3</b> Definition</a></li>
<li class="chapter" data-level="9.4" data-path="normal-distribution.html"><a href="normal-distribution.html#probability-distribution-2"><i class="fa fa-check"></i><b>9.4</b> Probability distribution</a></li>
<li class="chapter" data-level="9.5" data-path="normal-distribution.html"><a href="normal-distribution.html#standard-normal-density"><i class="fa fa-check"></i><b>9.5</b> Standard normal density</a></li>
<li class="chapter" data-level="9.6" data-path="normal-distribution.html"><a href="normal-distribution.html#standard-distribution"><i class="fa fa-check"></i><b>9.6</b> Standard distribution</a></li>
<li class="chapter" data-level="9.7" data-path="normal-distribution.html"><a href="normal-distribution.html#standardization"><i class="fa fa-check"></i><b>9.7</b> Standardization</a></li>
<li class="chapter" data-level="9.8" data-path="normal-distribution.html"><a href="normal-distribution.html#questions-6"><i class="fa fa-check"></i><b>9.8</b> Questions</a></li>
<li class="chapter" data-level="9.9" data-path="normal-distribution.html"><a href="normal-distribution.html#exercises-7"><i class="fa fa-check"></i><b>9.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="sampling-distributions.html"><a href="sampling-distributions.html"><i class="fa fa-check"></i><b>10</b> Sampling distributions</a>
<ul>
<li class="chapter" data-level="10.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#random-sample"><i class="fa fa-check"></i><b>10.1</b> Random sample</a></li>
<li class="chapter" data-level="10.2" data-path="sampling-distributions.html"><a href="sampling-distributions.html#parameter-estimation"><i class="fa fa-check"></i><b>10.2</b> Parameter estimation</a></li>
<li class="chapter" data-level="10.3" data-path="sampling-distributions.html"><a href="sampling-distributions.html#law-of-large-numbers"><i class="fa fa-check"></i><b>10.3</b> Law of Large Numbers</a></li>
<li class="chapter" data-level="10.4" data-path="sampling-distributions.html"><a href="sampling-distributions.html#inference"><i class="fa fa-check"></i><b>10.4</b> Inference</a></li>
<li class="chapter" data-level="10.5" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-mean"><i class="fa fa-check"></i><b>10.5</b> Sample mean</a></li>
<li class="chapter" data-level="10.6" data-path="sampling-distributions.html"><a href="sampling-distributions.html#prediction"><i class="fa fa-check"></i><b>10.6</b> Prediction</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#example-pacemaker-prediction"><i class="fa fa-check"></i><b>10.6.1</b> <strong>Example: Pacemaker Prediction</strong></a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="sampling-distributions.html"><a href="sampling-distributions.html#validation"><i class="fa fa-check"></i><b>10.7</b> Validation</a></li>
<li class="chapter" data-level="10.8" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-sum"><i class="fa fa-check"></i><b>10.8</b> Sample Sum</a>
<ul>
<li class="chapter" data-level="10.8.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#example-cables"><i class="fa fa-check"></i><b>10.8.1</b> Example (Cables)</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-variance-1"><i class="fa fa-check"></i><b>10.9</b> Sample Variance</a>
<ul>
<li class="chapter" data-level="10.9.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#example-cables-1"><i class="fa fa-check"></i><b>10.9.1</b> Example (Cables)</a></li>
</ul></li>
<li class="chapter" data-level="10.10" data-path="sampling-distributions.html"><a href="sampling-distributions.html#distribution-of-the-sample-variance"><i class="fa fa-check"></i><b>10.10</b> Distribution of the Sample Variance</a></li>
<li class="chapter" data-level="10.11" data-path="sampling-distributions.html"><a href="sampling-distributions.html#the-chi2-distribution"><i class="fa fa-check"></i><b>10.11</b> The <span class="math inline">\(\chi^2\)</span> Distribution</a></li>
<li class="chapter" data-level="10.12" data-path="sampling-distributions.html"><a href="sampling-distributions.html#questions-7"><i class="fa fa-check"></i><b>10.12</b> Questions</a></li>
<li class="chapter" data-level="10.13" data-path="sampling-distributions.html"><a href="sampling-distributions.html#exercises-8"><i class="fa fa-check"></i><b>10.13</b> Exercises</a>
<ul>
<li class="chapter" data-level="10.13.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#from-estimation-to-inference"><i class="fa fa-check"></i><b>10.13.1</b> From Estimation to Inference</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html"><i class="fa fa-check"></i><b>11</b> Central limit theorem</a>
<ul>
<li class="chapter" data-level="11.1" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#margin-of-error"><i class="fa fa-check"></i><b>11.1</b> Margin of error</a></li>
<li class="chapter" data-level="11.2" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#averages-of-normal-variables"><i class="fa fa-check"></i><b>11.2</b> Averages of normal variables</a></li>
<li class="chapter" data-level="11.3" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#central-limit-theorem-1"><i class="fa fa-check"></i><b>11.3</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="11.4" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#sample-sum-and-clt"><i class="fa fa-check"></i><b>11.4</b> Sample sum and CLT</a></li>
<li class="chapter" data-level="11.5" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#unknown-sigma"><i class="fa fa-check"></i><b>11.5</b> Unknown <span class="math inline">\(\sigma\)</span></a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#example-pacemaker-prediction-1"><i class="fa fa-check"></i><b>11.5.1</b> <strong>Example: Pacemaker Prediction</strong></a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#t-statistic"><i class="fa fa-check"></i><b>11.6</b> T-statistic</a></li>
<li class="chapter" data-level="11.7" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#questions-8"><i class="fa fa-check"></i><b>11.7</b> Questions</a></li>
<li class="chapter" data-level="11.8" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#exercises-9"><i class="fa fa-check"></i><b>11.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html"><i class="fa fa-check"></i><b>12</b> Maximum likelihood</a>
<ul>
<li class="chapter" data-level="12.1" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#statistic"><i class="fa fa-check"></i><b>12.1</b> Statistic</a></li>
<li class="chapter" data-level="12.2" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#properties"><i class="fa fa-check"></i><b>12.2</b> Properties</a></li>
<li class="chapter" data-level="12.3" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#maximum-likelihood-1"><i class="fa fa-check"></i><b>12.3</b> Maximum likelihood</a></li>
<li class="chapter" data-level="12.4" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#maximum-likelihood-2"><i class="fa fa-check"></i><b>12.4</b> Maximum likelihood</a></li>
<li class="chapter" data-level="12.5" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#questions-9"><i class="fa fa-check"></i><b>12.5</b> Questions</a></li>
<li class="chapter" data-level="12.6" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#exercises-10"><i class="fa fa-check"></i><b>12.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="interval-estimation.html"><a href="interval-estimation.html"><i class="fa fa-check"></i><b>13</b> Interval estimation</a>
<ul>
<li class="chapter" data-level="13.1" data-path="interval-estimation.html"><a href="interval-estimation.html#revisiting-parameter-estimation-and-marging-of-error"><i class="fa fa-check"></i><b>13.1</b> Revisiting parameter estimation and marging of error</a></li>
<li class="chapter" data-level="13.2" data-path="interval-estimation.html"><a href="interval-estimation.html#interval-estimation-for-the-mean"><i class="fa fa-check"></i><b>13.2</b> Interval estimation for the mean</a></li>
<li class="chapter" data-level="13.3" data-path="interval-estimation.html"><a href="interval-estimation.html#confidence-interval-estimation"><i class="fa fa-check"></i><b>13.3</b> Confidence Interval Estimation</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="interval-estimation.html"><a href="interval-estimation.html#estimation-of-the-mean-for-normal-variables"><i class="fa fa-check"></i><b>13.3.1</b> Estimation of the mean for normal variables</a></li>
<li class="chapter" data-level="13.3.2" data-path="interval-estimation.html"><a href="interval-estimation.html#estimation-of-the-proportion-for-dichotomic-variables"><i class="fa fa-check"></i><b>13.3.2</b> Estimation of the proportion for dichotomic variables</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="interval-estimation.html"><a href="interval-estimation.html#estimation-of-the-variance"><i class="fa fa-check"></i><b>13.4</b> Estimation of the variance</a></li>
<li class="chapter" data-level="13.5" data-path="interval-estimation.html"><a href="interval-estimation.html#confidence-interval-for-the-variance"><i class="fa fa-check"></i><b>13.5</b> Confidence interval for the variance</a></li>
<li class="chapter" data-level="13.6" data-path="interval-estimation.html"><a href="interval-estimation.html#questions-10"><i class="fa fa-check"></i><b>13.6</b> Questions</a></li>
<li class="chapter" data-level="13.7" data-path="interval-estimation.html"><a href="interval-estimation.html#exercises-11"><i class="fa fa-check"></i><b>13.7</b> Exercises</a></li>
<li class="chapter" data-level="13.8" data-path="interval-estimation.html"><a href="interval-estimation.html#practice-3"><i class="fa fa-check"></i><b>13.8</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>14</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="14.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-formulation"><i class="fa fa-check"></i><b>14.1</b> Hypothesis formulation</a></li>
<li class="chapter" data-level="14.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-1"><i class="fa fa-check"></i><b>14.2</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="14.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-for-the-mean"><i class="fa fa-check"></i><b>14.3</b> Hypothesis testing for the mean</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-with-a-confidence-interval"><i class="fa fa-check"></i><b>14.3.1</b> Hypothesis test with a confidence interval</a></li>
<li class="chapter" data-level="14.3.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-with-acceptancerejection-zones"><i class="fa fa-check"></i><b>14.3.2</b> Hypothesis test with acceptance/rejection zones</a></li>
<li class="chapter" data-level="14.3.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-with-a-p-value"><i class="fa fa-check"></i><b>14.3.3</b> Hypothesis test with a P-value</a></li>
<li class="chapter" data-level="14.3.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#upper-tail-hypothesis"><i class="fa fa-check"></i><b>14.3.4</b> Upper tail hypothesis</a></li>
<li class="chapter" data-level="14.3.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#paired-t-test"><i class="fa fa-check"></i><b>14.3.5</b> Paired t-test</a></li>
<li class="chapter" data-level="14.3.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#lower-tail-hypothesis"><i class="fa fa-check"></i><b>14.3.6</b> Lower tail hypothesis</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-for-the-proportion"><i class="fa fa-check"></i><b>14.4</b> Hypothesis testing for the proportion</a></li>
<li class="chapter" data-level="14.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-for-the-variance"><i class="fa fa-check"></i><b>14.5</b> Hypothesis Testing for the Variance</a></li>
<li class="chapter" data-level="14.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#errors-in-hypothesis-testing"><i class="fa fa-check"></i><b>14.6</b> Errors in hypothesis testing</a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sensitivity-and-specificity"><i class="fa fa-check"></i><b>14.6.1</b> Sensitivity and Specificity</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#exercises-12"><i class="fa fa-check"></i><b>14.7</b> Exercises</a></li>
<li class="chapter" data-level="14.8" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#practice-4"><i class="fa fa-check"></i><b>14.8</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="contingency-tables.html"><a href="contingency-tables.html"><i class="fa fa-check"></i><b>15</b> Contingency tables</a>
<ul>
<li class="chapter" data-level="15.1" data-path="contingency-tables.html"><a href="contingency-tables.html#difference-between-proportions"><i class="fa fa-check"></i><b>15.1</b> Difference between proportions</a></li>
<li class="chapter" data-level="15.2" data-path="contingency-tables.html"><a href="contingency-tables.html#difference-between-proportions-1"><i class="fa fa-check"></i><b>15.2</b> Difference between proportions</a></li>
<li class="chapter" data-level="15.3" data-path="contingency-tables.html"><a href="contingency-tables.html#contingency-table-of-conditional-probabilities"><i class="fa fa-check"></i><b>15.3</b> Contingency table of conditional probabilities</a></li>
<li class="chapter" data-level="15.4" data-path="contingency-tables.html"><a href="contingency-tables.html#test-for-the-difference-between-proportions"><i class="fa fa-check"></i><b>15.4</b> Test for the difference between proportions</a></li>
<li class="chapter" data-level="15.5" data-path="contingency-tables.html"><a href="contingency-tables.html#chi2-test"><i class="fa fa-check"></i><b>15.5</b> <span class="math inline">\(\chi^2\)</span> test</a></li>
<li class="chapter" data-level="15.6" data-path="contingency-tables.html"><a href="contingency-tables.html#fishers-exact-test"><i class="fa fa-check"></i><b>15.6</b> Fisherâs exact test</a></li>
<li class="chapter" data-level="15.7" data-path="contingency-tables.html"><a href="contingency-tables.html#hypergeometric-distribution"><i class="fa fa-check"></i><b>15.7</b> Hypergeometric distribution</a></li>
<li class="chapter" data-level="15.8" data-path="contingency-tables.html"><a href="contingency-tables.html#difference-between-several-proportions"><i class="fa fa-check"></i><b>15.8</b> Difference between several proportions</a></li>
<li class="chapter" data-level="15.9" data-path="contingency-tables.html"><a href="contingency-tables.html#goodness-of-fit"><i class="fa fa-check"></i><b>15.9</b> Goodness of fit</a></li>
<li class="chapter" data-level="15.10" data-path="contingency-tables.html"><a href="contingency-tables.html#questions-11"><i class="fa fa-check"></i><b>15.10</b> Questions</a></li>
<li class="chapter" data-level="15.11" data-path="contingency-tables.html"><a href="contingency-tables.html#practice-5"><i class="fa fa-check"></i><b>15.11</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html"><i class="fa fa-check"></i><b>16</b> Mean differences between two samples</a>
<ul>
<li class="chapter" data-level="16.1" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#difference-in-means-between-two-groups"><i class="fa fa-check"></i><b>16.1</b> Difference in means between two groups</a></li>
<li class="chapter" data-level="16.2" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#data-1"><i class="fa fa-check"></i><b>16.2</b> Data</a></li>
<li class="chapter" data-level="16.3" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#difference-between-means"><i class="fa fa-check"></i><b>16.3</b> Difference between means</a></li>
<li class="chapter" data-level="16.4" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#hypothesis-test"><i class="fa fa-check"></i><b>16.4</b> Hypothesis test</a></li>
<li class="chapter" data-level="16.5" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#estiamtor-of-the-mean-difference"><i class="fa fa-check"></i><b>16.5</b> Estiamtor of the mean difference</a></li>
<li class="chapter" data-level="16.6" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#standardized-error"><i class="fa fa-check"></i><b>16.6</b> Standardized error</a></li>
<li class="chapter" data-level="16.7" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#standardized-error-for-the-null"><i class="fa fa-check"></i><b>16.7</b> Standardized error for the null</a></li>
<li class="chapter" data-level="16.8" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#mean-differences-when-n-is-small"><i class="fa fa-check"></i><b>16.8</b> Mean differences when <span class="math inline">\(n\)</span> is small</a></li>
<li class="chapter" data-level="16.9" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#data-2"><i class="fa fa-check"></i><b>16.9</b> Data</a></li>
<li class="chapter" data-level="16.10" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#difference-between-means-1"><i class="fa fa-check"></i><b>16.10</b> Difference between means</a></li>
<li class="chapter" data-level="16.11" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#hypothesis-test-1"><i class="fa fa-check"></i><b>16.11</b> Hypothesis test</a></li>
<li class="chapter" data-level="16.12" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#estimator-of-the-mean-difference"><i class="fa fa-check"></i><b>16.12</b> Estimator of the mean difference</a></li>
<li class="chapter" data-level="16.13" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#standardized-error-for-the-null-1"><i class="fa fa-check"></i><b>16.13</b> Standardized error for the null</a></li>
<li class="chapter" data-level="16.14" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#mean-differences-with-unequall-variances"><i class="fa fa-check"></i><b>16.14</b> Mean differences with unequall variances</a></li>
<li class="chapter" data-level="16.15" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#data-3"><i class="fa fa-check"></i><b>16.15</b> Data</a></li>
<li class="chapter" data-level="16.16" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#questions-12"><i class="fa fa-check"></i><b>16.16</b> Questions</a></li>
<li class="chapter" data-level="16.17" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#practice-6"><i class="fa fa-check"></i><b>16.17</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html"><i class="fa fa-check"></i><b>17</b> Mean differences across several groups</a>
<ul>
<li class="chapter" data-level="17.1" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#different-means-among-several-conditions"><i class="fa fa-check"></i><b>17.1</b> Different means among several conditions</a></li>
<li class="chapter" data-level="17.2" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#data-4"><i class="fa fa-check"></i><b>17.2</b> Data</a></li>
<li class="chapter" data-level="17.3" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#difference-between-means-2"><i class="fa fa-check"></i><b>17.3</b> Difference between means</a></li>
<li class="chapter" data-level="17.4" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#hypothesis-test-2"><i class="fa fa-check"></i><b>17.4</b> Hypothesis test</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#distribution-of-group-means-under-h_0"><i class="fa fa-check"></i><b>17.4.1</b> Distribution of group means under <span class="math inline">\(H_0\)</span></a></li>
<li class="chapter" data-level="17.4.2" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#sources-of-variation"><i class="fa fa-check"></i><b>17.4.2</b> Sources of variation</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#variance-components-estimators"><i class="fa fa-check"></i><b>17.5</b> Variance components estimators</a></li>
<li class="chapter" data-level="17.6" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#analysis-of-variance-anova"><i class="fa fa-check"></i><b>17.6</b> Analysis of variance (ANOVA)</a></li>
<li class="chapter" data-level="17.7" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#anova-for-two-groups"><i class="fa fa-check"></i><b>17.7</b> ANOVA for Two Groups</a></li>
<li class="chapter" data-level="17.8" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#linear-model"><i class="fa fa-check"></i><b>17.8</b> Linear model</a></li>
<li class="chapter" data-level="17.9" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#way-anova"><i class="fa fa-check"></i><b>17.9</b> 2-way ANOVA</a></li>
<li class="chapter" data-level="17.10" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#data-5"><i class="fa fa-check"></i><b>17.10</b> Data</a></li>
<li class="chapter" data-level="17.11" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#modeling-residuals"><i class="fa fa-check"></i><b>17.11</b> Modeling residuals</a></li>
<li class="chapter" data-level="17.12" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#way-anova-linear-model"><i class="fa fa-check"></i><b>17.12</b> 2-way ANOVA linear model</a></li>
<li class="chapter" data-level="17.13" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#hypothesis-tests"><i class="fa fa-check"></i><b>17.13</b> Hypothesis tests</a></li>
<li class="chapter" data-level="17.14" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#variance-components"><i class="fa fa-check"></i><b>17.14</b> Variance components</a></li>
<li class="chapter" data-level="17.15" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#way-anova-with-interaction"><i class="fa fa-check"></i><b>17.15</b> 2-way ANOVA with interaction</a></li>
<li class="chapter" data-level="17.16" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#linear-model-1"><i class="fa fa-check"></i><b>17.16</b> Linear model</a></li>
<li class="chapter" data-level="17.17" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#hypothesis-tests-1"><i class="fa fa-check"></i><b>17.17</b> Hypothesis tests</a></li>
<li class="chapter" data-level="17.18" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#variance-components-1"><i class="fa fa-check"></i><b>17.18</b> Variance components</a></li>
<li class="chapter" data-level="17.19" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#questions-13"><i class="fa fa-check"></i><b>17.19</b> Questions</a></li>
<li class="chapter" data-level="17.20" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#practice-7"><i class="fa fa-check"></i><b>17.20</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html"><i class="fa fa-check"></i><b>18</b> Regression and Correlation</a>
<ul>
<li class="chapter" data-level="18.1" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#correlations"><i class="fa fa-check"></i><b>18.1</b> Correlations</a></li>
<li class="chapter" data-level="18.2" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#data-6"><i class="fa fa-check"></i><b>18.2</b> Data</a></li>
<li class="chapter" data-level="18.3" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#normal-bivariate"><i class="fa fa-check"></i><b>18.3</b> Normal bivariate</a></li>
<li class="chapter" data-level="18.4" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#estimators"><i class="fa fa-check"></i><b>18.4</b> Estimators</a></li>
<li class="chapter" data-level="18.5" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#correlation-coefficient"><i class="fa fa-check"></i><b>18.5</b> Correlation coefficient</a></li>
<li class="chapter" data-level="18.6" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#hypothesis-contrast"><i class="fa fa-check"></i><b>18.6</b> Hypothesis contrast</a></li>
<li class="chapter" data-level="18.7" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#regression-analysis"><i class="fa fa-check"></i><b>18.7</b> Regression analysis</a></li>
<li class="chapter" data-level="18.8" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#linear-model-2"><i class="fa fa-check"></i><b>18.8</b> Linear model</a></li>
<li class="chapter" data-level="18.9" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#hypothesis-contrast-1"><i class="fa fa-check"></i><b>18.9</b> Hypothesis contrast</a></li>
<li class="chapter" data-level="18.10" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#estimators-1"><i class="fa fa-check"></i><b>18.10</b> Estimators</a></li>
<li class="chapter" data-level="18.11" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#hypothesis-testing-2"><i class="fa fa-check"></i><b>18.11</b> Hypothesis testing</a></li>
<li class="chapter" data-level="18.12" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#stratified-analysis"><i class="fa fa-check"></i><b>18.12</b> Stratified analysis</a></li>
<li class="chapter" data-level="18.13" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#multiple-regression"><i class="fa fa-check"></i><b>18.13</b> Multiple Regression</a></li>
<li class="chapter" data-level="18.14" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#multiple-regression-interaction"><i class="fa fa-check"></i><b>18.14</b> Multiple Regression interaction</a></li>
<li class="chapter" data-level="18.15" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#model-diagnostics"><i class="fa fa-check"></i><b>18.15</b> Model diagnostics</a></li>
<li class="chapter" data-level="18.16" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#questions-14"><i class="fa fa-check"></i><b>18.16</b> Questions</a></li>
<li class="chapter" data-level="18.17" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#practice-8"><i class="fa fa-check"></i><b>18.17</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="apendix.html"><a href="apendix.html"><i class="fa fa-check"></i><b>19</b> Apendix</a>
<ul>
<li class="chapter" data-level="19.1" data-path="apendix.html"><a href="apendix.html#solutions-to-questions"><i class="fa fa-check"></i><b>19.1</b> Solutions to Questions</a></li>
<li class="chapter" data-level="19.2" data-path="apendix.html"><a href="apendix.html#summary-tables-python-and-r-code"><i class="fa fa-check"></i><b>19.2</b> Summary tables, Python and R code</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="apendix.html"><a href="apendix.html#creating-data-frames-and-loading-text-files"><i class="fa fa-check"></i><b>19.2.1</b> Creating Data Frames and Loading Text Files</a></li>
<li class="chapter" data-level="19.2.2" data-path="apendix.html"><a href="apendix.html#python-and-r-functions-for-data-description"><i class="fa fa-check"></i><b>19.2.2</b> Python and R Functions for Data Description</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="apendix.html"><a href="apendix.html#summary-of-common-probability-models"><i class="fa fa-check"></i><b>19.3</b> Summary of common probability models</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="apendix.html"><a href="apendix.html#python-and-r-functions-for-probability-models"><i class="fa fa-check"></i><b>19.3.1</b> Python and R Functions for Probability Models</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="apendix.html"><a href="apendix.html#summary-of-hypothesis"><i class="fa fa-check"></i><b>19.4</b> Summary of hypothesis</a>
<ul>
<li class="chapter" data-level="19.4.1" data-path="apendix.html"><a href="apendix.html#python-and-r-functions-for-hypothesis-tesing"><i class="fa fa-check"></i><b>19.4.1</b> Python and R Functions for Hypothesis tesing</a></li>
<li class="chapter" data-level="19.4.2" data-path="apendix.html"><a href="apendix.html#python-libraries-required"><i class="fa fa-check"></i><b>19.4.2</b> Python Libraries Required</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Data Analysis
for
Experimental Sciences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="conditional-probability" class="section level1 hasAnchor" number="4">
<h1><span class="header-section-number">Chapter 4</span> Conditional probability<a href="conditional-probability.html#conditional-probability" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>The final result of a random experiment can involve the observation of two or more types of outcomes. In a single realization of a random experiment, we may observe a list of observations of different types, each forming a column in an observation matrix. Repetitions of the random experiment add rows to the matrix. Random experiments thus increase in complexity.</p>
<p>Events that are not mutually exclusive naturally support random experiments where multiple types of outcomes can be measured. Joint probabilities of these events extend probability tables into contingency tables for two types of outcomes. This allows us to determine the likelihood of a specific pair of values occurring for the two outcome types. In some experiments, the measurement of one type outcome may provide information about the other, which may be, for instance, technically challenging to ascertain. For example, consider diagnostic tools. In other experiments, one outcome may be easier to control or may provide insights into the probabilities of the other outcome; take for instance the relationship between the temperature of an engine and the power it delivers.</p>
<p>In this chapter, we will introduce the concept of conditional probability. Conditional probability will be used to define statistical independence between two types of outcomes. Evaluating statistical independence is crucial for understanding and controlling random experiments. This topic will be explored further in subsequent chapters on hypothesis testing, where we will examine different ways of conditioning experiments and outcomes.</p>
<p>Additionally, we will discuss Bayesâ theorem and one of its primary applications: assessing the predictive efficiency of diagnostic tools.</p>
<div id="joint-probability" class="section level2 hasAnchor" number="4.1">
<h2><span class="header-section-number">4.1</span> Joint probability<a href="conditional-probability.html#joint-probability" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Recall that the joint probability of two events <span class="math inline">\(A\)</span> <strong>and</strong> <span class="math inline">\(B\)</span> is defined as the probability of their intersection</p>
<p><span class="math display">\[P( A ,B )=P(A \cap B)\]</span></p>
<p>Now imagine random experiments that measure simultaneously different types of outcomes:</p>
<ul>
<li><p>the throw of two dice: (<span class="math inline">\(n_1, n_2\)</span>)</p></li>
<li><p>height and weight of an individual: <span class="math inline">\((h, w)\)</span></p></li>
<li><p>position and speed of a molecule in a gas: <span class="math inline">\((x, v)\)</span></p></li>
<li><p>speed and distance of a galaxy: <span class="math inline">\((v, d)\)</span></p></li>
<li><p>in glycolysis (braking down of glucose), the time the process takes in the first two reactions (phosphorylation of glucose and isomerization of G6P): (<span class="math inline">\(t_1, t_2\)</span>)</p></li>
</ul>
<p>In the first four cases both measurements may appear to be simultaneous characteristics of the experiment, and it is clear that we can report one and then the other, or the other way round. In this last case, while the gycolysis reactions always occur in the same order, when running the experiment, we may also report the times of reaction as (<span class="math inline">\(t_1 \cap t_2\)</span>) or (<span class="math inline">\(t_ 2 \cap t_1\)</span>). That is, the joint events are commutative, or in the observation matrix, the columns can be reordered.</p>
<p>We are now interested in whether the values of one type of outcome <strong>conditions</strong> the values of the other.</p>
</div>
<div id="statistical-independence-and-correlation" class="section level2 hasAnchor" number="4.2">
<h2><span class="header-section-number">4.2</span> Statistical independence and correlation<a href="conditional-probability.html#statistical-independence-and-correlation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In many cases, we are interested in whether certain values of one type of outcome are more likely to occur alongside specific values of another. Our goal is to distinguish between these two scenarios:</p>
<ul>
<li><p><strong>Independence</strong> between events. For example, rolling a 1 on one die does not make it more likely to roll another 1 on a second die.</p></li>
<li><p><strong>Correlation</strong> between events. For example, if a man is tall, he is probably heavy.</p></li>
</ul>
<p>While independence between two events refers to the probability of one event being unaffected by the other event, dependence implies that the probability of the one event is higher when the other event occurs. Correlation thus refers to the likelihood of observing the two events together, or their joint event, or their constant conjunction. As joint events are commutative, correlation does not imply a temporal or causal relationship between the events. However, if there is a causal relationship then correlation is expected.</p>
<p><strong>Example (conductor)</strong></p>
<p>Imagine we conducted an experiment to find out if structural flaws in a material affects its electrical conductivity. We repeated the experiment in <span class="math inline">\(n\)</span> specimens and measured both quantities.</p>
<p>The observation matrix would look like</p>
<p><span class="math display">\[
\begin{array}{ccc}
\mathbf{Conductor} &amp; \mathbf{Structure} &amp; \mathbf{Conductivity} \\
c_1 &amp; \text{flaws} &amp; \text{low} \\
c_2 &amp; \text{no flaws} &amp; \text{high} \\
c_3 &amp; \text{flaws} &amp; \text{low} \\
\vdots &amp; \vdots &amp; \vdots \\
c_i &amp; \text{no flaws} &amp; \text{low*} \\
\vdots &amp; \vdots &amp; \vdots \\
\vdots &amp; \vdots &amp; \vdots \\
c_n &amp; \text{flaws} &amp; \text{high*} \\
\end{array}
\]</span></p>
<p>We may expect that low conductivity occurs more often with flaws than without flaws if the flaws affect conductivity. That is a correlation between the flaws and low conductivity where there is more likelihood for the structure-conductivity pairs with no star. However, we need a tool to assess it.</p>
<p>Let us imagine that from the data we obtain the following <strong>joint probability table</strong></p>
<p><span class="math display">\[
\begin{array}{ccc|c}
&amp; \mathbf{Flaws: F} &amp; \mathbf{No\, flaws: F&#39;} &amp; \mathbf{sum} \\
\mathbf{Low\, conductivity: L} &amp; 0.005 &amp; 0.045 &amp; 0.05 \\
\mathbf{High\, Conductivity: L&#39;} &amp; 0.095 &amp; 0.855 &amp; 0.95 \\ \hline
\mathbf{sum} &amp; 0.1 &amp; 0.9 &amp; 1 \\
\end{array}
\]</span></p>
<p>where, for example, the joint probability that one conductor has low conductivity (<span class="math inline">\(L\)</span>) and flaws (<span class="math inline">\(F\)</span>) is</p>
<ul>
<li><span class="math inline">\(P(L,F)=0.005\)</span></li>
</ul>
<p>and the marginal probabilities are</p>
<ul>
<li><span class="math inline">\(P(L)=P(L, F) + P(L, F&#39;)=0.05\)</span></li>
<li><span class="math inline">\(P(F)=P(L, F) + P(L&#39;, F)= 0.1\)</span>.</li>
</ul>
</div>
<div id="conditional-probability-1" class="section level2 hasAnchor" number="4.3">
<h2><span class="header-section-number">4.3</span> Conditional probability<a href="conditional-probability.html#conditional-probability-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We will say that low conductivity is <strong>independent</strong> of having structural flaws if the probability of having low conductivity (<span class="math inline">\(L\)</span>) is the same <strong>whether</strong> it has flaws (<span class="math inline">\(F\)</span>) or not (<span class="math inline">\(F&#39;\)</span> ) .</p>
<p>Let us first consider only the materials that have flaws.</p>
<p>Among those materials that have flaws (<span class="math inline">\(F\)</span>), what is the estimated probability that they have low conductivity?</p>
<p>Think of the observation matrix, and consider counting the number of specimens with low conductivity and flaws (<span class="math inline">\(n_{L,F}\)</span>), and all the specimens with flaws <span class="math inline">\(n_{F}\)</span>. Then the fraction of materials with flaws that have low conductivity is</p>
<p><span class="math inline">\(\frac{n_{L,F}}{n_{F}}=\frac{n_{L,F}/n}{n_{F}/n}= \frac{f_{L,F}}{f_{F}}\)</span>
<span class="math display">\[= \frac{\hat{P}( L,F )}{\hat{P}(F)}\]</span>
where <span class="math inline">\(f_{L,F}\)</span> are <span class="math inline">\(f_{F}\)</span> the relative frequencies for <span class="math inline">\(n_{L,F}\)</span> and <span class="math inline">\(n_{F}\)</span>; respectively, and <span class="math inline">\(n\)</span> the total number of specimens tested. The last term is the estimated probability that an specimen has low conductivity <strong>if</strong> it has flaws. In the limit when <span class="math inline">\(n \rightarrow \infty\)</span> is</p>
<p><span class="math display">\[P(L| F)= \frac{P(L,F)}{P(F)}=\frac{P(L\cap F)}{P(F)}\]</span></p>
<p>where the symbol <span class="math inline">\(|\)</span> states that the random experiment of measuring conductivity is now run <strong>only</strong> on the specimens that <strong>we know</strong> they have flaws. Note that in <span class="math inline">\(P(L| F)\)</span>, <span class="math inline">\(F\)</span> is not considered as an outcome but as a condition of the experiment. However, this new probability is computed from a random experiment where both <span class="math inline">\(L\)</span> and <span class="math inline">\(F\)</span> are outcomes <span class="math inline">\(P(L\cap F)\)</span>, by reducing the sample space to the specimens with the condition <span class="math inline">\(F\)</span>.</p>
<p><strong>Definition:</strong></p>
<p>The <strong>conditional probability</strong> of an event <span class="math inline">\(A\)</span> given an event <span class="math inline">\(B\)</span>, denoted <span class="math inline">\(P(B| A)\)</span> , is</p>
<p><span class="math display">\[P(A|B) = \frac{P(A\cap B)}{P(B)}.\]</span></p>
<p>We can prove that conditional probability satisfies the axioms of probability. The point here is that conditional probability can be understood as a probability where the conditional event <span class="math inline">\(B\)</span> is fixed. That is, reconsidering the random experiment where the event <span class="math inline">\(B\)</span> is a condition and part of its design. In our example, the new experiment includes only specimens with structural flaws.</p>
</div>
<div id="conditional-contingency-table" class="section level2 hasAnchor" number="4.4">
<h2><span class="header-section-number">4.4</span> Conditional contingency table<a href="conditional-probability.html#conditional-contingency-table" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>If we divide the columns of the joint probability table by their marginal probabilities <span class="math inline">\(P(F)\)</span> and <span class="math inline">\(P(F&#39;)\)</span>, we obtain a <strong>conditional contingency table</strong></p>
<p><span class="math display">\[
\begin{array}{cc|c}
    &amp; \mathbf{Flaws: F} &amp; \mathbf{No\, flaws: F&#39;} \\
    \mathbf{Low\, conductivity: L} &amp; P(L \mid F) &amp; P(L \mid F&#39;) \\
    \mathbf{High\, conductivity: L} &amp; P(L&#39; \mid F) &amp; P(L&#39; \mid F&#39;) \\
    \mathbf{sum} &amp; 1 &amp; 1
\end{array}
\]</span></p>
<p>where the column probabilities sum to one. The first column shows the probabilities of low conductivity or not, only of the materials that have flaws (first condition: <span class="math inline">\(F\)</span>). The second column shows the probabilities only for the materials that have no flaws (second condition: <span class="math inline">\(F&#39;\)</span>). This table refers to two different random experiments, one under the first condition and another under the second one.</p>
<p>Conditional probabilities are the probabilities of the joint events within each condition. We read them as:</p>
<ul>
<li><span class="math inline">\(P(L| F)\)</span>: Probability of having low conductivity <strong>if</strong> it has flaws</li>
<li><span class="math inline">\(P(L&#39;| F)\)</span>: Probability of not having low conductivity <strong>if</strong> it has flaws</li>
<li><span class="math inline">\(P(L|F &#39;)\)</span>: Probability of having low conductivity <strong>if</strong> it has no flaws</li>
<li><span class="math inline">\(P(L&#39;|F &#39;)\)</span>: Probability of not having low conductivity <strong>if</strong> it has no flaws</li>
</ul>
</div>
<div id="statistical-independence" class="section level2 hasAnchor" number="4.5">
<h2><span class="header-section-number">4.5</span> Statistical independence<a href="conditional-probability.html#statistical-independence" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In our example, the conditional contingency table is</p>
<p><span class="math display">\[
\begin{array}{cc|c}
    &amp; \mathbf{Flaws: F} &amp; \mathbf{No\, flaws: F&#39;} \\
    \mathbf{Low\, conductivity:L} &amp; 0.05 &amp; 0.05 \\
    \mathbf{High\, conductivity: L&#39;} &amp; 0.95 &amp; 0.95 \\
    \mathbf{sum} &amp; 1 &amp; 1
\end{array}
\]</span></p>
<p>We note that the conditional probabilities in this table are equal to the marginals <span class="math inline">\(P(L)\)</span> and <span class="math inline">\(P(L&#39;)\)</span> in the joint probability table (Section 4.2)</p>
<ul>
<li><span class="math inline">\(P(L)=P(L| F)= P(L|F&#39;)\)</span></li>
<li><span class="math inline">\(P(L&#39;)=P(L&#39;| F)= P(L&#39;|F&#39;)\)</span></li>
</ul>
<p>This means that the probability of observing low conductivity is <strong>not</strong> dependent on whether a structural flaw is present.</p>
<p>Note that in the joint probability table, the most probable outcome was high conductivity with no flaws, <span class="math inline">\(P(L&#39; \cap F&#39;) = 0.855\)</span>. At first glance, this might suggest a relationship between these two events. However, this apparent relationship arises because both low conductivity and flaws are relatively uncommon events (<span class="math inline">\(P(L) = 0.05\)</span>, <span class="math inline">\(P(F) = 0.1\)</span>) compared to their complements. Conditioning on flaws eliminates the disparity between the marginal probabilities and reveals the actual independence of the events.</p>
<p>We conclude that, for the physical situation represented by this experiment, low conductivity in the material is not influenced by the presence of structural flaws. Equivalently, high conductivity is independent of the absence of flaws.</p>
<p><strong>Definition</strong></p>
<p>Two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> are statistically independent if either of the equivalent cases occurs:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(P(A| B)= P(A)\)</span>; <span class="math inline">\(A\)</span> is independent of <span class="math inline">\(B\)</span></li>
<li><span class="math inline">\(P(B| A)= P(B)\)</span>; <span class="math inline">\(B\)</span> is independent of <span class="math inline">\(A\)</span></li>
</ol>
<p>and by the definition of conditional probability</p>
<ol start="3" style="list-style-type: decimal">
<li><span class="math inline">\(P(A\cap B)=P(A|B)P(B)=P(A)P(B)\)</span></li>
</ol>
<p>This third form is a statement about joint probabilities. It says that we can obtain joint probabilities by multiplying the marginal probabilities.</p>
<p>In our original joint probability table (Section 4.2),
we can confirm that all the entries of the matrix are indeed the product of the marginal probabilities. For example: <span class="math inline">\(P( L \cap F)=P(F)P(L)\)</span> and <span class="math inline">\(P(L&#39; \cap F&#39;)=P(L&#39;)P(F&#39;)\)</span>. Therefore, in our experiment, low conductivity is independent of having a structural flaw because their joint probability is the product of the marginals.</p>
<p><strong>Example (MendelÂ´s first law)</strong></p>
<p>We aim to confirm that the contingency table for Mendelâs first law represents an independent inheritance model of parental alleles.</p>
<p>For mice, the contingency table for the albinism allele <span class="math inline">\(A\)</span> of an offspring from parents, each with alleles (<span class="math inline">\(A, A&#39;\)</span>), is provided in Section 3.14.</p>
<p><span class="math display">\[
\begin{array}{ccc|c}
&amp; \mathbf{A_p} &amp; \mathbf{A_p&#39;} &amp; \mathbf{sum} \\
\mathbf{A_m} &amp; \mathbf{\frac{1}{4}} &amp; \mathbf{\frac{1}{4}} &amp; \frac{1}{2} \\
\mathbf{A_m&#39;} &amp; \mathbf{\frac{1}{4}} &amp; \frac{1}{4} &amp; \frac{1}{2} \\ \hline
\mathbf{sum} &amp; \frac{1}{2} &amp; \frac{1}{2} &amp; 1 \\
\end{array}
\]</span></p>
<p>From this table, we see that the probability of getting the albinism allele <span class="math inline">\(A\)</span> from the mother and from the father is the product of the marginals <span class="math inline">\(P(A_m, A_p)=P(A_m)P(A_p)=1/4\)</span>. Therefore, the inheritance of the maternal allele is independent from the paternal allele. If we build the conditional contingency table, we will see that inheriting a maternal allele is not conditioned by having inherited a paternal allele: <span class="math inline">\(P(A_m| A_p)=P(A_m)=1/2\)</span>.</p>
</div>
<div id="statistical-dependency" class="section level2 hasAnchor" number="4.6">
<h2><span class="header-section-number">4.6</span> Statistical dependency<a href="conditional-probability.html#statistical-dependency" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>An important example of statistical dependency or correlation is found in the performance of <strong>diagnostic tools</strong>, where we want to determine the state of a system with possible outcomes</p>
<ul>
<li>satisfactory (yes)</li>
<li>unsatisfactory (not)</li>
</ul>
<p>using a test with results</p>
<ul>
<li>positive</li>
<li>negative</li>
</ul>
<p>For example, we test a battery to see how long it can last. We perform a stress-strain test on a material to test its elasticity. We perform a PCR (polymerase chain reaction) to see if someone has an infection.</p>
</div>
<div id="diagnostic-test" class="section level2 hasAnchor" number="4.7">
<h2><span class="header-section-number">4.7</span> Diagnostic test<a href="conditional-probability.html#diagnostic-test" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let us consider diagnosing an infection with a new test. The infection status has two possible outcomes:</p>
<ul>
<li>yes (the patient is infected)</li>
<li>no (the patient is not infected)</li>
</ul>
<p>The test has two possible outcomes:</p>
<ul>
<li>positive (the test detects the infection)</li>
<li>negative (the test does not detect the infection)</li>
</ul>
<p>In the laboratory we run performance studies for the testing. In a control environment, where we know whether a patient has the infection, we run the random experiment of testing for the infection. If the testing has high performance, then its results will give mostly positive outcomes. However, we also expect some negatives as the test is not perfect. We also run second experiment where we test patients without the disease.</p>
<p>The conditional probability table describes the likelihoods of each testing outcome for each condition</p>
<p><span class="math display">\[
\begin{array}{cc|c}
    &amp; \mathbf{Infection: yes} &amp; \mathbf{Infection: no} \\
    \mathbf{Test: positive} &amp; P(pos \mid yes) &amp; P(pos \mid no) \\
    \mathbf{Test: negative} &amp; P(neg \mid yes) &amp; P(neg \mid no) \\
    \mathbf{sum} &amp; 1 &amp; 1
\end{array}
\]</span></p>
<p>The conditional table tells us that we are running an experiment where <strong>we know</strong> that the patient either has the disease or not. These are the <strong>controlled conditions</strong> of the experiment. Think for instance that you test the diagnostic tool in the hospital where you know the patients are infected. You also test the tool in healthy individuals who you know they are not infected.</p>
<p>Let us look at the table entries</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(P(pos| yes)\)</span> is called the <strong>sensitivity</strong> of the tool or the probability of a true positive: The probability of testing positive <strong>if</strong> a patient has the disease.</p></li>
<li><p><span class="math inline">\(P(neg| no)\)</span> is called the <strong>specificity</strong> of the tool or the probability of a true negative: The probability of testing negative <strong>if</strong> a patient does not have the disease.</p></li>
<li><p><span class="math inline">\(P(pos| no)\)</span> is called the probability of a false positive: the probability of testing positive <strong>if</strong> the patient does not have the disease.</p></li>
<li><p><span class="math inline">\(P(neg| yes)\)</span> is called the probability of a false negative: the probability of testing negative <strong>if</strong> the patient has the disease.</p></li>
</ol>
<p>High correlation (statistical dependence) between test and infection means high values for probabilities 1 and 2 in the diagonal (successes) <strong>and</strong> low values for probabilities 3 and 4 off the diagonal (errors).</p>
<p><strong>Example (COVID)</strong></p>
<p>Now, let us consider a real situation. In the early days of the sars-cov-2 pandemic (2019/2020), there was no measure of the effectiveness of PCRs in detecting the virus. One of the first published studies <span class="citation">(<a href="#ref-Woloshin2020FalseNegative">Woloshin, Patel, and Kesselheim 2020</a>)</span> found that</p>
<ul>
<li>The PCR had a sensitivity of 70%, in infection condition.</li>
<li>The PCR had a specificity of 94%, in non-infected condition.</li>
</ul>
<p>The conditional probability table for this study was</p>
<p><span class="math display">\[
\begin{array}{cc|c}
    &amp; \mathbf{Infection: yes} &amp; \mathbf{Infection: no} \\
    \mathbf{Test: positive} &amp; 0.7 &amp; 0.06 \\
    \mathbf{Test: negative} &amp; 0.3 &amp; 0.94 \\
    \mathbf{sum} &amp; 1 &amp; 1
\end{array}
\]</span></p>
<p>Therefore, the errors in the diagnostic tests had probabilities:</p>
<ul>
<li><span class="math inline">\(P(pos| no)= 0.06\)</span>, for a false positive.</li>
<li><span class="math inline">\(P(neg| yes)= 0.3\)</span>, for a false negative.</li>
</ul>
<p>Can we say with this data that the test is useful to detect the infection?</p>
</div>
<div id="inverse-probabilities" class="section level2 hasAnchor" number="4.8">
<h2><span class="header-section-number">4.8</span> Inverse probabilities<a href="conditional-probability.html#inverse-probabilities" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We are really interested in finding the probability of being infected if the test is positive <span class="math display">\[P(yes| pos)\]</span></p>
<p>instead of the reported sensitivity <span class="math inline">\(P(pos|yes)\)</span>. In other words, you may want to run an experiment on a patient that you know is positive for the test and determine the probability that he is infected. Note that this experiment is not in a controlled environment of the lab, it is rather a surveying campaign on the population, where you collect all the positives and determine the fraction that were infected.</p>
<p>To compute these inverse probability, where the condition is now on the other event (positive), we follow the steps:</p>
<ol style="list-style-type: decimal">
<li>Recover the contingency table for <strong>joint probabilities</strong>, multiplying by the marginal <span class="math inline">\(P(yes)\)</span> and <span class="math inline">\(P(no)\)</span> that we need to know or be given.</li>
</ol>
<p><span class="math display">\[
\begin{array}{ccc|c}
&amp; \mathbf{Infection: yes} &amp; \mathbf{Infection: no} &amp; \mathbf{sum} \\
\mathbf{Test: positive} &amp; P(pos \mid yes)P(yes) &amp; P(pos \mid no)P(no) &amp; P(pos) \\
\mathbf{Test: negative} &amp; P(neg \mid yes)P(yes) &amp; P(neg \mid no)P(no) &amp; P(neg) \\ \hline
\mathbf{sum} &amp; P(yes) &amp; P(no) &amp; 1 \\
\end{array}
\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Obtain the <strong>conditional probability table</strong> for rows.</li>
</ol>
<p><span class="math display">\[
\begin{array}{cccc}
    &amp; \mathbf{Infection: yes} &amp; \mathbf{Infection: no} &amp; \mathbf{sum} \\
    \mathbf{Test: positive} &amp; P(yes \mid pos) &amp; P(no \mid pos ) &amp; 1 \\ \hline
    \mathbf{Test: negative} &amp; P(yes \mid neg) &amp; P(no \mid neg) &amp; 1\\
\end{array}
\]</span></p>
<p>To compute these probabilities, we use the definition of conditional probabilities for rows instead of columns. We divide the rows of the joint probability table in step 1 by the marginals of the test outcomes: <span class="math inline">\(P(pos)\)</span> and <span class="math inline">\(P(neg)\)</span>. For example, for the first cell of the conditional probability table we obtain:</p>
<p><span class="math display">\[P(yes| pos)= \frac{P(pos|yes)P(yes)}{P(pos)}\]</span></p>
<p>Note that these is a new random experiment, in which all the individuals tested positive for the PCR fixed and we ask for the probability of infection.</p>
<p>While <span class="math inline">\(P(pos|yes)\)</span> was the result of the study (<span class="math inline">\(0.7\)</span>), we still need to know the the marginals <span class="math inline">\(P(yes)\)</span> (prevalence) and <span class="math inline">\(P(pos)\)</span>.</p>
<ul>
<li><p>The prevalence <span class="math inline">\(P(yes)\)</span> <strong>needs to be given</strong>. In real life, it is obtained from another study. The first prevalence study in Spain, before the summer of 2020, showed that during lock down the estimated probability of infection was <span class="math inline">\(P(yes)=0.05\)</span>, and of no infection <span class="math inline">\(P(no)=0.95\)</span>.</p></li>
<li><p>To find the marginal of positive tests <span class="math inline">\(P(pos)\)</span>, we can use the definition of marginal and conditional probabilities:</p></li>
</ul>
<p><span class="math inline">\(P(pos)= P(pos \cap yes) + P(pos \cap no)\)</span>
<span class="math display">\[= P(pos| yes)P (yes)+P(pos|no)P(no)\]</span>
This last relation of the marginals is called <strong>total probability rule</strong>.</p>
</div>
<div id="bayes-theorem" class="section level2 hasAnchor" number="4.9">
<h2><span class="header-section-number">4.9</span> Bayesâ Theorem<a href="conditional-probability.html#bayes-theorem" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>After substituting the total probability rule into <span class="math inline">\(P(yes| pos)\)</span> , we have</p>
<p><span class="math display">\[P(yes| pos)= \frac{P(pos|yes)P(yes)}{P(pos|yes)P(yes)+P(pos|no)P(no)}\]</span>
This expression is known as <strong>Bayesâ theorem</strong>. It allows us to reverse the conditionals:</p>
<p><span class="math display">\[P(pos|yes) \rightarrow P(yes| pos)\]</span>
This result is important. It allows us to <strong>assess</strong> a diagnostic tool in a controlled condition (infection status is a lab) and then use it to <strong>infer</strong> the probability of the condition (infection) when the test is positive.</p>
<p><strong>Example (COVID)</strong>:</p>
<p>The test performance was:</p>
<ul>
<li><p>Sensitivity: <span class="math inline">\(P(positive| yes)= 0.70\)</span></p></li>
<li><p>False positive: <span class="math inline">\(P(positive| no)= 1- P(neg|no)=0.06\)</span></p></li>
</ul>
<p>The study in the Spanish population gave:</p>
<ul>
<li><span class="math inline">\(P(yes)=0.05\)</span></li>
<li><span class="math inline">\(P(no)=1-P(yes)=0.95\)</span>.</li>
</ul>
<p>Therefore, the probability of being infected in case of testing positive was:</p>
<p><span class="math display">\[P(yes| pos)= 0.38\]</span></p>
<p>We conclude that at that time PCR was not very good at <strong>diagnosing</strong> infections.</p>
<p>However, let us now apply Bayesâ theorem to the probability of not being infected if the test was negative.</p>
<p><span class="math display">\[P(no|neg) = \frac{P(neg|no) P(no )}{ P(neg|no) P(no)+P(neg|yes)P(yes)}\]</span></p>
<p>Substituting all values gives</p>
<p><span class="math display">\[P(no| neg)= 0.98\]</span></p>
<p>Therefore, the tests were good for <strong>ruling out</strong> infections and a fair requirement for travelling.</p>
<p>In general, we can have more than two conditioning events, or controlled environments of our experiment. Therefore, Bayesâ theorem says that the probability of an event <span class="math inline">\(E_i\)</span> given the condition <span class="math inline">\(B\)</span>:</p>
<p><span class="math display">\[P(E_i| B)= \frac{P(B|E_i)P(E_i)}{P(B|E_0)P(E_0) +...+ P(B|E_k)P(E_k)}\]</span>
when <span class="math inline">\(E_0, E_1, ..., E_k\)</span> are <span class="math inline">\(k\)</span> mutually exclusive and exhaustive events and <span class="math inline">\(B\)</span> is a condition of interest.</p>
<p><strong>Example (Mosophonia)</strong></p>
<p>Consider the diagnosis of misophonia. An interesting question is whether misophonia severity <span class="math inline">\(4\)</span> is more likely in depressed patients (<span class="math inline">\(D\)</span>). This corresponds to the conditional probability <span class="math inline">\(P(4|D)\)</span>. In a clinical study of misophonia, patients were evaluated for four different severity levels and tested for signs of clinical depression. The probability of severity <span class="math inline">\(4\)</span> in depressed patients, <span class="math inline">\(P(4|D)\)</span>, can be expressed using Bayesâ theorem in terms of the probability of depression in severe cases (<span class="math inline">\(P(D|4)\)</span>) and the marginal probabilities <span class="math inline">\(P(4)\)</span> and <span class="math inline">\(P(D)\)</span>. The prevalence of depression (<span class="math inline">\(P(D)\)</span>) can be calculated using the total probability rule:</p>
<p><span class="math display">\[
P(D) = P(D|0)P(0) + \ldots + P(D|4)P(4)
\]</span></p>
<p>We do not know whether depression or misophonia occurs first, but reverse conditional probabilities (e.g., <span class="math inline">\(P(D|4)\)</span>) can be useful as an initial step toward identifying potential causal relationships. Depression relief could then, in some cases, be delivered by misophonia treatment. It is important to note that conditional probability reflects correlation, not causation. However, if misophonia is indeed a cause of depression, we would expect the probability of depression to increase with misophonia severity, following a dose-response relationship. Additionally, establishing causation requires biological or physical plausibility, ruling out reverse causation (e.g., depression causing misophonia), and other supporting criteria.</p>
<p>Even so, this may not be sufficient, as confounding factors could influence the observed relationship. For example, if misophonia severity and depression are both higher in women, the association may be due to their shared dependence on gender rather than a direct causal link. Adjustments and further conditioning of the experiment may be necessary, requiring additional control variables or the measurement of more outcome types to disentangle these effects.</p>
<p><strong>Conditional tree</strong></p>
<p>The terms in the total probability rule can also be <strong>organized</strong> in a conditional tree.</p>
<p><img src="figures/treetot.jpg" /></p>
<p>The <strong>total probability rule</strong> tells us in how many ways I can get the result <span class="math inline">\(B\)</span> from the outcomes <span class="math inline">\(A\)</span> or <span class="math inline">\(A&#39;\)</span></p>
<p><span class="math display">\[P(B)=P(B|A)P(A)+P(B|A&#39;)P(A&#39;)\]</span></p>
<p>Trees are an important tool to determine possible ways of causation as they can incorporate several types of conditions.</p>
<p><strong>Example (Monty Hall)</strong></p>
<p>Monty Hall, the host of a 1970s television show, asked a contestant to choose one of three doors. Behind one door was a car; behind the other two, goats. After the contestant made an initial choice, Monty revealed one of the two remaining doors that hid a goat. He then asked whether the contestant wanted to stick with their original choice or switch to the other unopened door. Once the final decision was made, the chosen door was opened to reveal the prize.</p>
<p>The game gained widespread attention after a 1990 column by Marilyn vos Savant in Parade magazine, in which many academics incorrectly argued that switching made no difference. The controversy highlighted the common difficulty of understanding conditional probabilities and sparked a lasting debate within the statistical community: Should the player stick with their choice or switch doors?</p>
<p>Consider now the events of choosing a car (<span class="math inline">\(c\)</span>), the first goat (<span class="math inline">\(g_1\)</span>), or the second goat (<span class="math inline">\(g_2\)</span>) in the first door choice:</p>
<ul>
<li><span class="math inline">\(S_1=\{c, g_1, g_2\}\)</span></li>
</ul>
<p>The probabilities of these events are equally likely <span class="math inline">\(P(c)=P(g_1)=P(g_2)=\frac{1}{3}\)</span>.</p>
<p>After Monty Hall opening a door that reveals either goat 1 or goat 2, consider the events that the unopened door has the car, the first goat, or the second one:</p>
<ul>
<li><span class="math inline">\(S_2=\{C, G_1, G_2\}\)</span></li>
</ul>
<p>The probabilities on these events are conditional probabilities, as they depend on what we have initially chosen:</p>
<p><span class="math display">\[
\begin{array}{cc|c|c}
    &amp; \mathbf{c} &amp; \mathbf{g_1} &amp; \mathbf{g_2}\\
    \mathbf{C} &amp; 0 &amp; 1 &amp; 1\\
    \mathbf{G_1} &amp; \frac{1}{2} &amp; 0 &amp; 0\\
    \mathbf{G_2} &amp; \frac{1}{2} &amp; 0 &amp; 0 \\
    \mathbf{Sum} &amp; 1 &amp; 1 &amp; 1
\end{array}
\]</span></p>
<p>For instance, the probability that Hallâs unopened door has goat 1 if the car is in the playerâs first door choice <span class="math inline">\(P(G_1|c)=\frac{1}{2}\)</span>. Or, the probability that the unopened door has goat 1 if goat 2 is in the first door <span class="math inline">\(P(G_1|g_2)=0\)</span>, since Monty Hall should reveal goat 1 in the second door.</p>
<p>What is the probability that in the remaining door there is a car?</p>
<p>The total probability rule for <span class="math inline">\(P(C)\)</span> is:</p>
<p><img src="figures/montyhall.jpg" /></p>
<p><span class="math display">\[
P(C)=P(C|g_1)P(g_1)+P(C|g_2)P(g_2)=\frac{2}{3}
\]</span></p>
<p>Therefore, there is more chance of winning a car if we always switch doors and select the remaining door, as correctly indicated Selvin <span class="citation">(<a href="#ref-Selvin1975-SELAPI-2">Selvin 1975</a>)</span>. Note that in the case Monty Hall does not reveal a door, the player remains with two doors to switch from. Then, the player has, for instance, half chance to win a car if they selected goat 1 in the first door <span class="math inline">\(P(C|g_1)=P(G_2|g_1)=\frac{1}{2}\)</span>. Consequently, their overall chances remain the same <span class="math inline">\(P(c)=P(C)=\frac{1}{3}\)</span> if they decide to switch doors or not.</p>
</div>
<div id="questions-2" class="section level2 hasAnchor" number="4.10">
<h2><span class="header-section-number">4.10</span> Questions<a href="conditional-probability.html#questions-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The following data is part of John Snowâs study on the London 1854 cholera epidemic <span class="citation">(<a href="#ref-snow1855mode">Snow 1855</a>)</span>. He famously showed that the lack of water supply hygiene was key in the spread of cholera. The data record the date of death and the water supply source used by 3920 deceased patients.</p>
<p><small>
<span class="math display">\[
\begin{array}{|l|r|r|r|r|r|r|}
\hline
\textbf{Week Ending} &amp; \textbf{Total} &amp; \textbf{S and V} &amp; \textbf{Lambeth} &amp; \textbf{Kent} &amp; \textbf{Other} &amp; \textbf{Not Ascertained} \\
\hline
\text{Sept 2, 1854}  &amp; 670 &amp; 399 &amp; 45  &amp; 38  &amp; 72 &amp; 116 \\
\text{Sept 9, 1854}  &amp; 972 &amp; 580 &amp; 72  &amp; 45  &amp; 62 &amp; 213 \\
\text{Sept 16, 1854} &amp; 856 &amp; 524 &amp; 66  &amp; 48  &amp; 44 &amp; 174 \\
\text{Sept 23, 1854} &amp; 724 &amp; 432 &amp; 72  &amp; 28  &amp; 62 &amp; 130 \\
\text{Sept 30, 1854} &amp; 383 &amp; 228 &amp; 25  &amp; 19  &amp; 24 &amp;  87 \\
\text{Oct 7, 1854}   &amp; 200 &amp; 121 &amp; 14  &amp; 10  &amp; 9  &amp;  46 \\
\text{Oct 14, 1854}  &amp; 115 &amp;  69 &amp; 8   &amp; 3   &amp; 6  &amp;  29 \\
\hline
\textbf{Total}       &amp; \textbf{3920} &amp; \textbf{2353} &amp; \textbf{302} &amp; \textbf{191} &amp; \textbf{279} &amp; \textbf{795} \\
\hline
\end{array}
\]</span>
</small></p>
<p><strong>1)</strong> What is the estimated probability that patient died at the on September the 2nd if use water from Southwark and Vauxhall supplier?</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> <span class="math inline">\(399/3920\)</span>; <strong><span class="math inline">\(\qquad\)</span>b:</strong> <span class="math inline">\(399/100\)</span>; <strong><span class="math inline">\(\qquad\)</span>c:</strong> <span class="math inline">\(399/2353\)</span>; <strong><span class="math inline">\(\qquad\)</span>d:</strong> <span class="math inline">\(399\)</span>;</p>
<p><strong>2)</strong> John Snow reports a total of 40046 houses supplied by Southwark and Vauxhall Company and 26107 houses by Lambeth Company. Build a contingency table for deaths and no-deaths in households by company. What is the probability of dying in Southwark and Vauxhall? (compare it with that of Lambeth)</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> <span class="math inline">\(0.011\)</span>; <strong><span class="math inline">\(\qquad\)</span>b:</strong> <span class="math inline">\(0.058\)</span>; <strong><span class="math inline">\(\qquad\)</span>c:</strong> <span class="math inline">\(0.035\)</span>; <strong><span class="math inline">\(\qquad\)</span>d:</strong> <span class="math inline">\(0.062\)</span></p>
<p><strong>3)</strong> A diagnostic test has a probability of <span class="math inline">\(8/9\)</span> of detecting a disease if the patients are sick and a probability of <span class="math inline">\(3/9\)</span> of detecting the disease if the patients are healthy. If the probability of being sick is <span class="math inline">\(1/9\)</span>. What is the probability that a patient is sick if a test detects the disease?</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> <span class="math inline">\(\frac{8/9}{8/9+3/9}\times1/9\)</span>;
<strong><span class="math inline">\(\qquad\)</span>b:</strong> <span class="math inline">\(\frac{3/9}{8/9+3/9}\times1/9\)</span>;
<strong><span class="math inline">\(\qquad\)</span>c:</strong> <span class="math inline">\(\frac{3/9\times8/9}{8/9\times1/9+3/9\times8/9}\)</span>; <strong><span class="math inline">\(\qquad\)</span>d:</strong> <span class="math inline">\(\frac{8/9\times1/9}{8/9\times1/9+3/9\times8/9}\)</span>;</p>
<p><strong>4)</strong> As discussed in the notes, a PCR test for coronavirus had a sensitivity of 70% and a specificity of 94% and in Spain during confinement there was an incidence of 5%. With these data, what was the probability of testing positive in Spain (<span class="math inline">\(P(positive)\)</span>)</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> <span class="math inline">\(0.035\)</span>; <strong><span class="math inline">\(\qquad\)</span>b:</strong> <span class="math inline">\(0.092\)</span>; <strong><span class="math inline">\(\qquad\)</span>c:</strong> <span class="math inline">\(0.908\)</span>; <strong><span class="math inline">\(\qquad\)</span>d:</strong> <span class="math inline">\(0.95\)</span></p>
<p><strong>5)</strong> With the same data as in question 4, testing positive in the PCR and being infected are not independent events because:</p>
<p><strong><span class="math inline">\(\qquad\)</span> a:</strong> Sensitivity is 70%;
<strong><span class="math inline">\(\qquad\)</span>b:</strong> Sensitivity and false positive rate are different;
<strong><span class="math inline">\(\qquad\)</span>c:</strong> The false positive rate is 0.06%; <strong><span class="math inline">\(\qquad\)</span>d:</strong> the specificity is 96%</p>
</div>
<div id="exercises-2" class="section level2 hasAnchor" number="4.11">
<h2><span class="header-section-number">4.11</span> Exercises<a href="conditional-probability.html#exercises-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="exercise-1-1" class="section level4 hasAnchor" number="4.11.0.1">
<h4><span class="header-section-number">4.11.0.1</span> Exercise 1<a href="conditional-probability.html#exercise-1-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A machine is tested for its performance in producing high-quality turning rods. These are the test results</p>
<p><span class="math display">\[
\begin{array}{ccc}
&amp; \textbf{Rounded: Yes} &amp; \textbf{Rounded: No} \\
\textbf{Smooth Surface: Yes} &amp; 200 &amp; 1 \\
\textbf{Smooth Surface: No} &amp; 4 &amp; 2 \\
\end{array}
\]</span></p>
<ul>
<li><p>What is the estimated probability that the machine will produce a rod that does not satisfy any quality control? (A: 2/207)</p></li>
<li><p>What is the estimated probability that the machine will produce a rod that fails at least one quality check? (A: 7/207)</p></li>
<li><p>What is the estimated probability that the machine will produce rods with a rounded and smooth surface? (A: 200/207)</p></li>
<li><p>What is the estimated probability that the bar is rounded if the bar is smooth? (A: 200/201)</p></li>
<li><p>What is the estimated probability that the rod is smooth if it is rounded? (A: 200/204)</p></li>
<li><p>What is the estimated probability that the rod is neither smooth nor rounded if it does not satisfy at least one quality check? (A: 2/7)</p></li>
<li><p>Are smoothness and roundness independent events? (No)</p></li>
</ul>
</div>
<div id="exercise-2-1" class="section level4 hasAnchor" number="4.11.0.2">
<h4><span class="header-section-number">4.11.0.2</span> Exercise 2<a href="conditional-probability.html#exercise-2-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Consider a probabilistic version of the quantum bomb tester using a double-slit experiment with a photon <span class="citation">(<a href="#ref-Elitzur1993">Elitzur and Vaidman 1993</a>)</span>. A photon is sent toward a barrier with two slits, and two detectors are placed at positions a and b, as shown in the figure below.</p>
<p>Each time a detector captures the photon, it registers a âtick.â Detector a is faulty, with a probability of being âonâ of <span class="math inline">\(4/5\)</span>. When a is âon,â it detects which slit the photon passed through, and there are three possible outcomes in this random experiment: I) The photon is detected at a, and thus not at b, II) The photon is detected at b with probability <span class="math inline">\(2/3\)</span>, III) The photon is not detected at either detector. If a is âoff,â the photon passes through both slits as a wave, and interference occurs. In that case, there is only one possible outcome: IV) No detection occurs at b, if we cleverly placed it at a location where, in the absence of which-path detection (i.e., when a is off), destructive interference occurs â meaning the photon will never be detected at b in that case.</p>
<p>Outcome 2 is the most curious: the photon is detected at b, yet we know that a was âonâ â meaning we obtain information about a without any interaction. Elitzur and Vaidman attached a bomb to detector a to make the effect more dramatic: we may infer that a bomb is âonâ without even interacting with it. Remarkably, this outcome occurs with nonzero probability.</p>
<ul>
<li><p>What is the probability that detector b ticks? (A:<span class="math inline">\(4/15\)</span>)</p></li>
<li><p>What is the probability that the bomb is âonâ if the photon was detected at b? (A:<span class="math inline">\(1\)</span>)</p></li>
<li><p>What is the probability that the bomb is âonâ if the photon was not detected at a (A:<span class="math inline">\(2/3\)</span>)</p></li>
</ul>
<p><img src="figures/quantum.jpg" /></p>
</div>
<div id="exercise-3-1" class="section level4 hasAnchor" number="4.11.0.3">
<h4><span class="header-section-number">4.11.0.3</span> Exercise 3<a href="conditional-probability.html#exercise-3-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We developed a test to detect the presence of bacteria in a lake. We found that if the lake contains the bacteria, the test is positive 70% of the time. If there are no bacteria, the test is negative 60% of the time. We implemented the test in a region where we know that 20% of the lakes have bacteria.</p>
<ul>
<li>What is the probability that a lake that tests positive is contaminated with bacteria? (A: 0.30)</li>
</ul>
</div>
<div id="exercise-4-1" class="section level4 hasAnchor" number="4.11.0.4">
<h4><span class="header-section-number">4.11.0.4</span> Exercise 4<a href="conditional-probability.html#exercise-4-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>A quality test on a random brick is defined by the events:</p>
<ul>
<li>Pass the quality test: <span class="math inline">\(E\)</span>, fail the quality test: <span class="math inline">\(E&#39;\)</span></li>
<li>Defective: <span class="math inline">\(D\)</span>, non-defective: <span class="math inline">\(D&#39;\)</span></li>
</ul>
<p>If the diagnostic test has sensitivity <span class="math inline">\(P(E|D&#39;)= 0.99\)</span> and specificity <span class="math inline">\(P(E&#39;|D)=0.98\)</span>, and the probability of passing the test is <span class="math inline">\(P(E) =0.893\)</span> then</p>
<ul>
<li><p>What is the probability that a randomly chosen brick is defective <span class="math inline">\(P(D)\)</span>? (A: 0.1)</p></li>
<li><p>What is the probability that a brick that has passed the test is actually defective? (A: 0.022)</p></li>
<li><p>The probability that a brick is not defective <strong>and</strong> that it fails the test (A: 0.009)</p></li>
<li><p>Are <span class="math inline">\(D\)</span> and <span class="math inline">\(E&#39;\)</span> statistically independent? (No)</p></li>
</ul>
</div>
</div>
<div id="practice-2" class="section level2 hasAnchor" number="4.12">
<h2><span class="header-section-number">4.12</span> Practice<a href="conditional-probability.html#practice-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Load misophonia data from <code><a href="https://alejandro-isglobal.github.io/SDA/data/Misophonia.txt" class="uri">https://alejandro-isglobal.github.io/SDA/data/Misophonia.txt</a></code></p>
<ul>
<li><p>Compute the conditional probability table of misophophonia (Misophonia) given marital status (Marital Status). What is the estimated probability of having misophonia if the patient is married?</p></li>
<li><p>Compute the conditional probability table of marital status (Marital Status) given misophonia (Misophonia). What is the estimated probability of being married if the patient is misophonic?</p></li>
</ul>
<p><a href="https://colab.research.google.com/drive/1ncTaoBgskCJcBIb0-PdnbUFr_AKU0XRF?usp=sharing">Solutions</a></p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Elitzur1993" class="csl-entry">
Elitzur, Avshalom C., and Lev Vaidman. 1993. <span>âQuantum Mechanical Interaction-Free Measurements.â</span> <em>Foundations of Physics</em> 23 (7): 987â97. <a href="https://doi.org/10.1007/BF00736012">https://doi.org/10.1007/BF00736012</a>.
</div>
<div id="ref-Selvin1975-SELAPI-2" class="csl-entry">
Selvin, Steve. 1975. <span>âA Problem in Probability (Letter to the Editor).â</span> <em>The American Statistician</em> 29 (1): 67.
</div>
<div id="ref-snow1855mode" class="csl-entry">
Snow, John. 1855. <em>On the Mode of Communication of Cholera</em>. London: John Churchill.
</div>
<div id="ref-Woloshin2020FalseNegative" class="csl-entry">
Woloshin, Steven, Neeraj G. Patel, and Aaron S. Kesselheim. 2020. <span>âFalse Negative Tests for SARS-CoV-2 Infection â Challenges and Implications.â</span> <em>New England Journal of Medicine</em> 383 (6): e38. <a href="https://doi.org/10.1056/NEJMp2015897">https://doi.org/10.1056/NEJMp2015897</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="probability.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="discrete-random-variables.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/03-ConditionalProbability.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
