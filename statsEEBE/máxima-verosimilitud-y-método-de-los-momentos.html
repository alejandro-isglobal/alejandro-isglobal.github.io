<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 12 Máxima verosimilitud y Método de los Momentos | Estadística</title>
  <meta name="description" content="This are slides for the Stats theory of the BIST master" />
  <meta name="generator" content="bookdown 0.34 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 12 Máxima verosimilitud y Método de los Momentos | Estadística" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This are slides for the Stats theory of the BIST master" />
  <meta name="github-repo" content="alejandro-isglobal/master" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 12 Máxima verosimilitud y Método de los Momentos | Estadística" />
  
  <meta name="twitter:description" content="This are slides for the Stats theory of the BIST master" />
  

<meta name="author" content="Alejandro Cáceres (alejandro.caceres.dominguez@upc.edu)" />


<meta name="date" content="2023-06-05" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="teorema-central-del-límite.html"/>
<link rel="next" href="intervalos-de-confianza.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Estadística EEBE</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Objetivo</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#lectura-recomendada"><i class="fa fa-check"></i><b>1.1</b> Lectura recomendada</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html"><i class="fa fa-check"></i><b>2</b> Descripción de datos</a>
<ul>
<li class="chapter" data-level="2.1" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#método-científico"><i class="fa fa-check"></i><b>2.1</b> Método científico</a></li>
<li class="chapter" data-level="2.2" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#estadística"><i class="fa fa-check"></i><b>2.2</b> Estadística</a></li>
<li class="chapter" data-level="2.3" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#datos"><i class="fa fa-check"></i><b>2.3</b> Datos</a></li>
<li class="chapter" data-level="2.4" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#tipos-de-resultado"><i class="fa fa-check"></i><b>2.4</b> Tipos de resultado</a></li>
<li class="chapter" data-level="2.5" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#experimentos-aleatorios"><i class="fa fa-check"></i><b>2.5</b> Experimentos aleatorios</a></li>
<li class="chapter" data-level="2.6" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#frecuencias-absolutas"><i class="fa fa-check"></i><b>2.6</b> Frecuencias absolutas</a></li>
<li class="chapter" data-level="2.7" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#frecuencias-relativas"><i class="fa fa-check"></i><b>2.7</b> Frecuencias relativas</a></li>
<li class="chapter" data-level="2.8" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#diagrama-de-barras"><i class="fa fa-check"></i><b>2.8</b> Diagrama de barras</a></li>
<li class="chapter" data-level="2.9" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#gráfico-de-sectores-pie"><i class="fa fa-check"></i><b>2.9</b> Gráfico de sectores (pie)</a></li>
<li class="chapter" data-level="2.10" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#variables-categóricas-ordinales"><i class="fa fa-check"></i><b>2.10</b> Variables categóricas ordinales</a></li>
<li class="chapter" data-level="2.11" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#frecuencias-acumuladas-absolutas-y-relativas"><i class="fa fa-check"></i><b>2.11</b> Frecuencias acumuladas absolutas y relativas</a></li>
<li class="chapter" data-level="2.12" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#gráfica-de-frecuencia-acumulada"><i class="fa fa-check"></i><b>2.12</b> Gráfica de frecuencia acumulada</a></li>
<li class="chapter" data-level="2.13" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#variables-numéricas"><i class="fa fa-check"></i><b>2.13</b> Variables numéricas</a></li>
<li class="chapter" data-level="2.14" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#transformando-datos-continuos"><i class="fa fa-check"></i><b>2.14</b> Transformando datos continuos</a></li>
<li class="chapter" data-level="2.15" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#tabla-de-frecuencias-para-una-variable-continua"><i class="fa fa-check"></i><b>2.15</b> Tabla de frecuencias para una variable continua</a></li>
<li class="chapter" data-level="2.16" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#histograma"><i class="fa fa-check"></i><b>2.16</b> Histograma</a></li>
<li class="chapter" data-level="2.17" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#gráfica-de-frecuencia-acumulada-1"><i class="fa fa-check"></i><b>2.17</b> Gráfica de frecuencia acumulada</a></li>
<li class="chapter" data-level="2.18" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#estadísticas-de-resumen"><i class="fa fa-check"></i><b>2.18</b> Estadísticas de resumen</a></li>
<li class="chapter" data-level="2.19" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#promedio-media-muestral"><i class="fa fa-check"></i><b>2.19</b> Promedio (media muestral)</a></li>
<li class="chapter" data-level="2.20" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#promedio"><i class="fa fa-check"></i><b>2.20</b> Promedio</a></li>
<li class="chapter" data-level="2.21" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#mediana"><i class="fa fa-check"></i><b>2.21</b> mediana</a></li>
<li class="chapter" data-level="2.22" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#dispersión"><i class="fa fa-check"></i><b>2.22</b> Dispersión</a></li>
<li class="chapter" data-level="2.23" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#variación-de-la-muestra"><i class="fa fa-check"></i><b>2.23</b> Variación de la muestra</a></li>
<li class="chapter" data-level="2.24" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#rango-intercuartílico-iqr"><i class="fa fa-check"></i><b>2.24</b> Rango intercuartílico (IQR)</a></li>
<li class="chapter" data-level="2.25" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#diagrama-de-caja"><i class="fa fa-check"></i><b>2.25</b> Diagrama de caja</a></li>
<li class="chapter" data-level="2.26" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#preguntas"><i class="fa fa-check"></i><b>2.26</b> Preguntas</a></li>
<li class="chapter" data-level="2.27" data-path="descripción-de-datos.html"><a href="descripción-de-datos.html#ejercicios"><i class="fa fa-check"></i><b>2.27</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probabilidad.html"><a href="probabilidad.html"><i class="fa fa-check"></i><b>3</b> Probabilidad</a>
<ul>
<li class="chapter" data-level="3.1" data-path="probabilidad.html"><a href="probabilidad.html#experimentos-aleatorios-1"><i class="fa fa-check"></i><b>3.1</b> Experimentos aleatorios</a></li>
<li class="chapter" data-level="3.2" data-path="probabilidad.html"><a href="probabilidad.html#probabilidad-de-medición"><i class="fa fa-check"></i><b>3.2</b> Probabilidad de medición</a></li>
<li class="chapter" data-level="3.3" data-path="probabilidad.html"><a href="probabilidad.html#probabilidad-clásica"><i class="fa fa-check"></i><b>3.3</b> Probabilidad clásica</a></li>
<li class="chapter" data-level="3.4" data-path="probabilidad.html"><a href="probabilidad.html#frecuencias-relativas-1"><i class="fa fa-check"></i><b>3.4</b> Frecuencias relativas</a></li>
<li class="chapter" data-level="3.5" data-path="probabilidad.html"><a href="probabilidad.html#frecuencias-relativas-en-el-infinito"><i class="fa fa-check"></i><b>3.5</b> Frecuencias relativas en el infinito</a></li>
<li class="chapter" data-level="3.6" data-path="probabilidad.html"><a href="probabilidad.html#probabilidad-frecuentista"><i class="fa fa-check"></i><b>3.6</b> Probabilidad frecuentista</a></li>
<li class="chapter" data-level="3.7" data-path="probabilidad.html"><a href="probabilidad.html#probabilidades-clásicas-y-frecuentistas"><i class="fa fa-check"></i><b>3.7</b> Probabilidades clásicas y frecuentistas</a></li>
<li class="chapter" data-level="3.8" data-path="probabilidad.html"><a href="probabilidad.html#definición-de-probabilidad"><i class="fa fa-check"></i><b>3.8</b> Definición de probabilidad</a></li>
<li class="chapter" data-level="3.9" data-path="probabilidad.html"><a href="probabilidad.html#tabla-de-probabilidades"><i class="fa fa-check"></i><b>3.9</b> Tabla de probabilidades</a></li>
<li class="chapter" data-level="3.10" data-path="probabilidad.html"><a href="probabilidad.html#espacio-muestral"><i class="fa fa-check"></i><b>3.10</b> Espacio muestral</a></li>
<li class="chapter" data-level="3.11" data-path="probabilidad.html"><a href="probabilidad.html#eventos"><i class="fa fa-check"></i><b>3.11</b> Eventos</a></li>
<li class="chapter" data-level="3.12" data-path="probabilidad.html"><a href="probabilidad.html#álgebra-de-eventos"><i class="fa fa-check"></i><b>3.12</b> Álgebra de eventos</a></li>
<li class="chapter" data-level="3.13" data-path="probabilidad.html"><a href="probabilidad.html#resultados-mutuamente-excluyentes"><i class="fa fa-check"></i><b>3.13</b> Resultados mutuamente excluyentes</a></li>
<li class="chapter" data-level="3.14" data-path="probabilidad.html"><a href="probabilidad.html#probabilidades-conjuntas"><i class="fa fa-check"></i><b>3.14</b> Probabilidades conjuntas</a></li>
<li class="chapter" data-level="3.15" data-path="probabilidad.html"><a href="probabilidad.html#tabla-de-contingencia"><i class="fa fa-check"></i><b>3.15</b> Tabla de contingencia</a></li>
<li class="chapter" data-level="3.16" data-path="probabilidad.html"><a href="probabilidad.html#la-regla-de-la-suma"><i class="fa fa-check"></i><b>3.16</b> La regla de la suma:</a></li>
<li class="chapter" data-level="3.17" data-path="probabilidad.html"><a href="probabilidad.html#preguntas-1"><i class="fa fa-check"></i><b>3.17</b> Preguntas</a></li>
<li class="chapter" data-level="3.18" data-path="probabilidad.html"><a href="probabilidad.html#ejercicios-1"><i class="fa fa-check"></i><b>3.18</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="probabilidad-condicional.html"><a href="probabilidad-condicional.html"><i class="fa fa-check"></i><b>4</b> Probabilidad condicional</a>
<ul>
<li class="chapter" data-level="4.1" data-path="probabilidad-condicional.html"><a href="probabilidad-condicional.html#probabilidad-conjunta"><i class="fa fa-check"></i><b>4.1</b> Probabilidad conjunta</a></li>
<li class="chapter" data-level="4.2" data-path="probabilidad-condicional.html"><a href="probabilidad-condicional.html#independencia-estadística"><i class="fa fa-check"></i><b>4.2</b> Independencia estadística</a></li>
<li class="chapter" data-level="4.3" data-path="probabilidad-condicional.html"><a href="probabilidad-condicional.html#la-probabilidad-condicional"><i class="fa fa-check"></i><b>4.3</b> La probabilidad condicional</a></li>
<li class="chapter" data-level="4.4" data-path="probabilidad-condicional.html"><a href="probabilidad-condicional.html#tabla-de-contingencia-condicional"><i class="fa fa-check"></i><b>4.4</b> Tabla de contingencia condicional</a></li>
<li class="chapter" data-level="4.5" data-path="probabilidad-condicional.html"><a href="probabilidad-condicional.html#independencia-estadística-1"><i class="fa fa-check"></i><b>4.5</b> Independencia estadística</a></li>
<li class="chapter" data-level="4.6" data-path="probabilidad-condicional.html"><a href="probabilidad-condicional.html#dependencia-estadística"><i class="fa fa-check"></i><b>4.6</b> Dependencia estadística</a></li>
<li class="chapter" data-level="4.7" data-path="probabilidad-condicional.html"><a href="probabilidad-condicional.html#prueba-de-diagnóstico"><i class="fa fa-check"></i><b>4.7</b> Prueba de diagnóstico</a></li>
<li class="chapter" data-level="4.8" data-path="probabilidad-condicional.html"><a href="probabilidad-condicional.html#probabilidades-inversas"><i class="fa fa-check"></i><b>4.8</b> Probabilidades inversas</a></li>
<li class="chapter" data-level="4.9" data-path="probabilidad-condicional.html"><a href="probabilidad-condicional.html#teorema-de-bayes"><i class="fa fa-check"></i><b>4.9</b> Teorema de Bayes</a></li>
<li class="chapter" data-level="4.10" data-path="probabilidad-condicional.html"><a href="probabilidad-condicional.html#ejercicios-2"><i class="fa fa-check"></i><b>4.10</b> Ejercicios</a></li>
<li class="chapter" data-level="4.11" data-path="probabilidad-condicional.html"><a href="probabilidad-condicional.html#preguntas-2"><i class="fa fa-check"></i><b>4.11</b> Preguntas</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html"><i class="fa fa-check"></i><b>5</b> Variables aleatorias discretas</a>
<ul>
<li class="chapter" data-level="5.1" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#objetivo-1"><i class="fa fa-check"></i><b>5.1</b> Objetivo</a></li>
<li class="chapter" data-level="5.2" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#frecuencias-relativas-2"><i class="fa fa-check"></i><b>5.2</b> Frecuencias relativas</a></li>
<li class="chapter" data-level="5.3" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#variable-aleatoria"><i class="fa fa-check"></i><b>5.3</b> Variable aleatoria</a></li>
<li class="chapter" data-level="5.4" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#eventos-de-observar-una-variable-aleatoria"><i class="fa fa-check"></i><b>5.4</b> Eventos de observar una variable aleatoria</a></li>
<li class="chapter" data-level="5.5" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#probabilidad-de-variables-aleatorias"><i class="fa fa-check"></i><b>5.5</b> Probabilidad de variables aleatorias</a></li>
<li class="chapter" data-level="5.6" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#funciones-de-probabilidad"><i class="fa fa-check"></i><b>5.6</b> Funciones de probabilidad</a></li>
<li class="chapter" data-level="5.7" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#funciones-de-probabilidad-1"><i class="fa fa-check"></i><b>5.7</b> Funciones de probabilidad</a></li>
<li class="chapter" data-level="5.8" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#probabilidades-y-frecuencias-relativas"><i class="fa fa-check"></i><b>5.8</b> Probabilidades y frecuencias relativas</a></li>
<li class="chapter" data-level="5.9" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#la-media-o-el-valor-esperado"><i class="fa fa-check"></i><b>5.9</b> La media o el valor esperado</a></li>
<li class="chapter" data-level="5.10" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#varianza"><i class="fa fa-check"></i><b>5.10</b> Varianza</a></li>
<li class="chapter" data-level="5.11" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#funciones-de-probabilidad-para-funciones-de-x"><i class="fa fa-check"></i><b>5.11</b> Funciones de probabilidad para funciones de <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="5.12" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#distribución-de-probabilidad"><i class="fa fa-check"></i><b>5.12</b> Distribución de probabilidad</a></li>
<li class="chapter" data-level="5.13" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#función-de-probabilidad-y-distribución-de-probabilidad"><i class="fa fa-check"></i><b>5.13</b> Función de probabilidad y distribución de probabilidad</a></li>
<li class="chapter" data-level="5.14" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#cuantiles"><i class="fa fa-check"></i><b>5.14</b> Cuantiles</a></li>
<li class="chapter" data-level="5.15" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#resumen"><i class="fa fa-check"></i><b>5.15</b> Resumen</a></li>
<li class="chapter" data-level="5.16" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#preguntas-3"><i class="fa fa-check"></i><b>5.16</b> Preguntas</a></li>
<li class="chapter" data-level="5.17" data-path="variables-aleatorias-discretas.html"><a href="variables-aleatorias-discretas.html#ejercicios-3"><i class="fa fa-check"></i><b>5.17</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html"><i class="fa fa-check"></i><b>6</b> Variables aleatorias continuas</a>
<ul>
<li class="chapter" data-level="6.1" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#objetivo-2"><i class="fa fa-check"></i><b>6.1</b> Objetivo</a></li>
<li class="chapter" data-level="6.2" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#variables-aleatorias-continuas-1"><i class="fa fa-check"></i><b>6.2</b> Variables aleatorias continuas</a></li>
<li class="chapter" data-level="6.3" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#frecuencias-relativas-3"><i class="fa fa-check"></i><b>6.3</b> frecuencias relativas</a></li>
<li class="chapter" data-level="6.4" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#función-de-densidad-de-probabilidad"><i class="fa fa-check"></i><b>6.4</b> función de densidad de probabilidad</a></li>
<li class="chapter" data-level="6.5" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#área-total-bajo-la-curva"><i class="fa fa-check"></i><b>6.5</b> Área total bajo la curva</a></li>
<li class="chapter" data-level="6.6" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#área-bajo-la-curva"><i class="fa fa-check"></i><b>6.6</b> Área bajo la curva</a></li>
<li class="chapter" data-level="6.7" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#probabilidades-de-variables-continuas"><i class="fa fa-check"></i><b>6.7</b> Probabilidades de variables continuas</a></li>
<li class="chapter" data-level="6.8" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#distribución-de-probabilidad-1"><i class="fa fa-check"></i><b>6.8</b> Distribución de probabilidad</a></li>
<li class="chapter" data-level="6.9" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#gráficas-de-probabilidad"><i class="fa fa-check"></i><b>6.9</b> Gráficas de probabilidad</a></li>
<li class="chapter" data-level="6.10" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#media"><i class="fa fa-check"></i><b>6.10</b> Media</a></li>
<li class="chapter" data-level="6.11" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#varianza-1"><i class="fa fa-check"></i><b>6.11</b> Varianza</a></li>
<li class="chapter" data-level="6.12" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#funciones-de-x"><i class="fa fa-check"></i><b>6.12</b> Funciones de <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="6.13" data-path="variables-aleatorias-continuas.html"><a href="variables-aleatorias-continuas.html#ejercicios-4"><i class="fa fa-check"></i><b>6.13</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="modelos-de-probabilidad-para-variables-aletorias-discretas.html"><a href="modelos-de-probabilidad-para-variables-aletorias-discretas.html"><i class="fa fa-check"></i><b>7</b> Modelos de probabilidad para variables aletorias discretas</a>
<ul>
<li class="chapter" data-level="7.1" data-path="modelos-de-probabilidad-para-variables-aletorias-discretas.html"><a href="modelos-de-probabilidad-para-variables-aletorias-discretas.html#objetivo-3"><i class="fa fa-check"></i><b>7.1</b> Objetivo</a></li>
<li class="chapter" data-level="7.2" data-path="modelos-de-probabilidad-para-variables-aletorias-discretas.html"><a href="modelos-de-probabilidad-para-variables-aletorias-discretas.html#función-de-probabilidad"><i class="fa fa-check"></i><b>7.2</b> Función de probabilidad</a></li>
<li class="chapter" data-level="7.3" data-path="modelos-de-probabilidad-para-variables-aletorias-discretas.html"><a href="modelos-de-probabilidad-para-variables-aletorias-discretas.html#modelo-de-probabilidad"><i class="fa fa-check"></i><b>7.3</b> Modelo de probabilidad</a></li>
<li class="chapter" data-level="7.4" data-path="modelos-de-probabilidad-para-variables-aletorias-discretas.html"><a href="modelos-de-probabilidad-para-variables-aletorias-discretas.html#modelos-paramétricos"><i class="fa fa-check"></i><b>7.4</b> Modelos paramétricos</a></li>
<li class="chapter" data-level="7.5" data-path="modelos-de-probabilidad-para-variables-aletorias-discretas.html"><a href="modelos-de-probabilidad-para-variables-aletorias-discretas.html#distribución-uniforme-un-parámetro"><i class="fa fa-check"></i><b>7.5</b> Distribución uniforme (un parámetro)</a></li>
<li class="chapter" data-level="7.6" data-path="modelos-de-probabilidad-para-variables-aletorias-discretas.html"><a href="modelos-de-probabilidad-para-variables-aletorias-discretas.html#distribución-uniforme-dos-parámetros"><i class="fa fa-check"></i><b>7.6</b> Distribución uniforme (dos parámetros)</a></li>
<li class="chapter" data-level="7.7" data-path="modelos-de-probabilidad-para-variables-aletorias-discretas.html"><a href="modelos-de-probabilidad-para-variables-aletorias-discretas.html#ensayo-de-bernoulli"><i class="fa fa-check"></i><b>7.7</b> ensayo de Bernoulli</a></li>
<li class="chapter" data-level="7.8" data-path="modelos-de-probabilidad-para-variables-aletorias-discretas.html"><a href="modelos-de-probabilidad-para-variables-aletorias-discretas.html#experimento-binomial"><i class="fa fa-check"></i><b>7.8</b> Experimento binomial</a></li>
<li class="chapter" data-level="7.9" data-path="modelos-de-probabilidad-para-variables-aletorias-discretas.html"><a href="modelos-de-probabilidad-para-variables-aletorias-discretas.html#función-de-probabilidad-binomial"><i class="fa fa-check"></i><b>7.9</b> Función de probabilidad binomial</a></li>
<li class="chapter" data-level="7.10" data-path="modelos-de-probabilidad-para-variables-aletorias-discretas.html"><a href="modelos-de-probabilidad-para-variables-aletorias-discretas.html#función-de-probabilidad-binomial-negativa"><i class="fa fa-check"></i><b>7.10</b> Función de probabilidad binomial negativa</a></li>
<li class="chapter" data-level="7.11" data-path="modelos-de-probabilidad-para-variables-aletorias-discretas.html"><a href="modelos-de-probabilidad-para-variables-aletorias-discretas.html#distribución-geométrica"><i class="fa fa-check"></i><b>7.11</b> Distribución geométrica</a></li>
<li class="chapter" data-level="7.12" data-path="modelos-de-probabilidad-para-variables-aletorias-discretas.html"><a href="modelos-de-probabilidad-para-variables-aletorias-discretas.html#modelo-hipergeométrico"><i class="fa fa-check"></i><b>7.12</b> Modelo hipergeométrico</a></li>
<li class="chapter" data-level="7.13" data-path="modelos-de-probabilidad-para-variables-aletorias-discretas.html"><a href="modelos-de-probabilidad-para-variables-aletorias-discretas.html#preguntas-4"><i class="fa fa-check"></i><b>7.13</b> Preguntas</a></li>
<li class="chapter" data-level="7.14" data-path="modelos-de-probabilidad-para-variables-aletorias-discretas.html"><a href="modelos-de-probabilidad-para-variables-aletorias-discretas.html#ejercicios-5"><i class="fa fa-check"></i><b>7.14</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="modelos-de-poisson-y-exponencial.html"><a href="modelos-de-poisson-y-exponencial.html"><i class="fa fa-check"></i><b>8</b> Modelos de Poisson y Exponencial</a>
<ul>
<li class="chapter" data-level="8.1" data-path="modelos-de-poisson-y-exponencial.html"><a href="modelos-de-poisson-y-exponencial.html#objetivo-4"><i class="fa fa-check"></i><b>8.1</b> Objetivo</a></li>
<li class="chapter" data-level="8.2" data-path="modelos-de-poisson-y-exponencial.html"><a href="modelos-de-poisson-y-exponencial.html#modelos-de-probabilidad-para-variables-discretas"><i class="fa fa-check"></i><b>8.2</b> Modelos de probabilidad para variables discretas</a></li>
<li class="chapter" data-level="8.3" data-path="modelos-de-poisson-y-exponencial.html"><a href="modelos-de-poisson-y-exponencial.html#experimento-de-poissson"><i class="fa fa-check"></i><b>8.3</b> Experimento de Poissson</a></li>
<li class="chapter" data-level="8.4" data-path="modelos-de-poisson-y-exponencial.html"><a href="modelos-de-poisson-y-exponencial.html#función-de-masa-de-probabilidad-de-poisson"><i class="fa fa-check"></i><b>8.4</b> Función de masa de probabilidad de Poisson</a></li>
<li class="chapter" data-level="8.5" data-path="modelos-de-poisson-y-exponencial.html"><a href="modelos-de-poisson-y-exponencial.html#modelos-de-probabilidad-para-variables-continuas"><i class="fa fa-check"></i><b>8.5</b> Modelos de probabilidad para variables continuas</a></li>
<li class="chapter" data-level="8.6" data-path="modelos-de-poisson-y-exponencial.html"><a href="modelos-de-poisson-y-exponencial.html#experimento-exponencial"><i class="fa fa-check"></i><b>8.6</b> Experimento exponencial</a></li>
<li class="chapter" data-level="8.7" data-path="modelos-de-poisson-y-exponencial.html"><a href="modelos-de-poisson-y-exponencial.html#densidad-de-probabilidad-exponencial"><i class="fa fa-check"></i><b>8.7</b> Densidad de probabilidad exponencial</a></li>
<li class="chapter" data-level="8.8" data-path="modelos-de-poisson-y-exponencial.html"><a href="modelos-de-poisson-y-exponencial.html#distribución-exponencial"><i class="fa fa-check"></i><b>8.8</b> Distribución exponencial</a></li>
<li class="chapter" data-level="8.9" data-path="modelos-de-poisson-y-exponencial.html"><a href="modelos-de-poisson-y-exponencial.html#preguntas-5"><i class="fa fa-check"></i><b>8.9</b> Preguntas</a></li>
<li class="chapter" data-level="8.10" data-path="modelos-de-poisson-y-exponencial.html"><a href="modelos-de-poisson-y-exponencial.html#ejercicios-6"><i class="fa fa-check"></i><b>8.10</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="distribución-normal.html"><a href="distribución-normal.html"><i class="fa fa-check"></i><b>9</b> Distribución normal</a>
<ul>
<li class="chapter" data-level="9.1" data-path="distribución-normal.html"><a href="distribución-normal.html#objetivo-5"><i class="fa fa-check"></i><b>9.1</b> Objetivo</a></li>
<li class="chapter" data-level="9.2" data-path="distribución-normal.html"><a href="distribución-normal.html#historia"><i class="fa fa-check"></i><b>9.2</b> Historia</a></li>
<li class="chapter" data-level="9.3" data-path="distribución-normal.html"><a href="distribución-normal.html#densidad-normal"><i class="fa fa-check"></i><b>9.3</b> Densidad normal</a></li>
<li class="chapter" data-level="9.4" data-path="distribución-normal.html"><a href="distribución-normal.html#definición"><i class="fa fa-check"></i><b>9.4</b> Definición</a></li>
<li class="chapter" data-level="9.5" data-path="distribución-normal.html"><a href="distribución-normal.html#distribución-de-probabilidad-2"><i class="fa fa-check"></i><b>9.5</b> Distribución de probabilidad</a></li>
<li class="chapter" data-level="9.6" data-path="distribución-normal.html"><a href="distribución-normal.html#densidad-normal-estándar"><i class="fa fa-check"></i><b>9.6</b> Densidad normal estándar</a></li>
<li class="chapter" data-level="9.7" data-path="distribución-normal.html"><a href="distribución-normal.html#distribución-estándar"><i class="fa fa-check"></i><b>9.7</b> Distribución estándar</a></li>
<li class="chapter" data-level="9.8" data-path="distribución-normal.html"><a href="distribución-normal.html#resumen-de-modelos-de-probabilidad"><i class="fa fa-check"></i><b>9.8</b> Resumen de modelos de probabilidad</a></li>
<li class="chapter" data-level="9.9" data-path="distribución-normal.html"><a href="distribución-normal.html#funciones-r-de-modelos-de-probabilidad"><i class="fa fa-check"></i><b>9.9</b> Funciones R de modelos de probabilidad</a></li>
<li class="chapter" data-level="9.10" data-path="distribución-normal.html"><a href="distribución-normal.html#preguntas-6"><i class="fa fa-check"></i><b>9.10</b> Preguntas</a></li>
<li class="chapter" data-level="9.11" data-path="distribución-normal.html"><a href="distribución-normal.html#ejercicios-7"><i class="fa fa-check"></i><b>9.11</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="distribuciones-de-muestreo.html"><a href="distribuciones-de-muestreo.html"><i class="fa fa-check"></i><b>10</b> Distribuciones de muestreo</a>
<ul>
<li class="chapter" data-level="10.1" data-path="distribuciones-de-muestreo.html"><a href="distribuciones-de-muestreo.html#objetivo-6"><i class="fa fa-check"></i><b>10.1</b> Objetivo</a></li>
<li class="chapter" data-level="10.2" data-path="distribuciones-de-muestreo.html"><a href="distribuciones-de-muestreo.html#muestra-aleatoria"><i class="fa fa-check"></i><b>10.2</b> Muestra aleatoria</a></li>
<li class="chapter" data-level="10.3" data-path="distribuciones-de-muestreo.html"><a href="distribuciones-de-muestreo.html#cálculo-de-probabilidades"><i class="fa fa-check"></i><b>10.3</b> Cálculo de probabilidades</a></li>
<li class="chapter" data-level="10.4" data-path="distribuciones-de-muestreo.html"><a href="distribuciones-de-muestreo.html#estimación-de-los-parámetros"><i class="fa fa-check"></i><b>10.4</b> Estimación de los parámetros</a></li>
<li class="chapter" data-level="10.5" data-path="distribuciones-de-muestreo.html"><a href="distribuciones-de-muestreo.html#margen-de-error-de-las-estimaciones"><i class="fa fa-check"></i><b>10.5</b> Margen de error de las estimaciones</a></li>
<li class="chapter" data-level="10.6" data-path="distribuciones-de-muestreo.html"><a href="distribuciones-de-muestreo.html#inferencia"><i class="fa fa-check"></i><b>10.6</b> Inferencia</a></li>
<li class="chapter" data-level="10.7" data-path="distribuciones-de-muestreo.html"><a href="distribuciones-de-muestreo.html#distribución-media-muestral"><i class="fa fa-check"></i><b>10.7</b> Distribución media muestral</a>
<ul>
<li class="chapter" data-level="10.7.1" data-path="distribuciones-de-muestreo.html"><a href="distribuciones-de-muestreo.html#suma-muestral"><i class="fa fa-check"></i><b>10.7.1</b> Suma muestral</a></li>
</ul></li>
<li class="chapter" data-level="10.8" data-path="distribuciones-de-muestreo.html"><a href="distribuciones-de-muestreo.html#variaza-muestral"><i class="fa fa-check"></i><b>10.8</b> Variaza muestral</a></li>
<li class="chapter" data-level="10.9" data-path="distribuciones-de-muestreo.html"><a href="distribuciones-de-muestreo.html#probabilidades-de-la-varianza-muestral"><i class="fa fa-check"></i><b>10.9</b> Probabilidades de la varianza muestral</a></li>
<li class="chapter" data-level="10.10" data-path="distribuciones-de-muestreo.html"><a href="distribuciones-de-muestreo.html#chi2-estadística"><i class="fa fa-check"></i><b>10.10</b> <span class="math inline">\(\chi^2\)</span>-estadística</a></li>
<li class="chapter" data-level="10.11" data-path="distribuciones-de-muestreo.html"><a href="distribuciones-de-muestreo.html#preguntas-7"><i class="fa fa-check"></i><b>10.11</b> Preguntas</a></li>
<li class="chapter" data-level="10.12" data-path="distribuciones-de-muestreo.html"><a href="distribuciones-de-muestreo.html#ejercicios-8"><i class="fa fa-check"></i><b>10.12</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="teorema-central-del-límite.html"><a href="teorema-central-del-límite.html"><i class="fa fa-check"></i><b>11</b> Teorema central del límite</a>
<ul>
<li class="chapter" data-level="11.1" data-path="teorema-central-del-límite.html"><a href="teorema-central-del-límite.html#objetivo-7"><i class="fa fa-check"></i><b>11.1</b> Objetivo</a></li>
<li class="chapter" data-level="11.2" data-path="teorema-central-del-límite.html"><a href="teorema-central-del-límite.html#margen-de-error"><i class="fa fa-check"></i><b>11.2</b> Margen de error</a></li>
<li class="chapter" data-level="11.3" data-path="teorema-central-del-límite.html"><a href="teorema-central-del-límite.html#ejemplo-cables"><i class="fa fa-check"></i><b>11.3</b> Ejemplo (cables)</a></li>
<li class="chapter" data-level="11.4" data-path="teorema-central-del-límite.html"><a href="teorema-central-del-límite.html#teorema-central-del-límite-1"><i class="fa fa-check"></i><b>11.4</b> Teorema central del límite</a></li>
<li class="chapter" data-level="11.5" data-path="teorema-central-del-límite.html"><a href="teorema-central-del-límite.html#suma-muestral-y-clt"><i class="fa fa-check"></i><b>11.5</b> Suma muestral y CLT</a></li>
<li class="chapter" data-level="11.6" data-path="teorema-central-del-límite.html"><a href="teorema-central-del-límite.html#preguntas-8"><i class="fa fa-check"></i><b>11.6</b> Preguntas</a></li>
<li class="chapter" data-level="11.7" data-path="teorema-central-del-límite.html"><a href="teorema-central-del-límite.html#ejercicios-9"><i class="fa fa-check"></i><b>11.7</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="máxima-verosimilitud-y-método-de-los-momentos.html"><a href="máxima-verosimilitud-y-método-de-los-momentos.html"><i class="fa fa-check"></i><b>12</b> Máxima verosimilitud y Método de los Momentos</a>
<ul>
<li class="chapter" data-level="12.1" data-path="máxima-verosimilitud-y-método-de-los-momentos.html"><a href="máxima-verosimilitud-y-método-de-los-momentos.html#objetivo-8"><i class="fa fa-check"></i><b>12.1</b> Objetivo</a></li>
<li class="chapter" data-level="12.2" data-path="máxima-verosimilitud-y-método-de-los-momentos.html"><a href="máxima-verosimilitud-y-método-de-los-momentos.html#estadística-1"><i class="fa fa-check"></i><b>12.2</b> Estadística</a></li>
<li class="chapter" data-level="12.3" data-path="máxima-verosimilitud-y-método-de-los-momentos.html"><a href="máxima-verosimilitud-y-método-de-los-momentos.html#propiedades"><i class="fa fa-check"></i><b>12.3</b> Propiedades</a></li>
<li class="chapter" data-level="12.4" data-path="máxima-verosimilitud-y-método-de-los-momentos.html"><a href="máxima-verosimilitud-y-método-de-los-momentos.html#máxima-verosimilitud"><i class="fa fa-check"></i><b>12.4</b> Máxima verosimilitud</a></li>
<li class="chapter" data-level="12.5" data-path="máxima-verosimilitud-y-método-de-los-momentos.html"><a href="máxima-verosimilitud-y-método-de-los-momentos.html#máxima-verosimilitud-1"><i class="fa fa-check"></i><b>12.5</b> Máxima verosimilitud</a></li>
<li class="chapter" data-level="12.6" data-path="máxima-verosimilitud-y-método-de-los-momentos.html"><a href="máxima-verosimilitud-y-método-de-los-momentos.html#método-de-los-momentos"><i class="fa fa-check"></i><b>12.6</b> Método de los Momentos</a></li>
<li class="chapter" data-level="12.7" data-path="máxima-verosimilitud-y-método-de-los-momentos.html"><a href="máxima-verosimilitud-y-método-de-los-momentos.html#método-de-momentos-para-varios-parámetros"><i class="fa fa-check"></i><b>12.7</b> Método de Momentos para varios parámetros</a></li>
<li class="chapter" data-level="12.8" data-path="máxima-verosimilitud-y-método-de-los-momentos.html"><a href="máxima-verosimilitud-y-método-de-los-momentos.html#ejercicios-máxima-verosimilitud"><i class="fa fa-check"></i><b>12.8</b> Ejercicios Máxima Verosimilitud</a></li>
<li class="chapter" data-level="12.9" data-path="máxima-verosimilitud-y-método-de-los-momentos.html"><a href="máxima-verosimilitud-y-método-de-los-momentos.html#método-de-los-momentos-1"><i class="fa fa-check"></i><b>12.9</b> Método de los momentos</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html"><i class="fa fa-check"></i><b>13</b> Intervalos de confianza</a>
<ul>
<li class="chapter" data-level="13.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#objetivo-9"><i class="fa fa-check"></i><b>13.1</b> Objetivo</a></li>
<li class="chapter" data-level="13.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#estimación-de-la-media"><i class="fa fa-check"></i><b>13.2</b> Estimación de la media</a></li>
<li class="chapter" data-level="13.3" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#margen-de-error-1"><i class="fa fa-check"></i><b>13.3</b> Margen de error</a></li>
<li class="chapter" data-level="13.4" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#estimación-de-intervalo-para-la-media"><i class="fa fa-check"></i><b>13.4</b> Estimación de intervalo para la media</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#caso-1-varianza-conocida"><i class="fa fa-check"></i><b>13.4.1</b> Caso 1 (varianza conocida)</a></li>
<li class="chapter" data-level="13.4.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#nivel-de-confianza"><i class="fa fa-check"></i><b>13.4.2</b> Nivel de confianza</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#margen-de-error-para-varianza-desconocida"><i class="fa fa-check"></i><b>13.5</b> Margen de error para varianza desconocida</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#thorem-estadística-t"><i class="fa fa-check"></i><b>13.5.1</b> Thorem (estadística T)</a></li>
<li class="chapter" data-level="13.5.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#caso-2-varianza-desconocida"><i class="fa fa-check"></i><b>13.5.2</b> Caso 2 (varianza desconocida)</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#estimación-de-proporciones"><i class="fa fa-check"></i><b>13.6</b> Estimación de proporciones</a>
<ul>
<li class="chapter" data-level="13.6.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#caso-3-proporciones"><i class="fa fa-check"></i><b>13.6.1</b> Caso 3 (proporciones)</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#estimación-de-la-varianza"><i class="fa fa-check"></i><b>13.7</b> Estimación de la varianza</a></li>
<li class="chapter" data-level="13.8" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalo-de-confianza-para-la-varianza"><i class="fa fa-check"></i><b>13.8</b> Intervalo de confianza para la varianza</a>
<ul>
<li class="chapter" data-level="13.8.1" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#teorema-chi2"><i class="fa fa-check"></i><b>13.8.1</b> Teorema (<span class="math inline">\(\chi^2\)</span>):</a></li>
<li class="chapter" data-level="13.8.2" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#intervalo-de-confianza-para-la-varianza-1"><i class="fa fa-check"></i><b>13.8.2</b> Intervalo de confianza para la varianza</a></li>
<li class="chapter" data-level="13.8.3" data-path="intervalos-de-confianza.html"><a href="intervalos-de-confianza.html#caso-4-varianza"><i class="fa fa-check"></i><b>13.8.3</b> Caso 4 (varianza)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="contraste-de-hipótesis.html"><a href="contraste-de-hipótesis.html"><i class="fa fa-check"></i><b>14</b> Contraste de hipótesis</a>
<ul>
<li class="chapter" data-level="14.1" data-path="contraste-de-hipótesis.html"><a href="contraste-de-hipótesis.html#objetivo-10"><i class="fa fa-check"></i><b>14.1</b> Objetivo</a></li>
<li class="chapter" data-level="14.2" data-path="contraste-de-hipótesis.html"><a href="contraste-de-hipótesis.html#hipótesis"><i class="fa fa-check"></i><b>14.2</b> Hipótesis</a></li>
<li class="chapter" data-level="14.3" data-path="contraste-de-hipótesis.html"><a href="contraste-de-hipótesis.html#contraste-de-hipótesis-1"><i class="fa fa-check"></i><b>14.3</b> Contraste de hipótesis</a></li>
<li class="chapter" data-level="14.4" data-path="contraste-de-hipótesis.html"><a href="contraste-de-hipótesis.html#caso-1-para-la-media-con-varianza-conocida"><i class="fa fa-check"></i><b>14.4</b> Caso 1 (para la media con varianza conocida)</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="contraste-de-hipótesis.html"><a href="contraste-de-hipótesis.html#prueba-de-hipótesis-con-un-intervalo-de-confianza"><i class="fa fa-check"></i><b>14.4.1</b> Prueba de hipótesis con un intervalo de confianza</a></li>
<li class="chapter" data-level="14.4.2" data-path="contraste-de-hipótesis.html"><a href="contraste-de-hipótesis.html#prueba-de-hipótesis-con-zonas-de-aceptaciónrechazo"><i class="fa fa-check"></i><b>14.4.2</b> Prueba de hipótesis con zonas de aceptación/rechazo</a></li>
<li class="chapter" data-level="14.4.3" data-path="contraste-de-hipótesis.html"><a href="contraste-de-hipótesis.html#prueba-de-hipótesis-con-un-p-valor"><i class="fa fa-check"></i><b>14.4.3</b> Prueba de hipótesis con un P valor</a></li>
<li class="chapter" data-level="14.4.4" data-path="contraste-de-hipótesis.html"><a href="contraste-de-hipótesis.html#hipótesis-de-la-cola-superior"><i class="fa fa-check"></i><b>14.4.4</b> Hipótesis de la cola superior</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="contraste-de-hipótesis.html"><a href="contraste-de-hipótesis.html#caso-2-para-la-media-con-varianza-desconocida"><i class="fa fa-check"></i><b>14.5</b> Caso 2 (para la media con varianza desconocida)</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="contraste-de-hipótesis.html"><a href="contraste-de-hipótesis.html#hipótesis-la-cola-inferior"><i class="fa fa-check"></i><b>14.5.1</b> Hipótesis la cola inferior</a></li>
<li class="chapter" data-level="14.5.2" data-path="contraste-de-hipótesis.html"><a href="contraste-de-hipótesis.html#prueba-de-hipótesis-con-n-grande-y-cualquier-distribución"><i class="fa fa-check"></i><b>14.5.2</b> Prueba de hipótesis con n grande y cualquier distribución</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="contraste-de-hipótesis.html"><a href="contraste-de-hipótesis.html#caso-3-para-proporciones"><i class="fa fa-check"></i><b>14.6</b> Caso 3 (para proporciones)</a></li>
<li class="chapter" data-level="14.7" data-path="contraste-de-hipótesis.html"><a href="contraste-de-hipótesis.html#caso-4-para-la-varianza"><i class="fa fa-check"></i><b>14.7</b> Caso 4 (para la varianza)</a></li>
<li class="chapter" data-level="14.8" data-path="contraste-de-hipótesis.html"><a href="contraste-de-hipótesis.html#errores-en-la-prueba-de-hipótesis"><i class="fa fa-check"></i><b>14.8</b> Errores en la prueba de hipótesis</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Estadística</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="máxima-verosimilitud-y-método-de-los-momentos" class="section level1 hasAnchor" number="12">
<h1><span class="header-section-number">Chapter 12</span> Máxima verosimilitud y Método de los Momentos<a href="máxima-verosimilitud-y-método-de-los-momentos.html#máxima-verosimilitud-y-método-de-los-momentos" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="objetivo-8" class="section level2 hasAnchor" number="12.1">
<h2><span class="header-section-number">12.1</span> Objetivo<a href="máxima-verosimilitud-y-método-de-los-momentos.html#objetivo-8" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En este capítulo discutiremos qué es un <strong>estimador</strong> y daremos algunos ejemplos. Luego introduciremos dos métodos para obtener <strong>estimadores</strong> de los parámetros de los modelos de probabilidad.</p>
<p>Estos son la <strong>máxima verosimilitud</strong> y el <strong>método de los momentos</strong>.</p>
</div>
<div id="estadística-1" class="section level2 hasAnchor" number="12.2">
<h2><span class="header-section-number">12.2</span> Estadística<a href="máxima-verosimilitud-y-método-de-los-momentos.html#estadística-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>Definición</strong></p>
<p>Una <strong>estadística</strong> es cualquier función de una <strong>muestra aleatoria</strong>
<span class="math display">\[T(X_1,X_2, ..., X_n)\]</span></p>
<p>Por lo general, devuelve un número.</p>
<p>Las estadísticas son <strong>variables aleatorias</strong> y sus <strong>distribuciones de probabilidad</strong> se llaman <strong>distribuciones de muestreo</strong></p>
<p>Las estadísticas tienen diferentes funciones:</p>
<ol style="list-style-type: decimal">
<li><strong>Descripción</strong> de los datos de una muestra</li>
</ol>
<ul>
<li>ubicación: <span class="math inline">\(\bar{X}\)</span></li>
<li>Mínimo: <span class="math inline">\(\min\{X_i\}\)</span></li>
<li>Máximo: <span class="math inline">\(\max\{X_i\}\)</span></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><strong>Estimación</strong> de los <strong>parámetros</strong> de un modelo de probabilidad</li>
</ol>
<ul>
<li>media: <span class="math inline">\(\bar{X}\)</span> para <span class="math inline">\(\mu\)</span></li>
<li>varianza: <span class="math inline">\(S^2\)</span> para <span class="math inline">\(\sigma^2\)</span></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li><strong>Inferencia</strong> para decir algo sobre los parámetros dados los datos</li>
</ol>
<ul>
<li>media: <span class="math inline">\(Z\)</span>, <span class="math inline">\(T\)</span></li>
<li>varianza: <span class="math inline">\(\chi^2\)</span></li>
</ul>
<p>Recuerda: Todas son variables aleatorias. Cada vez que tomamos otra muestra cambian su valor.</p>
<p><strong>Definición de estimadores</strong></p>
<p>Un <strong>estimador</strong> es un estadístico cuyos valores observados se utilizan para estimar los <strong>parámetros</strong> de la distribución de la población sobre la que se define la muestra.</p>
<p>Si escribimos la distribución de la población como</p>
<p><span class="math display">\[X \rightarrow f(x; \theta)\]</span></p>
<p>entonces <span class="math inline">\(\theta\)</span> es un parámetro y <span class="math inline">\(\Theta\)</span> es una variable aleatoria cuyas observaciones <span class="math inline">\(\hat{\theta}\)</span> tomamos como estimaciones de <span class="math inline">\(\theta\)</span></p>
<p><span class="math display">\[\hat{\theta} \sim \theta\]</span></p>
<p>Por lo tanto hay tres cantidades diferentes que debemos considerar:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\theta\)</span> es un <strong>parámetro</strong> de la distribución de la población <span class="math inline">\(f(x; \theta)\)</span></li>
<li><span class="math inline">\(\Theta\)</span> es un <strong>estimador</strong> de <span class="math inline">\(\theta\)</span>: Una variable aleatoria</li>
<li><span class="math inline">\(\hat{\theta}\)</span> es la <strong>estimación</strong> de <span class="math inline">\(\theta\)</span>: un valor realizado de <span class="math inline">\(\Theta\)</span></li>
</ol>
<p><img src="figures/estimator.JPG" style="width:100%"  align="center"></p>
<p><strong>Ejemplo (media de la muestra)</strong></p>
<p>Cuando tenemos una variable aleatoria normal</p>
<p><span class="math display">\[X \rightarrow N(\mu, \sigma^2)\]</span></p>
<p>identificamos las tres cantidades diferentes:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\mu\)</span> es un <strong>parámetro</strong> de la distribución de la <strong>población</strong>: <span class="math inline">\(N(\mu, \sigma^2)\)</span></li>
<li><span class="math inline">\(\bar{X}=\frac{1}{n} \sum_{i=1}^n X_i\)</span> es un <strong>estimador</strong> de <span class="math inline">\(\mu\)</span></li>
<li><span class="math inline">\(\bar{x}=\hat{\mu}\)</span> es la <strong>estimación</strong> de <span class="math inline">\(\mu\)</span></li>
</ol>
<p><strong>Ejemplo (varianza de la muestra)</strong></p>
<p>Cuando tenemos una variable aleatoria normal</p>
<p><span class="math display">\[X \rightarrow N(\mu, \sigma^2)\]</span></p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\sigma^2\)</span> es un <strong>parámetro</strong> de la distribución de la población</li>
<li><span class="math inline">\(S^2=\frac{1}{n-1} \sum_{i=1}^n (X_i-\bar{X})^2\)</span> es un <strong>estimador</strong> de <span class="math inline">\(\sigma^2\)</span></li>
<li><span class="math inline">\(s^2=\hat{\sigma}^2\)</span> es la <strong>estimación</strong> de <span class="math inline">\(\sigma^2\)</span></li>
</ol>
</div>
<div id="propiedades" class="section level2 hasAnchor" number="12.3">
<h2><span class="header-section-number">12.3</span> Propiedades<a href="máxima-verosimilitud-y-método-de-los-momentos.html#propiedades" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<ol style="list-style-type: decimal">
<li>Un estimador es <strong>insesgado</strong> si su valor esperado es el parámetro</li>
</ol>
<p><span class="math display">\[E(\Theta)=\theta\]</span></p>
<p>Por ejemplo:</p>
<ul>
<li><p><span class="math inline">\(\bar{X}\)</span> es un estimador <strong>insesgado</strong> de <span class="math inline">\(\mu\)</span> porque <span class="math inline">\(E(\bar{X})=\mu\)</span></p></li>
<li><p><span class="math inline">\(S^2\)</span> es un estimador <strong>insesgado</strong> de <span class="math inline">\(\sigma^2\)</span> porque <span class="math inline">\(E(S^2)=\sigma^2\)</span></p></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>Un estimador es <strong>consistente</strong> cuando sus valores observados están cada vez menos dispersos al rededor de la medida a medida que el tamaño de la muestra crece</li>
</ol>
<p><span class="math display">\[lim_{n\rightarrow \infty} V(\Theta) = 0\]</span></p>
<p>Por ejemplo:</p>
<ul>
<li><span class="math inline">\(\bar{X}\)</span> es <strong>consistente</strong> porque <span class="math inline">\(V(\bar{X})=\frac{\sigma^2}{n}\rightarrow 0\)</span> cuando <span class="math inline">\(n \rightarrow \infty\)</span>.</li>
</ul>
</div>
<div id="máxima-verosimilitud" class="section level2 hasAnchor" number="12.4">
<h2><span class="header-section-number">12.4</span> Máxima verosimilitud<a href="máxima-verosimilitud-y-método-de-los-momentos.html#máxima-verosimilitud" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>¿Cómo se pueden obtener <strong>estimadores</strong> de los parámetros de <strong>cualquier</strong> modelo de probabilidad?</p>
<p><strong>Ejemplo (Láser)</strong></p>
<p>Imagina que diseñamos un láser con un diámetro de <span class="math inline">\(1 mm\)</span> que queremos usar para aplicaciones clínicas.</p>
<p>Queremos caracterizar el diámetro de un piercing en un tejido realizado con láser y tomar una muestra aleatoria de <span class="math inline">\(30\)</span> cortes realizados con láser. Aquí están los resultados</p>
<pre><code>##  [1] 1.11 1.64 1.20 1.79 1.89 1.01 1.31 1.81 1.34 1.25 1.92 1.24 1.49 1.36 1.03
## [16] 1.82 1.09 1.01 1.14 1.91 1.80 1.51 1.44 1.98 1.46 1.53 1.33 1.39 1.12 1.04</code></pre>
<p>y el histograma</p>
<p><img src="_main_files/figure-html/unnamed-chunk-83-1.png" width="672" /></p>
<p>¿Cuál sería una función de probabilidad que podría describir los datos?</p>
<p>Para ello seguimos el siguiente proceso:</p>
<ol style="list-style-type: decimal">
<li>Proponemos <strong>un modelo</strong> que depende de parámetros</li>
<li>Derivamos los <strong>estimadores</strong> para los parámetros, por máxima verosimilitud o el método de momentos.</li>
<li>Finalmente usamos el estimador para <strong>estimar los parámetros</strong> con los datos.</li>
</ol>
<p><em>Proponiendo una densidad de probabilidad</em></p>
<p>En muchas aplicaciones, podemos proponer la forma de una densidad de probabilidad que depende de algunos parámetros. Proponer un modelo de probabilidad se hace siguiendo <strong>propiedades generales</strong> de las observaciones, o lo que esperamos observar. El modelado requiere experiencia, habilidad y conocimiento de varias funciones matemáticas. Sin embargo, en la mayoría de los casos se suelen aplicar <strong>modelos bien conocidos</strong>.</p>
<p><strong>Ejemplo (Láser)</strong></p>
<p>En nuestro ejemplo, podemos considerar, por ejemplo, que se debe dar la máxima probabilidad a los diámetros de <span class="math inline">\(x=1 mm\)</span>, y que los diámetros deben disminuir como la potencia inversa de algún parámetro <strong>desconocido</strong> <span class="math inline">\(\alpha\)</span>, con un límite de <span class="math inline">\(2mm\)</span> más allá del cual la probabilidad es de <span class="math inline">\(0\)</span>.</p>
<p>Una distribución de densidad de probabilidad adecuada es</p>
<p><span class="math display">\[
    f(x)= 
\begin{cases}
\frac{1}{\alpha}(x-1)^{\frac{1}{\alpha}-1},&amp; \text{if } x \in (1,2)\\
    0,&amp; x \notin (1,2)\\
\end{cases}
\]</span></p>
<p>Donde <span class="math inline">\(\alpha\)</span> es un parámetro. Esta es una densidad de probabilidad porque se integra a uno y es positiva. En particular, para <span class="math inline">\(\alpha=2\)</span> podemos graficarlo</p>
<p><img src="_main_files/figure-html/unnamed-chunk-84-1.png" width="672" /></p>
<p><em>Derivar los estimadores</em></p>
<p>Si realizamos una muestra de tamaño <span class="math inline">\(n\)</span>: <span class="math inline">\((X_1,...X_n)\)</span>, ¿Cómo debemos combinar los datos para obtener el mejor valor de <span class="math inline">\(\alpha\)</span>?</p>
<p>Muchos valores de para el parámetro podrían explicar los datos. Nos interesa <strong>un criterio</strong> para elegir un valor en particular.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-85-1.png" width="672" /></p>
<p>El método de <strong>máxima verosimilitud</strong> nos da un estimador para <span class="math inline">\(\alpha\)</span></p>
<p><span class="math display">\[\hat{\alpha}_{ml}\]</span></p>
</div>
<div id="máxima-verosimilitud-1" class="section level2 hasAnchor" number="12.5">
<h2><span class="header-section-number">12.5</span> Máxima verosimilitud<a href="máxima-verosimilitud-y-método-de-los-momentos.html#máxima-verosimilitud-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El objetivo es encontrar el valor del parámetro que <strong>creemos</strong> es el que <strong>mejor</strong> representa los datos.</p>
<p>El método de máxima verosimilitud se basa en la búsqueda del valor del parámetro que hace más <strong>probable</strong> la <strong>observación</strong> de la muestra.</p>
<p><strong>Máxima verosimilitud paso 1</strong></p>
<p>Calculamos la probabilidad de haber observado la muestra <span class="math inline">\(n\)</span>: <span class="math inline">\(x_1,...x_n\)</span>. Es el producto de probabilidades porque las observaciones son independientes entre sí:</p>
<p><span class="math inline">\(P(M=x_1,...x_n)=P(X=x_1)P(X=x_2)...P(X=x_n)\)</span>
<span class="math display">\[=f(x_1;\alpha)f(x_2;\alpha) ...f(x_n;\alpha)\]</span></p>
<p>A esta función la llamamos <strong>función de verosimilitud</strong> y consideramos que:</p>
<ul>
<li>Una vez observados los datos estos son <strong>fijos</strong></li>
<li>La incógnita es <span class="math inline">\(\alpha\)</span></li>
</ul>
<p><span class="math display">\[L(\alpha)= \Pi_{i=1..n} f(x_i; \alpha)\]</span></p>
<p><strong>Ejemplo (Láser)</strong></p>
<p>Para el experimento con láser la función de verosimilitud es</p>
<p><span class="math inline">\(L(\alpha;x_1,..x_n)= \frac{1}{\alpha^n} \Pi_{i=1..n} (x_i-1)^{\frac{1-\alpha}{ \alpha}}= \frac{1}{\alpha^n} \{(x_1-1)(x_2-1)...(x_n-1)\}^{\frac{1-\alpha}{\alpha}}\)</span></p>
<p><strong>Máxima verosimilitud paso 2</strong></p>
<p>Entonces nos preguntamos: ¿cuál es el valor de <span class="math inline">\(\alpha\)</span> que hace que la muestra observada sea el evento más probable? Por lo tanto, queremos maximizar <span class="math inline">\(L(\alpha)\)</span> con respecto a <span class="math inline">\(\alpha\)</span>. Como tenemos la multiplicación de muchos factores es más fácil maximizar el logaritmo de <span class="math inline">\(L(\alpha)\)</span>. Esto se llama la función logaritmo de verosimilitud:</p>
<p><span class="math display">\[\ln L(\alpha;x_1,..x_n)\]</span></p>
<p><strong>Ejemplo (Láser)</strong></p>
<p>En el ejemplo del láser, tomamos el logaritmo y obtenemos la <strong>Logaritmo de verosimilitud</strong></p>
<p><span class="math display">\[\ln L(\alpha;x_1,..x_n)= -n \ln(\alpha) + {\frac{1-\alpha}{\alpha}} \Sigma_{i=1...n} \ln (x_i-1)\]</span></p>
<p><strong>Máxima verosimilitud paso 3</strong></p>
<p>Finalmente <strong>maximizamos</strong> el logaritmo de verosimilitud con respecto al parámetro. Por lo tanto, diferenciamos el log-verosimilitud con respecto al parámetro <span class="math inline">\(\alpha\)</span>, igualamos a cero y resolvemos para el máximo.</p>
<p><span class="math display">\[\frac{d \ln L(\alpha)}{d \alpha} \big|_{\hat{\alpha}}=0 \]</span>
El valor máximo del parámetro se denomina <strong>estimación de máxima verosimilitud</strong> para el parámetro y se escribe con un sombrero <span class="math inline">\(\hat{\alpha}\)</span>.</p>
<p><strong>Ejemplo (Láser)</strong></p>
<p>Derivamos la función log-verosimilitud</p>
<p><span class="math display">\[\frac{d \ln L(\alpha)}{d \alpha}= -\frac{n}{\alpha} - \frac{1}{\alpha^2} \Sigma_{i=1.. .n} \ln (x_i-1)\]</span>
El máximo es donde la derivada es <span class="math inline">\(0\)</span>. Este máximo es el valor de nuestro estimador <span class="math inline">\(\hat{\alpha}_{ml}\)</span>.</p>
<p><span class="math display">\[\hat{\alpha}_{ml}=-\frac{1}{n}\sum_{i=1}^n \ln (x_i-1)\]</span></p>
<p>El estimador del parámetro es por lo tanto (nótese las letras mayúsculas)</p>
<p><span class="math display">\[A=-\frac{1}{n}\sum_{i=1}^n \ln (X_i-1)\]</span></p>
<p>Que es una variable aleatoria, función de la muestra aleatoria</p>
<p><span class="math display">\[(X_1, X_2, ... X_n)\]</span></p>
<p><em>Estimando los parámetros con los datos</em></p>
<p>En nuestro ejemplo, tenemos entonces la observación de la muestra aleatoria como un conjunto de 30 números <span class="math inline">\((x_1, x_2, ...x_{30})\)</span>, por lo tanto sustituimos los números en el estimador y esto nos dará su valor observado.</p>
<p><span class="math inline">\(\hat{\alpha}_{ml}=-\frac{1}{30}\{ \ln (1.11-1)+ \ln (1.64-1)+...\ln (1.04-1)\}=1.320\)</span></p>
<p>Por lo tanto, la estimación de máxima verosimilitud del parámetro es <span class="math inline">\(1.320\)</span>. Si sustituimos este valor en la función de probabilidad y lo superponemos con el histograma, podemos ver que nos da una descripción adecuada de los datos.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-86-1.png" width="672" /></p>
<p>Veamos la función del logaritmo de la verosimilitud para nuestros <span class="math inline">\(30\)</span> cortes láser. Recuerda, los datos son fijos para nuestro experimento y <span class="math inline">\(\alpha\)</span> varía. La función tiene un máximo. Sin embargo, si tomamos otra muestra, esta función cambia y también su lo hará su máximo.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-87-1.png" width="672" /></p>
<p><strong>Máxima verosimilitud: Historia</strong></p>
<p>Para inferir la verdadera posición de Ceres en un momento dado, Gauss derivó la función de error</p>
<p><span class="math display">\[f(x; \mu, \sigma^2)= \frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{1}{2\sigma^2} (x- \mu)^2}\]</span></p>
<p>Donde la posición <strong>verdadera</strong> de Ceres era la media <span class="math inline">\(\mu\)</span>. ¿Cómo podemos combinar los datos para tener la mejor estimación de la posición de Ceres?</p>
<p>¿Cuál es la estadística que mejor puede describir su posición?</p>
<p><img src="figures/cerestime.JPG" style="width:100%"  align="center"></p>
<p>Esta pregunta se puede formular como: ¿Cuál es la estimación de máxima verosimilitud de <span class="math inline">\(\mu\)</span> para una variable aleatoria normal?</p>
<p><strong>Máxima verosimilitud de la distribución normal</strong></p>
<p>Para una variable aleatoria normal</p>
<p><span class="math display">\[X \rightarrow N(\mu, \sigma^2)\]</span>.</p>
<p>¿Cuáles son los estimadores de <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma^2\)</span> que maximizan la probabilidad de los datos observados?</p>
<p><img src="figures/normpar.JPG" style="width:35%"  align="center"></p>
<p>Seguimos el método de máxima verosimilitud:</p>
<ol style="list-style-type: decimal">
<li>La función de verosimilitud, o la probabilidad de haber observado la muestra <span class="math inline">\((x_1, ....x_n)\)</span> es</li>
</ol>
<p><span class="math inline">\(L(\mu, \sigma^2)=\Pi_{i=1..n} f(x_i;\mu,\sigma)\)</span></p>
<p><span class="math display">\[=\big( \frac{1}{\sigma \sqrt{2 \pi}}\big)^ne^{-\frac{1}{2\sigma^2} \sum_i(x_i-\mu) ^2}\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Tomamos el logaritmo de <span class="math inline">\(L\)</span> y calculamos la función <strong>log-verosimilitud</strong></li>
</ol>
<p><span class="math display">\[\ln L(\mu, \sigma^2)=-n \ln(\sigma \sqrt{2 \pi})-\frac{1}{2\sigma^2} \Sigma_i(x_i-\mu )^2\]</span></p>
<p>Las estimaciones de <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma^2\)</span> son donde la probabilidad es máxima. Dan la probabilidad más alta para los datos de la muestra.</p>
<ol start="3" style="list-style-type: decimal">
<li>Diferenciamos con respecto a <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma^2\)</span>. Estas dos derivadas nos dan dos ecuaciones, una para cada uno de los parámetros. Para derivar con respecto a <span class="math inline">\(\sigma^2\)</span>, es más fácil hacer una sustitución <span class="math inline">\(t=\sigma^2\)</span>.</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><p><span class="math inline">\(\frac{d \ln L(\mu, \sigma^2)}{d\mu}=\frac{1}{\sigma^2} \sum_i(x_i-\mu)\)</span></p></li>
<li><p><span class="math inline">\(\frac{d \ln L(\mu, \sigma^2)}{d\sigma^2}=-\frac{n}{2 \sigma^2}+\frac{1}{2\sigma^4} \sum_i(x_i-\mu)^2\)</span></p></li>
</ol>
<p>Las derivadas son <span class="math inline">\(0\)</span> en el máximo</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(\frac{1}{\hat{\sigma}^2} \sum_i(x_i-\hat{\mu})=0\)</span></li>
<li><span class="math inline">\(-\frac{n}{2 \hat{\sigma}^2}+\frac{1}{2\hat{\sigma}^4} \sum_i(x_i-\hat{\mu})^ 2=0\)</span></li>
</ol>
<p>resolviendo ambas ecuaciones para los parámetros, encontramos para <span class="math inline">\(\mu\)</span></p>
<p><span class="math display">\[\hat{\mu}_{ml}=\frac{1}{n}\sum_i x_i=\bar{x}\]</span></p>
<p>y para <span class="math inline">\(\sigma^2\)</span></p>
<p><span class="math display">\[\hat{\sigma}^2_{ml}=\frac{1}{n}\sum_i(x_i-\bar{x})^2\]</span></p>
<p>Por lo tanto la <strong>media mestral</strong> o promedio <span class="math inline">\(\bar{X}\)</span> es el estimador de máxima verosimilitud de la media <span class="math inline">\(\mu\)</span> de la población. Gauss demostró que la estadística en la que más deberíamos confiar (la que tienen la mayor verosimilitud) para la posición real de Ceres era el <strong>promedio</strong>. Gauss, al resolvier la posición de Ceres, no solo descubrió la distribución normal, sino que también creó el análisis de regresión y mostró la importancia del promedio. Es debido a él que usamos el promedio para muchas cosas, y no otro tipo de estadísticas.</p>
<p>Además, el estimador de máxima verosimilitud de <span class="math inline">\(\sigma^2\)</span> es un estimador <strong>sesgado</strong> porque se puede demostrar que <span class="math display">\[E(\hat{\sigma}^2_{ml})=\sigma^2+ \frac{\sigma^2}{n}\neq\sigma^2\]</span></p>
<p>Fue Fisher quien demostró que a pesar de ser sesgado este estimador es importante, ya que lo usó para generalizar el teorema del límite central, donde pierde su sesgo en <span class="math inline">\(n\rightarrow \infty\)</span>.</p>
</div>
<div id="método-de-los-momentos" class="section level2 hasAnchor" number="12.6">
<h2><span class="header-section-number">12.6</span> Método de los Momentos<a href="máxima-verosimilitud-y-método-de-los-momentos.html#método-de-los-momentos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El método de máxima verosimilitud tiene como objetivo producir los estimadores de distribuciones de probabilidad a partir de datos. Sin embargo, existe otra forma de producir esos estimadores, que se basa en la idea frecuentista de las probabilidades.</p>
<p>Hbíamos visto que las frecuancias relativas tienden a las probabilidades cuando <span class="math inline">\(n\)</span> es grande <span class="math inline">\(f_i \rightarrow f(x_i)\)</span>, y como consequencia</p>
<p><span class="math display">\[\bar{x} \rightarrow \mu\]</span>
El centro de gravedad de los datos tiende al centro de gravedad de la probabilidad.
El método de los momentos dice que podemos tomar el valor <strong>observado</strong> de la media meustral <span class="math inline">\(\bar{X}\)</span> como estimador de <span class="math inline">\(E(X)=\mu\)</span></p>
<p><span class="math display">\[E(X)\sim \bar{x}=\hat{\mu}\]</span></p>
<p>Es decir que la variable aleatoria que estima la media de la población es el promedio:</p>
<p><span class="math display">\[\bar{X}= \frac{1}{n}\sum_i X_i\]</span></p>
<p>que también se denomina el primer <strong>momento de muestra</strong></p>
<p>En general, si <span class="math inline">\(X \rightarrow f(x, \theta)\)</span> el estimador del parámetro <span class="math inline">\(\theta\)</span> se obtiene entonces de la ecuación:</p>
<p><span class="math display">\[E(X; \hat{\theta})=\bar{x}\]</span></p>
<p>debido a que el valor esperado de la variable aletoria siempre es función del parámetro <span class="math inline">\(\theta\)</span>.</p>
<p><strong>Ejemplo (exponencial)</strong></p>
<p>Si una variable aleatoria sigue una distribución exponencial</p>
<p><span class="math display">\[X \hookrightarrow exp(\lambda)\]</span></p>
<p>entonces podemos usar el método de los momentos para estimar <span class="math inline">\(\lambda\)</span>. El método consta de tres pasos:</p>
<ol style="list-style-type: decimal">
<li><p>Calcular el valor esperado de la variable <span class="math display">\[E(X; \lambda)=\mu\]</span></p></li>
<li><p>Escribir la ecuación donde el valor esperado es igual al primer momento muestral <span class="math display">\[\frac{1}{\hat{\lambda}}=\bar{x}\]</span></p></li>
<li><p>Resolver para el parámetro</p></li>
</ol>
<p><span class="math display">\[\hat{\lambda}=\frac{1}{\bar{x}}\]</span>
En términos de datos, esto es <span class="math inline">\(\hat{\lambda}=(\frac{1}{n}\sum_i x_i)^{-1}\)</span>. Es decir que si queremos estimar el parámetro <span class="math inline">\(\lambda\)</span> de una variable exponencial de un experimento aleatorio, debemos tomar una muestra aleatoria, sacar su promedio y tomar su inversa. El resultado es el estimador de parámetro que después, junto al modelo, lo podemos usar para calcular las probabilidades de observaciones futuras.</p>
<p><strong>Ejemplo (Baterías)</strong></p>
<p>Supongamos que tenemos varias baterías (nuevas y viejas) que cargamos durante el período de 1 hora. Medimos el estado de carga de la batería, siendo 1 un 100% de carga.</p>
<p>El estado de carga de una batería es una variable aleatoria que puede tener una distribución uniforme, donde no sabemos el valor mínimo que puede tomar <span class="math inline">\(x\)</span>, pero sabemos que el máximo es 1 (<span class="math inline">\(100\%\)</span> de carga)</p>
<p><span class="math display">\[
f(x)=
\begin{cases}
    \frac{1}{1-a},&amp; \text{if } x\in (a,1)\\
    0,&amp; x\notin (a,1)
\end{cases}
\]</span></p>
<p>¿Cuál es el estimador de <span class="math inline">\(a\)</span> (la carga mínima después de una hora)?</p>
<p>Si ejecutamos un experimento y obtenemos <span class="math inline">\(x_1,...x_n\)</span>, nos preguntamos ¿cómo podemos estimar <span class="math inline">\(a\)</span> a partir de los datos?</p>
<p>Seguimos los tres pasos del método de los momentos:</p>
<ol style="list-style-type: decimal">
<li>Calculamos el valor esperado de la variable aleatoria</li>
</ol>
<p><span class="math display">\[E(X)=\frac{a+1}{2}\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Obtenemos la ecuación para <span class="math inline">\(\hat{a}\)</span> donde igualamos el valor esperado al primer momento muestral</li>
</ol>
<p><span class="math display">\[\frac{\hat{a}+1}{2}=\bar{x}\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>Resolvemos para el estimador <span class="math inline">\(\hat{a}\)</span></li>
</ol>
<p><span class="math display">\[\hat{a}=2\bar{x}-1\]</span></p>
<p>Este es el estimador de la carga mínima que podemos observar.</p>
<p>Ten en cuenta si tomaramos el mínimo de las observaciones esto sería claramente subóptimo. El método nos dio una respuesta inteligente que también se puede resumir en los siguientes pasos</p>
<ol style="list-style-type: lower-alpha">
<li>Podemos calcular <span class="math inline">\(\bar{x}\)</span> con precisión creciente dada por <span class="math inline">\(n\)</span></li>
<li>Sabemos que ninguna medida supera <span class="math inline">\(b=1\)</span></li>
<li>Luego calculamos la distancia entre <span class="math inline">\(\bar{x}\)</span> y <span class="math inline">\(b\)</span> que es <span class="math inline">\(1-\bar{x}\)</span></li>
<li>Esta distancia la restamos al promedio <span class="math inline">\(\bar{x}\)</span> para estimar el valor mínimo de carga:</li>
</ol>
<p><span class="math display">\[\bar{x}-(1-\bar{x})=2\bar{x}-1\]</span></p>
<p>Esta debería ser nuestra mejor suposición para <span class="math inline">\(\hat{a}\)</span>. Como tal llegamos a la misma estimación dada por el método de los momentos.</p>
</div>
<div id="método-de-momentos-para-varios-parámetros" class="section level2 hasAnchor" number="12.7">
<h2><span class="header-section-number">12.7</span> Método de Momentos para varios parámetros<a href="máxima-verosimilitud-y-método-de-los-momentos.html#método-de-momentos-para-varios-parámetros" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El método dice que se puede encontrar un estimador para el parámetro <span class="math inline">\(\theta\)</span> de <span class="math inline">\(f(x;\theta)\)</span> a partir de la ecuación:</p>
<p><span class="math display">\[E(X)=\frac{1}{n}\sum_i x_i\]</span></p>
<p>Si hay más parámetros, usamos los <strong>momentos de muestra</strong> más altos. Consideremos que el segundo momento muestral es</p>
<p><span class="math display">\[\frac{1}{n}\sum_i X^2_i\]</span></p>
<p>Por lo tanto, una observación de este momento es cercana a <span class="math inline">\(E(X^2)\)</span></p>
<p><span class="math display">\[E(X ^ 2)=\frac{1}{n}\sum_i x^2_i\]</span></p>
<p>El método para dos parámetros dice que se puede encontrar una estimación para los parámetros <span class="math inline">\(\theta_1\)</span> y <span class="math inline">\(\theta_2\)</span> de <span class="math inline">\(f(x;\theta_1,\theta_2)\)</span> a partir de las ecuaciones:</p>
<ol style="list-style-type: lower-alpha">
<li><p><span class="math inline">\(E(X)= \frac{1}{n}\sum_i x_i\)</span></p></li>
<li><p><span class="math inline">\(E(X^2)=\frac{1}{n}\sum_i x^2_i\)</span></p></li>
</ol>
<p>Podemos tener tantas ecuaciones como parámetros necesitemos calcular, incrementando el grado de los momentos, es decir las potencias de <span class="math inline">\(X\)</span>.</p>
<p><strong>Ejemplo (Distribución normal)</strong></p>
<p>Si <span class="math inline">\(X\)</span> se distribuye normalmente, tenemos dos parámetros para estimar
<span class="math display">\[X \rightarrow N(\mu, \sigma^2)\]</span></p>
<p>Seguimos los pasos del método de los momentos para dos parámetros:</p>
<ol style="list-style-type: decimal">
<li>Calculamos el valor esperado de la variable</li>
</ol>
<p><span class="math display">\[E(X)=\mu\]</span>
y el valor esperado de <span class="math inline">\(X^2\)</span></p>
<p><span class="math display">\[E(X^2)=\sigma^2+\mu^2\]</span></p>
<p><span class="math inline">\(E(X^2)\)</span> se sigue de la propiedad: <span class="math inline">\(E(X^2) = V(X)+\mu^2\)</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Obtenemos las ecuaciones para los parámetros donde hacemos (a) el valor esperado de la variable igual al primer momento muestral, y (b) el valor esperado del segundo momento igual al segundo momento muestral</li>
</ol>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(E(X)\)</span> se estima por <span class="math display">\[\hat{\mu}=\frac{1}{n}\sum_i x_i\]</span></li>
<li><span class="math inline">\(E(X^2)\)</span> se estima por <span class="math display">\[\hat{\sigma}^2+\hat{\mu}^2=\frac{1}{n}\sum_i x^2_i\]</span></li>
</ol>
<ol start="3" style="list-style-type: decimal">
<li>Resolvemos los parámetros</li>
</ol>
<p>La primera ecuación da directamente el estimador de la media <span class="math inline">\(\mu\)</span>.</p>
<p><span class="math display">\[\hat{\mu}=\frac{1}{n}\sum_i x_i\]</span></p>
<p>Que de nuevo es el promedio. De la segunda ecuación obtenemos</p>
<p><span class="math display">\[\hat{\sigma}^2= \frac{1}{n} \sum_i x^2_i-\hat{\mu}^2\]</span></p>
<p>que también se puede escribir como:
<span class="math display">\[\hat{\sigma}^2=\frac{1}{n} \sum_i(x_i-\hat{\mu})^2\]</span>
Encontramos que el método de los momentos y las estimaciones de máxima verosimilitud para la distribución normal son iguales. Sin embargo, este no siempre es el caso.</p>
<p><strong>Ejemplo (láser)</strong></p>
<p>¿Cuál es el estimador del parámetro <span class="math inline">\(\alpha\)</span> para el corte láser dado por el método de los momentos?</p>
<p><span class="math display">\[
    f(x; \alpha)= 
\begin{cases}
\frac{1}{\alpha}(x-1)^{\frac{1}{\alpha}-1},&amp; \text{if } x \in (1,2)\\
    0,&amp; x \notin (1,2)\\
\end{cases}
\]</span></p>
<p>Donde <span class="math inline">\(\alpha\)</span> es un parámetro.</p>
<p>El método dice que se puede encontrar un estimador para el parámetro <span class="math inline">\(\alpha\)</span> de <span class="math inline">\(f(x;\alpha)\)</span> a partir de la ecuación:</p>
<p><span class="math display">\[E(X)=\frac{1}{n}\sum_i x_i\]</span>
por <span class="math inline">\(\hat{\alpha}\)</span></p>
<ol style="list-style-type: decimal">
<li>Calculamos el valor esperado <span class="math inline">\(E(X)\)</span></li>
</ol>
<p><span class="math display">\[E(X)=\int_{-\infty}^{\infty} xf(x;\alpha)dx\]</span></p>
<p>Considera un cambio de variables <span class="math inline">\(Z=X-1\)</span> entonces <span class="math inline">\(E(X)=E(Z)+1\)</span> y</p>
<p><span class="math inline">\(E(Z)= \frac{1}{\alpha} \int_0^1 zz^{\frac{1-\alpha}{\alpha}}dz= \frac{1}{\alpha} \int_0^1 z^{1+\frac{1-\alpha}{\alpha}}dz\)</span></p>
<p><span class="math inline">\(= \frac{1}{\alpha} \frac{z^{2+\frac{1-\alpha}{\alpha}}}{{2+\frac{1-\alpha}{\alpha}} } |_0^1=\frac{1}{1+\alpha}\)</span></p>
<p>Por lo tanto,</p>
<p><span class="math display">\[E(X)=E(Z+1)=\frac{1}{1+\alpha}+1\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li>Obtenemos la ecuación para <span class="math inline">\(\hat{\alpha}_m\)</span> donde igualamos el valor esperado al primer momento muestral. Sustituyendo <span class="math inline">\(\hat{\alpha}_m\)</span>, el método de los momentos nos da la ecuación</li>
</ol>
<p><span class="math display">\[\frac{1}{1+\hat{\alpha}}+1=\bar{x}\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li><p>Resolvemos para <span class="math inline">\(\hat{\alpha}\)</span> <span class="math display">\[\hat{\alpha}_m=\frac{1}{\bar{x}-1}-1\]</span></p></li>
<li><p>Calculamos el valor de nuestros datos</p></li>
</ol>
<p><span class="math display">\[\hat{\alpha}_m=1.314\]</span></p>
<p>Tenga en cuenta que este es un ejemplo para el cual las estimaciones por máxima verosimilitud y el método de momentos son <strong>diferentes</strong>.</p>
<p>La estimación de máxima verosimilitud fue:</p>
<p><span class="math display">\[\hat{\alpha}_{ml}=-\frac{1}{n}\sum_{i=1}^n \ln (x_i-1)=1.320\]</span></p>
<p>El método de estimación de momentos fue:</p>
<p><span class="math display">\[\hat{\alpha}_m=\frac{1}{\bar{x}-1}-1=1.314\]</span></p>
<p>Necesitamos estudios de <strong>simulación</strong>, donde <strong>sabemos</strong> el verdadero valor del parámetro <span class="math inline">\(\alpha\)</span>, para encontrar cuál de estas estadísticas tiene menos error.</p>
<p>Nota: los datos para perforaciones con láser de <span class="math inline">\(30\)</span> se simularon con <span class="math inline">\(\alpha=2\)</span>, por lo tanto, debemos preferir la estimación de máxima verosimilitud. Para obtener mejores estimaciones de <span class="math inline">\(\alpha\)</span> necesitamos aumentar el tamaño de la muestra.</p>
</div>
<div id="ejercicios-máxima-verosimilitud" class="section level2 hasAnchor" number="12.8">
<h2><span class="header-section-number">12.8</span> Ejercicios Máxima Verosimilitud<a href="máxima-verosimilitud-y-método-de-los-momentos.html#ejercicios-máxima-verosimilitud" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="ejercicio-1-9" class="section level4 hasAnchor" number="12.8.0.1">
<h4><span class="header-section-number">12.8.0.1</span> Ejercicio 1<a href="máxima-verosimilitud-y-método-de-los-momentos.html#ejercicio-1-9" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Toma una variable aleatoria con la siguiente función de densidad de probabilidad</p>
<p><span class="math display">\[
f(x)=
\begin{cases}
    (1+\theta)x^\theta,&amp; \text{if } x\in (0,1)\\
    0,&amp;  x\notin (0,1)
\end{cases}
\]</span></p>
<ul>
<li><p>¿Cuál es la estimación de máxima verosimilitud para <span class="math inline">\(\theta\)</span>?</p></li>
<li><p>Si tomamos una muestra de <span class="math inline">\(5\)</span> obsevaciones
<span class="math inline">\(x_1 = 0.92; \qquad x_2 = 0.79; \qquad x_3 = 0.90; \qquad x_4 = 0.65; \qquad x_5 = 0.86\)</span></p></li>
</ul>
<p>¿Cuál es el valor estimado del parámetro <span class="math inline">\(\theta\)</span>?</p>
<ul>
<li>Calcula <span class="math inline">\(E(X)=\mu\)</span> en función de <span class="math inline">\(\theta\)</span>. ¿Cuál es la estimación de máxima verosimilitud para <span class="math inline">\(\mu\)</span>?</li>
</ul>
</div>
<div id="ejercicio-2-9" class="section level4 hasAnchor" number="12.8.0.2">
<h4><span class="header-section-number">12.8.0.2</span> Ejercicio 2<a href="máxima-verosimilitud-y-método-de-los-momentos.html#ejercicio-2-9" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Para una variable aleatoria con una función de probabilidad binomial</p>
<p><span class="math display">\[f(x; p)=\binom nxp^x(1-p)^{n-x}\]</span></p>
<ul>
<li><p>¿Cuál es el estimador de máxima verosimilitud de <span class="math inline">\(p\)</span> para una muestra de tamaño <span class="math inline">\(1\)</span> de esta variable aleatoria?</p></li>
<li><p>¿Es el estimador insesgado y/o consistente?</p></li>
<li><p>En <strong>un</strong> examen de <span class="math inline">\(100\)</span> estudiantes observamos <span class="math inline">\(x_1=68\)</span> estudiantes que aprobaron el examen. ¿Cuál es la estimación de máxima verosimilitud para la probabilidad de pasar el examen?</p></li>
</ul>
</div>
<div id="ejercicio-3-6" class="section level4 hasAnchor" number="12.8.0.3">
<h4><span class="header-section-number">12.8.0.3</span> Ejercicio 3<a href="máxima-verosimilitud-y-método-de-los-momentos.html#ejercicio-3-6" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Toma una variable aleatoria con la siguiente función de densidad de probabilidad</p>
<p><span class="math display">\[
    f(x)= 
\begin{cases}
    \lambda e^{-\lambda x},&amp;  x &gt; 0 \\
    0,&amp; x\leq 0  
\end{cases}
\]</span></p>
<ul>
<li><p>¿Cuál es la estimación de máxima verosimilitud para <span class="math inline">\(\lambda\)</span>?</p></li>
<li><p>Si tomamos una muestra de <span class="math inline">\(5\)</span> observaciones
<span class="math inline">\(x_1 = 0.223 \qquad x_2 = 0.681; \qquad x_3 = 0.117; \qquad x_4 = 0.150; \qquad x_5 = 0.520\)</span></p></li>
</ul>
<p>¿Cuál es el valor estimado del parámetro <span class="math inline">\(\lambda\)</span>?</p>
<ul>
<li><p>¿Cuál es la estimación de máxima verosimilitud de la varianza de la variable exponencial <span class="math inline">\(\sigma^2=\frac{1}{\lambda^2}\)</span>?</p></li>
<li><p>¿Es <span class="math inline">\(\hat{\sigma}^2\)</span> un estimador insesgado y consistente de <span class="math inline">\(\sigma^2\)</span>?</p></li>
</ul>
</div>
</div>
<div id="método-de-los-momentos-1" class="section level2 hasAnchor" number="12.9">
<h2><span class="header-section-number">12.9</span> Método de los momentos<a href="máxima-verosimilitud-y-método-de-los-momentos.html#método-de-los-momentos-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="ejercicio-1-10" class="section level4 hasAnchor" number="12.9.0.1">
<h4><span class="header-section-number">12.9.0.1</span> Ejercicio 1<a href="máxima-verosimilitud-y-método-de-los-momentos.html#ejercicio-1-10" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>¿Cuáles son los estimadores de los siguientes modelos paramétricos dados por el método de los momentos?</p>
<table>
<thead>
<tr class="header">
<th>Model</th>
<th>f(x)</th>
<th>E(X)</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Bernoulli</td>
<td><span class="math inline">\(p^x(1-p)^{1-x}\)</span></td>
<td><span class="math inline">\(p\)</span></td>
</tr>
<tr class="even">
<td>Binomial</td>
<td><span class="math inline">\(\binom n x p^x(1-p)^{n-x}\)</span></td>
<td><span class="math inline">\(np\)</span></td>
</tr>
<tr class="odd">
<td>Geometrica</td>
<td><span class="math inline">\(p(1-p)^{x-1}\)</span></td>
<td><span class="math inline">\(\frac{1}{p}\)</span></td>
</tr>
<tr class="even">
<td>Binomial Negativa</td>
<td><span class="math inline">\(\binom {x+r-1} x p^r(1-p)^x\)</span></td>
<td><span class="math inline">\(r\frac{1-p}{p}\)</span></td>
</tr>
<tr class="odd">
<td>Poisson</td>
<td><span class="math inline">\(\frac{e^{-\lambda}\lambda^x}{x!}\)</span></td>
<td><span class="math inline">\(\lambda\)</span></td>
</tr>
<tr class="even">
<td>Exponencial</td>
<td><span class="math inline">\(\lambda e^{-\lambda x}\)</span></td>
<td><span class="math inline">\(\frac{1}{\lambda}\)</span></td>
</tr>
<tr class="odd">
<td>Normal</td>
<td><span class="math inline">\(\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\)</span></td>
<td><span class="math inline">\(\mu\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="ejercicio-2-10" class="section level4 hasAnchor" number="12.9.0.2">
<h4><span class="header-section-number">12.9.0.2</span> Ejercicio 2<a href="máxima-verosimilitud-y-método-de-los-momentos.html#ejercicio-2-10" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Toma una variable aleatoria con la siguiente función de densidad de probabilidad</p>
<p><span class="math display">\[
f(x)=
\begin{cases}
    (1+\theta)x^\theta,&amp; \text{if } x\in (0,1)\\
    0,&amp; x\notin (0,1)
\end{cases}
\]</span></p>
<ul>
<li>Calcula <span class="math inline">\(E(X)\)</span> como una función de <span class="math inline">\(\theta\)</span></li>
<li>¿Cuál es la estimación de <span class="math inline">\(\theta\)</span> utilizando el método de los momentos?</li>
<li>Si tomamos una muestra de <span class="math inline">\(5\)</span> observaciones
<span class="math inline">\(x_1 = 0,92; \qquad x_2 = 0,79; \qquad x_3 = 0,90; \qquad x_4 = 0,65; \qquad x_5 = 0,86\)</span></li>
</ul>
<p>¿Cuál es el valor estimado del parámetro <span class="math inline">\(\theta\)</span>?</p>
</div>
<div id="ejercicio-3-7" class="section level4 hasAnchor" number="12.9.0.3">
<h4><span class="header-section-number">12.9.0.3</span> Ejercicio 3<a href="máxima-verosimilitud-y-método-de-los-momentos.html#ejercicio-3-7" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Considera una variable aleatoria discreta <span class="math inline">\(X\)</span> que sigue una distribución binomial negativa con función de masa de probabilidad:</p>
<p><span class="math display">\[f(x) = \binom{x+r-1}{x}p^r(1-p)^x\]</span></p>
<p>Dado que</p>
<ul>
<li><span class="math inline">\(E(X)=\dfrac{r(1-p)}{p}\)</span></li>
<li><span class="math inline">\(V(X) =\dfrac{r(1-p)}{p^2}\)</span></li>
</ul>
<p>calcular:</p>
<ul>
<li><p>Una estimación del parámetro <span class="math inline">\(r\)</span> y una estimación del parámetro <span class="math inline">\(p\)</span> obtenidas a partir de una muestra aleatoria de tamaño <span class="math inline">\(n\)</span> por el método de los momentos.</p></li>
<li><p>Los valores de las estimaciones de <span class="math inline">\(r\)</span> y <span class="math inline">\(p\)</span> para la siguiente muestra aleatoria:</p></li>
</ul>
<p><span class="math display">\[x_1 = 27; \qquad   x_2 = 8; \qquad   x_3 = 22; \qquad   x_4 = 29; \qquad   x_5 = 19; \qquad   x_5 = 32\]</span></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="teorema-central-del-límite.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="intervalos-de-confianza.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/12-MaximumLikelihood.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
