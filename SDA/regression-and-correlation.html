<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 18 Regression and Correlation | Statistical Data Analysis for Experimental Sciences</title>
  <meta name="description" content="This is a markdown book titled Statistical Data Analysis for Experimental Sciences by Alejandro Caceres" />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 18 Regression and Correlation | Statistical Data Analysis for Experimental Sciences" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a markdown book titled Statistical Data Analysis for Experimental Sciences by Alejandro Caceres" />
  <meta name="github-repo" content="alejandro-isglobal/master" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 18 Regression and Correlation | Statistical Data Analysis for Experimental Sciences" />
  
  <meta name="twitter:description" content="This is a markdown book titled Statistical Data Analysis for Experimental Sciences by Alejandro Caceres" />
  

<meta name="author" content="Alejandro CÃ¡ceres" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="mean-differences-across-several-groups.html"/>
<link rel="next" href="apendix.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">SDA</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#how-to-read-the-book"><i class="fa fa-check"></i><b>1.1</b> How to read the book</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>1.2</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-description.html"><a href="data-description.html"><i class="fa fa-check"></i><b>2</b> Data description</a>
<ul>
<li class="chapter" data-level="2.1" data-path="data-description.html"><a href="data-description.html#scientific-method"><i class="fa fa-check"></i><b>2.1</b> Scientific method</a></li>
<li class="chapter" data-level="2.2" data-path="data-description.html"><a href="data-description.html#data"><i class="fa fa-check"></i><b>2.2</b> Data</a></li>
<li class="chapter" data-level="2.3" data-path="data-description.html"><a href="data-description.html#types-of-outcomes"><i class="fa fa-check"></i><b>2.3</b> Types of outcomes</a></li>
<li class="chapter" data-level="2.4" data-path="data-description.html"><a href="data-description.html#random-experiments"><i class="fa fa-check"></i><b>2.4</b> Random experiments</a></li>
<li class="chapter" data-level="2.5" data-path="data-description.html"><a href="data-description.html#absolute-frequencies"><i class="fa fa-check"></i><b>2.5</b> Absolute frequencies</a></li>
<li class="chapter" data-level="2.6" data-path="data-description.html"><a href="data-description.html#relative-frequencies"><i class="fa fa-check"></i><b>2.6</b> Relative frequencies</a></li>
<li class="chapter" data-level="2.7" data-path="data-description.html"><a href="data-description.html#bar-chart"><i class="fa fa-check"></i><b>2.7</b> Bar chart</a></li>
<li class="chapter" data-level="2.8" data-path="data-description.html"><a href="data-description.html#pie-chart"><i class="fa fa-check"></i><b>2.8</b> Pie chart</a></li>
<li class="chapter" data-level="2.9" data-path="data-description.html"><a href="data-description.html#ordinal-categorical-outcomes"><i class="fa fa-check"></i><b>2.9</b> Ordinal categorical outcomes</a></li>
<li class="chapter" data-level="2.10" data-path="data-description.html"><a href="data-description.html#absolute-and-relative-cumulative-frequencies"><i class="fa fa-check"></i><b>2.10</b> Absolute and relative cumulative frequencies</a></li>
<li class="chapter" data-level="2.11" data-path="data-description.html"><a href="data-description.html#cumulative-frequency-graph"><i class="fa fa-check"></i><b>2.11</b> Cumulative frequency graph</a></li>
<li class="chapter" data-level="2.12" data-path="data-description.html"><a href="data-description.html#numerical-outcomes"><i class="fa fa-check"></i><b>2.12</b> Numerical outcomes</a></li>
<li class="chapter" data-level="2.13" data-path="data-description.html"><a href="data-description.html#transforming-continuous-data"><i class="fa fa-check"></i><b>2.13</b> Transforming continuous data</a></li>
<li class="chapter" data-level="2.14" data-path="data-description.html"><a href="data-description.html#frequency-table-for-a-continuous-variable"><i class="fa fa-check"></i><b>2.14</b> Frequency table for a continuous variable</a></li>
<li class="chapter" data-level="2.15" data-path="data-description.html"><a href="data-description.html#histogram"><i class="fa fa-check"></i><b>2.15</b> Histogram</a></li>
<li class="chapter" data-level="2.16" data-path="data-description.html"><a href="data-description.html#cumulative-frequency-graph-1"><i class="fa fa-check"></i><b>2.16</b> Cumulative frequency graph</a></li>
<li class="chapter" data-level="2.17" data-path="data-description.html"><a href="data-description.html#summary-statistics"><i class="fa fa-check"></i><b>2.17</b> Summary Statistics</a></li>
<li class="chapter" data-level="2.18" data-path="data-description.html"><a href="data-description.html#average-sample-mean"><i class="fa fa-check"></i><b>2.18</b> Average (sample mean)</a></li>
<li class="chapter" data-level="2.19" data-path="data-description.html"><a href="data-description.html#median"><i class="fa fa-check"></i><b>2.19</b> Median</a></li>
<li class="chapter" data-level="2.20" data-path="data-description.html"><a href="data-description.html#dispersion"><i class="fa fa-check"></i><b>2.20</b> Dispersion</a></li>
<li class="chapter" data-level="2.21" data-path="data-description.html"><a href="data-description.html#sample-variance"><i class="fa fa-check"></i><b>2.21</b> Sample variance</a></li>
<li class="chapter" data-level="2.22" data-path="data-description.html"><a href="data-description.html#interquartile-range-iqr"><i class="fa fa-check"></i><b>2.22</b> Interquartile range (IQR)</a></li>
<li class="chapter" data-level="2.23" data-path="data-description.html"><a href="data-description.html#boxplot"><i class="fa fa-check"></i><b>2.23</b> Boxplot</a></li>
<li class="chapter" data-level="2.24" data-path="data-description.html"><a href="data-description.html#questions"><i class="fa fa-check"></i><b>2.24</b> Questions</a></li>
<li class="chapter" data-level="2.25" data-path="data-description.html"><a href="data-description.html#exercises"><i class="fa fa-check"></i><b>2.25</b> Exercises</a></li>
<li class="chapter" data-level="2.26" data-path="data-description.html"><a href="data-description.html#practice"><i class="fa fa-check"></i><b>2.26</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>3</b> Probability</a>
<ul>
<li class="chapter" data-level="3.1" data-path="probability.html"><a href="probability.html#probability-mesurement"><i class="fa fa-check"></i><b>3.1</b> Probability mesurement</a></li>
<li class="chapter" data-level="3.2" data-path="probability.html"><a href="probability.html#classical-probability"><i class="fa fa-check"></i><b>3.2</b> Classical probability</a></li>
<li class="chapter" data-level="3.3" data-path="probability.html"><a href="probability.html#relative-frequencies-1"><i class="fa fa-check"></i><b>3.3</b> Relative frequencies</a></li>
<li class="chapter" data-level="3.4" data-path="probability.html"><a href="probability.html#frequentist-probability"><i class="fa fa-check"></i><b>3.4</b> Frequentist probability</a></li>
<li class="chapter" data-level="3.5" data-path="probability.html"><a href="probability.html#classical-and-frequentist-probabilities"><i class="fa fa-check"></i><b>3.5</b> Classical and frequentist probabilities</a></li>
<li class="chapter" data-level="3.6" data-path="probability.html"><a href="probability.html#sample-space"><i class="fa fa-check"></i><b>3.6</b> Sample space</a></li>
<li class="chapter" data-level="3.7" data-path="probability.html"><a href="probability.html#events"><i class="fa fa-check"></i><b>3.7</b> Events</a></li>
<li class="chapter" data-level="3.8" data-path="probability.html"><a href="probability.html#algebra-of-events"><i class="fa fa-check"></i><b>3.8</b> Algebra of events</a></li>
<li class="chapter" data-level="3.9" data-path="probability.html"><a href="probability.html#mutually-exclusive-events"><i class="fa fa-check"></i><b>3.9</b> Mutually exclusive events</a></li>
<li class="chapter" data-level="3.10" data-path="probability.html"><a href="probability.html#definition-of-probability"><i class="fa fa-check"></i><b>3.10</b> Definition of probability</a></li>
<li class="chapter" data-level="3.11" data-path="probability.html"><a href="probability.html#probability-table"><i class="fa fa-check"></i><b>3.11</b> Probability table</a></li>
<li class="chapter" data-level="3.12" data-path="probability.html"><a href="probability.html#joint-probabilities"><i class="fa fa-check"></i><b>3.12</b> Joint probabilities</a></li>
<li class="chapter" data-level="3.13" data-path="probability.html"><a href="probability.html#contingency-table"><i class="fa fa-check"></i><b>3.13</b> Contingency table</a></li>
<li class="chapter" data-level="3.14" data-path="probability.html"><a href="probability.html#the-addition-rule"><i class="fa fa-check"></i><b>3.14</b> The addition rule</a></li>
<li class="chapter" data-level="3.15" data-path="probability.html"><a href="probability.html#questions-1"><i class="fa fa-check"></i><b>3.15</b> Questions</a></li>
<li class="chapter" data-level="3.16" data-path="probability.html"><a href="probability.html#exercises-1"><i class="fa fa-check"></i><b>3.16</b> Exercises</a></li>
<li class="chapter" data-level="3.17" data-path="probability.html"><a href="probability.html#practice-1"><i class="fa fa-check"></i><b>3.17</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="conditional-probability.html"><a href="conditional-probability.html"><i class="fa fa-check"></i><b>4</b> Conditional probability</a>
<ul>
<li class="chapter" data-level="4.1" data-path="conditional-probability.html"><a href="conditional-probability.html#joint-probability"><i class="fa fa-check"></i><b>4.1</b> Joint probability</a></li>
<li class="chapter" data-level="4.2" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-independence-and-correlation"><i class="fa fa-check"></i><b>4.2</b> Statistical independence and correlation</a></li>
<li class="chapter" data-level="4.3" data-path="conditional-probability.html"><a href="conditional-probability.html#conditional-probability-1"><i class="fa fa-check"></i><b>4.3</b> Conditional probability</a></li>
<li class="chapter" data-level="4.4" data-path="conditional-probability.html"><a href="conditional-probability.html#conditional-contingency-table"><i class="fa fa-check"></i><b>4.4</b> Conditional contingency table</a></li>
<li class="chapter" data-level="4.5" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-independence"><i class="fa fa-check"></i><b>4.5</b> Statistical independence</a></li>
<li class="chapter" data-level="4.6" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-dependency"><i class="fa fa-check"></i><b>4.6</b> Statistical dependency</a></li>
<li class="chapter" data-level="4.7" data-path="conditional-probability.html"><a href="conditional-probability.html#diagnostic-test"><i class="fa fa-check"></i><b>4.7</b> Diagnostic test</a></li>
<li class="chapter" data-level="4.8" data-path="conditional-probability.html"><a href="conditional-probability.html#inverse-probabilities"><i class="fa fa-check"></i><b>4.8</b> Inverse probabilities</a></li>
<li class="chapter" data-level="4.9" data-path="conditional-probability.html"><a href="conditional-probability.html#bayes-theorem"><i class="fa fa-check"></i><b>4.9</b> Bayesâ Theorem</a></li>
<li class="chapter" data-level="4.10" data-path="conditional-probability.html"><a href="conditional-probability.html#questions-2"><i class="fa fa-check"></i><b>4.10</b> Questions</a></li>
<li class="chapter" data-level="4.11" data-path="conditional-probability.html"><a href="conditional-probability.html#exercises-2"><i class="fa fa-check"></i><b>4.11</b> Exercises</a></li>
<li class="chapter" data-level="4.12" data-path="conditional-probability.html"><a href="conditional-probability.html#practice-2"><i class="fa fa-check"></i><b>4.12</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html"><i class="fa fa-check"></i><b>5</b> Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="5.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#definition-of-a-random-variable"><i class="fa fa-check"></i><b>5.1</b> Definition of a Random Variable</a></li>
<li class="chapter" data-level="5.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#the-value-of-a-random-variable"><i class="fa fa-check"></i><b>5.2</b> The value of a random variable</a></li>
<li class="chapter" data-level="5.3" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-of-random-variables"><i class="fa fa-check"></i><b>5.3</b> Probability of random variables</a></li>
<li class="chapter" data-level="5.4" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-functions"><i class="fa fa-check"></i><b>5.4</b> Probability functions</a></li>
<li class="chapter" data-level="5.5" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-mass-functions"><i class="fa fa-check"></i><b>5.5</b> Probability mass functions</a></li>
<li class="chapter" data-level="5.6" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#mean-or-expected-value"><i class="fa fa-check"></i><b>5.6</b> Mean or expected value</a></li>
<li class="chapter" data-level="5.7" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#variance"><i class="fa fa-check"></i><b>5.7</b> Variance</a></li>
<li class="chapter" data-level="5.8" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-functions-for-functions-of-x"><i class="fa fa-check"></i><b>5.8</b> Probability functions for functions of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="5.9" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-distribution"><i class="fa fa-check"></i><b>5.9</b> Probability distribution</a></li>
<li class="chapter" data-level="5.10" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-function-and-probability-distribution"><i class="fa fa-check"></i><b>5.10</b> Probability function and probability distribution</a></li>
<li class="chapter" data-level="5.11" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#quantiles"><i class="fa fa-check"></i><b>5.11</b> Quantiles</a></li>
<li class="chapter" data-level="5.12" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#summary"><i class="fa fa-check"></i><b>5.12</b> Summary</a></li>
<li class="chapter" data-level="5.13" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#questions-3"><i class="fa fa-check"></i><b>5.13</b> Questions</a></li>
<li class="chapter" data-level="5.14" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#exercises-3"><i class="fa fa-check"></i><b>5.14</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="continous-random-variables.html"><a href="continous-random-variables.html"><i class="fa fa-check"></i><b>6</b> Continous Random Variables</a>
<ul>
<li class="chapter" data-level="6.1" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probabilities-of-continuous-random-variables"><i class="fa fa-check"></i><b>6.1</b> Probabilities of continuous random variables</a></li>
<li class="chapter" data-level="6.2" data-path="continous-random-variables.html"><a href="continous-random-variables.html#relative-frequencies-2"><i class="fa fa-check"></i><b>6.2</b> Relative frequencies</a></li>
<li class="chapter" data-level="6.3" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-density-function"><i class="fa fa-check"></i><b>6.3</b> Probability Density Function</a></li>
<li class="chapter" data-level="6.4" data-path="continous-random-variables.html"><a href="continous-random-variables.html#total-area-under-the-curve"><i class="fa fa-check"></i><b>6.4</b> Total area under the curve</a></li>
<li class="chapter" data-level="6.5" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probabilities-of-continous-variables"><i class="fa fa-check"></i><b>6.5</b> Probabilities of continous variables</a></li>
<li class="chapter" data-level="6.6" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-distribution-1"><i class="fa fa-check"></i><b>6.6</b> Probability distribution</a></li>
<li class="chapter" data-level="6.7" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-plots"><i class="fa fa-check"></i><b>6.7</b> Probability plots</a></li>
<li class="chapter" data-level="6.8" data-path="continous-random-variables.html"><a href="continous-random-variables.html#mean"><i class="fa fa-check"></i><b>6.8</b> Mean</a></li>
<li class="chapter" data-level="6.9" data-path="continous-random-variables.html"><a href="continous-random-variables.html#variance-1"><i class="fa fa-check"></i><b>6.9</b> Variance</a></li>
<li class="chapter" data-level="6.10" data-path="continous-random-variables.html"><a href="continous-random-variables.html#functions-of-x"><i class="fa fa-check"></i><b>6.10</b> Functions of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="6.11" data-path="continous-random-variables.html"><a href="continous-random-variables.html#exercises-4"><i class="fa fa-check"></i><b>6.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html"><i class="fa fa-check"></i><b>7</b> Discrete Probability Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#probability-model"><i class="fa fa-check"></i><b>7.1</b> Probability model</a></li>
<li class="chapter" data-level="7.2" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#parametric-models"><i class="fa fa-check"></i><b>7.2</b> Parametric models</a></li>
<li class="chapter" data-level="7.3" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#uniform-probability-mass-function-one-parameter"><i class="fa fa-check"></i><b>7.3</b> Uniform probability mass function (one parameter)</a></li>
<li class="chapter" data-level="7.4" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#uniform-probability-mass-function-two-parameters"><i class="fa fa-check"></i><b>7.4</b> Uniform probability mass function (two parameters)</a></li>
<li class="chapter" data-level="7.5" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#bernoulli-trial"><i class="fa fa-check"></i><b>7.5</b> Bernoulli trial</a></li>
<li class="chapter" data-level="7.6" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#binomial-experiment"><i class="fa fa-check"></i><b>7.6</b> Binomial experiment</a></li>
<li class="chapter" data-level="7.7" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#binomial-probability-function"><i class="fa fa-check"></i><b>7.7</b> Binomial probability function</a></li>
<li class="chapter" data-level="7.8" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#negative-binomial"><i class="fa fa-check"></i><b>7.8</b> Negative binomial</a></li>
<li class="chapter" data-level="7.9" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#geometric-distribution"><i class="fa fa-check"></i><b>7.9</b> Geometric distribution</a></li>
<li class="chapter" data-level="7.10" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#hypergeometric-model"><i class="fa fa-check"></i><b>7.10</b> Hypergeometric model</a></li>
<li class="chapter" data-level="7.11" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#questions-4"><i class="fa fa-check"></i><b>7.11</b> Questions</a></li>
<li class="chapter" data-level="7.12" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#exercises-5"><i class="fa fa-check"></i><b>7.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html"><i class="fa fa-check"></i><b>8</b> Poisson and Exponential Models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#discrete-probability-models-1"><i class="fa fa-check"></i><b>8.1</b> Discrete probability models</a></li>
<li class="chapter" data-level="8.2" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#poissson-experiment"><i class="fa fa-check"></i><b>8.2</b> Poissson experiment</a></li>
<li class="chapter" data-level="8.3" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#poisson-probability-mass-function"><i class="fa fa-check"></i><b>8.3</b> Poisson probability mass function</a></li>
<li class="chapter" data-level="8.4" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#continuous-probability-models"><i class="fa fa-check"></i><b>8.4</b> Continuous probability models</a></li>
<li class="chapter" data-level="8.5" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-process"><i class="fa fa-check"></i><b>8.5</b> Exponential process</a></li>
<li class="chapter" data-level="8.6" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-probability-density"><i class="fa fa-check"></i><b>8.6</b> Exponential probability density</a></li>
<li class="chapter" data-level="8.7" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-distribution"><i class="fa fa-check"></i><b>8.7</b> Exponential Distribution</a></li>
<li class="chapter" data-level="8.8" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#questions-5"><i class="fa fa-check"></i><b>8.8</b> Questions</a></li>
<li class="chapter" data-level="8.9" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exercises-6"><i class="fa fa-check"></i><b>8.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="normal-distribution.html"><a href="normal-distribution.html"><i class="fa fa-check"></i><b>9</b> Normal Distribution</a>
<ul>
<li class="chapter" data-level="9.1" data-path="normal-distribution.html"><a href="normal-distribution.html#history"><i class="fa fa-check"></i><b>9.1</b> History</a></li>
<li class="chapter" data-level="9.2" data-path="normal-distribution.html"><a href="normal-distribution.html#normal-probability-density"><i class="fa fa-check"></i><b>9.2</b> Normal probability density</a></li>
<li class="chapter" data-level="9.3" data-path="normal-distribution.html"><a href="normal-distribution.html#probability-distribution-2"><i class="fa fa-check"></i><b>9.3</b> Probability distribution</a></li>
<li class="chapter" data-level="9.4" data-path="normal-distribution.html"><a href="normal-distribution.html#quantiles-of-the-normal-distribution"><i class="fa fa-check"></i><b>9.4</b> Quantiles of the normal distribution</a></li>
<li class="chapter" data-level="9.5" data-path="normal-distribution.html"><a href="normal-distribution.html#standard-normal-density"><i class="fa fa-check"></i><b>9.5</b> Standard normal density</a></li>
<li class="chapter" data-level="9.6" data-path="normal-distribution.html"><a href="normal-distribution.html#standard-distribution"><i class="fa fa-check"></i><b>9.6</b> Standard distribution</a></li>
<li class="chapter" data-level="9.7" data-path="normal-distribution.html"><a href="normal-distribution.html#standardization"><i class="fa fa-check"></i><b>9.7</b> Standardization</a></li>
<li class="chapter" data-level="9.8" data-path="normal-distribution.html"><a href="normal-distribution.html#questions-6"><i class="fa fa-check"></i><b>9.8</b> Questions</a></li>
<li class="chapter" data-level="9.9" data-path="normal-distribution.html"><a href="normal-distribution.html#exercises-7"><i class="fa fa-check"></i><b>9.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="sampling-distributions.html"><a href="sampling-distributions.html"><i class="fa fa-check"></i><b>10</b> Sampling distributions</a>
<ul>
<li class="chapter" data-level="10.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#random-sample"><i class="fa fa-check"></i><b>10.1</b> Random sample</a></li>
<li class="chapter" data-level="10.2" data-path="sampling-distributions.html"><a href="sampling-distributions.html#parameter-estimation"><i class="fa fa-check"></i><b>10.2</b> Parameter estimation</a></li>
<li class="chapter" data-level="10.3" data-path="sampling-distributions.html"><a href="sampling-distributions.html#law-of-large-numbers"><i class="fa fa-check"></i><b>10.3</b> Law of Large Numbers</a></li>
<li class="chapter" data-level="10.4" data-path="sampling-distributions.html"><a href="sampling-distributions.html#inference"><i class="fa fa-check"></i><b>10.4</b> Inference</a></li>
<li class="chapter" data-level="10.5" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-mean"><i class="fa fa-check"></i><b>10.5</b> Sample mean</a></li>
<li class="chapter" data-level="10.6" data-path="sampling-distributions.html"><a href="sampling-distributions.html#prediction"><i class="fa fa-check"></i><b>10.6</b> Prediction</a></li>
<li class="chapter" data-level="10.7" data-path="sampling-distributions.html"><a href="sampling-distributions.html#validation"><i class="fa fa-check"></i><b>10.7</b> Validation</a></li>
<li class="chapter" data-level="10.8" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-sum"><i class="fa fa-check"></i><b>10.8</b> Sample Sum</a></li>
<li class="chapter" data-level="10.9" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-variance-1"><i class="fa fa-check"></i><b>10.9</b> Sample Variance</a>
<ul>
<li class="chapter" data-level="10.9.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#example-cables"><i class="fa fa-check"></i><b>10.9.1</b> Example (Cables)</a></li>
</ul></li>
<li class="chapter" data-level="10.10" data-path="sampling-distributions.html"><a href="sampling-distributions.html#distribution-of-the-sample-variance"><i class="fa fa-check"></i><b>10.10</b> Distribution of the Sample Variance</a></li>
<li class="chapter" data-level="10.11" data-path="sampling-distributions.html"><a href="sampling-distributions.html#the-chi2-distribution"><i class="fa fa-check"></i><b>10.11</b> The <span class="math inline">\(\chi^2\)</span> Distribution</a></li>
<li class="chapter" data-level="10.12" data-path="sampling-distributions.html"><a href="sampling-distributions.html#questions-7"><i class="fa fa-check"></i><b>10.12</b> Questions</a></li>
<li class="chapter" data-level="10.13" data-path="sampling-distributions.html"><a href="sampling-distributions.html#exercises-8"><i class="fa fa-check"></i><b>10.13</b> Exercises</a>
<ul>
<li class="chapter" data-level="10.13.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#from-estimation-to-inference"><i class="fa fa-check"></i><b>10.13.1</b> From Estimation to Inference</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html"><i class="fa fa-check"></i><b>11</b> Central limit theorem</a>
<ul>
<li class="chapter" data-level="11.1" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#margin-of-error"><i class="fa fa-check"></i><b>11.1</b> Margin of error</a></li>
<li class="chapter" data-level="11.2" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#averages-of-normal-variables"><i class="fa fa-check"></i><b>11.2</b> Averages of normal variables</a></li>
<li class="chapter" data-level="11.3" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#central-limit-theorem-1"><i class="fa fa-check"></i><b>11.3</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="11.4" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#sample-sum-and-clt"><i class="fa fa-check"></i><b>11.4</b> Sample sum and CLT</a></li>
<li class="chapter" data-level="11.5" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#unknown-sigma"><i class="fa fa-check"></i><b>11.5</b> Unknown <span class="math inline">\(\sigma\)</span></a></li>
<li class="chapter" data-level="11.6" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#t-statistic"><i class="fa fa-check"></i><b>11.6</b> T-statistic</a></li>
<li class="chapter" data-level="11.7" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#questions-8"><i class="fa fa-check"></i><b>11.7</b> Questions</a></li>
<li class="chapter" data-level="11.8" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#exercises-9"><i class="fa fa-check"></i><b>11.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html"><i class="fa fa-check"></i><b>12</b> Maximum likelihood</a>
<ul>
<li class="chapter" data-level="12.1" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#statistic"><i class="fa fa-check"></i><b>12.1</b> Statistic</a></li>
<li class="chapter" data-level="12.2" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#properties"><i class="fa fa-check"></i><b>12.2</b> Properties</a></li>
<li class="chapter" data-level="12.3" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#maximum-likelihood-1"><i class="fa fa-check"></i><b>12.3</b> Maximum likelihood</a></li>
<li class="chapter" data-level="12.4" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#maximum-likelihood-2"><i class="fa fa-check"></i><b>12.4</b> Maximum likelihood</a></li>
<li class="chapter" data-level="12.5" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#questions-9"><i class="fa fa-check"></i><b>12.5</b> Questions</a></li>
<li class="chapter" data-level="12.6" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#exercises-10"><i class="fa fa-check"></i><b>12.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="interval-estimation.html"><a href="interval-estimation.html"><i class="fa fa-check"></i><b>13</b> Interval estimation</a>
<ul>
<li class="chapter" data-level="13.1" data-path="interval-estimation.html"><a href="interval-estimation.html#revisiting-parameter-estimation-and-marging-of-error"><i class="fa fa-check"></i><b>13.1</b> Revisiting parameter estimation and marging of error</a></li>
<li class="chapter" data-level="13.2" data-path="interval-estimation.html"><a href="interval-estimation.html#interval-estimation-for-the-mean"><i class="fa fa-check"></i><b>13.2</b> Interval estimation for the mean</a></li>
<li class="chapter" data-level="13.3" data-path="interval-estimation.html"><a href="interval-estimation.html#confidence-interval-estimation"><i class="fa fa-check"></i><b>13.3</b> Confidence Interval Estimation</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="interval-estimation.html"><a href="interval-estimation.html#estimation-of-the-mean-for-normal-variables"><i class="fa fa-check"></i><b>13.3.1</b> Estimation of the mean for normal variables</a></li>
<li class="chapter" data-level="13.3.2" data-path="interval-estimation.html"><a href="interval-estimation.html#estimation-of-the-proportion-for-dichotomic-variables"><i class="fa fa-check"></i><b>13.3.2</b> Estimation of the proportion for dichotomic variables</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="interval-estimation.html"><a href="interval-estimation.html#estimation-of-the-variance"><i class="fa fa-check"></i><b>13.4</b> Estimation of the variance</a></li>
<li class="chapter" data-level="13.5" data-path="interval-estimation.html"><a href="interval-estimation.html#confidence-interval-for-the-variance"><i class="fa fa-check"></i><b>13.5</b> Confidence interval for the variance</a></li>
<li class="chapter" data-level="13.6" data-path="interval-estimation.html"><a href="interval-estimation.html#questions-10"><i class="fa fa-check"></i><b>13.6</b> Questions</a></li>
<li class="chapter" data-level="13.7" data-path="interval-estimation.html"><a href="interval-estimation.html#exercises-11"><i class="fa fa-check"></i><b>13.7</b> Exercises</a></li>
<li class="chapter" data-level="13.8" data-path="interval-estimation.html"><a href="interval-estimation.html#practice-3"><i class="fa fa-check"></i><b>13.8</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>14</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="14.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-formulation"><i class="fa fa-check"></i><b>14.1</b> Hypothesis formulation</a></li>
<li class="chapter" data-level="14.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-1"><i class="fa fa-check"></i><b>14.2</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="14.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-for-the-mean"><i class="fa fa-check"></i><b>14.3</b> Hypothesis testing for the mean</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-with-a-confidence-interval"><i class="fa fa-check"></i><b>14.3.1</b> Hypothesis test with a confidence interval</a></li>
<li class="chapter" data-level="14.3.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-with-acceptancerejection-zones"><i class="fa fa-check"></i><b>14.3.2</b> Hypothesis test with acceptance/rejection zones</a></li>
<li class="chapter" data-level="14.3.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-with-a-p-value"><i class="fa fa-check"></i><b>14.3.3</b> Hypothesis test with a P-value</a></li>
<li class="chapter" data-level="14.3.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#upper-tail-hypothesis"><i class="fa fa-check"></i><b>14.3.4</b> Upper tail hypothesis</a></li>
<li class="chapter" data-level="14.3.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#paired-t-test"><i class="fa fa-check"></i><b>14.3.5</b> Paired t-test</a></li>
<li class="chapter" data-level="14.3.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#lower-tail-hypothesis"><i class="fa fa-check"></i><b>14.3.6</b> Lower tail hypothesis</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-for-the-proportion"><i class="fa fa-check"></i><b>14.4</b> Hypothesis testing for the proportion</a></li>
<li class="chapter" data-level="14.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-for-the-variance"><i class="fa fa-check"></i><b>14.5</b> Hypothesis Testing for the Variance</a></li>
<li class="chapter" data-level="14.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#errors-in-hypothesis-testing"><i class="fa fa-check"></i><b>14.6</b> Errors in hypothesis testing</a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sensitivity-and-specificity"><i class="fa fa-check"></i><b>14.6.1</b> Sensitivity and Specificity</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#exercises-12"><i class="fa fa-check"></i><b>14.7</b> Exercises</a></li>
<li class="chapter" data-level="14.8" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#practice-4"><i class="fa fa-check"></i><b>14.8</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="contingency-tables.html"><a href="contingency-tables.html"><i class="fa fa-check"></i><b>15</b> Contingency tables</a>
<ul>
<li class="chapter" data-level="15.1" data-path="contingency-tables.html"><a href="contingency-tables.html#difference-between-proportions"><i class="fa fa-check"></i><b>15.1</b> Difference between proportions</a></li>
<li class="chapter" data-level="15.2" data-path="contingency-tables.html"><a href="contingency-tables.html#difference-between-proportions-1"><i class="fa fa-check"></i><b>15.2</b> Difference between proportions</a></li>
<li class="chapter" data-level="15.3" data-path="contingency-tables.html"><a href="contingency-tables.html#contingency-table-of-conditional-probabilities"><i class="fa fa-check"></i><b>15.3</b> Contingency table of conditional probabilities</a></li>
<li class="chapter" data-level="15.4" data-path="contingency-tables.html"><a href="contingency-tables.html#test-for-the-difference-between-proportions"><i class="fa fa-check"></i><b>15.4</b> Test for the difference between proportions</a></li>
<li class="chapter" data-level="15.5" data-path="contingency-tables.html"><a href="contingency-tables.html#chi2-test"><i class="fa fa-check"></i><b>15.5</b> <span class="math inline">\(\chi^2\)</span> test</a></li>
<li class="chapter" data-level="15.6" data-path="contingency-tables.html"><a href="contingency-tables.html#fishers-exact-test"><i class="fa fa-check"></i><b>15.6</b> Fisherâs exact test</a></li>
<li class="chapter" data-level="15.7" data-path="contingency-tables.html"><a href="contingency-tables.html#hypergeometric-distribution"><i class="fa fa-check"></i><b>15.7</b> Hypergeometric distribution</a></li>
<li class="chapter" data-level="15.8" data-path="contingency-tables.html"><a href="contingency-tables.html#difference-between-several-proportions"><i class="fa fa-check"></i><b>15.8</b> Difference between several proportions</a></li>
<li class="chapter" data-level="15.9" data-path="contingency-tables.html"><a href="contingency-tables.html#goodness-of-fit"><i class="fa fa-check"></i><b>15.9</b> Goodness of fit</a></li>
<li class="chapter" data-level="15.10" data-path="contingency-tables.html"><a href="contingency-tables.html#questions-11"><i class="fa fa-check"></i><b>15.10</b> Questions</a></li>
<li class="chapter" data-level="15.11" data-path="contingency-tables.html"><a href="contingency-tables.html#practice-5"><i class="fa fa-check"></i><b>15.11</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html"><i class="fa fa-check"></i><b>16</b> Mean differences between two samples</a>
<ul>
<li class="chapter" data-level="16.1" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#difference-in-means-between-two-groups"><i class="fa fa-check"></i><b>16.1</b> Difference in means between two groups</a></li>
<li class="chapter" data-level="16.2" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#data-1"><i class="fa fa-check"></i><b>16.2</b> Data</a></li>
<li class="chapter" data-level="16.3" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#difference-between-means"><i class="fa fa-check"></i><b>16.3</b> Difference between means</a></li>
<li class="chapter" data-level="16.4" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#hypothesis-test"><i class="fa fa-check"></i><b>16.4</b> Hypothesis test</a></li>
<li class="chapter" data-level="16.5" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#estiamtor-of-the-mean-difference"><i class="fa fa-check"></i><b>16.5</b> Estiamtor of the mean difference</a></li>
<li class="chapter" data-level="16.6" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#standardized-error"><i class="fa fa-check"></i><b>16.6</b> Standardized error</a></li>
<li class="chapter" data-level="16.7" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#standardized-error-for-the-null"><i class="fa fa-check"></i><b>16.7</b> Standardized error for the null</a></li>
<li class="chapter" data-level="16.8" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#mean-differences-when-n-is-small"><i class="fa fa-check"></i><b>16.8</b> Mean differences when <span class="math inline">\(n\)</span> is small</a></li>
<li class="chapter" data-level="16.9" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#data-2"><i class="fa fa-check"></i><b>16.9</b> Data</a></li>
<li class="chapter" data-level="16.10" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#difference-between-means-1"><i class="fa fa-check"></i><b>16.10</b> Difference between means</a></li>
<li class="chapter" data-level="16.11" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#hypothesis-test-1"><i class="fa fa-check"></i><b>16.11</b> Hypothesis test</a></li>
<li class="chapter" data-level="16.12" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#estimator-of-the-mean-difference"><i class="fa fa-check"></i><b>16.12</b> Estimator of the mean difference</a></li>
<li class="chapter" data-level="16.13" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#standardized-error-for-the-null-1"><i class="fa fa-check"></i><b>16.13</b> Standardized error for the null</a></li>
<li class="chapter" data-level="16.14" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#mean-differences-with-unequall-variances"><i class="fa fa-check"></i><b>16.14</b> Mean differences with unequall variances</a></li>
<li class="chapter" data-level="16.15" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#data-3"><i class="fa fa-check"></i><b>16.15</b> Data</a></li>
<li class="chapter" data-level="16.16" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#questions-12"><i class="fa fa-check"></i><b>16.16</b> Questions</a></li>
<li class="chapter" data-level="16.17" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#practice-6"><i class="fa fa-check"></i><b>16.17</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html"><i class="fa fa-check"></i><b>17</b> Mean differences across several groups</a>
<ul>
<li class="chapter" data-level="17.1" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#different-means-among-several-conditions"><i class="fa fa-check"></i><b>17.1</b> Different means among several conditions</a></li>
<li class="chapter" data-level="17.2" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#data-4"><i class="fa fa-check"></i><b>17.2</b> Data</a></li>
<li class="chapter" data-level="17.3" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#difference-between-means-2"><i class="fa fa-check"></i><b>17.3</b> Difference between means</a></li>
<li class="chapter" data-level="17.4" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#hypothesis-test-2"><i class="fa fa-check"></i><b>17.4</b> Hypothesis test</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#distribution-of-group-means-under-h_0"><i class="fa fa-check"></i><b>17.4.1</b> Distribution of group means under <span class="math inline">\(H_0\)</span></a></li>
<li class="chapter" data-level="17.4.2" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#sources-of-variation"><i class="fa fa-check"></i><b>17.4.2</b> Sources of variation</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#variance-components-estimators"><i class="fa fa-check"></i><b>17.5</b> Variance components estimators</a></li>
<li class="chapter" data-level="17.6" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#analysis-of-variance-anova"><i class="fa fa-check"></i><b>17.6</b> Analysis of variance (ANOVA)</a></li>
<li class="chapter" data-level="17.7" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#anova-for-two-groups"><i class="fa fa-check"></i><b>17.7</b> ANOVA for Two Groups</a></li>
<li class="chapter" data-level="17.8" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#linear-model"><i class="fa fa-check"></i><b>17.8</b> Linear model</a></li>
<li class="chapter" data-level="17.9" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#way-anova"><i class="fa fa-check"></i><b>17.9</b> 2-way ANOVA</a></li>
<li class="chapter" data-level="17.10" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#data-5"><i class="fa fa-check"></i><b>17.10</b> Data</a></li>
<li class="chapter" data-level="17.11" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#modeling-residuals"><i class="fa fa-check"></i><b>17.11</b> Modeling residuals</a></li>
<li class="chapter" data-level="17.12" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#way-anova-linear-model"><i class="fa fa-check"></i><b>17.12</b> 2-way ANOVA linear model</a></li>
<li class="chapter" data-level="17.13" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#hypothesis-tests"><i class="fa fa-check"></i><b>17.13</b> Hypothesis tests</a></li>
<li class="chapter" data-level="17.14" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#variance-components"><i class="fa fa-check"></i><b>17.14</b> Variance components</a></li>
<li class="chapter" data-level="17.15" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#way-anova-with-interaction"><i class="fa fa-check"></i><b>17.15</b> 2-way ANOVA with interaction</a></li>
<li class="chapter" data-level="17.16" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#linear-model-1"><i class="fa fa-check"></i><b>17.16</b> Linear model</a></li>
<li class="chapter" data-level="17.17" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#hypothesis-tests-1"><i class="fa fa-check"></i><b>17.17</b> Hypothesis tests</a></li>
<li class="chapter" data-level="17.18" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#variance-components-1"><i class="fa fa-check"></i><b>17.18</b> Variance components</a></li>
<li class="chapter" data-level="17.19" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#questions-13"><i class="fa fa-check"></i><b>17.19</b> Questions</a></li>
<li class="chapter" data-level="17.20" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#practice-7"><i class="fa fa-check"></i><b>17.20</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html"><i class="fa fa-check"></i><b>18</b> Regression and Correlation</a>
<ul>
<li class="chapter" data-level="18.1" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#correlations"><i class="fa fa-check"></i><b>18.1</b> Correlations</a></li>
<li class="chapter" data-level="18.2" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#data-6"><i class="fa fa-check"></i><b>18.2</b> Data</a></li>
<li class="chapter" data-level="18.3" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#normal-bivariate"><i class="fa fa-check"></i><b>18.3</b> Normal bivariate</a></li>
<li class="chapter" data-level="18.4" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#estimators"><i class="fa fa-check"></i><b>18.4</b> Estimators</a></li>
<li class="chapter" data-level="18.5" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#correlation-coefficient"><i class="fa fa-check"></i><b>18.5</b> Correlation coefficient</a></li>
<li class="chapter" data-level="18.6" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#hypothesis-contrast"><i class="fa fa-check"></i><b>18.6</b> Hypothesis contrast</a></li>
<li class="chapter" data-level="18.7" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#regression-analysis"><i class="fa fa-check"></i><b>18.7</b> Regression analysis</a></li>
<li class="chapter" data-level="18.8" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#linear-model-2"><i class="fa fa-check"></i><b>18.8</b> Linear model</a></li>
<li class="chapter" data-level="18.9" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#hypothesis-contrast-1"><i class="fa fa-check"></i><b>18.9</b> Hypothesis contrast</a></li>
<li class="chapter" data-level="18.10" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#estimators-1"><i class="fa fa-check"></i><b>18.10</b> Estimators</a></li>
<li class="chapter" data-level="18.11" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#hypothesis-testing-2"><i class="fa fa-check"></i><b>18.11</b> Hypothesis testing</a></li>
<li class="chapter" data-level="18.12" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#stratified-analysis"><i class="fa fa-check"></i><b>18.12</b> Stratified analysis</a></li>
<li class="chapter" data-level="18.13" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#multiple-regression"><i class="fa fa-check"></i><b>18.13</b> Multiple Regression</a></li>
<li class="chapter" data-level="18.14" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#multiple-regression-interaction"><i class="fa fa-check"></i><b>18.14</b> Multiple Regression interaction</a></li>
<li class="chapter" data-level="18.15" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#model-diagnostics"><i class="fa fa-check"></i><b>18.15</b> Model diagnostics</a></li>
<li class="chapter" data-level="18.16" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#questions-14"><i class="fa fa-check"></i><b>18.16</b> Questions</a></li>
<li class="chapter" data-level="18.17" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#practice-8"><i class="fa fa-check"></i><b>18.17</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="apendix.html"><a href="apendix.html"><i class="fa fa-check"></i><b>19</b> Apendix</a>
<ul>
<li class="chapter" data-level="19.1" data-path="apendix.html"><a href="apendix.html#solutions-to-questions"><i class="fa fa-check"></i><b>19.1</b> Solutions to Questions</a></li>
<li class="chapter" data-level="19.2" data-path="apendix.html"><a href="apendix.html#summary-tables-python-and-r-code"><i class="fa fa-check"></i><b>19.2</b> Summary tables, Python and R code</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="apendix.html"><a href="apendix.html#creating-data-frames-and-loading-text-files"><i class="fa fa-check"></i><b>19.2.1</b> Creating Data Frames and Loading Text Files</a></li>
<li class="chapter" data-level="19.2.2" data-path="apendix.html"><a href="apendix.html#python-and-r-functions-for-data-description"><i class="fa fa-check"></i><b>19.2.2</b> Python and R Functions for Data Description</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="apendix.html"><a href="apendix.html#summary-of-common-probability-models"><i class="fa fa-check"></i><b>19.3</b> Summary of common probability models</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="apendix.html"><a href="apendix.html#python-and-r-functions-for-probability-models"><i class="fa fa-check"></i><b>19.3.1</b> Python and R Functions for Probability Models</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="apendix.html"><a href="apendix.html#summary-of-hypothesis"><i class="fa fa-check"></i><b>19.4</b> Summary of hypothesis</a>
<ul>
<li class="chapter" data-level="19.4.1" data-path="apendix.html"><a href="apendix.html#python-and-r-functions-for-hypothesis-tesing"><i class="fa fa-check"></i><b>19.4.1</b> Python and R Functions for Hypothesis tesing</a></li>
<li class="chapter" data-level="19.4.2" data-path="apendix.html"><a href="apendix.html#python-libraries-required"><i class="fa fa-check"></i><b>19.4.2</b> Python Libraries Required</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Data Analysis
for
Experimental Sciences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regression-and-correlation" class="section level1 hasAnchor" number="18">
<h1><span class="header-section-number">Chapter 18</span> Regression and Correlation<a href="regression-and-correlation.html#regression-and-correlation" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>When analyzing a continuous variable, the conditions under which observations are made may also be continuous. Unlike categorical groups, clearly defined repeating conditions are not available, as a group is defined by a continuous variable whose values cannot be repeated exactly. For example, consider measuring the velocity of a galaxy and its distance from Earth. We might want to know whether the velocity depends on distanceâthat is, whether higher distances correspond to higher velocities, as evidence of the expansion of the Universe.</p>
<p>In this chapter, we will explore how to test the statistical dependence between two continuous random variables. We will introduce <strong>correlation</strong> as a parameter of a bivariate normal distribution and perform statistical tests on correlation, illustrating Hubbleâs law.</p>
<p>We will also discuss how to assess statistical dependence when one variable is considered the outcome (dependent) and the other the predictor (independent). We will introduce <strong>regression analysis</strong> to test linear relationships, using, for example, leptin levels in blood as explained by fat mass. Finally, we will discuss <strong>multiple regression</strong>, which allows adjusting associations for additional variables that may confound the relationship. For instance, we will examine how monthly variations in atmospheric CO2 can obscure the yearly trend first reported by Keeling in his groundbreaking 1960s work.</p>
<p>Sex differences are often important modulatory factors in biomedical research. We will show how the effect of fat mass on leptin levels differs between sexes. In models relating a continuous outcome to a continuous predictor, interactions with additional variables can explain important variation in the outcome. We will conclude by introducing regression analysis with interactions, highlighting how these models capture more complex relationships between variables.</p>
<div id="correlations" class="section level2 hasAnchor" number="18.1">
<h2><span class="header-section-number">18.1</span> Correlations<a href="regression-and-correlation.html#correlations" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In 1929, Edwin Hubble reported the distances and velocities of 22 nebulae, providing the first evidence for the expansion of the Universe <span class="citation">(<a href="#ref-Hubble1929_distance_velocity">Hubble 1929</a>)</span>. He measured distances using different techniques depending on the scale. For relatively nearby galaxies, he relied on supergiant pulsating stars, whose pulsation periods are related to their intrinsic luminosity. By comparing the observed luminosity to the predicted luminosity, Hubble could estimate the distance to the galaxy containing the star. Velocities were determined from the redshift of spectral lines: the faster a galaxy moves away, the more its light is shifted toward the red.</p>
<p>From a statistical perspective, Hubbleâs data can be seen as a simultaneous measurement of two continuous variablesâdistance and velocityâfor each galaxy. This dataset naturally leads to questions about the relationship between these variables, providing an early example of the kind of correlation and regression analysis that we discuss in this chapter.</p>
<p>Hubbleâs random experiment is the simultaneous measurement of two continuous outcomes on a galaxy:</p>
<ul>
<li>The velocity of a galaxy, which has a probability density</li>
</ul>
<p><span class="math display">\[Y \sim N(\mu_y, \sigma_y^2)\]</span></p>
<ul>
<li>The distance of the galaxy, with density</li>
</ul>
<p><span class="math display">\[X \sim N(\mu_x, \sigma_x^2)\]</span></p>
</div>
<div id="data-6" class="section level2 hasAnchor" number="18.2">
<h2><span class="header-section-number">18.2</span> Data<a href="regression-and-correlation.html#data-6" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>One random experiment in Hubbleâs study has two outcomes: <span class="math inline">\((velocity, distance)\)</span>.</p>
<p>Continuous variable (outcome of interest)</p>
<ul>
<li><span class="math inline">\(velocity \in (-25.0, 1800.0)\)</span> km/s</li>
</ul>
<p>Continuous variable (explanatory variable)</p>
<ul>
<li><span class="math inline">\(fatmass \in (0.62, 3.450)\)</span> Mpc</li>
</ul>
<p>Repeating the experiment <span class="math inline">\(n=21\)</span> times, the data for look like</p>
<p><small>
<span class="math display">\[
  \begin{array}{ccc}
  \mathbf{Object} &amp; \mathbf{Velocity} &amp; \mathbf{Distance} \\
  278 &amp; 650 &amp; 1.52 \\
  584 &amp; 1800 &amp; 3.45 \\
  936 &amp; 1300 &amp; 2.37 \\
  1023 &amp; 300 &amp; 0.62 \\
  1700 &amp; 800 &amp; 1.16 \\
  2681 &amp; 700 &amp; 1.42 \\
  2683 &amp; 400 &amp; 0.67 \\
  2841 &amp; 600 &amp; 1.24 \\
  3034 &amp; 290 &amp; 0.79 \\
  3115 &amp; 600 &amp; 1.00 \\
  3368 &amp; 940 &amp; 1.74 \\
  3379 &amp; 810 &amp; 1.49 \\
  3489 &amp; 600 &amp; 1.10 \\
  3521 &amp; 730 &amp; 1.27 \\
  3623 &amp; 800 &amp; 1.53 \\
  4111 &amp; 800 &amp; 1.79 \\
  4526 &amp; 580 &amp; 1.20 \\
  4565 &amp; 1100 &amp; 2.35 \\
  4594 &amp; 1140 &amp; 2.23 \\
  5005 &amp; 900 &amp; 2.06 \\
  5866 &amp; 650 &amp; 1.73 \\
  \end{array}
\]</span>
</small></p>
<p>and the plot of velocity against distance is</p>
<p><img src="_main_files/figure-html/unnamed-chunk-198-1.png" width="672" /></p>
<p>We see a clear linear relationship between the outcomes. How can we test for it? We need to formulate a hypothesis test on a parameter of a join probability distribution that represents this linear relationship, which we will call the correlation between the variables.</p>
</div>
<div id="normal-bivariate" class="section level2 hasAnchor" number="18.3">
<h2><span class="header-section-number">18.3</span> Normal bivariate<a href="regression-and-correlation.html#normal-bivariate" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let us consider that one random experiment of the study consists on drawing a pair of measurements of both the distance <strong>and</strong> and the velocity of a a single galaxy. We, therefore, have a random variable that is a pair of measurements that follows a probability distribution. We will assume that the distribution is the <strong>two-dimensional</strong> version of a normal probability density</p>
<p><span class="math display">\[(Y, X) \sim N(\mu_y, \sigma^2_y, \mu_x, \sigma^2_x, \rho)\]</span></p>
<p>This is function has five parameters. More explicitly the function is of the form</p>
<p><span class="math display">\[f(y,x)=\frac{1}{2\pi \sigma_y\sigma_x \sqrt{1-\rho^2}}e^{\frac{(y-\mu_y)^2}{\sigma_y^2}-\frac{2\rho(y-\mu_y)(x-\mu_x)}{\sigma_y\sigma_x}+\frac{(x-\mu_x)^2}{\sigma_x^2}}\]</span></p>
<p>and the parameters are <span class="math inline">\(\mu_y, \mu_x, \sigma^2_y, \sigma_x^2, \rho\)</span>. These are</p>
<p>The <strong>marginal mean</strong> and variance of <span class="math inline">\(Y\)</span></p>
<ul>
<li><span class="math inline">\(\mu_y=E(Y)\)</span>, <span class="math inline">\(\sigma^2_y=V(Y)\)</span></li>
</ul>
<p>The <strong>marginal mean</strong> and variance of <span class="math inline">\(X\)</span></p>
<ul>
<li><span class="math inline">\(\mu_x=E(X)\)</span>, <span class="math inline">\(\sigma^2_x=V(X)\)</span></li>
</ul>
<p>The <strong>correlation</strong> between <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span></p>
<ul>
<li><span class="math inline">\(\rho=\frac{E[(Y-\mu_y)(X-\mu_x)]}{\sigma_y\sigma_x}\)</span></li>
</ul>
<p><span class="math inline">\(\rho\)</span> is called the <strong>correlation coefficient</strong>.</p>
<p>When we draw the probability density in two dimensions, we see that the marginal densities are the projections of the densities on each axis. Let us define the densities for each variable</p>
<p><span class="math display">\[X \sim N(\mu_x, \sigma_x^2)\]</span></p>
<p>and</p>
<p><span class="math display">\[Y \sim N(\mu_y, \sigma_y^2)\]</span></p>
<p>with its parameters. We can plot the 2D density as contour lines and the marginal densities on each axis</p>
<p><img src="_main_files/figure-html/unnamed-chunk-199-1.png" width="672" /></p>
<p>We can also plot the density in a 3D plot, where the <span class="math inline">\(Z\)</span> axis is the value of the probability density.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-200-1.png" width="672" /></p>
<p>looking at the contour plots of the 2D distribution, we see that the fifth parameter <span class="math inline">\(\rho\)</span> defines the direction on which the ellipses are elongated (mayor axis).</p>
<p><img src="_main_files/figure-html/unnamed-chunk-201-1.png" width="672" /></p>
<p>The density is entirely determined by 5 parameters.</p>
</div>
<div id="estimators" class="section level2 hasAnchor" number="18.4">
<h2><span class="header-section-number">18.4</span> Estimators<a href="regression-and-correlation.html#estimators" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We can derive the estimator of all 5 parameters, if we formulate the likelihood function</p>
<p><span class="math display">\[L=\Pi_{i=1}^n f(y_i,x_i; \mu_x, \mu_y, \sigma^2_x, \sigma_y^2, \rho)\]</span>
and maximize it for each parameter. As a result, we obtain the following estimators of the parameters.</p>
<p>The estimators for the means are the usual averages</p>
<ul>
<li><span class="math inline">\(\bar{Y}=\frac{1}{n}\sum_{i=1}^n y_i\)</span> estimates <span class="math inline">\(\mu_y\)</span></li>
<li><span class="math inline">\(\bar{X}=\frac{1}{n}\sum_{i=1}^n x_i\)</span> estimates <span class="math inline">\(\mu_x\)</span></li>
</ul>
<p>The maximum likelihood of the estimators for the variances are the uncorrected sample variances (dividing by <span class="math inline">\(n\)</span>)</p>
<ul>
<li><span class="math inline">\(S^2_y=\frac{1}{n}\sum_{i=1}^n (y_i-\bar{y})^2\)</span> estimates <span class="math inline">\(\sigma^2_y\)</span></li>
<li><span class="math inline">\(S^2_x=\frac{1}{n}\sum_{i=1}^n (x_i-\bar{x})^2\)</span> estimates <span class="math inline">\(\sigma^2_x\)</span></li>
</ul>
<p>The estimator for the correlation is</p>
<ul>
<li><span class="math inline">\(R=\frac{\sum_{i=0}^n(X_i-\bar{X})(Y_i-\bar{Y})}{\sqrt{\sum_{i=1}^n(X_i-\bar{X})^2}\sqrt{\sum_{i=1}^n(Y_i-\bar{Y})^2}}\)</span> estimates <span class="math inline">\(\rho\)</span>.</li>
</ul>
</div>
<div id="correlation-coefficient" class="section level2 hasAnchor" number="18.5">
<h2><span class="header-section-number">18.5</span> Correlation coefficient<a href="regression-and-correlation.html#correlation-coefficient" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><span class="math inline">\(R\)</span> is then a <strong>statistics</strong> that can be computed from the data and we can take one value as an estimate of <span class="math inline">\(\rho\)</span>. The sampling distribution of <span class="math inline">\(R\)</span> can be obtained if we transform it into a new variable (Fisherâs z transformation)</p>
<p><span class="math display">\[Z=\frac{1}{2}\ln (\frac{1+R}{1-R})\]</span>
The new variable <span class="math inline">\(Z\)</span> is a normal variable</p>
<p><span class="math display">\[Z \sim_{aprox} N(\frac{1}{2}\ln (\frac{1+\rho}{1-\rho}), \frac{1}{n-3})\]</span></p>
<p>with mean <span class="math inline">\(\frac{1}{2}\ln (\frac{1+\rho}{1-\rho})\)</span> and variance <span class="math inline">\(\frac{1}{n-3}\)</span>.</p>
<p>As <span class="math inline">\(R\)</span> estimates <span class="math inline">\(\rho\)</span> we have that</p>
<ul>
<li><p>If <span class="math inline">\(R\)</span> is near <span class="math inline">\(0\)</span> then there is no linear relationship between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> (the mayor and minor axes of the 2D plot are the x and y axes).</p></li>
<li><p>If <span class="math inline">\(R\)</span> is near <span class="math inline">\(1\)</span> there is strong evidence of a linear relationship between <span class="math inline">\(y\)</span> and <span class="math inline">\(x\)</span> (the mayor axis does not align with neither the x or the y axis).</p></li>
</ul>
<p><span class="math inline">\(R\)</span> is then a measure of the statistical dependence between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>. We can use it to test that hypothesis.</p>
</div>
<div id="hypothesis-contrast" class="section level2 hasAnchor" number="18.6">
<h2><span class="header-section-number">18.6</span> Hypothesis contrast<a href="regression-and-correlation.html#hypothesis-contrast" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The hypothesis contrast for the independence on the relationship between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> that follow a <strong>bivariate normal distribution</strong> can be formulated as</p>
<ol style="list-style-type: lower-alpha">
<li><p><span class="math inline">\(H_0: \rho=0\)</span> (null hypothesis). Therefore, <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> are consider statistically <strong>independent</strong> and consequently <span class="math inline">\(f(y,x)=f(x)f(y)\)</span> (the joint probability is the product of the marginals)</p></li>
<li><p><span class="math inline">\(H_1: \rho \neq 0\)</span> (alternative hypothesis). Therefore, <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> are statistically <strong>dependent</strong>.</p></li>
</ol>
<p>We then use the statistic <span class="math inline">\(R\)</span> to test whether there is a dependency between <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span>. For testing the hypothesis contrast, we take the observed value of <span class="math inline">\(R\)</span></p>
<p><span class="math display">\[r_{obs}=\hat{\rho}=\frac{\sum_{i=0}^n(x_i-\bar{x})(y_i-\bar{y})}{\sqrt{\sum_{i=1}^n(x_i-\bar{x})^2}\sqrt{\sum_{i=1}^n(y_i-\bar{y})^2}}\]</span></p>
<p>and compute its <span class="math inline">\(pvalue\)</span>. That is the probability that we obtain a larger value if we repeat the sample when the <strong>null hypothesis</strong> is true. Under the null hypothesis <span class="math inline">\(\rho=0\)</span>, we then compute the two-tailed <span class="math inline">\(pvalue\)</span></p>
<p><span class="math display">\[pvalue=2(1- F(|r_{obs}|)= 2(1- F_{N(0, 1/(n-3
)})(|z_{obs}|)  \]</span></p>
<p>where</p>
<p><span class="math display">\[Z \sim_{aprox} N(0, \frac{1}{n-3})\]</span>
<strong>Example (Hubbleâs law)</strong></p>
<p>For Hubbleâs data, we have that the observed correlation coefficient is <span class="math inline">\(r_{obs}=0.956\)</span> and its transformed value</p>
<p><span class="math display">\[z_{obs}=ln((1+0.956)/(1-0.956))/2=1.89\]</span></p>
<p>The <span class="math inline">\(pvalue\)</span> is therefore</p>
<p><span class="math display">\[pvalue=2(1- F_{N(0,1/18)}(1.89))=1.4\times 10^{-11}\]</span></p>
<p>Therefore, since it is lower than <span class="math inline">\(\alpha=0.05\)</span>, we reject the null hypothesis that galaxy velocity and distance are independent. The correlation is strongly positive, showing that as more distance galaxies are observed, we expect that they are moving away from the Earth and between each other at faster speeds. This result clearly implies that at some time in the past all the mass of the Universe was close together, perhaps at a point before it exploded in a Big Bang.</p>
<p>In Python and R:</p>
<pre><code>from scipy import stats
r, p_value = stats.pearsonr(dat[&quot;velocity&quot;], dat[&quot;distance&quot;])

R:
cor.test(dat$velocity, dat$distance)</code></pre>
<p><strong>Example (leptin and fat mass)</strong></p>
<p>Leptin is a hormone produced by adipose tissue. We want to study the serum leptin levels in the adult population. Zhang et al.Â studied the gene expression of patients with metabolic syndrome, for which one of its characteristics is high weight <span class="citation">(<a href="#ref-Zhang2013_adiponectinQTLs">Zhang et al. 2013</a>)</span>. They recorded relevant data of 188 individuals that included leptin levels in blood, lean fatmass(kg), age and sex. Data is available at the public repository GEO and can be accessed from R</p>
<p>We can use this publicly available data to inquiry on the relationship between fatmas and leptin and contrast it with expected results from previous studies, although this was not the main objective of the study.</p>
<p>From this data, we assume that the levels of fatmass (<span class="math inline">\(X\)</span>) and (log) leptin in blood <span class="math inline">\(Y\)</span> are random variables that have a join bivarite normal distribution</p>
<p><span class="math display">\[(X, Y) \sim N(\mu_x, \mu_y, \sigma_x^2, \sigma_y^2, \rho)\]</span>
We are interested in finding whether letpin levels depend on the levels of fatmass. Leptin is a hormone released from adipose tissue. Therefore, as more fatmas we expect more leptin in ciculating blood that regulate regulates satiety. The breaking of satiety regulation by leptin may be a cause for obesity.</p>
<p>One random experiment in our study has two outcomes: <span class="math inline">\((leptin, fatmass)\)</span>.</p>
<p>Continuous variable (outcome of interest)</p>
<ul>
<li><span class="math inline">\(lepting \in (0, 5)\)</span></li>
</ul>
<p>Continuous variable (explanatory variable)</p>
<ul>
<li><span class="math inline">\(fatmass \in (20,80)\)</span></li>
</ul>
<p>Repeating the experiment <span class="math inline">\(n=188\)</span> times, the data for the first five repetitions look like</p>
<p><span class="math display">\[
  \begin{array}{ccc}
  \mathbf{Subject} &amp; \mathbf{Leptin} &amp; \mathbf{Fatmass} \\
1 &amp; 3.355677  &amp; 45.721 \\
2 &amp; 2.272126  &amp; 43.895 \\
3 &amp; 1.071584  &amp; 47.871 \\
4 &amp; 3.921082  &amp; 65.801 \\
5 &amp; 1.536867  &amp; 56.644 \\
... &amp; ...  &amp; ... \\
\end{array}
\]</span></p>
<p>For this data, we have that the observed correlation coefficient is <span class="math inline">\(r_{obs}=-0.276\)</span> and its transformed value</p>
<p><span class="math display">\[z_{obs}=\frac{1}{2}\ln(\frac{1-0.276}{1+0.276})=-0.284\]</span></p>
<p>The <span class="math inline">\(pvalue\)</span> is therefore</p>
<p><span class="math display">\[pvalue=2(1- F_{N(0,1/185)}(0.284))=0.0001\]</span></p>
<p>Therefore, since it is lower than <span class="math inline">\(\alpha=0.05\)</span>, we reject the null hypothesis that leptin and fat mass are independent. Note that leptin and fat mass are <strong>weakly correlated</strong> and <strong>negatively</strong> <span class="math inline">\(r=-0.28\)</span>, although the correlation is <strong>highly significant</strong> because <span class="math inline">\(pvalue=0.0001\)</span>.</p>
<p>We should take this result with caution:</p>
<ul>
<li><p>Looking at the data, we see the fitted 2D probability function with negative correlation, but the <strong>marginal</strong> histograms are not quite normally distributed.</p></li>
<li><p>From literature, we know that as we increase fat mass, we should obtain <strong>more</strong> leptin, not the contrary, as it is released from adipose tissue.</p></li>
</ul>
<p><img src="_main_files/figure-html/unnamed-chunk-205-1.png" width="672" /></p>
<p>How can we improve our analysis, so that our results are as expected?</p>
</div>
<div id="regression-analysis" class="section level2 hasAnchor" number="18.7">
<h2><span class="header-section-number">18.7</span> Regression analysis<a href="regression-and-correlation.html#regression-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>To determine if <span class="math inline">\(leptin\)</span> and <span class="math inline">\(fatmass\)</span> are statistically independent, we can rather ask: What is the probability density of leptin at a <strong>given value</strong> of fat mass. Does the density changes when we change the value of fat mass? We will then consider the that the continuous fat mass value is a condition for leptin, or that changing fat mass will produce a change in leptin levels, as it is the tissue that releases it. We call the condition variable the explanatory or independent variable, and the outcome of interest the explained or dependent variable.</p>
<p>Let us explore first the independence of two bivariate normal variables in terms of conditinal probabilities. Remember, two variables <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> are independent if</p>
<p><span class="math display">\[P(Y|X)=P(Y)\]</span></p>
<p>Therefore, we can calculate the <strong>conditional probability density</strong> of <span class="math inline">\(Y\)</span> (leptin) given <span class="math inline">\(X\)</span> (fat mass) from the definition</p>
<p><span class="math display">\[f(y|x)=\frac{f(y,x)}{f(y)}
=N(\mu_{y|x}, \sigma^2_{y|x})\]</span></p>
<p>This turns up to be a normal distribution. The conditional probability density is the profile, or a slice, of the 2D distribution at a given value of <span class="math inline">\(x\)</span>.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-206-1.png" width="672" /></p>
<p>The conditional density at a given point is the dotted line in red. Its mean is the red dot and, in terms of the parameter of the binomial normal density, is given by</p>
<p><span class="math display">\[\mu_{y|x}=\mu_y+\frac{\sigma_y\rho}{\sigma_x}(x-\mu_x)\]</span></p>
<p>If we manipulate this equation, we see that the <strong>conditional mean</strong> is a linear function of <span class="math inline">\(x\)</span></p>
<p><span class="math display">\[\mu_{y|x}=(\mu_y-\mu_x \frac{\sigma_y\rho}{\sigma_x})+\frac{\sigma_y \rho}{\sigma_x} x=\alpha + \beta x\]</span></p>
<p>where <span class="math inline">\(\alpha=\mu_y-\mu_x \beta\)</span> and <span class="math inline">\(\beta=\frac{\sigma_y \rho}{\sigma_x}\)</span>. This line is called a <strong>regression</strong> line (red dotted line in the plot). That is, when we move along the <span class="math inline">\(X\)</span> axis, the conditional mean of <span class="math inline">\(Y\)</span> moves linearly.</p>
<p>The variance of the conditional density is</p>
<p><span class="math display">\[\sigma^2_{y|x}= \sigma_y^2(1-\rho^2)\]</span>
Solving for <span class="math inline">\(\rho^2\)</span>, we have</p>
<p><span class="math display">\[\rho^2=\frac{\sigma_y^2-\sigma^2_{y|x}}{\sigma_y^2} \]</span>
<span class="math inline">\(\rho^2\)</span> is then the proportion of the total variance that is explained by the regression line. For instance, <span class="math inline">\(\rho^2=1\)</span> when the conditional variability <span class="math inline">\(\sigma^2_{y|x}\)</span> is zero ans the conditional distribution shinks to its mean; that is, all the observations fall on the regression line.</p>
</div>
<div id="linear-model-2" class="section level2 hasAnchor" number="18.8">
<h2><span class="header-section-number">18.8</span> Linear model<a href="regression-and-correlation.html#linear-model-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Consider the <strong>linear model</strong> for the values of <span class="math inline">\(Y\)</span> <strong>conditioned</strong> to the value of <span class="math inline">\(x_i\)</span></p>
<p><span class="math display">\[Y_i = \alpha + \beta x_i +\varepsilon_{i}\]</span></p>
<p><span class="math inline">\(i\)</span> is the index of the observation from <span class="math inline">\((1,...n)\)</span>, typically one for every <span class="math inline">\(x_i\)</span> as <span class="math inline">\(x_i\)</span> is continuous, and <span class="math inline">\(\varepsilon_{i}\)</span> is the random error, a <strong>random variable</strong> with expected value <span class="math inline">\(E(\varepsilon_{i})=0\)</span> and variance <span class="math inline">\(V(\varepsilon_{i})=\sigma_{y|x}^2\)</span>. The expected value of <span class="math inline">\(Y_{x_i}\)</span> is the regression line</p>
<p><span class="math display">\[\mu_{y|x_i}=\alpha + \beta x_i\]</span>
with</p>
<p><span class="math display">\[\alpha=\mu_y-\beta\mu_x\]</span>
and</p>
<p><span class="math display">\[\beta=\rho\frac{\sigma_y}{\sigma_x}\]</span></p>
</div>
<div id="hypothesis-contrast-1" class="section level2 hasAnchor" number="18.9">
<h2><span class="header-section-number">18.9</span> Hypothesis contrast<a href="regression-and-correlation.html#hypothesis-contrast-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Null hypothesis:</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0: \beta=0\)</span>. <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> are statistically <strong>independent</strong>, and therefore <span class="math inline">\(f(y|x)=f(y)\)</span>. If this is the case then the regression line is flat, as the conditional density is the same no matter the point of the slice. The null hypothesis model is shown in the plot</li>
</ol>
<p><img src="_main_files/figure-html/unnamed-chunk-207-1.png" width="672" /></p>
<p>Note that the marginal probability (projection of the probability on the <span class="math inline">\(y\)</span> axis) would be identical to all the conditional probabilities, which is the condition for independence.</p>
<p>Alternative hypothesis:</p>
<ol start="2" style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_1: \beta\neq 0\)</span>. <span class="math inline">\(Y\)</span> and <span class="math inline">\(X\)</span> are statistically <strong>dependent</strong>. If this is the case then we have the following model</li>
</ol>
<p><img src="_main_files/figure-html/unnamed-chunk-208-1.png" width="672" /></p>
<p>Note that the marginal probability would be the combination of the conditional probabilities.</p>
</div>
<div id="estimators-1" class="section level2 hasAnchor" number="18.10">
<h2><span class="header-section-number">18.10</span> Estimators<a href="regression-and-correlation.html#estimators-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><span class="math inline">\(\beta\)</span> is therefore our parameter of interest and we need a probability distribution to test its hypothesis contrast</p>
<ul>
<li><span class="math inline">\(\beta=\rho\frac{\sigma_y}{\sigma_x}\)</span> suggest the estimator for <span class="math inline">\(\beta\)</span></li>
</ul>
<p><span class="math display">\[B=\frac{\sum_{i=1}^m(x_i-\bar{x})(Y_i-\bar{Y})}{\sum_{i=1}^n(x_i-\bar{x})^2}\]</span></p>
<ul>
<li><span class="math inline">\(\alpha=\mu_y-\beta\mu_x\)</span> suggests the estimator for <span class="math inline">\(\alpha\)</span></li>
</ul>
<p><span class="math display">\[A=\bar{Y}- \hat{\beta}\bar{x}\]</span></p>
<p>The estimators <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> for <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span> can formally be derived from <strong>minimizing the sum of squares</strong> for the error given <span class="math inline">\(x_i\)</span></p>
<p><span class="math display">\[SSE=\sum_{i=1}^n(Y_i-\bar{Y_i})^2=\sum_{i=1}^n(Y_i-\alpha + \beta x_i)^2\]</span>
with respect to <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\beta\)</span>. If <span class="math inline">\(\bar{Y_i}\)</span> is normal then</p>
<p><span class="math display">\[B \sim N(\beta, \frac{n\sigma^2_y}{{(n-2)s^2_x}})\]</span></p>
<p>with mean <span class="math inline">\(E(B)=\beta\)</span> and, therefore, it is an unbiased estimator.</p>
</div>
<div id="hypothesis-testing-2" class="section level2 hasAnchor" number="18.11">
<h2><span class="header-section-number">18.11</span> Hypothesis testing<a href="regression-and-correlation.html#hypothesis-testing-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The standardized error, we make when we estimate <span class="math inline">\(\beta\)</span> with <span class="math inline">\(B\)</span></p>
<p><span class="math display">\[\frac{B -\beta}{\sqrt{\frac{ns^2_y}{{(n-2)s^2_x}}}} \sim t(n-2)\]</span>
that follows a t-distribution with <span class="math inline">\(n-2\)</span> degrees of freedom. If the null hypothesis is true then <span class="math inline">\(\beta=0\)</span> and the observed error is</p>
<p><span class="math display">\[t_{obs}= \frac{\hat{\beta}}{\sqrt{\frac{ns^2_y}{{(n-2)s^2_x}}}} \sim t(n-2)\]</span>
Where <span class="math inline">\(\hat{\beta}\)</span> is the observed value of the random variable <span class="math inline">\(B\)</span>.</p>
<p><strong>Example (leptin and fatmass)</strong></p>
<p>We can perform the statistical test in Pyhton and R:</p>
<pre><code>Python:
import pandas as pd
from scipy.stats import pearsonr

##loading dat
model = ols(&#39;leptin ~ fatmass&#39;, data=data).fit()
print(model.summary())

R:
##loading dat
summary(lm(leptin ~ fatmass, data=dat))</code></pre>
<p>The outut is a table like</p>
<p><small>
<span class="math display">\[
\begin{array}{lcccc}
&amp; \mathbf{Estimate} &amp; \mathbf{Std.\ Error} &amp; \mathbf{t\ value} &amp; \mathbf{Pr(&gt;|t|)} \\
\mathbf{(Intercept)} &amp; 3.720 &amp; 0.295 &amp; 12.604 &amp; &lt;2 \times 10^{-16} \ ^{***} \\
\mathbf{fatmass}     &amp; -0.0226 &amp; 0.00576 &amp; -3.926 &amp; 0.000121 \ ^{***} \\
\end{array}
\]</span>
</small></p>
<p>The observed value of <span class="math inline">\(B\)</span> is</p>
<p><span class="math display">\[\hat{\beta}= \frac{\sum_{i=1}^m(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^n(x_i-\bar{x})^2}= -0.02262\]</span>
and the observed value of <span class="math inline">\(A\)</span> is</p>
<p><span class="math display">\[\hat{\alpha}=\bar{y}-\hat{\beta}\bar{x}= 3.72012\]</span>
Only <span class="math inline">\(7\%\)</span> of the variability is explained by the regression line, since (<code>R-squared: 0.07653</code>)</p>
<p><span class="math display">\[r_{obs}^2=0.07653\]</span></p>
<p>We can draw the regression line</p>
<p><img src="_main_files/figure-html/unnamed-chunk-210-1.png" width="672" /></p>
<p>We see that the regression line is negative and there is dispersion about it. Remember that the correct way to interpret the line is to think that these are the mean values of <span class="math inline">\(Y\)</span> <strong>conditioned</strong> on <span class="math inline">\(X\)</span>. The bands, are the contious confidence intervals at a fix value of <span class="math inline">\(X\)</span>.</p>
</div>
<div id="stratified-analysis" class="section level2 hasAnchor" number="18.12">
<h2><span class="header-section-number">18.12</span> Stratified analysis<a href="regression-and-correlation.html#stratified-analysis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We can include other conditions in the regression analysis. In general, it is important <strong>to adjust</strong> for other factors that we believe are correlated with the outcome <span class="math inline">\(Y\)</span> and the condition <span class="math inline">\(x\)</span>, as they may explain part of the association. These are called <strong>confounders</strong>.</p>
<p><strong>Example (Fat mass and leptin)</strong>
In the datudy of Zhang and colleageues <span class="citation">(<a href="#ref-Zhang2013_adiponectinQTLs">Zhang et al. 2013</a>)</span> they measure othre determinats of leptin levels, such as sex and age. The leptin level may have multiple covariates or explanatory variables that can affect the association between fat mass and letpin. The first observations of the complete data sex looks like</p>
<p><span class="math display">\[
  \begin{array}{ccccc}
  \mathbf{Subject} &amp; \mathbf{Leptin} &amp; \mathbf{Fatmass} &amp; \mathbf{Sex} &amp; \mathbf{Age} \\
1 &amp; 3.356 &amp; 45.721 &amp; F &amp; 45 \\
2 &amp; 2.272 &amp; 43.895 &amp; F &amp; 77 \\
3 &amp; 1.072 &amp; 47.871 &amp; M &amp; 79 \\
4 &amp; 3.921 &amp; 65.801 &amp; F &amp; 58 \\
5 &amp; 1.537 &amp; 56.644 &amp; M &amp; 42 \\
\vdots &amp; \vdots &amp; \vdots &amp; \vdots &amp; \vdots \\
\end{array}
\]</span></p>
<p>Consider the previous regression and color the points according to their sex</p>
<p><img src="_main_files/figure-html/unnamed-chunk-211-1.png" width="672" /></p>
<p>We clearly see that the negative association between leptin and fat mass is given by the <strong>effect of sex</strong>. As males have lower leptin levels and higher fat mass then the negative correlation between leptin and fat mass is due to sex.</p>
</div>
<div id="multiple-regression" class="section level2 hasAnchor" number="18.13">
<h2><span class="header-section-number">18.13</span> Multiple Regression<a href="regression-and-correlation.html#multiple-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The linear regression can be extended to include several number of factors. Consider the <strong>linear model</strong> with one additional factor</p>
<p><span class="math display">\[Y_{jr} = \alpha + \beta x_j +\gamma z_{r}+\varepsilon_{jr}\]</span></p>
<p>Here, our effect of interest is the coefficient <span class="math inline">\(\beta\)</span> of <span class="math inline">\(x_i\)</span> (leptin) and we want to adjust for the effect of <span class="math inline">\(z_j\)</span> (sex). The model is similar to the linear model we used for ANOVA, only that now the treatment effects are continuous and depend on the variable <span class="math inline">\(X\)</span>.</p>
<p>Running the model in Python or R we obtain</p>
<pre><code>Python:
import pandas as pd
from scipy.stats import pearsonr
from statsmodels.formula.api import ols

model = ols(&#39;leptin ~ fatmass + sex&#39;, data=dat).fit()

print(model.summary())

R:
summary(lm(leptin ~ fatmass + sex, data=dat))
</code></pre>
<p><small>
<span class="math display">\[
\begin{array}{lcccc}
&amp; \mathbf{Estimate} &amp; \mathbf{Std.\ Error} &amp; \mathbf{t\ value} &amp; \mathbf{Pr(&gt;|t|)} \\
\mathbf{(Intercept)} &amp; 1.716 &amp; 0.277 &amp; 6.187 &amp; 3.84 \times 10^{-9} \ ^{***} \\
\mathbf{fatmass}     &amp; 0.0279 &amp; 0.00604 &amp; 4.630 &amp; 6.88 \times 10^{-6} \ ^{***} \\
\mathbf{sexM}        &amp; -1.636 &amp; 0.136 &amp; -12.023 &amp; &lt;2 \times 10^{-16} \ ^{***} \\
\end{array}
\]</span>
</small></p>
<p>Therefore, we observe that there is a positive increase in leptin when we adjust for sex <span class="math inline">\(\hat{\beta}=4.63\)</span>, <span class="math inline">\(pvalue=6.88 \times 10^{-6}\)</span>. In addition males have a negative association with leptin, compared with women <span class="math inline">\(\gamma=-12.02\)</span>, <span class="math inline">\(pvalue&lt;2 \times 10^{-16}\)</span>. But within each sex the association is positive as expected.
The regression lines for each sex will be parallel but displaced by the average effect of changing from female (reference) to male.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-213-1.png" width="672" /></p>
<p><strong>Example(C02 concentration in atmosphere)</strong></p>
<p>Perhaps one of the most consequential observations of the second half of the 20 century was reported by Keeling in 1960 <span class="citation">(<a href="#ref-Keeling1960">Keeling 1960</a>)</span>. Using continuous recording within less than three years (1958-1960), and over different geographic regions and methods, he showed that the levels of CO2 were significantly increasing in the atmosphere. He started CO2 survey in Hawaii in Mauna Loa, which have continue for 66 years. The data from on this station from his 1960 paper is</p>
<p><small>
<span class="math display">\[
  \begin{array}{cccc}
  \mathbf{Observation} &amp; \mathbf{CO2 (ppm)} &amp; \mathbf{Month} &amp; \mathbf{Year} \\
1  &amp; 313.4 &amp;  3  &amp; 1958 \\
2  &amp; 314.4 &amp;  4  &amp; 1958 \\
3  &amp; 315.1 &amp;  5  &amp; 1958 \\
5  &amp; 312.9 &amp;  7  &amp; 1958 \\
6  &amp; 312.3 &amp;  8  &amp; 1958 \\
7  &amp; 311.6 &amp;  9  &amp; 1958 \\
9  &amp; 310.6 &amp; 11  &amp; 1958 \\
10 &amp; 311.6 &amp; 12  &amp; 1958 \\
11 &amp; 312.5 &amp;  1  &amp; 1959 \\
12 &amp; 313.5 &amp;  2  &amp; 1959 \\
13 &amp; 314.0 &amp;  3  &amp; 1959 \\
14 &amp; 314.7 &amp;  4  &amp; 1959 \\
15 &amp; 315.3 &amp;  5  &amp; 1959 \\
16 &amp; 315.2 &amp;  6  &amp; 1959 \\
17 &amp; 313.5 &amp;  7  &amp; 1959 \\
18 &amp; 311.9 &amp;  8  &amp; 1959 \\
19 &amp; 311.1 &amp;  9  &amp; 1959 \\
20 &amp; 310.5 &amp; 10  &amp; 1959 \\
21 &amp; 311.8 &amp; 11  &amp; 1959 \\
22 &amp; 312.5 &amp; 12  &amp; 1959 \\
23 &amp; 313.4 &amp;  1  &amp; 1960 \\
24 &amp; 313.7 &amp;  2  &amp; 1960 \\
25 &amp; 314.4 &amp;  3  &amp; 1960 \\
  \end{array}
\]</span>
</small>
The plot of the observations per month though out years (now known as Kelling plot is)</p>
<p><img src="_main_files/figure-html/unnamed-chunk-214-1.png" width="672" /></p>
<p>Can we say from this data that C02 concentrations are getting increasing in Mauna Loa thoughout the years?</p>
<p>Finding a year trend from the inspection of the data is difficult because the variations per month are large, in comparison with the year variation. Maximum CO2 coincides with summer in the northern hemisphere when vegetation is the greenest, and vegetation respiration maximum. Therefore, the monthly variation is a confounding factor for the regressing CO2 concentration on years. The model we are interested in fitting is</p>
<p><span class="math display">\[Y_{year, month} = \alpha + \beta x_{year} + z_{month}+\varepsilon_{year, month}\]</span>
where <span class="math inline">\(Y\)</span> is the CO2 concentrations (outcome), <span class="math inline">\(\beta\)</span> is the effect of years (explanatory variable), and <span class="math inline">\(z_{month}\)</span> is the effect of the month (covariate). The covariate month is better encoded as categorical as we expect each month to have its own specific effect (with respect to January). Encoded as numeric the model will fit pair-wise comarisons between January and each month, as 11 covariates for the effect of year.</p>
<p>The code in if Python and R</p>
<pre><code>Pyhton:
import pandas as pd
import statsmodels.api as sm
import statsmodels.formula.api as smf

df = pd.DataFrame({
    &#39;y&#39;: [313.4, 314.4, 315.1, 312.9, 312.3, 311.6, 310.6, 311.6,
          312.5, 313.5, 314.0, 314.7, 315.3, 315.2, 313.5, 311.9, 
          311.1, 310.5, 311.8, 312.5, 313.4, 313.7, 314.4],
    &#39;month&#39;: [3,4,5,7,8,9,11,12,1,2,3,4,5,6,7,8,9,10,11,12,1,2,3],
    &#39;year&#39;: [1958,1958,1958,1958,1958,1958,1958,1958,
             1959,1959,1959,1959,1959,1959,1959,1959,
             1959,1959,1959,1959,1960,1960,1960]
})
model = smf.ols(&#39;y ~ year + C(month)&#39;, data=df).fit()
print(model.summary())


R:
df &lt;- data.frame(
  y = c(313.4, 314.4, 315.1, 312.9, 312.3, 311.6, 310.6, 311.6,
        312.5, 313.5, 314.0, 314.7, 315.3, 315.2, 313.5, 311.9, 
        311.1, 310.5, 311.8, 312.5, 313.4, 313.7, 314.4),
  month = c(3,4,5,7,8,9,11,12,1,2,3,4,5,6,7,8,9,10,11,12,1,2,3),
  year = c(1958,1958,1958,1958,1958,1958,1958,1958,
           1959,1959,1959,1959,1959,1959,1959,1959,
           1959,1959,1959,1959,1960,1960,1960)
)

summary(lm(y~year+factor(month), data=df))
</code></pre>
<p>with results</p>
<p><small>
<span class="math display">\[
\begin{array}{lcccc}
&amp; \mathbf{Estimate} &amp; \mathbf{Std.\ Error} &amp; \mathbf{t\ value} &amp; \mathbf{Pr(&gt;|t|)} \\
\mathbf{(Intercept)}    &amp; -500.9962 &amp; 286.0446 &amp; -1.751 &amp; 0.110420 \\
\mathbf{year}           &amp; 0.4154 &amp; 0.1460 &amp; 2.846 &amp; 0.017383 \ ^{*} \\
\mathbf{factor(month)2} &amp; 0.6500 &amp; 0.3722 &amp; 1.746 &amp; 0.111309 \\
\mathbf{factor(month)3} &amp; 1.1910 &amp; 0.3475 &amp; 3.427 &amp; 0.006466 \ ^{**} \\
\mathbf{factor(month)4} &amp; 2.0154 &amp; 0.3998 &amp; 5.041 &amp; 0.000506 \ ^{***} \\
\mathbf{factor(month)5} &amp; 2.6654 &amp; 0.3998 &amp; 6.667 &amp; 5.59 \times 10^{-5} \ ^{***} \\
\mathbf{factor(month)6} &amp; 2.4577 &amp; 0.4616 &amp; 5.324 &amp; 0.000336 \ ^{***} \\
\mathbf{factor(month)7} &amp; 0.6654 &amp; 0.3998 &amp; 1.664 &amp; 0.127009 \\
\mathbf{factor(month)8} &amp; -0.4346 &amp; 0.3998 &amp; -1.087 &amp; 0.302483 \\
\mathbf{factor(month)9} &amp; -1.1846 &amp; 0.3998 &amp; -2.963 &amp; 0.014211 \ ^{*} \\
\mathbf{factor(month)10}&amp; -2.2423 &amp; 0.4616 &amp; -4.857 &amp; 0.000664 \ ^{***} \\
\mathbf{factor(month)11}&amp; -1.3346 &amp; 0.3998 &amp; -3.338 &amp; 0.007511 \ ^{**} \\
\mathbf{factor(month)12}&amp; -0.4846 &amp; 0.3998 &amp; -1.212 &amp; 0.253294 \\
\end{array}
\]</span>
</small></p>
<p>We see an significant increase in <span class="math inline">\(\hat{\beta}=0.4154\)</span> ppm per year <span class="math inline">\(pvalue=0.01\)</span>, adjusting for month variation. While this was preliminary data on global CO2 emissions, a year plot of the residuals from fitting the CO2 concentrations on moths clearly shows the trend. Additionally, continuous monitoring at Mauna Loa for over 66 year reveals how the underlying yearly trend has largely superseded the monthly variations.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-215-1.png" width="672" /></p>
</div>
<div id="multiple-regression-interaction" class="section level2 hasAnchor" number="18.14">
<h2><span class="header-section-number">18.14</span> Multiple Regression interaction<a href="regression-and-correlation.html#multiple-regression-interaction" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Sometimes the explanatory variable has an effect that is modulated by a covariate. That is, the strngth of the effect depends on another condition.</p>
<p><strong>Example (Fat mass, letptin and sex)</strong></p>
<p>For the association between fat mass and leptin we can fit the regression model <strong>separating</strong>, or stratifying, by sex. We find that the strength of the association between leptin and fat mass depends on sex. That is, the slope of the regression line changes between sexes.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-216-1.png" width="672" /></p>
<p>We can furthermore include interactions between conditions in the regression.</p>
<p>Consider the <strong>linear model</strong></p>
<p><span class="math display">\[Y_{jr} = \alpha + \beta x_{j} +\gamma z_{r} + \delta (xz)_{jr} +\varepsilon_{jr}\]</span>
The parameter <span class="math inline">\(\delta\)</span> will add a contribution to the slope <span class="math inline">\(\beta\)</span> that is <strong>specific</strong> to the condition <span class="math inline">\(r\)</span>. For instance, if <span class="math inline">\(z_i \in (0,1)\)</span> then when <span class="math inline">\(z=0\)</span> the coefficient of <span class="math inline">\(x_i\)</span> is <span class="math inline">\(\beta\)</span>. But when <span class="math inline">\(z=1\)</span> the coefficient of <span class="math inline">\(x_i\)</span> is <span class="math inline">\(\beta+\gamma\)</span>.</p>
<p><strong>Example (Fat mass and leptin)</strong></p>
<p>In the fat mass and leptin relationship, if <span class="math inline">\(z\)</span> is sex, then <span class="math inline">\(\gamma\)</span> will test the differences in <span class="math inline">\(\beta\)</span>s between males and females. We can further adjust by age.</p>
<p><span class="math display">\[Y_{jrs} = \alpha + \beta\times fatmass_{j} +\gamma\times sex_{r} + \delta\times (fatmass\times sex)_{jr} + \epsilon_s age+\varepsilon_{jrs}\]</span>
We can re-fit the model with the interaction term</p>
<pre><code>Python:
import pandas as pd
from scipy.stats import pearsonr

model = ols(&#39;leptin ~ fatmass*sex + age&#39;, data=dat).fit()

print(model.summary())

R:

summary(lm(leptin ~ fatmass*sex + age, data=dat))</code></pre>
<p>with th efollowing results</p>
<p><small>
<span class="math display">\[
\begin{array}{lcccc}
&amp; \mathbf{Estimate} &amp; \mathbf{Std.\ Error} &amp; \mathbf{t\ value} &amp; \mathbf{Pr(&gt;|t|)} \\
\mathbf{(Intercept)} &amp; 1.800 &amp; 0.337 &amp; 5.337 &amp; 2.77 \times 10^{-7} \ ^{***} \\
\mathbf{fatmass}     &amp; 0.0200 &amp; 0.00695 &amp; 2.881 &amp; 0.00443 \ ^{**} \\
\mathbf{sexM}        &amp; -3.218 &amp; 0.775 &amp; -4.151 &amp; 5.07 \times 10^{-5} \ ^{***} \\
\mathbf{age}         &amp; 0.00585 &amp; 0.00294 &amp; 1.989 &amp; 0.0482 \ ^{*} \\
\mathbf{fatmass{:}sexM} &amp; 0.0284 &amp; 0.0135 &amp; 2.104 &amp; 0.0368 \ ^{*} \\
\end{array}
\]</span>
</small></p>
<p>The data suggest a steeper increase of leptin with body fat in males than in females (interaction: <span class="math inline">\(0.028427\)</span>, <span class="math inline">\(pvalue=0.03\)</span>), as we saw in the figures of the stratified analysis. A positive and significant interaction means that the slope for males is higher than the slope for females. The effect of fatmass on letpin levels is stronger in males.</p>
<p>We also observe a signification effect of age on leptin levels. As the coefficient is a slope, we can say that for a year increase in the age of the patient, we see a significant increase in <span class="math inline">\(0.005\)</span> units of leptin levels (<span class="math inline">\(pvalue=0.048\)</span>). Therefore age is also a contributing factor of leptin levels. The model now explains <span class="math inline">\(50\%\)</span> of the variance as <span class="math inline">\(R^2=0.5\)</span>.</p>
</div>
<div id="model-diagnostics" class="section level2 hasAnchor" number="18.15">
<h2><span class="header-section-number">18.15</span> Model diagnostics<a href="regression-and-correlation.html#model-diagnostics" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>All linear models have been made on the supposition that</p>
<ol style="list-style-type: decimal">
<li><p>Errors are distributed normally</p></li>
<li><p>Errors have the same variance</p></li>
</ol>
<p>There are a number of plots to check that at least the data is consistent with these suppositions. In particular, we are interested to see that the residuals distribute symmetrically against the fitted values, revealing equal variance (homoscedasticity). We also want to check that the points in a quantile-quantile (QQ) plot fall in the line, revealing how close the residuals distribute normally.</p>
<pre><code>R:
mod &lt;- lm(leptin ~ fatmass * sex + age, data = dat)

plot(mod, which = 1, main = &quot;Residuals vs Fitted&quot;)
plot(mod, which = 2, main = &quot;Normal Q-Q&quot;)
</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-218-1.png" width="672" /></p>
<p>The residuals versus fitted values plot shows that the residuals are fairly randomly scattered around zero, with no strong pattern, suggesting that the linear model fits the data reasonably well and that the assumption of linearity is broadly satisfied. While there may be a slight concentration of residuals at certain fitted values, it is not pronounced. The Normal Q-Q plot indicates that the residuals are approximately normally distributed, as most points follow the reference line given by the nornal quantiles, with only minor deviations at the extremes, which are typical in real datasets. Overall, the model age appears to provide a reasonable fit, with assumptions of linearity and normality largely met.</p>
</div>
<div id="questions-14" class="section level2 hasAnchor" number="18.16">
<h2><span class="header-section-number">18.16</span> Questions<a href="regression-and-correlation.html#questions-14" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>1)</strong> We perform a regression analysis when we have</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> one categorical variable;
<strong><span class="math inline">\(\qquad\)</span>b:</strong> two categorical variables;
<strong><span class="math inline">\(\qquad\)</span>c:</strong> one continuous random variable;
<strong><span class="math inline">\(\qquad\)</span>d:</strong> two continuous random variables;</p>
<p><strong>2)</strong> The correlation coefficient <span class="math inline">\(\rho\)</span> is</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> a parameter of a 2D probability density;
<strong><span class="math inline">\(\qquad\)</span>b:</strong> a statistic of the relationship between two continuous variables;
<strong><span class="math inline">\(\qquad\)</span>c:</strong> the linear coefficient btween of two variables;
<strong><span class="math inline">\(\qquad\)</span>d:</strong> the variance explained by one continuous variable on other;</p>
<p><strong>3)</strong> <span class="math inline">\(\beta\)</span> in the linear model</p>
<p><span class="math display">\[Y_{x_i} = \alpha + \beta x_i +E_{i}\]</span></p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> is a statistic that measure the linear relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>;
<strong><span class="math inline">\(\qquad\)</span>b:</strong> is zero for the null hypothesis;
<strong><span class="math inline">\(\qquad\)</span>c:</strong> is a parameter with expected value of zero;
<strong><span class="math inline">\(\qquad\)</span>d:</strong> is the correlation between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span></p>
<p><strong>4)</strong> Why do we adjust for a variable in a regression coefficient?</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> to test the interaction between the variable and <span class="math inline">\(x\)</span>;
<strong><span class="math inline">\(\qquad\)</span>b:</strong> to stratify the relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>;
<strong><span class="math inline">\(\qquad\)</span>c:</strong> to remove confounding in the relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>;
<strong><span class="math inline">\(\qquad\)</span>d:</strong> to improve the significance of the relationship between <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>;</p>
<p><strong>5)</strong> The regression analysis assumes that</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> the errors have mean 0 and equal variances;
<strong><span class="math inline">\(\qquad\)</span>b:</strong> the errors distribute normally with mean 0 and equal variances;
<strong><span class="math inline">\(\qquad\)</span>c:</strong> the errors distribute normally with different mean and equal variances;
<strong><span class="math inline">\(\qquad\)</span>d:</strong> the errors distribute normally with different mean and different variances;</p>
</div>
<div id="practice-8" class="section level2 hasAnchor" number="18.17">
<h2><span class="header-section-number">18.17</span> Practice<a href="regression-and-correlation.html#practice-8" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="practice-9" class="section level4 hasAnchor" number="18.17.0.1">
<h4><span class="header-section-number">18.17.0.1</span> Practice<a href="regression-and-correlation.html#practice-9" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Load misophonia data <code><a href="https://alejandro-isglobal.github.io/SDA/data/data_0.txt" class="uri">https://alejandro-isglobal.github.io/SDA/data/data_0.txt</a></code></p>
<p>We have four measures of anxiety:</p>
<ul>
<li>Trait: ansiedad.rasgo (are you an anxious person?) continuous:0-100</li>
<li>State: ansiedad.estado (are you currently feeling anxious?) continuous:0-100</li>
<li>Diagnosed: ansiedad.medicada (have you been diagnosed with an anxiety disorder?) binary (si, no)</li>
<li>Excess: ansiedad.dif (difference between State and Trait)</li>
</ul>
<p>We formulate the following hypothesis:</p>
<p>Participants who enrolled in the study had an increased level of anxiety from their baseline (trait) that is related to their:</p>
<ul>
<li>age</li>
<li>sex</li>
<li>anxiety state.</li>
</ul>
<p>We are interested in the variable anxiety.dif, that is the observed <strong>excess</strong> of anxiety from the trait</p>
<p><span class="math inline">\(excess = state - trait\)</span></p>
<p>Answer the following questions:</p>
<ol style="list-style-type: decimal">
<li><p>Are the state and trait of anxiety correlated?</p></li>
<li><p>Is excess in anxiety higher in older people?</p></li>
<li><p>Is excess in anxiety higher in older people after adjusting by sex?</p></li>
<li><p>Is the interaction between age and sex significant on excess anxiety?</p></li>
</ol>
<p><a href="https://colab.research.google.com/drive/14i2h9AYxHh4KIfxBB9Px7VwnYdSFVBq5?usp=sharing">Solutions</a></p>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Hubble1929_distance_velocity" class="csl-entry">
Hubble, Edwin. 1929. <span>âA Relation Between Distance and Radial Velocity Among Extra-Galactic Nebulae.â</span> <em>Proceedings of the National Academy of Sciences of the United States of America</em> 15 (3): 168â73. <a href="https://doi.org/10.1073/pnas.15.3.168">https://doi.org/10.1073/pnas.15.3.168</a>.
</div>
<div id="ref-Keeling1960" class="csl-entry">
Keeling, Charles D. 1960. <span>âThe Concentration and Isotopic Abundances of Carbon Dioxide in the Atmosphere.â</span> <em>Tellus A: Dynamic Meteorology and Oceanography</em> 12 (2): 200â203. <a href="https://doi.org/10.3402/tellusa.v12i2.9366">https://doi.org/10.3402/tellusa.v12i2.9366</a>.
</div>
<div id="ref-Zhang2013_adiponectinQTLs" class="csl-entry">
Zhang, Yi, Jack W. Kent Jr., Michael Olivier, Omar Ali, Diana Cerjak, Ulrich Broeckel, Reham M. Abdou, et al. 2013. <span>â<span class="nocase">A comprehensive analysis of adiponectin QTLs using SNP association, SNP cis-effects on peripheral blood gene expression and gene expression correlation identified novel metabolic syndrome (MetS) genes with potential role in carcinogenesis and systemic inflammation</span>.â</span> <em>BMC Medical Genomics</em> 6: 14. <a href="https://doi.org/10.1186/1755-8794-6-14">https://doi.org/10.1186/1755-8794-6-14</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="mean-differences-across-several-groups.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="apendix.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/18-Regression.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
