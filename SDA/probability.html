<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Probability | Statistical Data Analysis for Experimental Sciences</title>
  <meta name="description" content="This is a markdown book titled Statistical Data Analysis for Experimental Sciences by Alejandro Caceres" />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Probability | Statistical Data Analysis for Experimental Sciences" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a markdown book titled Statistical Data Analysis for Experimental Sciences by Alejandro Caceres" />
  <meta name="github-repo" content="alejandro-isglobal/master" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Probability | Statistical Data Analysis for Experimental Sciences" />
  
  <meta name="twitter:description" content="This is a markdown book titled Statistical Data Analysis for Experimental Sciences by Alejandro Caceres" />
  

<meta name="author" content="Alejandro CÃ¡ceres" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="data-description.html"/>
<link rel="next" href="conditional-probability.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">SDA</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#how-to-read-the-book"><i class="fa fa-check"></i><b>1.1</b> How to read the book</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>1.2</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-description.html"><a href="data-description.html"><i class="fa fa-check"></i><b>2</b> Data description</a>
<ul>
<li class="chapter" data-level="2.1" data-path="data-description.html"><a href="data-description.html#scientific-method"><i class="fa fa-check"></i><b>2.1</b> Scientific method</a></li>
<li class="chapter" data-level="2.2" data-path="data-description.html"><a href="data-description.html#data"><i class="fa fa-check"></i><b>2.2</b> Data</a></li>
<li class="chapter" data-level="2.3" data-path="data-description.html"><a href="data-description.html#types-of-outcomes"><i class="fa fa-check"></i><b>2.3</b> Types of outcomes</a></li>
<li class="chapter" data-level="2.4" data-path="data-description.html"><a href="data-description.html#random-experiments"><i class="fa fa-check"></i><b>2.4</b> Random experiments</a></li>
<li class="chapter" data-level="2.5" data-path="data-description.html"><a href="data-description.html#absolute-frequencies"><i class="fa fa-check"></i><b>2.5</b> Absolute frequencies</a></li>
<li class="chapter" data-level="2.6" data-path="data-description.html"><a href="data-description.html#relative-frequencies"><i class="fa fa-check"></i><b>2.6</b> Relative frequencies</a></li>
<li class="chapter" data-level="2.7" data-path="data-description.html"><a href="data-description.html#bar-chart"><i class="fa fa-check"></i><b>2.7</b> Bar chart</a></li>
<li class="chapter" data-level="2.8" data-path="data-description.html"><a href="data-description.html#pie-chart"><i class="fa fa-check"></i><b>2.8</b> Pie chart</a></li>
<li class="chapter" data-level="2.9" data-path="data-description.html"><a href="data-description.html#ordinal-categorical-outcomes"><i class="fa fa-check"></i><b>2.9</b> Ordinal categorical outcomes</a></li>
<li class="chapter" data-level="2.10" data-path="data-description.html"><a href="data-description.html#absolute-and-relative-cumulative-frequencies"><i class="fa fa-check"></i><b>2.10</b> Absolute and relative cumulative frequencies</a></li>
<li class="chapter" data-level="2.11" data-path="data-description.html"><a href="data-description.html#cumulative-frequency-graph"><i class="fa fa-check"></i><b>2.11</b> Cumulative frequency graph</a></li>
<li class="chapter" data-level="2.12" data-path="data-description.html"><a href="data-description.html#numerical-outcomes"><i class="fa fa-check"></i><b>2.12</b> Numerical outcomes</a></li>
<li class="chapter" data-level="2.13" data-path="data-description.html"><a href="data-description.html#transforming-continuous-data"><i class="fa fa-check"></i><b>2.13</b> Transforming continuous data</a></li>
<li class="chapter" data-level="2.14" data-path="data-description.html"><a href="data-description.html#frequency-table-for-a-continuous-variable"><i class="fa fa-check"></i><b>2.14</b> Frequency table for a continuous variable</a></li>
<li class="chapter" data-level="2.15" data-path="data-description.html"><a href="data-description.html#histogram"><i class="fa fa-check"></i><b>2.15</b> Histogram</a></li>
<li class="chapter" data-level="2.16" data-path="data-description.html"><a href="data-description.html#cumulative-frequency-graph-1"><i class="fa fa-check"></i><b>2.16</b> Cumulative frequency graph</a></li>
<li class="chapter" data-level="2.17" data-path="data-description.html"><a href="data-description.html#summary-statistics"><i class="fa fa-check"></i><b>2.17</b> Summary Statistics</a></li>
<li class="chapter" data-level="2.18" data-path="data-description.html"><a href="data-description.html#average-sample-mean"><i class="fa fa-check"></i><b>2.18</b> Average (sample mean)</a></li>
<li class="chapter" data-level="2.19" data-path="data-description.html"><a href="data-description.html#median"><i class="fa fa-check"></i><b>2.19</b> Median</a></li>
<li class="chapter" data-level="2.20" data-path="data-description.html"><a href="data-description.html#dispersion"><i class="fa fa-check"></i><b>2.20</b> Dispersion</a></li>
<li class="chapter" data-level="2.21" data-path="data-description.html"><a href="data-description.html#sample-variance"><i class="fa fa-check"></i><b>2.21</b> Sample variance</a></li>
<li class="chapter" data-level="2.22" data-path="data-description.html"><a href="data-description.html#interquartile-range-iqr"><i class="fa fa-check"></i><b>2.22</b> Interquartile range (IQR)</a></li>
<li class="chapter" data-level="2.23" data-path="data-description.html"><a href="data-description.html#boxplot"><i class="fa fa-check"></i><b>2.23</b> Boxplot</a></li>
<li class="chapter" data-level="2.24" data-path="data-description.html"><a href="data-description.html#questions"><i class="fa fa-check"></i><b>2.24</b> Questions</a></li>
<li class="chapter" data-level="2.25" data-path="data-description.html"><a href="data-description.html#exercises"><i class="fa fa-check"></i><b>2.25</b> Exercises</a></li>
<li class="chapter" data-level="2.26" data-path="data-description.html"><a href="data-description.html#practice"><i class="fa fa-check"></i><b>2.26</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>3</b> Probability</a>
<ul>
<li class="chapter" data-level="3.1" data-path="probability.html"><a href="probability.html#probability-mesurement"><i class="fa fa-check"></i><b>3.1</b> Probability mesurement</a></li>
<li class="chapter" data-level="3.2" data-path="probability.html"><a href="probability.html#classical-probability"><i class="fa fa-check"></i><b>3.2</b> Classical probability</a></li>
<li class="chapter" data-level="3.3" data-path="probability.html"><a href="probability.html#relative-frequencies-1"><i class="fa fa-check"></i><b>3.3</b> Relative frequencies</a></li>
<li class="chapter" data-level="3.4" data-path="probability.html"><a href="probability.html#frequentist-probability"><i class="fa fa-check"></i><b>3.4</b> Frequentist probability</a></li>
<li class="chapter" data-level="3.5" data-path="probability.html"><a href="probability.html#classical-and-frequentist-probabilities"><i class="fa fa-check"></i><b>3.5</b> Classical and frequentist probabilities</a></li>
<li class="chapter" data-level="3.6" data-path="probability.html"><a href="probability.html#sample-space"><i class="fa fa-check"></i><b>3.6</b> Sample space</a></li>
<li class="chapter" data-level="3.7" data-path="probability.html"><a href="probability.html#events"><i class="fa fa-check"></i><b>3.7</b> Events</a></li>
<li class="chapter" data-level="3.8" data-path="probability.html"><a href="probability.html#algebra-of-events"><i class="fa fa-check"></i><b>3.8</b> Algebra of events</a></li>
<li class="chapter" data-level="3.9" data-path="probability.html"><a href="probability.html#mutually-exclusive-events"><i class="fa fa-check"></i><b>3.9</b> Mutually exclusive events</a></li>
<li class="chapter" data-level="3.10" data-path="probability.html"><a href="probability.html#definition-of-probability"><i class="fa fa-check"></i><b>3.10</b> Definition of probability</a></li>
<li class="chapter" data-level="3.11" data-path="probability.html"><a href="probability.html#probability-table"><i class="fa fa-check"></i><b>3.11</b> Probability table</a></li>
<li class="chapter" data-level="3.12" data-path="probability.html"><a href="probability.html#joint-probabilities"><i class="fa fa-check"></i><b>3.12</b> Joint probabilities</a></li>
<li class="chapter" data-level="3.13" data-path="probability.html"><a href="probability.html#contingency-table"><i class="fa fa-check"></i><b>3.13</b> Contingency table</a></li>
<li class="chapter" data-level="3.14" data-path="probability.html"><a href="probability.html#the-addition-rule"><i class="fa fa-check"></i><b>3.14</b> The addition rule</a></li>
<li class="chapter" data-level="3.15" data-path="probability.html"><a href="probability.html#questions-1"><i class="fa fa-check"></i><b>3.15</b> Questions</a></li>
<li class="chapter" data-level="3.16" data-path="probability.html"><a href="probability.html#exercises-1"><i class="fa fa-check"></i><b>3.16</b> Exercises</a></li>
<li class="chapter" data-level="3.17" data-path="probability.html"><a href="probability.html#practice-1"><i class="fa fa-check"></i><b>3.17</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="conditional-probability.html"><a href="conditional-probability.html"><i class="fa fa-check"></i><b>4</b> Conditional probability</a>
<ul>
<li class="chapter" data-level="4.1" data-path="conditional-probability.html"><a href="conditional-probability.html#joint-probability"><i class="fa fa-check"></i><b>4.1</b> Joint probability</a></li>
<li class="chapter" data-level="4.2" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-independence-and-correlation"><i class="fa fa-check"></i><b>4.2</b> Statistical independence and correlation</a></li>
<li class="chapter" data-level="4.3" data-path="conditional-probability.html"><a href="conditional-probability.html#conditional-probability-1"><i class="fa fa-check"></i><b>4.3</b> Conditional probability</a></li>
<li class="chapter" data-level="4.4" data-path="conditional-probability.html"><a href="conditional-probability.html#conditional-contingency-table"><i class="fa fa-check"></i><b>4.4</b> Conditional contingency table</a></li>
<li class="chapter" data-level="4.5" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-independence"><i class="fa fa-check"></i><b>4.5</b> Statistical independence</a></li>
<li class="chapter" data-level="4.6" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-dependency"><i class="fa fa-check"></i><b>4.6</b> Statistical dependency</a></li>
<li class="chapter" data-level="4.7" data-path="conditional-probability.html"><a href="conditional-probability.html#diagnostic-test"><i class="fa fa-check"></i><b>4.7</b> Diagnostic test</a></li>
<li class="chapter" data-level="4.8" data-path="conditional-probability.html"><a href="conditional-probability.html#inverse-probabilities"><i class="fa fa-check"></i><b>4.8</b> Inverse probabilities</a></li>
<li class="chapter" data-level="4.9" data-path="conditional-probability.html"><a href="conditional-probability.html#bayes-theorem"><i class="fa fa-check"></i><b>4.9</b> Bayesâ Theorem</a></li>
<li class="chapter" data-level="4.10" data-path="conditional-probability.html"><a href="conditional-probability.html#questions-2"><i class="fa fa-check"></i><b>4.10</b> Questions</a></li>
<li class="chapter" data-level="4.11" data-path="conditional-probability.html"><a href="conditional-probability.html#exercises-2"><i class="fa fa-check"></i><b>4.11</b> Exercises</a></li>
<li class="chapter" data-level="4.12" data-path="conditional-probability.html"><a href="conditional-probability.html#practice-2"><i class="fa fa-check"></i><b>4.12</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html"><i class="fa fa-check"></i><b>5</b> Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="5.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#definition-of-a-random-variable"><i class="fa fa-check"></i><b>5.1</b> Definition of a Random Variable</a></li>
<li class="chapter" data-level="5.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#the-value-of-a-random-variable"><i class="fa fa-check"></i><b>5.2</b> The value of a random variable</a></li>
<li class="chapter" data-level="5.3" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-of-random-variables"><i class="fa fa-check"></i><b>5.3</b> Probability of random variables</a></li>
<li class="chapter" data-level="5.4" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-functions"><i class="fa fa-check"></i><b>5.4</b> Probability functions</a></li>
<li class="chapter" data-level="5.5" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-mass-functions"><i class="fa fa-check"></i><b>5.5</b> Probability mass functions</a></li>
<li class="chapter" data-level="5.6" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#mean-or-expected-value"><i class="fa fa-check"></i><b>5.6</b> Mean or expected value</a></li>
<li class="chapter" data-level="5.7" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#variance"><i class="fa fa-check"></i><b>5.7</b> Variance</a></li>
<li class="chapter" data-level="5.8" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-functions-for-functions-of-x"><i class="fa fa-check"></i><b>5.8</b> Probability functions for functions of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="5.9" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-distribution"><i class="fa fa-check"></i><b>5.9</b> Probability distribution</a></li>
<li class="chapter" data-level="5.10" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-function-and-probability-distribution"><i class="fa fa-check"></i><b>5.10</b> Probability function and probability distribution</a></li>
<li class="chapter" data-level="5.11" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#quantiles"><i class="fa fa-check"></i><b>5.11</b> Quantiles</a></li>
<li class="chapter" data-level="5.12" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#summary"><i class="fa fa-check"></i><b>5.12</b> Summary</a></li>
<li class="chapter" data-level="5.13" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#questions-3"><i class="fa fa-check"></i><b>5.13</b> Questions</a></li>
<li class="chapter" data-level="5.14" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#exercises-3"><i class="fa fa-check"></i><b>5.14</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="continous-random-variables.html"><a href="continous-random-variables.html"><i class="fa fa-check"></i><b>6</b> Continous Random Variables</a>
<ul>
<li class="chapter" data-level="6.1" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probabilities-of-continuous-random-variables"><i class="fa fa-check"></i><b>6.1</b> Probabilities of continuous random variables</a></li>
<li class="chapter" data-level="6.2" data-path="continous-random-variables.html"><a href="continous-random-variables.html#relative-frequencies-2"><i class="fa fa-check"></i><b>6.2</b> Relative frequencies</a></li>
<li class="chapter" data-level="6.3" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-density-function"><i class="fa fa-check"></i><b>6.3</b> Probability Density Function</a></li>
<li class="chapter" data-level="6.4" data-path="continous-random-variables.html"><a href="continous-random-variables.html#total-area-under-the-curve"><i class="fa fa-check"></i><b>6.4</b> Total area under the curve</a></li>
<li class="chapter" data-level="6.5" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probabilities-of-continous-variables"><i class="fa fa-check"></i><b>6.5</b> Probabilities of continous variables</a></li>
<li class="chapter" data-level="6.6" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-distribution-1"><i class="fa fa-check"></i><b>6.6</b> Probability distribution</a></li>
<li class="chapter" data-level="6.7" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-plots"><i class="fa fa-check"></i><b>6.7</b> Probability plots</a></li>
<li class="chapter" data-level="6.8" data-path="continous-random-variables.html"><a href="continous-random-variables.html#mean"><i class="fa fa-check"></i><b>6.8</b> Mean</a></li>
<li class="chapter" data-level="6.9" data-path="continous-random-variables.html"><a href="continous-random-variables.html#variance-1"><i class="fa fa-check"></i><b>6.9</b> Variance</a></li>
<li class="chapter" data-level="6.10" data-path="continous-random-variables.html"><a href="continous-random-variables.html#functions-of-x"><i class="fa fa-check"></i><b>6.10</b> Functions of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="6.11" data-path="continous-random-variables.html"><a href="continous-random-variables.html#exercises-4"><i class="fa fa-check"></i><b>6.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html"><i class="fa fa-check"></i><b>7</b> Discrete Probability Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#probability-model"><i class="fa fa-check"></i><b>7.1</b> Probability model</a></li>
<li class="chapter" data-level="7.2" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#parametric-models"><i class="fa fa-check"></i><b>7.2</b> Parametric models</a></li>
<li class="chapter" data-level="7.3" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#uniform-probability-mass-function-one-parameter"><i class="fa fa-check"></i><b>7.3</b> Uniform probability mass function (one parameter)</a></li>
<li class="chapter" data-level="7.4" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#uniform-probability-mass-function-two-parameters"><i class="fa fa-check"></i><b>7.4</b> Uniform probability mass function (two parameters)</a></li>
<li class="chapter" data-level="7.5" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#bernoulli-trial"><i class="fa fa-check"></i><b>7.5</b> Bernoulli trial</a></li>
<li class="chapter" data-level="7.6" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#binomial-experiment"><i class="fa fa-check"></i><b>7.6</b> Binomial experiment</a></li>
<li class="chapter" data-level="7.7" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#binomial-probability-function"><i class="fa fa-check"></i><b>7.7</b> Binomial probability function</a></li>
<li class="chapter" data-level="7.8" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#negative-binomial"><i class="fa fa-check"></i><b>7.8</b> Negative binomial</a></li>
<li class="chapter" data-level="7.9" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#geometric-distribution"><i class="fa fa-check"></i><b>7.9</b> Geometric distribution</a></li>
<li class="chapter" data-level="7.10" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#hypergeometric-model"><i class="fa fa-check"></i><b>7.10</b> Hypergeometric model</a></li>
<li class="chapter" data-level="7.11" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#questions-4"><i class="fa fa-check"></i><b>7.11</b> Questions</a></li>
<li class="chapter" data-level="7.12" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#exercises-5"><i class="fa fa-check"></i><b>7.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html"><i class="fa fa-check"></i><b>8</b> Poisson and Exponential Models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#discrete-probability-models-1"><i class="fa fa-check"></i><b>8.1</b> Discrete probability models</a></li>
<li class="chapter" data-level="8.2" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#poissson-experiment"><i class="fa fa-check"></i><b>8.2</b> Poissson experiment</a></li>
<li class="chapter" data-level="8.3" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#poisson-probability-mass-function"><i class="fa fa-check"></i><b>8.3</b> Poisson probability mass function</a></li>
<li class="chapter" data-level="8.4" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#continuous-probability-models"><i class="fa fa-check"></i><b>8.4</b> Continuous probability models</a></li>
<li class="chapter" data-level="8.5" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-process"><i class="fa fa-check"></i><b>8.5</b> Exponential process</a></li>
<li class="chapter" data-level="8.6" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-probability-density"><i class="fa fa-check"></i><b>8.6</b> Exponential probability density</a></li>
<li class="chapter" data-level="8.7" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-distribution"><i class="fa fa-check"></i><b>8.7</b> Exponential Distribution</a></li>
<li class="chapter" data-level="8.8" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#questions-5"><i class="fa fa-check"></i><b>8.8</b> Questions</a></li>
<li class="chapter" data-level="8.9" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exercises-6"><i class="fa fa-check"></i><b>8.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="normal-distribution.html"><a href="normal-distribution.html"><i class="fa fa-check"></i><b>9</b> Normal Distribution</a>
<ul>
<li class="chapter" data-level="9.1" data-path="normal-distribution.html"><a href="normal-distribution.html#history"><i class="fa fa-check"></i><b>9.1</b> History</a></li>
<li class="chapter" data-level="9.2" data-path="normal-distribution.html"><a href="normal-distribution.html#normal-density"><i class="fa fa-check"></i><b>9.2</b> normal density</a></li>
<li class="chapter" data-level="9.3" data-path="normal-distribution.html"><a href="normal-distribution.html#definition"><i class="fa fa-check"></i><b>9.3</b> Definition</a></li>
<li class="chapter" data-level="9.4" data-path="normal-distribution.html"><a href="normal-distribution.html#probability-distribution-2"><i class="fa fa-check"></i><b>9.4</b> Probability distribution</a></li>
<li class="chapter" data-level="9.5" data-path="normal-distribution.html"><a href="normal-distribution.html#standard-normal-density"><i class="fa fa-check"></i><b>9.5</b> Standard normal density</a></li>
<li class="chapter" data-level="9.6" data-path="normal-distribution.html"><a href="normal-distribution.html#standard-distribution"><i class="fa fa-check"></i><b>9.6</b> Standard distribution</a></li>
<li class="chapter" data-level="9.7" data-path="normal-distribution.html"><a href="normal-distribution.html#standardization"><i class="fa fa-check"></i><b>9.7</b> Standardization</a></li>
<li class="chapter" data-level="9.8" data-path="normal-distribution.html"><a href="normal-distribution.html#questions-6"><i class="fa fa-check"></i><b>9.8</b> Questions</a></li>
<li class="chapter" data-level="9.9" data-path="normal-distribution.html"><a href="normal-distribution.html#exercises-7"><i class="fa fa-check"></i><b>9.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="sampling-distributions.html"><a href="sampling-distributions.html"><i class="fa fa-check"></i><b>10</b> Sampling distributions</a>
<ul>
<li class="chapter" data-level="10.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#random-sample"><i class="fa fa-check"></i><b>10.1</b> Random sample</a></li>
<li class="chapter" data-level="10.2" data-path="sampling-distributions.html"><a href="sampling-distributions.html#parameter-estimation"><i class="fa fa-check"></i><b>10.2</b> Parameter estimation</a></li>
<li class="chapter" data-level="10.3" data-path="sampling-distributions.html"><a href="sampling-distributions.html#law-of-large-numbers"><i class="fa fa-check"></i><b>10.3</b> Law of Large Numbers</a></li>
<li class="chapter" data-level="10.4" data-path="sampling-distributions.html"><a href="sampling-distributions.html#inference"><i class="fa fa-check"></i><b>10.4</b> Inference</a></li>
<li class="chapter" data-level="10.5" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-mean"><i class="fa fa-check"></i><b>10.5</b> Sample mean</a></li>
<li class="chapter" data-level="10.6" data-path="sampling-distributions.html"><a href="sampling-distributions.html#prediction"><i class="fa fa-check"></i><b>10.6</b> Prediction</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#example-pacemaker-prediction"><i class="fa fa-check"></i><b>10.6.1</b> <strong>Example: Pacemaker Prediction</strong></a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="sampling-distributions.html"><a href="sampling-distributions.html#validation"><i class="fa fa-check"></i><b>10.7</b> Validation</a></li>
<li class="chapter" data-level="10.8" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-sum"><i class="fa fa-check"></i><b>10.8</b> Sample Sum</a>
<ul>
<li class="chapter" data-level="10.8.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#example-cables"><i class="fa fa-check"></i><b>10.8.1</b> Example (Cables)</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-variance-1"><i class="fa fa-check"></i><b>10.9</b> Sample Variance</a>
<ul>
<li class="chapter" data-level="10.9.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#example-cables-1"><i class="fa fa-check"></i><b>10.9.1</b> Example (Cables)</a></li>
</ul></li>
<li class="chapter" data-level="10.10" data-path="sampling-distributions.html"><a href="sampling-distributions.html#distribution-of-the-sample-variance"><i class="fa fa-check"></i><b>10.10</b> Distribution of the Sample Variance</a></li>
<li class="chapter" data-level="10.11" data-path="sampling-distributions.html"><a href="sampling-distributions.html#the-chi2-distribution"><i class="fa fa-check"></i><b>10.11</b> The <span class="math inline">\(\chi^2\)</span> Distribution</a></li>
<li class="chapter" data-level="10.12" data-path="sampling-distributions.html"><a href="sampling-distributions.html#questions-7"><i class="fa fa-check"></i><b>10.12</b> Questions</a></li>
<li class="chapter" data-level="10.13" data-path="sampling-distributions.html"><a href="sampling-distributions.html#exercises-8"><i class="fa fa-check"></i><b>10.13</b> Exercises</a>
<ul>
<li class="chapter" data-level="10.13.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#from-estimation-to-inference"><i class="fa fa-check"></i><b>10.13.1</b> From Estimation to Inference</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html"><i class="fa fa-check"></i><b>11</b> Central limit theorem</a>
<ul>
<li class="chapter" data-level="11.1" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#margin-of-error"><i class="fa fa-check"></i><b>11.1</b> Margin of error</a></li>
<li class="chapter" data-level="11.2" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#averages-of-normal-variables"><i class="fa fa-check"></i><b>11.2</b> Averages of normal variables</a></li>
<li class="chapter" data-level="11.3" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#central-limit-theorem-1"><i class="fa fa-check"></i><b>11.3</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="11.4" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#sample-sum-and-clt"><i class="fa fa-check"></i><b>11.4</b> Sample sum and CLT</a></li>
<li class="chapter" data-level="11.5" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#unknown-sigma"><i class="fa fa-check"></i><b>11.5</b> Unknown <span class="math inline">\(\sigma\)</span></a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#example-pacemaker-prediction-1"><i class="fa fa-check"></i><b>11.5.1</b> <strong>Example: Pacemaker Prediction</strong></a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#t-statistic"><i class="fa fa-check"></i><b>11.6</b> T-statistic</a></li>
<li class="chapter" data-level="11.7" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#questions-8"><i class="fa fa-check"></i><b>11.7</b> Questions</a></li>
<li class="chapter" data-level="11.8" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#exercises-9"><i class="fa fa-check"></i><b>11.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html"><i class="fa fa-check"></i><b>12</b> Maximum likelihood</a>
<ul>
<li class="chapter" data-level="12.1" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#statistic"><i class="fa fa-check"></i><b>12.1</b> Statistic</a></li>
<li class="chapter" data-level="12.2" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#properties"><i class="fa fa-check"></i><b>12.2</b> Properties</a></li>
<li class="chapter" data-level="12.3" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#maximum-likelihood-1"><i class="fa fa-check"></i><b>12.3</b> Maximum likelihood</a></li>
<li class="chapter" data-level="12.4" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#maximum-likelihood-2"><i class="fa fa-check"></i><b>12.4</b> Maximum likelihood</a></li>
<li class="chapter" data-level="12.5" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#questions-9"><i class="fa fa-check"></i><b>12.5</b> Questions</a></li>
<li class="chapter" data-level="12.6" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#exercises-10"><i class="fa fa-check"></i><b>12.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="interval-estimation.html"><a href="interval-estimation.html"><i class="fa fa-check"></i><b>13</b> Interval estimation</a>
<ul>
<li class="chapter" data-level="13.1" data-path="interval-estimation.html"><a href="interval-estimation.html#revisiting-parameter-estimation-and-marging-of-error"><i class="fa fa-check"></i><b>13.1</b> Revisiting parameter estimation and marging of error</a></li>
<li class="chapter" data-level="13.2" data-path="interval-estimation.html"><a href="interval-estimation.html#interval-estimation-for-the-mean"><i class="fa fa-check"></i><b>13.2</b> Interval estimation for the mean</a></li>
<li class="chapter" data-level="13.3" data-path="interval-estimation.html"><a href="interval-estimation.html#confidence-interval-estimation"><i class="fa fa-check"></i><b>13.3</b> Confidence Interval Estimation</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="interval-estimation.html"><a href="interval-estimation.html#estimation-of-the-mean-for-normal-variables"><i class="fa fa-check"></i><b>13.3.1</b> Estimation of the mean for normal variables</a></li>
<li class="chapter" data-level="13.3.2" data-path="interval-estimation.html"><a href="interval-estimation.html#estimation-of-the-proportion-for-dichotomic-variables"><i class="fa fa-check"></i><b>13.3.2</b> Estimation of the proportion for dichotomic variables</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="interval-estimation.html"><a href="interval-estimation.html#estimation-of-the-variance"><i class="fa fa-check"></i><b>13.4</b> Estimation of the variance</a></li>
<li class="chapter" data-level="13.5" data-path="interval-estimation.html"><a href="interval-estimation.html#confidence-interval-for-the-variance"><i class="fa fa-check"></i><b>13.5</b> Confidence interval for the variance</a></li>
<li class="chapter" data-level="13.6" data-path="interval-estimation.html"><a href="interval-estimation.html#questions-10"><i class="fa fa-check"></i><b>13.6</b> Questions</a></li>
<li class="chapter" data-level="13.7" data-path="interval-estimation.html"><a href="interval-estimation.html#exercises-11"><i class="fa fa-check"></i><b>13.7</b> Exercises</a></li>
<li class="chapter" data-level="13.8" data-path="interval-estimation.html"><a href="interval-estimation.html#practice-3"><i class="fa fa-check"></i><b>13.8</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>14</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="14.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-formulation"><i class="fa fa-check"></i><b>14.1</b> Hypothesis formulation</a></li>
<li class="chapter" data-level="14.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-1"><i class="fa fa-check"></i><b>14.2</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="14.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-for-the-mean"><i class="fa fa-check"></i><b>14.3</b> Hypothesis testing for the mean</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-with-a-confidence-interval"><i class="fa fa-check"></i><b>14.3.1</b> Hypothesis test with a confidence interval</a></li>
<li class="chapter" data-level="14.3.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-with-acceptancerejection-zones"><i class="fa fa-check"></i><b>14.3.2</b> Hypothesis test with acceptance/rejection zones</a></li>
<li class="chapter" data-level="14.3.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-with-a-p-value"><i class="fa fa-check"></i><b>14.3.3</b> Hypothesis test with a P-value</a></li>
<li class="chapter" data-level="14.3.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#upper-tail-hypothesis"><i class="fa fa-check"></i><b>14.3.4</b> Upper tail hypothesis</a></li>
<li class="chapter" data-level="14.3.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#paired-t-test"><i class="fa fa-check"></i><b>14.3.5</b> Paired t-test</a></li>
<li class="chapter" data-level="14.3.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#lower-tail-hypothesis"><i class="fa fa-check"></i><b>14.3.6</b> Lower tail hypothesis</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-for-the-proportion"><i class="fa fa-check"></i><b>14.4</b> Hypothesis testing for the proportion</a></li>
<li class="chapter" data-level="14.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-for-the-variance"><i class="fa fa-check"></i><b>14.5</b> Hypothesis Testing for the Variance</a></li>
<li class="chapter" data-level="14.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#errors-in-hypothesis-testing"><i class="fa fa-check"></i><b>14.6</b> Errors in hypothesis testing</a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sensitivity-and-specificity"><i class="fa fa-check"></i><b>14.6.1</b> Sensitivity and Specificity</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#exercises-12"><i class="fa fa-check"></i><b>14.7</b> Exercises</a></li>
<li class="chapter" data-level="14.8" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#practice-4"><i class="fa fa-check"></i><b>14.8</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="contingency-tables.html"><a href="contingency-tables.html"><i class="fa fa-check"></i><b>15</b> Contingency tables</a>
<ul>
<li class="chapter" data-level="15.1" data-path="contingency-tables.html"><a href="contingency-tables.html#difference-between-proportions"><i class="fa fa-check"></i><b>15.1</b> Difference between proportions</a></li>
<li class="chapter" data-level="15.2" data-path="contingency-tables.html"><a href="contingency-tables.html#difference-between-proportions-1"><i class="fa fa-check"></i><b>15.2</b> Difference between proportions</a></li>
<li class="chapter" data-level="15.3" data-path="contingency-tables.html"><a href="contingency-tables.html#contingency-table-of-conditional-probabilities"><i class="fa fa-check"></i><b>15.3</b> Contingency table of conditional probabilities</a></li>
<li class="chapter" data-level="15.4" data-path="contingency-tables.html"><a href="contingency-tables.html#test-for-the-difference-between-proportions"><i class="fa fa-check"></i><b>15.4</b> Test for the difference between proportions</a></li>
<li class="chapter" data-level="15.5" data-path="contingency-tables.html"><a href="contingency-tables.html#chi2-test"><i class="fa fa-check"></i><b>15.5</b> <span class="math inline">\(\chi^2\)</span> test</a></li>
<li class="chapter" data-level="15.6" data-path="contingency-tables.html"><a href="contingency-tables.html#fishers-exact-test"><i class="fa fa-check"></i><b>15.6</b> Fisherâs exact test</a></li>
<li class="chapter" data-level="15.7" data-path="contingency-tables.html"><a href="contingency-tables.html#hypergeometric-distribution"><i class="fa fa-check"></i><b>15.7</b> Hypergeometric distribution</a></li>
<li class="chapter" data-level="15.8" data-path="contingency-tables.html"><a href="contingency-tables.html#difference-between-several-proportions"><i class="fa fa-check"></i><b>15.8</b> Difference between several proportions</a></li>
<li class="chapter" data-level="15.9" data-path="contingency-tables.html"><a href="contingency-tables.html#goodness-of-fit"><i class="fa fa-check"></i><b>15.9</b> Goodness of fit</a></li>
<li class="chapter" data-level="15.10" data-path="contingency-tables.html"><a href="contingency-tables.html#questions-11"><i class="fa fa-check"></i><b>15.10</b> Questions</a></li>
<li class="chapter" data-level="15.11" data-path="contingency-tables.html"><a href="contingency-tables.html#practice-5"><i class="fa fa-check"></i><b>15.11</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html"><i class="fa fa-check"></i><b>16</b> Mean differences between two samples</a>
<ul>
<li class="chapter" data-level="16.1" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#difference-in-means-between-two-groups"><i class="fa fa-check"></i><b>16.1</b> Difference in means between two groups</a></li>
<li class="chapter" data-level="16.2" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#data-1"><i class="fa fa-check"></i><b>16.2</b> Data</a></li>
<li class="chapter" data-level="16.3" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#difference-between-means"><i class="fa fa-check"></i><b>16.3</b> Difference between means</a></li>
<li class="chapter" data-level="16.4" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#hypothesis-test"><i class="fa fa-check"></i><b>16.4</b> Hypothesis test</a></li>
<li class="chapter" data-level="16.5" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#estiamtor-of-the-mean-difference"><i class="fa fa-check"></i><b>16.5</b> Estiamtor of the mean difference</a></li>
<li class="chapter" data-level="16.6" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#standardized-error"><i class="fa fa-check"></i><b>16.6</b> Standardized error</a></li>
<li class="chapter" data-level="16.7" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#standardized-error-for-the-null"><i class="fa fa-check"></i><b>16.7</b> Standardized error for the null</a></li>
<li class="chapter" data-level="16.8" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#mean-differences-when-n-is-small"><i class="fa fa-check"></i><b>16.8</b> Mean differences when <span class="math inline">\(n\)</span> is small</a></li>
<li class="chapter" data-level="16.9" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#data-2"><i class="fa fa-check"></i><b>16.9</b> Data</a></li>
<li class="chapter" data-level="16.10" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#difference-between-means-1"><i class="fa fa-check"></i><b>16.10</b> Difference between means</a></li>
<li class="chapter" data-level="16.11" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#hypothesis-test-1"><i class="fa fa-check"></i><b>16.11</b> Hypothesis test</a></li>
<li class="chapter" data-level="16.12" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#estimator-of-the-mean-difference"><i class="fa fa-check"></i><b>16.12</b> Estimator of the mean difference</a></li>
<li class="chapter" data-level="16.13" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#standardized-error-for-the-null-1"><i class="fa fa-check"></i><b>16.13</b> Standardized error for the null</a></li>
<li class="chapter" data-level="16.14" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#mean-differences-with-unequall-variances"><i class="fa fa-check"></i><b>16.14</b> Mean differences with unequall variances</a></li>
<li class="chapter" data-level="16.15" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#data-3"><i class="fa fa-check"></i><b>16.15</b> Data</a></li>
<li class="chapter" data-level="16.16" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#questions-12"><i class="fa fa-check"></i><b>16.16</b> Questions</a></li>
<li class="chapter" data-level="16.17" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#practice-6"><i class="fa fa-check"></i><b>16.17</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html"><i class="fa fa-check"></i><b>17</b> Mean differences across several groups</a>
<ul>
<li class="chapter" data-level="17.1" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#different-means-among-several-conditions"><i class="fa fa-check"></i><b>17.1</b> Different means among several conditions</a></li>
<li class="chapter" data-level="17.2" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#data-4"><i class="fa fa-check"></i><b>17.2</b> Data</a></li>
<li class="chapter" data-level="17.3" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#difference-between-means-2"><i class="fa fa-check"></i><b>17.3</b> Difference between means</a></li>
<li class="chapter" data-level="17.4" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#hypothesis-test-2"><i class="fa fa-check"></i><b>17.4</b> Hypothesis test</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#distribution-of-group-means-under-h_0"><i class="fa fa-check"></i><b>17.4.1</b> Distribution of group means under <span class="math inline">\(H_0\)</span></a></li>
<li class="chapter" data-level="17.4.2" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#sources-of-variation"><i class="fa fa-check"></i><b>17.4.2</b> Sources of variation</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#variance-components-estimators"><i class="fa fa-check"></i><b>17.5</b> Variance components estimators</a></li>
<li class="chapter" data-level="17.6" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#analysis-of-variance-anova"><i class="fa fa-check"></i><b>17.6</b> Analysis of variance (ANOVA)</a></li>
<li class="chapter" data-level="17.7" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#anova-for-two-groups"><i class="fa fa-check"></i><b>17.7</b> ANOVA for Two Groups</a></li>
<li class="chapter" data-level="17.8" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#linear-model"><i class="fa fa-check"></i><b>17.8</b> Linear model</a></li>
<li class="chapter" data-level="17.9" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#way-anova"><i class="fa fa-check"></i><b>17.9</b> 2-way ANOVA</a></li>
<li class="chapter" data-level="17.10" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#data-5"><i class="fa fa-check"></i><b>17.10</b> Data</a></li>
<li class="chapter" data-level="17.11" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#modeling-residuals"><i class="fa fa-check"></i><b>17.11</b> Modeling residuals</a></li>
<li class="chapter" data-level="17.12" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#way-anova-linear-model"><i class="fa fa-check"></i><b>17.12</b> 2-way ANOVA linear model</a></li>
<li class="chapter" data-level="17.13" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#hypothesis-tests"><i class="fa fa-check"></i><b>17.13</b> Hypothesis tests</a></li>
<li class="chapter" data-level="17.14" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#variance-components"><i class="fa fa-check"></i><b>17.14</b> Variance components</a></li>
<li class="chapter" data-level="17.15" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#way-anova-with-interaction"><i class="fa fa-check"></i><b>17.15</b> 2-way ANOVA with interaction</a></li>
<li class="chapter" data-level="17.16" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#linear-model-1"><i class="fa fa-check"></i><b>17.16</b> Linear model</a></li>
<li class="chapter" data-level="17.17" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#hypothesis-tests-1"><i class="fa fa-check"></i><b>17.17</b> Hypothesis tests</a></li>
<li class="chapter" data-level="17.18" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#variance-components-1"><i class="fa fa-check"></i><b>17.18</b> Variance components</a></li>
<li class="chapter" data-level="17.19" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#questions-13"><i class="fa fa-check"></i><b>17.19</b> Questions</a></li>
<li class="chapter" data-level="17.20" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#practice-7"><i class="fa fa-check"></i><b>17.20</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html"><i class="fa fa-check"></i><b>18</b> Regression and Correlation</a>
<ul>
<li class="chapter" data-level="18.1" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#correlations"><i class="fa fa-check"></i><b>18.1</b> Correlations</a></li>
<li class="chapter" data-level="18.2" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#data-6"><i class="fa fa-check"></i><b>18.2</b> Data</a></li>
<li class="chapter" data-level="18.3" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#normal-bivariate"><i class="fa fa-check"></i><b>18.3</b> Normal bivariate</a></li>
<li class="chapter" data-level="18.4" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#estimators"><i class="fa fa-check"></i><b>18.4</b> Estimators</a></li>
<li class="chapter" data-level="18.5" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#correlation-coefficient"><i class="fa fa-check"></i><b>18.5</b> Correlation coefficient</a></li>
<li class="chapter" data-level="18.6" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#hypothesis-contrast"><i class="fa fa-check"></i><b>18.6</b> Hypothesis contrast</a></li>
<li class="chapter" data-level="18.7" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#regression-analysis"><i class="fa fa-check"></i><b>18.7</b> Regression analysis</a></li>
<li class="chapter" data-level="18.8" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#linear-model-2"><i class="fa fa-check"></i><b>18.8</b> Linear model</a></li>
<li class="chapter" data-level="18.9" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#hypothesis-contrast-1"><i class="fa fa-check"></i><b>18.9</b> Hypothesis contrast</a></li>
<li class="chapter" data-level="18.10" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#estimators-1"><i class="fa fa-check"></i><b>18.10</b> Estimators</a></li>
<li class="chapter" data-level="18.11" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#hypothesis-testing-2"><i class="fa fa-check"></i><b>18.11</b> Hypothesis testing</a></li>
<li class="chapter" data-level="18.12" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#stratified-analysis"><i class="fa fa-check"></i><b>18.12</b> Stratified analysis</a></li>
<li class="chapter" data-level="18.13" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#multiple-regression"><i class="fa fa-check"></i><b>18.13</b> Multiple Regression</a></li>
<li class="chapter" data-level="18.14" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#multiple-regression-interaction"><i class="fa fa-check"></i><b>18.14</b> Multiple Regression interaction</a></li>
<li class="chapter" data-level="18.15" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#model-diagnostics"><i class="fa fa-check"></i><b>18.15</b> Model diagnostics</a></li>
<li class="chapter" data-level="18.16" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#questions-14"><i class="fa fa-check"></i><b>18.16</b> Questions</a></li>
<li class="chapter" data-level="18.17" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#practice-8"><i class="fa fa-check"></i><b>18.17</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="apendix.html"><a href="apendix.html"><i class="fa fa-check"></i><b>19</b> Apendix</a>
<ul>
<li class="chapter" data-level="19.1" data-path="apendix.html"><a href="apendix.html#solutions-to-questions"><i class="fa fa-check"></i><b>19.1</b> Solutions to Questions</a></li>
<li class="chapter" data-level="19.2" data-path="apendix.html"><a href="apendix.html#summary-tables-python-and-r-code"><i class="fa fa-check"></i><b>19.2</b> Summary tables, Python and R code</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="apendix.html"><a href="apendix.html#creating-data-frames-and-loading-text-files"><i class="fa fa-check"></i><b>19.2.1</b> Creating Data Frames and Loading Text Files</a></li>
<li class="chapter" data-level="19.2.2" data-path="apendix.html"><a href="apendix.html#python-and-r-functions-for-data-description"><i class="fa fa-check"></i><b>19.2.2</b> Python and R Functions for Data Description</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="apendix.html"><a href="apendix.html#summary-of-common-probability-models"><i class="fa fa-check"></i><b>19.3</b> Summary of common probability models</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="apendix.html"><a href="apendix.html#python-and-r-functions-for-probability-models"><i class="fa fa-check"></i><b>19.3.1</b> Python and R Functions for Probability Models</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="apendix.html"><a href="apendix.html#summary-of-hypothesis"><i class="fa fa-check"></i><b>19.4</b> Summary of hypothesis</a>
<ul>
<li class="chapter" data-level="19.4.1" data-path="apendix.html"><a href="apendix.html#python-and-r-functions-for-hypothesis-tesing"><i class="fa fa-check"></i><b>19.4.1</b> Python and R Functions for Hypothesis tesing</a></li>
<li class="chapter" data-level="19.4.2" data-path="apendix.html"><a href="apendix.html#python-libraries-required"><i class="fa fa-check"></i><b>19.4.2</b> Python Libraries Required</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Data Analysis
for
Experimental Sciences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="probability" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">Chapter 3</span> Probability<a href="probability.html#probability" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>We may state that one of the primary objectives of experimental sciences is either to predict the outcomes of a random experiment or to gain control over the experiment to influence the frequencies of outcomes in a desired manner.</p>
<p>We hold a strong belief that advances in our knowledge and understanding of the experiment, framed within a coherent body of theories, will shed light on these objectives. Statistics plays a pivotal role in this endeavor, as it seeks to account for the randomness inherent in experiments and helps us extract meaningful signals from noise. Paradoxically, statistics involves the systematic study of aspects the experimentalist is not directly interested in: randomness and noise.</p>
<p>The central epistemic question behind statistics is this: How can we derive knowledge from a random experiment when its results vary each time it is conducted? There must be some invariantâa physical property of the experimentâthat we can identify and, in certain cases, influence. A cornerstone of experimental sciences is the recognition that the propensities with which outcomes occur are intrinsic properties of the random experiment itself. When a random experiment is repeated, each outcome retains the same propensity of being observed. Sometimes a specific outcome will occur, and sometimes it will not, but as the experiment is repeated, the outcome will appear with a certain regularity: perhaps 2 out of 5 times, or 3 out of 7. While we can never predict with certainty for a finite number of repetitions, if the experiment were repeated an infinite number of times, the exact propensity of each outcome would be revealed.</p>
<p>In this chapter, we introduce the concept of probability as the value approached by relative frequencies when a random experiment is repeated infinitely. For experiments in which all outcomes have equal probabilities, this frequentist definition aligns with the classical definition of probability: the ratio of the number of favorable outcomes to the total number of possible outcomes. The frequentist definition also allows for a propensity interpretation, which views probabilities as abstract defining properties of the random experiment.</p>
<p>With the help of a dice, computer simulations and the inheritance of genetic traits, we will define and explain the fundamental rules of probability in alignment with relative frequency tables. Events will be introduced as the basic elements to which probabilities are assigned. Composite events will be constructed using the principles of set algebra.</p>
<p>The concept of the joint probability of two events will be derived from these axioms and will serve as the foundation for incorporating multiple simultaneous measurements in a random experiment. This will form the foundation of conditional probability and statistical independence, which will be explored in the next chapter.</p>
<div id="probability-mesurement" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Probability mesurement<a href="probability.html#probability-mesurement" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We seek a measure of the likelihood that a particular outcome will occur in a future instance of a random experiment. These likelihoods will be referred to as probabilities of outcomes and will represent statements about their future occurrences.</p>
<p>We define the probability of an outcome as a measure of its propensity or likelihood of occurring, assigning it specific values:</p>
<ul>
<li>0, when the outcome has <strong>no possibility</strong> of occurring in the next run of the experiment.</li>
<li>1, when the outcome <strong>is certain</strong> to occur in the next run of the experiment.</li>
</ul>
<p>Intermediate values can be easily conceived for a class of experiments with many outcomes, each equally likely.</p>
</div>
<div id="classical-probability" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Classical probability<a href="probability.html#classical-probability" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As long as a random experiment has <span class="math inline">\(m\)</span> possible outcomes that are all equally likely, the probability of each outcome <span class="math inline">\(i\)</span> can be defined as:</p>
<p><span class="math display">\[P_i =\frac{1}{m}\]</span>.</p>
<p>Classical probability was explicitly defined by Laplace (1814).</p>
<p>Since every outcome is equally likely in this type of experiment, we may declare complete ignorance and, consequently, the best we can do is to equally distribute the same probability to each outcome. In other words, there are some random experiments for which we have no reason to assign more likelihood to one outcome than another.</p>
<p>Note that:</p>
<ul>
<li><span class="math inline">\(P_i\)</span> is an abstract defining property of the random experiment.</li>
<li>We do not observe <span class="math inline">\(P_i\)</span>.</li>
<li>We deduce <span class="math inline">\(P_i\)</span> from the ratio above and have no need to carry out any experiment to know it.</li>
</ul>
<p><strong>Example (dice):</strong></p>
<p>What is the probability that we will get <span class="math inline">\(2\)</span> on the roll of a die?</p>
<p><span class="math display">\[P_2=1/6=0.166666\]</span></p>
<p>We reason that all other <span class="math inline">\(5\)</span> numbers in the dice are equally likely to <span class="math inline">\(2\)</span>. The equal probability of the dice outcomes is a property of the random experiment of rolling it, which just states that the dice is fair and we should not expect one outcome rather than another.</p>
</div>
<div id="relative-frequencies-1" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Relative frequencies<a href="probability.html#relative-frequencies-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>What about random experiments whose possible outcomes are <strong>not</strong> equally likely?</p>
<p>How then can we define the probabilities of the outcomes?</p>
<p><strong>Example (mouse coating)</strong></p>
<p>Imagine that we obtain <span class="math inline">\(20\)</span> mice from a couple, both of which are grey in color. We write down the colors of their progeny:</p>
<p><small>grey, grey, grey, grey, grey, albino, grey, black, albino, grey, black, grey, grey, grey, grey, black, grey, albino, black, grey</small></p>
<p>From this data, how sure are we of obtaining an albino offspring from a future breading of the couple?</p>
<p>The frequency table is</p>
<p><span class="math display">\[
\begin{array}{ccc}
\mathbf{outcome} &amp; \mathbf{n_i} &amp; \mathbf{f_i} \\
\text{grey}  &amp; 13    &amp; 0.65  \\
\text{black}   &amp; 4     &amp; 0.20  \\
\text{albino}  &amp; 3     &amp; 0.15  \\ \hline
\mathbf{sum} &amp; 20 &amp; 1
\end{array}
\]</span></p>
<p>and the bar plot</p>
<p><img src="_main_files/figure-html/unnamed-chunk-48-1.png" width="672" /></p>
<p>The <strong>relative frequency</strong> <span class="math inline">\(f_i =\frac{n_ i}{n}\)</span> seems like a reasonable probability measure because</p>
<ul>
<li>it is a number between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>; and</li>
<li>it measures the proportion of the total number of observations that we obtained for a particular outcome.</li>
</ul>
<p>Since <span class="math inline">\(f_{albino}=0.15\)</span> then we would be about one sixth sure or, more precisely, three out of every <span class="math inline">\(20\)</span> observations, of getting albino.</p>
<p>How good is <span class="math inline">\(f_i\)</span> as a measure of the outcomeâs <span class="math inline">\(i\)</span> likelihood?</p>
<p>Let us imagine, we repeat the previous experiment <span class="math inline">\(100,000\)</span> more times. This is clearly impossible in practice but to achieve this, we will use the computer to simulate data based on a known inheritance model.</p>
<p>Here is the approach: Genetic theory for the epistatic model (Exercise 5), where albinism inhibits the grey and black coat colors, tell us that the relative ratios are 9:3:4 for grey, black and albino respectively. This means that out of <span class="math inline">\(16\)</span> possible mice, <span class="math inline">\(4\)</span> can be albino. To simulate this, we instruct the computer to create an urn containing <span class="math inline">\(9\)</span> grey balls, <span class="math inline">\(3\)</span> black balls, and <span class="math inline">\(4\)</span> albino balls. A ball is drawn at random, its label is recorded, and then it is returned to the urn. This simulates running one single random experiment of epistatic inheritance.</p>
<p>We can repeat this process <span class="math inline">\(20\)</span> times, as we did earlier, or <span class="math inline">\(100,000\)</span> times, as we now show. The resulting frequency table is now as follows:</p>
<p><span class="math display">\[
\begin{array}{ccc}
\mathbf{outcome}   &amp; \mathbf{n_i} &amp; \mathbf{f_i} \\
\text{grey}  &amp; 56281    &amp; 0.56281  \\
\text{black}   &amp; 18542    &amp; 0.18542  \\
\text{albino}  &amp; 25177    &amp; 0.25177  \\
\hline
\mathbf{sum} &amp; 100000 &amp; 1
\end{array}
\]</span></p>
<p>and the bar plot is</p>
<p><img src="_main_files/figure-html/unnamed-chunk-50-1.png" width="672" /></p>
<p>We see that the frequency for <span class="math inline">\(f_{albino}\)</span> is now <span class="math inline">\(0.25145\)</span>, which is closer to the likelihood of <span class="math inline">\(4\)</span> in <span class="math inline">\(16\)</span> (<span class="math inline">\(0.25\)</span>) for producing an albino in the next offspring. Thus, we note that the probabilities measured by <span class="math inline">\(f_i\)</span> vary with <span class="math inline">\(n\)</span>.</p>
<p>A crucial fact is that when we compute <span class="math inline">\(f_i\)</span> with increasing values of <span class="math inline">\(n\)</span>, <span class="math inline">\(f_i\)</span> <strong>converges</strong>.</p>
<p>In the following, graph each vertical section gives the relative frequency of each observation, for a given value of <span class="math inline">\(n\)</span>. We see that after <span class="math inline">\(n=1000\)</span> (<span class="math inline">\(log10(n)=3\)</span>) the sectionsâ proportions hardly change with more <span class="math inline">\(n\)</span>, and the relative frequencies stabilize.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-51-1.png" width="672" /></p>
<p>An important point needs to be made. The unequal frequencies <span class="math inline">\(f_1\)</span>, <span class="math inline">\(f_2\)</span> and <span class="math inline">\(f_3\)</span>, at given <span class="math inline">\(n\)</span> and shown in the figure, were obtained from an experiment with <span class="math inline">\(16\)</span> equally likely outcomes. Each of the <span class="math inline">\(16\)</span> balls in the urn has the same chance of being drawn. Four balls are labeled âalbino,â giving them an accumulated probability of <span class="math inline">\(0.25\)</span> of being drawn. In practice, after drawing a million balls, we observed a relative frequency of <span class="math inline">\(0.249898\)</span> for albino. While this is not exactly <span class="math inline">\(0.25\)</span>, it is very close. As the number of draws increases, the relative frequency approaches the probability, becoming equal to it only at infinity.</p>
<p>By drawing an analogy between the urn and the reproduction of mice, we can imagine that the mice could reproduce to arbitrary numbers. While this is clearly impossible, it represents a step toward abstract thinking. If the mice could reproduce indefinitely, just as balls can be drawn from an urn indefinitely, then the relative frequency would converge to the probability. Specifically, the relative frequency <span class="math inline">\(f_i\)</span> at infinity becomes an abstract quantity <span class="math inline">\(P_i\)</span>, the constant value to which <span class="math inline">\(f_i\)</span> converges:</p>
<p><span class="math display">\[\lim_{n \to \infty} f_i = P_i\]</span></p>
<p>This quantity, <span class="math inline">\(P_i\)</span>, is what we call frequentist probability. It is important to note that <span class="math inline">\(f_i\)</span> is derived from a finite number <span class="math inline">\(n\)</span> of observations. In the lab, we can only perform a limited number of repetitions of a random experimentâalways far from infinity. No amount of observations can definitively prove that the inheritance model is epistatic, especially with just <span class="math inline">\(20\)</span> observations, or with real data from actual mice. However, as we will discuss in the following chapters, we can state with a certain level of confidence that the observed frequencies are consistent with an epistatic model.</p>
</div>
<div id="frequentist-probability" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> Frequentist probability<a href="probability.html#frequentist-probability" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We call <strong>Probability</strong> <span class="math inline">\(P_i\)</span> the limit as <span class="math inline">\(n \rightarrow \infty\)</span> of the <strong>relative frequency</strong> of observing the outcome <span class="math inline">\(i\)</span> in a random experiment.</p>
<p>Defended by Venn (1876), the frequentist definition of probability is derived from (empirical) data/experience.</p>
<p>Note that:</p>
<ul>
<li><span class="math inline">\(P_i\)</span> is a property of an infinite repetition of the random experiment.</li>
<li>We do not observe <span class="math inline">\(P_i\)</span>, we observe <span class="math inline">\(f_i\)</span> at a given value of <span class="math inline">\(n\)</span>.</li>
<li><strong>We estimate</strong> <span class="math inline">\(P_i\)</span> with <span class="math inline">\(f_i\)</span> (usually when <span class="math inline">\(n\)</span> is large), and write: <span class="math display">\[\hat {P_ i}= f_i\]</span></li>
</ul>
<p>Similar to the relationship between observation and outcome, there is a relationship between relative frequency and probability: a concrete value corresponding to an abstract quantity.</p>
<p>A suitable interpretation of probability in experimental sciences is as the propensity of a random experiment to produce a given outcome <span class="citation">(<a href="#ref-popper2002logic">Popper 2002</a>)</span>. Probability is thus viewed as an abstract defining property of a random experiment, which can be either approximated as the experiment is repeated a large number of times, or known by experimental design.</p>
</div>
<div id="classical-and-frequentist-probabilities" class="section level2 hasAnchor" number="3.5">
<h2><span class="header-section-number">3.5</span> Classical and frequentist probabilities<a href="probability.html#classical-and-frequentist-probabilities" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have situations where classical probability can be used to find the limit of relative frequencies:</p>
<ul>
<li>If the results are <strong>equally probable</strong>, the classical probability gives us the limit:</li>
</ul>
<p><span class="math display">\[P_i=lim_{n\rightarrow \infty} \frac{n_i}{n}=\frac{1}{m}\]</span></p>
<ul>
<li>If the results in which we are interested can be derived from other <strong>equally probable</strong> results, as in the mice coating example and the following one.</li>
</ul>
<p><strong>Example (sum of two dice)</strong></p>
<p>Let us consider the sum of the outcomes when rolling two dice. We can determine the exact probabilities of the outcomes without actually rolling the dice.</p>
<p>This probability <strong>follows</strong> from the fact that the outcome of each die is <strong>equally likely</strong>. From this assumption, we can find that (Exercise 1)</p>
<p><span class="math display">\[
    P_i =
\begin{cases}
\frac{i-1}{36},&amp; i \in \{2,3,4,5,6, 7\} \\
\frac{13-i}{36},&amp; i \in \{8,9,10,11,12\} \\
\end{cases}
\]</span></p>
<p>Imagine, however, that we have a black box where we do not know that two dice are being thrown, but we can see the result of their roll displayed on a screen</p>
<p><span class="math display">\[5, 3, 11, 9, 5, 7\]</span></p>
<p>We are then able to closely approach the probabilities of the random experiment using the <strong>relative frequencies</strong> if we repeat the experiment a million times (as simulated by a computer)</p>
<p><span class="math display">\[
\begin{array}{cccc}
\mathbf{outcome}   &amp; \mathbf{n_i} &amp; \mathbf{f_i} &amp; \mathbf{P_i} \\
2  &amp; 28070  &amp; 0.028070  &amp; 0.02777778 \\
3  &amp; 55617  &amp; 0.055617  &amp; 0.05555556 \\
4  &amp; 82964  &amp; 0.082964  &amp; 0.08333333 \\
5  &amp; 111113 &amp; 0.111113  &amp; 0.11111111 \\
6  &amp; 138749 &amp; 0.138749  &amp; 0.13888889 \\
7  &amp; 166717 &amp; 0.166717  &amp; 0.16666667 \\
8  &amp; 139011 &amp; 0.139011  &amp; 0.13888889 \\
9  &amp; 111193 &amp; 0.111193  &amp; 0.11111111 \\
10 &amp; 83504  &amp; 0.083504  &amp; 0.08333333 \\
11 &amp; 55397  &amp; 0.055397  &amp; 0.05555556 \\
12 &amp; 27665  &amp; 0.027665  &amp; 0.02777778 \\ \hline
\mathbf{sum} &amp; 1000000 &amp; 1 &amp; 1 \\
\end{array}
\]</span></p>
<p>Exact knowledge can be obtained from a model without the need to conduct an experiment, using the formula for <span class="math inline">\(P_i\)</span>. In contrast, precise knowledge about outcome likelihoods can be derived from large amounts of data, even without understanding the underlying mechanisms. Models are free to describe any experiment, real or not, while data can yield accurate predictions without necessarily deepening our understanding. Kant observed, âThoughts without content are empty; intuitions without concepts are blind.â Thus, scientific content and insight are often achieved by contrasting a modelâs predictions with experimental results.</p>
<p>The motivation behind the frequentist definition of probability is empirical, while that of the classical definition is rational. Since both approaches are complementary, we often combine them with inference and deduction to determine the probabilities of our random experiment.</p>
</div>
<div id="sample-space" class="section level2 hasAnchor" number="3.6">
<h2><span class="header-section-number">3.6</span> Sample space<a href="probability.html#sample-space" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Probabilities are numbers assigned to each possible outcome of a random experiment. However, probabilities are also applied to composite outcomes or <strong>events</strong>. For instance, we can ask about the probability of drawing a ball labeled âalbinoâ when there are four such balls out of a total of 16. Each âalbinoâ ball represents a different outcome of the drawing, but the event of drawing an âalbinoâ ball is the same.</p>
<p>Therefore, before providing a formal definition of probabilities, we need a further characterization of the outcomes that a random experiment can produce.</p>
<p>The set of all possible outcomes of a random experiment is called the sample space and is denoted by <span class="math inline">\(S\)</span>.</p>
<p>The sample space can consist of categorical or numerical outcomes. It represents the range of outcomes that a random experiment can yield.</p>
<p><em>For example:</em></p>
<ul>
<li>human temperature: <span class="math inline">\(S = (36, 42)\)</span> degrees Celsius</li>
<li>sugar levels in humans: <span class="math inline">\(S =( 70,80) mg/ dL\)</span></li>
<li>the size of a production line screw: <span class="math inline">\(S =(70,72) mm\)</span></li>
<li>number of emails received in an hour: <span class="math inline">\(S = \{0, ...\infty \}\)</span></li>
<li>coat colors of mice: <span class="math inline">\(S= \{grey, black, albino\}\)</span></li>
<li>the throw of a dice: <span class="math inline">\(S= \{ 1, 2, 3, 4, 5, 6\}\)</span></li>
</ul>
</div>
<div id="events" class="section level2 hasAnchor" number="3.7">
<h2><span class="header-section-number">3.7</span> Events<a href="probability.html#events" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>An <strong>event</strong> <span class="math inline">\(A\)</span> is a <strong>subset</strong> of the sample space. It is a <strong>collection</strong> of possible outcomes.</p>
<p><em>Examples of events:</em></p>
<ul>
<li>The event of a healthy temperature: <span class="math inline">\(A=(37,38)\)</span> degrees Celsius</li>
<li>The event of producing a screw with a size range: <span class="math inline">\(A = (71.5mm, 71.6mm)\)</span></li>
<li>The event of receiving more than <span class="math inline">\(4\)</span> emails in an hour: <span class="math inline">\(A= \{ 4, \infty \}\)</span></li>
<li>The event of obtaining an albino mouse <span class="math inline">\(A=\{albino\}\)</span></li>
<li>The event of obtaining a number less than or equal to 3 in the throw of a dice: <span class="math inline">\(A= \{ 1,2,3\}\)</span></li>
</ul>
<p>An event refers to a possible set of primary <strong>outcomes</strong>.</p>
</div>
<div id="algebra-of-events" class="section level2 hasAnchor" number="3.8">
<h2><span class="header-section-number">3.8</span> Algebra of events<a href="probability.html#algebra-of-events" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>While it seems clear that the result of a random experiment can give us a specific outcome or a more general event, it is also expected that the result of the experiment can be a composite event.</p>
<p>For two events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>, we can construct the following <strong>composite events</strong> using the basic set operations:</p>
<ul>
<li>Complement <span class="math inline">\(A&#39;\)</span>: the event of <strong>not</strong> <span class="math inline">\(A\)</span></li>
<li>Union <span class="math inline">\(A \cup B\)</span>: the event of <span class="math inline">\(A\)</span> <strong>or</strong> <span class="math inline">\(B\)</span></li>
<li>Intersection <span class="math inline">\(A \cap B\)</span>: the event of <span class="math inline">\(A\)</span> <strong>and</strong> <span class="math inline">\(B\)</span></li>
</ul>
<p><strong>Example (dice)</strong></p>
<p>Let us imagine we intend to roll a die but first we want look at a range of interesting events (composite outcomes):</p>
<ul>
<li>a number less than or equal to three <span class="math inline">\(A:\{ 1,2,3\}\)</span></li>
<li>an even number <span class="math inline">\(B:\{ 2,4,6\}\)</span></li>
</ul>
<p>Let us see how we can build new events with set operations:</p>
<ul>
<li>a number <strong>not</strong> less than three: <span class="math inline">\(A&#39;:\{4,5,6\}\)</span></li>
<li>a number less than or equal to three <strong>or</strong> even: <span class="math inline">\(A \cup B: \{ 1,2,3,4,6\}\)</span></li>
<li>a number less than or equal to three <strong>and</strong> even <span class="math inline">\(A \cap B: \{ 2\}\)</span></li>
</ul>
<p>Random experiments produce a rich set of outcomes that can be gather together in events and transformed into other more complex events. Probabilities will be, consequently, defined on events.</p>
</div>
<div id="mutually-exclusive-events" class="section level2 hasAnchor" number="3.9">
<h2><span class="header-section-number">3.9</span> Mutually exclusive events<a href="probability.html#mutually-exclusive-events" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Primary outcomes like rolling <span class="math inline">\(1\)</span> and <span class="math inline">\(2\)</span> on a die are events that cannot occur at the same run of the experiment, a single roll of the dice. We say that they are <strong>mutually exclusive</strong>.</p>
<p>In general, two events denoted as <span class="math inline">\(E_1\)</span> and <span class="math inline">\(E_2\)</span> are mutually exclusive when they have no element in common</p>
<p><span class="math display">\[E_1\cap E_2=\emptyset\]</span></p>
<p><em>Examples:</em></p>
<p>The following events are mutually exclusive:</p>
<ul>
<li><p>The result that a patient has a misophonia severity <span class="math inline">\(1\)</span> and severity <span class="math inline">\(4\)</span>. Only one severity is possible.</p></li>
<li><p>The results of obtaining <span class="math inline">\(12\)</span> and <span class="math inline">\(5\)</span> in the roll of two dice. If we get <span class="math inline">\(12\)</span> we do not get <span class="math inline">\(5\)</span>.</p></li>
</ul>
<p>However, the events of rolling a number âless than or equal to threeâ <strong>and</strong> âevenâ in a dice are <strong>not</strong> mutually exclusive. They share the outcome <span class="math inline">\(2\)</span>.</p>
</div>
<div id="definition-of-probability" class="section level2 hasAnchor" number="3.10">
<h2><span class="header-section-number">3.10</span> Definition of probability<a href="probability.html#definition-of-probability" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The probability of an event, as an abstract quantity, is defined by a set of axioms. These axioms represent the minimum set of rules that relate to relative frequencies.</p>
<p>The probabilities of a random experimentâs events are numbers satisfying the following properties or axioms:</p>
<ol style="list-style-type: decimal">
<li><p>When the events <span class="math inline">\(E_1\)</span> and <span class="math inline">\(E_2\)</span> are mutually exclusive; that is, only one of them can occur, the probability of observing <span class="math inline">\(E_1\)</span> <strong>or</strong> <span class="math inline">\(E_1\)</span> is their sum:
<span class="math display">\[ P( E_1\cup E_2) = P(E_1) + P(E_2)\]</span></p></li>
<li><p>When <span class="math inline">\(S\)</span> is the sample space, then its probability is <span class="math inline">\(1\)</span> (at least something is observed): <span class="math display">\[P(S)=1\]</span></p></li>
<li><p>The probability of any event is between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span> (a continuous and bounded measure) <span class="math display">\[P(E) \in [0,1]\]</span></p></li>
</ol>
<p>Remarkably, the axioms were proposed by Kolmogorov in 1933 <span class="citation">(<a href="#ref-kolmogorov2013foundations">Kolmogorov 2013</a>)</span>, after statistics had already been formally established as a distinct discipline and following the formulation of statistical and quantum mechanicsâtwo prominent physics theories based on probability concepts. Advancement in these theories was possible because probabilities were treated as frequencies of infinite populations.</p>
</div>
<div id="probability-table" class="section level2 hasAnchor" number="3.11">
<h2><span class="header-section-number">3.11</span> Probability table<a href="probability.html#probability-table" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Kolmogorovâs axioms are the fundamental rules for defining a measure on the sample space and, as such, are independent of any specific interpretation. Probabilities, as mathematical objects, do not necessarily need to represent any random experiment. However, our interest lies in probabilities as measures of the likelihood of outcomes in real random experiments. Kolmogorovâs axioms importantly support the close alignment of probabilities with relative frequencies, as they also form the foundational rules for constructing a probability table, similar to relative frequency tables.</p>
<p>Therefore, we can assert that frequencies tend to probabilities as the random experiment is repeated indefinitely, or that probabilities may be regarded as abstract defining properties of the experiment, representing the likelihood of its outcomes in the next repetition of the experiment.</p>
<p><strong>Example (dice)</strong></p>
<p>The probability table for the roll of a dice is</p>
<p><span class="math display">\[
\begin{array}{cc}
\mathbf{outcome}  &amp; \mathbf{P_i} \\
1  &amp; 1/6 \\
2  &amp; 1/6 \\
3  &amp; 1/6 \\
4  &amp; 1/6 \\
5  &amp; 1/6 \\
6  &amp; 1/6 \\ \hline
S=\{1, 2, ... 6\} &amp; 1 \\
\end{array}
\]</span></p>
<p>Let us verify the axioms:</p>
<ol style="list-style-type: decimal">
<li><p>Where <span class="math inline">\(1 \cup 2\)</span> is, for example, the <strong>event</strong> of rolling a <span class="math inline">\(1\)</span> <strong>or</strong> a <span class="math inline">\(2\)</span>. So <span class="math display">\[ P( 1 \cup 2)=P(1)+P(2)=2/6\]</span></p></li>
<li><p>Since <span class="math inline">\(S= \{ 1,2,3,4,5,6\}\)</span> is made up of <strong>mutually exclusive</strong> outcomes, then</p></li>
</ol>
<p><span class="math display">\[P(S)=P(1\cup 2 ... \cup 6) = P(1)+P(2)+ ...+P(6)=1\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>The probabilities of each outcome are between <span class="math inline">\(0\)</span> and <span class="math inline">\(1\)</span>. This can be seen in the table.</li>
</ol>
<p>According to Kolmogorovâs properties, only mutually exclusive outcomes can be organized into probability tables, similar to relative frequency tables.</p>
</div>
<div id="joint-probabilities" class="section level2 hasAnchor" number="3.12">
<h2><span class="header-section-number">3.12</span> Joint probabilities<a href="probability.html#joint-probabilities" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Mutually exclusive events whose overall union is the sample space can be considered primary events. They constitute all the possible values of a type of measurement of the experiment that can be listed in a table.</p>
<p>However, we have seen that there are events that are not mutually exclusive. How are we to understand them and to list them on a probability table? Two different events with a common outcome may then constitute two different types of measurement, that sometimes coincide in that common outcome.</p>
<p>Let us consider the probability table for the dice and the events:</p>
<ul>
<li><p>a number less than or equal to three <span class="math inline">\(A:\{ 1,2,3\}\)</span></p></li>
<li><p>an even number <span class="math inline">\(B:\{ 2,4,6\}\)</span></p></li>
</ul>
<p>which are not mutually exclusive coinciding in the outcome <span class="math inline">\(2\)</span>: <span class="math inline">\(A \cap B = \{2\}\)</span>.</p>
<p>In the rolling of a dice, we can observe there <em>types of outcomes</em>, or three types of measurements: a number from 1 to 6 (outcome 1), the event of whether a number is <span class="math inline">\(\leq 3\)</span> (outcome 2) or the event of whether a number is pair (outcome 3).</p>
<p><span class="math display">\[
\begin{array}{cccc}
\mathbf{outcome\, 1} &amp; \mathbf{outcome\, 2} &amp; \mathbf{outcome\, 3}  &amp; \mathbf{P_i} \\
1 &amp; A &amp; B&#39; &amp; 1/6 \\
\mathbf{2} &amp; \mathbf{A} &amp; \mathbf{B} &amp; \mathbf{1/6} \\
3 &amp; A &amp; B&#39; &amp; 1/6 \\
4 &amp; A&#39;&amp; B &amp; 1/6 \\
5 &amp; A&#39;&amp; B&#39; &amp; 1/6 \\
6 &amp; A&#39;&amp; B &amp; 1/6 \\ \hline
S=\{1, 2, ... ,6\} &amp; S=\{A \cup A&#39;\} &amp; S=\{B \cup B&#39;\} &amp; 1 \\
\end{array}
\]</span></p>
<p>Now, we can also observe the occurrence of the the crossed possibilities between outcomes 2 <strong>and</strong> 3. In particular, we can consider the joint event <span class="math inline">\(A\cap B\)</span> as the event with two different qualities: âbeing greater or equal to 3â and âpairâ, namely, outcome 1 being <span class="math inline">\(2\)</span>.</p>
<p>For non mutually exclusive events, those that share common primary outcomes, we note that we can always decompose the sample space into <strong>mutually exclusive</strong> sets involving the intersections of the crossed possibilities between the events and their complements:</p>
<p><span class="math display">\[S=\{A\cap B, A \cap B&#39;, A&#39;\cap B, A&#39;\cap B&#39;\}\]</span>
If one of those events occur the others do not. We can now make a probability table of these events. The <strong>joint probability</strong> of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> is the probability of <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span>. That is <span class="math display">\[P( A \cap B)\]</span> or <span class="math inline">\(P(A,B)\)</span>. The <strong>probability table</strong> for the joint probabilities will be as follows</p>
<p><span class="math display">\[
\begin{array}{ll}
\mathbf{outcome\, 4}  &amp; \mathbf{joint\,probabilities} \\
A\cap B=\{2\}    &amp; P(A\cap B)=1/6 \\
A\cap B&#39;=\{1,3\} &amp; P(A\cap B&#39;)=2/6 \\
A&#39;\cap B=\{4,6\} &amp; P(A&#39;\cap B)=2/6 \\
A&#39;\cap B&#39;=\{5\}  &amp; P(A&#39;\cap B&#39;)=1/6 \\ \hline
S=\{A\cap B, ... A&#39;\cap B&#39;\} &amp; P(S)=1 \\
\end{array}
\]</span></p>
<p>The outcomes of type 4 are, therefore, composed of 4 mutually exclusive events, namely a number in the dice that is: â<span class="math inline">\(\leq 3\)</span> and pairâ; or â<span class="math inline">\(\leq 3\)</span> and not pairâ; or ânot <span class="math inline">\(\leq 3\)</span> and pairâ; or ânot <span class="math inline">\(\leq 3\)</span> and not pairâ. The probabilities of the sum off all these composite events is <span class="math inline">\(1\)</span>.</p>
<p>The <strong>marginals</strong> of <span class="math inline">\(A\)</span> and <span class="math inline">\(A&#39;\)</span> are the probabilities of each of those events. That is</p>
<p><span class="math display">\[
\begin{array}{ll}
\mathbf{outcome\, 2}  &amp; \mathbf{marginal\,probabilities} \\
A=\{1,2,3\}    &amp; P(A)=3/6 \\
A&#39;=\{4,5,6\} &amp; P(A&#39;)=3/6 \\ \hline
S=A\cup A&#39; &amp; P(S)=1 \\
\end{array}
\]</span></p>
<p>Note that the marginal <span class="math inline">\(P(A)\)</span> is the addition of the joint probabilities where <span class="math inline">\(A\)</span> occurs <span class="math display">\[P(A)=P(A\cap B&#39;) + P(A \cap B)\]</span> <span class="math display">\[=2/6+1/6=3/6\]</span> .</p>
<p>Similarly we have the marginals for <span class="math inline">\(B\)</span> and <span class="math inline">\(B&#39;\)</span></p>
<p><span class="math display">\[
\begin{array}{ll}
\mathbf{outcome\, 3}  &amp; \mathbf{marginal\,probabilities} \\
B=\{2,4,6\}    &amp; P(B)=3/6 \\
B&#39;=\{1,3,5\} &amp; P(B&#39;)=3/6 \\ \hline
S=A\cup A&#39; &amp; P(S)=1 \\
\end{array}
\]</span></p>
<p>And, the marginal <span class="math inline">\(P(B)\)</span> is the addition of all the probabilities where event <span class="math inline">\(B\)</span> occurs <span class="math display">\[P(B)=P(A&#39;\cap B) +P(A \cap B)\]</span> <span class="math display">\[=2/6+1/6=3/6\]</span></p>
</div>
<div id="contingency-table" class="section level2 hasAnchor" number="3.13">
<h2><span class="header-section-number">3.13</span> Contingency table<a href="probability.html#contingency-table" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The joint and the marginal probability tables can be written in a single <strong>contingency table</strong></p>
<p><span class="math display">\[
\begin{array}{ccc|c}
           &amp; \mathbf{B}             &amp; \mathbf{B&#39;}             &amp; \mathbf{marginals} \\
\mathbf{A}        &amp; P(A \cap B)   &amp; P(A \cap B&#39;)   &amp; P(A)       \\
\mathbf{A&#39;}       &amp; P(A&#39; \cap B)  &amp; P(A&#39; \cap B&#39;)  &amp; P(A&#39;)      \\ \hline
\mathbf{marginals} &amp; P(B)        &amp; P(B&#39;)         &amp; 1            \\
\end{array}
\]</span></p>
<p>Where the marginals are the sums in the margins of the table, for example:</p>
<ul>
<li><span class="math inline">\(P(A)=P(A \cap B&#39;) + P(A \cap B)\)</span></li>
<li><span class="math inline">\(P(B)=P(A&#39; \cap B) + P(A \cap B)\)</span></li>
</ul>
<p>In our example, the contingency table for the events <span class="math inline">\(A\)</span> and <span class="math inline">\(B\)</span> and their complements is</p>
<p><span class="math display">\[
\begin{array}{ccc|c}
           &amp; \mathbf{B}             &amp; \mathbf{B&#39;}             &amp; \mathbf{marginals} \\
\mathbf{A}        &amp; 1/6   &amp; 2/6   &amp; 3/6       \\
\mathbf{A&#39;}       &amp; 2/6  &amp; 1/6   &amp; 3/6     \\ \hline
\mathbf{marginals} &amp; 3/6        &amp; 3/6         &amp; 1            \\
\end{array}
\]</span></p>
</div>
<div id="the-addition-rule" class="section level2 hasAnchor" number="3.14">
<h2><span class="header-section-number">3.14</span> The addition rule<a href="probability.html#the-addition-rule" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The addition rule allows us to calculate the probability of <span class="math inline">\(A\)</span> <strong>or</strong> <span class="math inline">\(B\)</span>, <span class="math inline">\(P( A \cup B)\)</span>, in terms of the probability of <span class="math inline">\(A\)</span> <strong>and</strong> <span class="math inline">\(B\)</span>, <span class="math inline">\(P(A \cap B )\)</span>. We can do this in three equivalent ways:</p>
<ol style="list-style-type: decimal">
<li><p>Using only joint probabilities
<span class="math display">\[P( A \cup B)=P(A \cap B)+P(A\cap B&#39;)+P(A&#39;\cap B)\]</span></p></li>
<li><p>Using the complement of the joint probability
<span class="math display">\[P(A \cup B)=1-P(A&#39;\cap B&#39;)\]</span></p></li>
<li><p>Using the marginals and the joint probability
<span class="math display">\[P(A \cup B)=P(A) + P(B) - P(A\cap B)\]</span></p></li>
</ol>
<p><strong>Example (Mendelâs first law)</strong></p>
<p>Every organism inherits two versions of a gene that we call alleles, one from each parent (<span class="math inline">\(X_m\)</span>,<span class="math inline">\(X_f\)</span>). This is the joint event (<span class="math inline">\(X_m \cap X_f\)</span>). The alleles can be identical or different, and sometimes can be linked to a characteristic of the organism. For the coat color of mice there is one allele for albino (<span class="math inline">\(A\)</span>) and another for not-albino (<span class="math inline">\(A&#39;\)</span>), which allows any color.</p>
<p>Inheritance of the alleles is made at random with equal probabilities from the parental alleles. For one offspring, we define</p>
<ul>
<li><p>the event of inheriting albino allele from the mother <span class="math inline">\(A_m\)</span></p></li>
<li><p>the event of inheriting albino allele from the father <span class="math inline">\(A_f\)</span></p></li>
</ul>
<p>If both parents are hybrids they both have alleles (<span class="math inline">\(A \cap A&#39;\)</span>) and their offspring can have four allele pairs</p>
<p><span class="math display">\[S =\{A_m \cap A_f,  A_m \cap A_f&#39;, A_m&#39; \cap A_f, A_m&#39; \cap A_f&#39;\}\]</span></p>
<p>with equal probabilities of <span class="math inline">\(1/4\)</span>. The contingency table is</p>
<p><span class="math display">\[
\begin{array}{ccc|c}
                   &amp; \mathbf{A_f}   &amp; \mathbf{A_f&#39;} &amp; \mathbf{marginals} \\
\mathbf{A_m}       &amp; 1/4   &amp; \mathbf{1/4}  &amp; 1/2                \\
\mathbf{A_m&#39;}      &amp; \mathbf{1/4}   &amp; \mathbf{1/4}           &amp; 1/2                 \\ \hline
\mathbf{marginals} &amp; 1/2            &amp; 1/2           &amp; 1                   \\
\end{array}
\]</span></p>
<p>Having a color is dominant trait, which means that a mouse is colored if at least one the alleles is not albino. That is the event <span class="math inline">\((A&#39;_m \cup A&#39;_f)\)</span>.</p>
<p>Therefore, the probability of producing a color mouse is <span class="math inline">\(3/4\)</span> that can be computed in three different ways:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(P( A&#39;_m \cup A&#39;_f)=P(A&#39;_m \cap A&#39;_f)+P(A_m\cap A_f&#39;)+P(A_m&#39;\cap A_f)=1/4+1/4+1/4=3/4\)</span></p></li>
<li><p><span class="math inline">\(P(A&#39;_m \cup A&#39;_f)=1-P(A_m\cap A_f)= 1-1/4=3/4\)</span></p></li>
<li><p><span class="math inline">\(P( A&#39;_m \cup A&#39;_f)=P(A&#39;_m) + P(A&#39;_f) - P(A&#39;_m\cap A&#39;_f)=1/2+1/2-1/4=3/4\)</span></p></li>
</ol>
<p>In the contingency table, <span class="math inline">\(P( A&#39;_m \cup A&#39;_f)\)</span> corresponds to the addition of the three cells in bold (method 1 above). The probability is also given by the addition of all cells but the <span class="math inline">\(1/4\)</span> from the top left (method 2), or by adding the marginals and subtracting <span class="math inline">\(P(A&#39;_m\cap A&#39;_f)\)</span> that has been added twice (method 3).</p>
<p>Color is a dominant trait because it masks albinism when present in only one allele. We can also say that albino is a recessive trait. Therefore, the probabilities for color and albino are given by the ratio of 3 to 1 (3:1), or probability <span class="math inline">\(3/4=0.75\)</span>, satisfying the Mendelâs first law <span class="citation">(<a href="#ref-mendel1901experiments">Mendel 1901</a>)</span>.</p>
<p>We can consider more alleles at other genes that are not mutually exclusive with the inheritance of the albino alleles. For example, if we observe an additional trait (outcome type) with two alleles for the length of the ears (short or long), there will be <span class="math inline">\(16\)</span> possible allele combinations, for all the possible crossings of paternal alleles. According to Mendelâs second law, if the traits are independent, there will be four possible types of mice with different albino and tail length status, having ratios of 9:3:3:1 (see Exercise 4); with only one possibility in 16 for the albino and long ear mice.</p>
<p>William Bateson observed that some traits interfere with each other; for instance, being albino eliminates coat pigmentation. In such cases, inheritance deviates from Mendelian patterns and is considered epistatic, resulting in ratios like 9:3:4 (see Exercise 5), with only three observed colors.</p>
<p>After collecting data from several offspring, our scientific interest may lie in determining whether two traits are independent or if one trait suppresses the other, potentially to gain control over the first if harmful. While exact probabilities cannot be derived from relative frequencies, sufficient evidence may still be obtained to decide which scenario is more likely.</p>
</div>
<div id="questions-1" class="section level2 hasAnchor" number="3.15">
<h2><span class="header-section-number">3.15</span> Questions<a href="probability.html#questions-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The following data is part of John Snowâs study on the London 1854 cholera epidemic, which was foundational for modern epidemiology and early germ theory <span class="citation">(<a href="#ref-snow1855mode">Snow 1855</a>)</span>. He famously showed that cholera was transmitted by water and that identified Southwark and Vauxall water supply was the likely source of the epidemic. The following data record the date of death and the water supply source used by 3920 deceased patients. While more deaths were recorded Southwark and Vauxall the number of houses supplied by each company needs to be taken into account for correct conclusions.<br />
<small>
<span class="math display">\[
\begin{array}{|l|r|r|r|r|r|r|}
\hline
\textbf{Week Ending} &amp; \textbf{Total} &amp; \textbf{S and V} &amp; \textbf{Lambeth} &amp; \textbf{Kent} &amp; \textbf{Other} &amp; \textbf{Not Ascertained} \\
\hline
\text{Sept 2, 1854}  &amp; 670 &amp; 399 &amp; 45  &amp; 38  &amp; 72 &amp; 116 \\
\text{Sept 9, 1854}  &amp; 972 &amp; 580 &amp; 72  &amp; 45  &amp; 62 &amp; 213 \\
\text{Sept 16, 1854} &amp; 856 &amp; 524 &amp; 66  &amp; 48  &amp; 44 &amp; 174 \\
\text{Sept 23, 1854} &amp; 724 &amp; 432 &amp; 72  &amp; 28  &amp; 62 &amp; 130 \\
\text{Sept 30, 1854} &amp; 383 &amp; 228 &amp; 25  &amp; 19  &amp; 24 &amp;  87 \\
\text{Oct 7, 1854}   &amp; 200 &amp; 121 &amp; 14  &amp; 10  &amp; 9  &amp;  46 \\
\text{Oct 14, 1854}  &amp; 115 &amp;  69 &amp; 8   &amp; 3   &amp; 6  &amp;  29 \\
\hline
\textbf{Total}       &amp; \textbf{3920} &amp; \textbf{2353} &amp; \textbf{302} &amp; \textbf{191} &amp; \textbf{279} &amp; \textbf{795} \\
\hline
\end{array}
\]</span>
</small></p>
<p><strong>1)</strong> What is the estimated probability that a patient died on the 16th of September and likely drank from Southwark and Vauxhallâs water supply?</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> <span class="math inline">\(524/3920\)</span>; <strong><span class="math inline">\(\qquad\)</span>b:</strong> <span class="math inline">\(524/2353\)</span>; <strong><span class="math inline">\(\qquad\)</span>c:</strong> <span class="math inline">\(524\)</span>; <strong><span class="math inline">\(\qquad\)</span>d:</strong> <span class="math inline">\(524/856\)</span></p>
<p><strong>2)</strong> What is the estimated probability that the deceased patient was not from the borough of Lambeth?</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> <span class="math inline">\(302/3920\)</span>; <strong><span class="math inline">\(\qquad\)</span>b:</strong> <span class="math inline">\(3618/3920\)</span>; <strong><span class="math inline">\(\qquad\)</span>c:</strong> <span class="math inline">\(795/3920\)</span>; <strong><span class="math inline">\(\qquad\)</span>d:</strong> <span class="math inline">\(279/3920\)</span></p>
<p><strong>3)</strong> What is the marginal probability of dying in October?</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> <span class="math inline">\(3605/100\)</span>; <strong><span class="math inline">\(\qquad\)</span>b:</strong> <span class="math inline">\(315/3920\)</span>; <strong><span class="math inline">\(\qquad\)</span>c:</strong> <span class="math inline">\(315/100\)</span>; <strong><span class="math inline">\(\qquad\)</span>d:</strong> <span class="math inline">\(3605/3920\)</span></p>
<p><strong>4)</strong> What is the marginal probability that Kent water company supplied a deceased patient?</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> <span class="math inline">\(13/191\)</span>; <strong><span class="math inline">\(\qquad\)</span>b:</strong> <span class="math inline">\(191\)</span>; <strong><span class="math inline">\(\qquad\)</span>c:</strong> <span class="math inline">\(191/3920\)</span>; <strong><span class="math inline">\(\qquad\)</span>d:</strong> <span class="math inline">\(191/100\)</span></p>
<p><strong>5)</strong> What is the probability of dying in September or from an unknown water source?
<strong><span class="math inline">\(\qquad\)</span>a:</strong> <span class="math inline">\(3680/3920\)</span>; <strong><span class="math inline">\(\qquad\)</span>b:</strong> <span class="math inline">\(3634/3920\)</span>; <strong><span class="math inline">\(\qquad\)</span>c:</strong> <span class="math inline">\(3620/3920\)</span>; <strong><span class="math inline">\(\qquad\)</span>d:</strong> <span class="math inline">\(3611/3920\)</span></p>
</div>
<div id="exercises-1" class="section level2 hasAnchor" number="3.16">
<h2><span class="header-section-number">3.16</span> Exercises<a href="probability.html#exercises-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="classical-probability-exercise-1" class="section level4 hasAnchor" number="3.16.0.1">
<h4><span class="header-section-number">3.16.0.1</span> Classical probability: Exercise 1<a href="probability.html#classical-probability-exercise-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p>Write the table of <strong>joint probability</strong> for the <strong>results</strong> of rolling two dice; In the rows write the results of the first die and in the columns the results of the second die.</p></li>
<li><p>What is the probability of drawing <span class="math inline">\((3, 4)\)</span> ? (A:1/36)</p></li>
<li><p>What is the probability of rolling <span class="math inline">\(3\)</span> and <span class="math inline">\(4\)</span> with any of the two dice? (A:2/36)</p></li>
<li><p>What is the probability of rolling <span class="math inline">\(3\)</span> on the first die or <span class="math inline">\(4\)</span> on the second? (To:11/36)</p></li>
<li><p>What is the probability of rolling <span class="math inline">\(3\)</span> or <span class="math inline">\(4\)</span> with any dice? (A:20/36)</p></li>
<li><p>Write the <strong>probability table</strong> for the result of the <strong>add</strong> of two dice. Assume that the outcome of each die is <strong>equally likely</strong>. Verify that it is:</p></li>
</ul>
<p><span class="math display">\[
P_i=
\begin{cases}
\frac{i-1}{36},&amp; i \in \{2,3,4,5,6, 7\} \\
\frac{13-i}{36},&amp; i \in \{8,9,10,11,12\} \\
\end{cases}
\]</span></p>
</div>
<div id="frequentist-probability-exercise-2" class="section level4 hasAnchor" number="3.16.0.2">
<h4><span class="header-section-number">3.16.0.2</span> Frequentist probability: Exercise 2<a href="probability.html#frequentist-probability-exercise-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The result of a randomized experiment is to measure the severity of misophonia <strong>and</strong> the state of depression of a patient.</p>
<p>Misophonia</p>
<ul>
<li>severity: <span class="math inline">\(S_M:\{M_ 0,M _1,M_2,M_3,M_4\}\)</span></li>
<li>Depression: <span class="math inline">\(S_ D:\{ D&#39;, D\}\)</span>)</li>
</ul>
<p>Write the contingency table for the absolute frequencies (<span class="math inline">\(n_{ M,D }\)</span>) for a study on a total of 123 patients in which it was observed</p>
<ul>
<li>100 individuals did not have depression.</li>
<li>No individual with misophonia 4 and without depression.</li>
<li>5 individuals with grade 1 misophonia and no depression.</li>
<li>The same number as the previous case for individuals with depression and without misophonia .</li>
<li>25 individuals without depression and grade 3 misophonia .</li>
<li>The number of misophonics without depression for grades 2 and 0 were distributed equally .</li>
<li>The number of individuals with depression and misophonia increased progressively
in multiples of three, starting at 0 individuals for grade 1.</li>
</ul>
<p>Answer the following questions:</p>
<ul>
<li>How many individuals had misophonia ? (A:83)</li>
<li>How many individuals had grade 3 misophonia ? (A:31)</li>
<li>How many individuals had grade 2 misophonia without depression? (A:35)</li>
</ul>
<p>Write down the contingency table for relative frequencies <span class="math inline">\(f_{ M,D }\)</span>. Suppose <span class="math inline">\(N\)</span> is large and the absolute frequencies <strong>estimate</strong> the probabilities <span class="math inline">\(f_{ M,D }=\hat {P}(M \cap D)\)</span>. Answer the following questions:</p>
<ul>
<li>What is the marginal probability of severity 2 misophonia ? (A: 0.3)</li>
<li>What is the probability of not being misophonic <strong>and</strong> not being depressed? (A:0.284)</li>
<li>What is the probability of being misophonic <strong>or</strong> depressed? (A: 0.715)</li>
<li>What is the probability of being misophonic <strong>and</strong> being depressed? (A: 0.146)</li>
<li>Describe in spoken language the results with probability 0.</li>
</ul>
</div>
<div id="exercise-3" class="section level4 hasAnchor" number="3.16.0.3">
<h4><span class="header-section-number">3.16.0.3</span> Exercise 3<a href="probability.html#exercise-3" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We have carried out a randomized experiment <span class="math inline">\(10\)</span> times, which consists of recording the sex and vital status of patients with some type of cancer after 10 years of diagnosis. We got the following results</p>
<p><span class="math display">\[
\begin{array}{ccc}
\mathbf{Patient}   &amp;\mathbf{Sex}   &amp; \mathbf{Status}  \\
1 &amp; male  &amp; dead \\
2 &amp;male  &amp; dead \\
3 &amp;male  &amp; dead \\
4 &amp;female&amp; alive \\
5 &amp;male  &amp; dead \\
6 &amp;female&amp; alive \\
7 &amp;female&amp; dead \\
8 &amp;female&amp; alive \\
9 &amp;male  &amp; alive \\
10 &amp;male  &amp; alive \\
\end{array}
\]</span></p>
<ul>
<li>Create the contingency table for the number (<span class="math inline">\(n_{ i,j }\)</span>) of observations of each result (<span class="math inline">\(A,B\)</span>)</li>
<li>Create the contingency table for the relative frequency (<span class="math inline">\(f_{ i,j }\)</span>) of the results</li>
<li>What is the marginal frequency of being a man? (R/0.6)</li>
<li>What is the marginal frequency of being alive? (R/0.5)</li>
<li>What is the frequency of being alive <strong>or</strong> being a woman? (R/0.6)</li>
</ul>
</div>
<div id="exercise-4" class="section level4 hasAnchor" number="3.16.0.4">
<h4><span class="header-section-number">3.16.0.4</span> Exercise 4<a href="probability.html#exercise-4" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Consider an additional gene in mice that determines ear length, with short ears being the dominant trait. Each mouse inherits alleles (<span class="math inline">\(X_m\)</span>, <span class="math inline">\(X_f\)</span>, <span class="math inline">\(Y_m\)</span>, <span class="math inline">\(Y_f\)</span>), where <span class="math inline">\(X\)</span> represents the alleles for albinism and <span class="math inline">\(Y\)</span> the alleles for ear length, inherited from the mother (subscript m) and the father (subscript f).</p>
<p>Suppose both parents are dihybridâi.e., (<span class="math inline">\(A,A&#39;,B,B&#39;\)</span>)âand therefore express the dominant phenotypes: non-albino with short ears. Show that if the traits for albinism and ear length assort independently, then there are four distinct phenotypic outcomes among the offspring that appear in a 9:3:3:1 ratio, illustrating Mendelâs second law of independent assortment.</p>
</div>
<div id="exercise-5" class="section level4 hasAnchor" number="3.16.0.5">
<h4><span class="header-section-number">3.16.0.5</span> Exercise 5<a href="probability.html#exercise-5" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Consider an additional gene in mice that determines black or grey color, with grey the dominant trait. Each mouse inherits alleles (<span class="math inline">\(X_m\)</span>, <span class="math inline">\(X_f\)</span>, <span class="math inline">\(Y_m\)</span>, <span class="math inline">\(Y_f\)</span>), where <span class="math inline">\(X\)</span> represents the alleles for albinism and <span class="math inline">\(Y\)</span> the alleles for grey and black colors, inherited from the mother (subscript m) and the father (subscript f).</p>
<p>Suppose both parents are dihybridâi.e., (<span class="math inline">\(A,A&#39;,B,B&#39;\)</span>)âand therefore express the dominant phenotype: non-albino with grey color. Show that if the albinism removes pigmentation, then there are three distinct phenotypic outcomes among the offspring that appear in a 9:3:4 ratio, illustrating an apistatic model of inheritance.</p>
</div>
<div id="exercise-6" class="section level4 hasAnchor" number="3.16.0.6">
<h4><span class="header-section-number">3.16.0.6</span> Exercise 6<a href="probability.html#exercise-6" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p>From the second form of the addition rule, obtain the first and the third form.</p></li>
<li><p>What is the third form addition rule for the probability of three events <span class="math inline">\(P(A \cup B \cup C)\)</span>?</p></li>
</ul>
</div>
</div>
<div id="practice-1" class="section level2 hasAnchor" number="3.17">
<h2><span class="header-section-number">3.17</span> Practice<a href="probability.html#practice-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Load misophonia data <code><a href="https://alejandro-isglobal.github.io/SDA/data/Misophonia.txt" class="uri">https://alejandro-isglobal.github.io/SDA/data/Misophonia.txt</a></code></p>
<ul>
<li><p>Compute the contingency table of absolute frequencies for misophonia diagnosis (Misophonia severity) and depression (Depression)</p></li>
<li><p>Compute the contingency table of relative frequencies for misophonia diagnosis and depression</p></li>
<li><p>Compare the differences with exercise 2.</p></li>
</ul>
<p><a href="https://colab.research.google.com/drive/1ncTaoBgskCJcBIb0-PdnbUFr_AKU0XRF?usp=sharing">Solutions</a></p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-kolmogorov2013foundations" class="csl-entry">
Kolmogorov, Andrey N. 2013. <em>Foundations of the Theory of Probability</em>. Reprint edition. Mineola, NY: Dover Publications.
</div>
<div id="ref-mendel1901experiments" class="csl-entry">
Mendel, Gregor. 1901. <em>Experiments in Plant Hybridisation</em>. Translated by William Bateson. Cambridge: Cambridge University Press.
</div>
<div id="ref-popper2002logic" class="csl-entry">
Popper, Karl. 2002. <em>The Logic of Scientific Discovery</em>. Routledge Classics. London: Routledge.
</div>
<div id="ref-snow1855mode" class="csl-entry">
Snow, John. 1855. <em>On the Mode of Communication of Cholera</em>. London: John Churchill.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="data-description.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="conditional-probability.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/02-Probability.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
