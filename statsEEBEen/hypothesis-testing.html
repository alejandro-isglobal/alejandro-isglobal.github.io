<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 14 Hypothesis testing | EEBE stats</title>
  <meta name="description" content="EEBE" />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 14 Hypothesis testing | EEBE stats" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="EEBE" />
  <meta name="github-repo" content="alejandro-isglobal/master" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 14 Hypothesis testing | EEBE stats" />
  
  <meta name="twitter:description" content="EEBE" />
  

<meta name="author" content="Alejandro Caceres" />


<meta name="date" content="2023-12-10" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="interval-estimation.html"/>
<link rel="next" href="solutions-to-questions.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">EEBE</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Objective</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#recommended-reading"><i class="fa fa-check"></i><b>1.1</b> Recommended reading</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-description.html"><a href="data-description.html"><i class="fa fa-check"></i><b>2</b> Data description</a>
<ul>
<li class="chapter" data-level="2.1" data-path="data-description.html"><a href="data-description.html#scientific-method"><i class="fa fa-check"></i><b>2.1</b> Scientific method</a></li>
<li class="chapter" data-level="2.2" data-path="data-description.html"><a href="data-description.html#statistics"><i class="fa fa-check"></i><b>2.2</b> Statistics</a></li>
<li class="chapter" data-level="2.3" data-path="data-description.html"><a href="data-description.html#data"><i class="fa fa-check"></i><b>2.3</b> Data</a></li>
<li class="chapter" data-level="2.4" data-path="data-description.html"><a href="data-description.html#result-types"><i class="fa fa-check"></i><b>2.4</b> Result types</a></li>
<li class="chapter" data-level="2.5" data-path="data-description.html"><a href="data-description.html#random-experiments"><i class="fa fa-check"></i><b>2.5</b> Random experiments</a></li>
<li class="chapter" data-level="2.6" data-path="data-description.html"><a href="data-description.html#absolute-frequencies"><i class="fa fa-check"></i><b>2.6</b> Absolute frequencies</a></li>
<li class="chapter" data-level="2.7" data-path="data-description.html"><a href="data-description.html#relative-frequencies"><i class="fa fa-check"></i><b>2.7</b> Relative frequencies</a></li>
<li class="chapter" data-level="2.8" data-path="data-description.html"><a href="data-description.html#bar-chart"><i class="fa fa-check"></i><b>2.8</b> Bar chart</a></li>
<li class="chapter" data-level="2.9" data-path="data-description.html"><a href="data-description.html#pie-chart-pie"><i class="fa fa-check"></i><b>2.9</b> Pie chart (pie)</a></li>
<li class="chapter" data-level="2.10" data-path="data-description.html"><a href="data-description.html#ordinal-categorical-variables"><i class="fa fa-check"></i><b>2.10</b> Ordinal categorical variables</a></li>
<li class="chapter" data-level="2.11" data-path="data-description.html"><a href="data-description.html#accumulated-absolute-and-relative-frequencies"><i class="fa fa-check"></i><b>2.11</b> Accumulated absolute and relative frequencies</a></li>
<li class="chapter" data-level="2.12" data-path="data-description.html"><a href="data-description.html#cumulative-frequency-graph"><i class="fa fa-check"></i><b>2.12</b> Cumulative frequency graph</a></li>
<li class="chapter" data-level="2.13" data-path="data-description.html"><a href="data-description.html#numeric-variables"><i class="fa fa-check"></i><b>2.13</b> Numeric variables</a></li>
<li class="chapter" data-level="2.14" data-path="data-description.html"><a href="data-description.html#transforming-continuous-data"><i class="fa fa-check"></i><b>2.14</b> Transforming continuous data</a></li>
<li class="chapter" data-level="2.15" data-path="data-description.html"><a href="data-description.html#frequency-table-for-a-continuous-variable"><i class="fa fa-check"></i><b>2.15</b> Frequency table for a continuous variable</a></li>
<li class="chapter" data-level="2.16" data-path="data-description.html"><a href="data-description.html#histogram"><i class="fa fa-check"></i><b>2.16</b> Histogram</a></li>
<li class="chapter" data-level="2.17" data-path="data-description.html"><a href="data-description.html#cumulative-frequency-graph-1"><i class="fa fa-check"></i><b>2.17</b> Cumulative frequency graph</a></li>
<li class="chapter" data-level="2.18" data-path="data-description.html"><a href="data-description.html#summary-statistics"><i class="fa fa-check"></i><b>2.18</b> Summary Statistics</a></li>
<li class="chapter" data-level="2.19" data-path="data-description.html"><a href="data-description.html#average-sample-mean"><i class="fa fa-check"></i><b>2.19</b> Average (sample mean)</a></li>
<li class="chapter" data-level="2.20" data-path="data-description.html"><a href="data-description.html#median"><i class="fa fa-check"></i><b>2.20</b> Median</a></li>
<li class="chapter" data-level="2.21" data-path="data-description.html"><a href="data-description.html#dispersion"><i class="fa fa-check"></i><b>2.21</b> Dispersion</a></li>
<li class="chapter" data-level="2.22" data-path="data-description.html"><a href="data-description.html#sample-variance"><i class="fa fa-check"></i><b>2.22</b> Sample variance</a></li>
<li class="chapter" data-level="2.23" data-path="data-description.html"><a href="data-description.html#interquartile-range-iqr"><i class="fa fa-check"></i><b>2.23</b> Interquartile range (IQR)</a></li>
<li class="chapter" data-level="2.24" data-path="data-description.html"><a href="data-description.html#boxplot"><i class="fa fa-check"></i><b>2.24</b> Boxplot</a></li>
<li class="chapter" data-level="2.25" data-path="data-description.html"><a href="data-description.html#questions"><i class="fa fa-check"></i><b>2.25</b> Questions</a></li>
<li class="chapter" data-level="2.26" data-path="data-description.html"><a href="data-description.html#exercises"><i class="fa fa-check"></i><b>2.26</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>3</b> Probability</a>
<ul>
<li class="chapter" data-level="3.1" data-path="probability.html"><a href="probability.html#random-experiments-1"><i class="fa fa-check"></i><b>3.1</b> Random experiments</a></li>
<li class="chapter" data-level="3.2" data-path="probability.html"><a href="probability.html#measurement-probability"><i class="fa fa-check"></i><b>3.2</b> Measurement probability</a></li>
<li class="chapter" data-level="3.3" data-path="probability.html"><a href="probability.html#classical-probability"><i class="fa fa-check"></i><b>3.3</b> Classical probability</a></li>
<li class="chapter" data-level="3.4" data-path="probability.html"><a href="probability.html#relative-frequencies-1"><i class="fa fa-check"></i><b>3.4</b> Relative frequencies</a></li>
<li class="chapter" data-level="3.5" data-path="probability.html"><a href="probability.html#relative-frequencies-at-infinity"><i class="fa fa-check"></i><b>3.5</b> Relative frequencies at infinity</a></li>
<li class="chapter" data-level="3.6" data-path="probability.html"><a href="probability.html#frequentist-probability"><i class="fa fa-check"></i><b>3.6</b> Frequentist probability</a></li>
<li class="chapter" data-level="3.7" data-path="probability.html"><a href="probability.html#classical-and-frequentist-probabilities"><i class="fa fa-check"></i><b>3.7</b> Classical and frequentist probabilities</a></li>
<li class="chapter" data-level="3.8" data-path="probability.html"><a href="probability.html#definition-of-probability"><i class="fa fa-check"></i><b>3.8</b> Definition of probability</a></li>
<li class="chapter" data-level="3.9" data-path="probability.html"><a href="probability.html#probabilities-table"><i class="fa fa-check"></i><b>3.9</b> Probabilities Table</a></li>
<li class="chapter" data-level="3.10" data-path="probability.html"><a href="probability.html#sample-space"><i class="fa fa-check"></i><b>3.10</b> Sample space</a></li>
<li class="chapter" data-level="3.11" data-path="probability.html"><a href="probability.html#events"><i class="fa fa-check"></i><b>3.11</b> Events</a></li>
<li class="chapter" data-level="3.12" data-path="probability.html"><a href="probability.html#algebra-of-events"><i class="fa fa-check"></i><b>3.12</b> Algebra of events</a></li>
<li class="chapter" data-level="3.13" data-path="probability.html"><a href="probability.html#mutually-exclusive-results"><i class="fa fa-check"></i><b>3.13</b> Mutually exclusive results</a></li>
<li class="chapter" data-level="3.14" data-path="probability.html"><a href="probability.html#joint-probabilities"><i class="fa fa-check"></i><b>3.14</b> Joint probabilities</a></li>
<li class="chapter" data-level="3.15" data-path="probability.html"><a href="probability.html#contingency-table"><i class="fa fa-check"></i><b>3.15</b> Contingency table</a></li>
<li class="chapter" data-level="3.16" data-path="probability.html"><a href="probability.html#the-addition-rule"><i class="fa fa-check"></i><b>3.16</b> The addition rule:</a></li>
<li class="chapter" data-level="3.17" data-path="probability.html"><a href="probability.html#questions-1"><i class="fa fa-check"></i><b>3.17</b> Questions</a></li>
<li class="chapter" data-level="3.18" data-path="probability.html"><a href="probability.html#exercises-1"><i class="fa fa-check"></i><b>3.18</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="conditional-probability.html"><a href="conditional-probability.html"><i class="fa fa-check"></i><b>4</b> Conditional probability</a>
<ul>
<li class="chapter" data-level="4.1" data-path="conditional-probability.html"><a href="conditional-probability.html#joint-probability"><i class="fa fa-check"></i><b>4.1</b> Joint probability</a></li>
<li class="chapter" data-level="4.2" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-independence"><i class="fa fa-check"></i><b>4.2</b> Statistical independence</a></li>
<li class="chapter" data-level="4.3" data-path="conditional-probability.html"><a href="conditional-probability.html#the-conditional-probability"><i class="fa fa-check"></i><b>4.3</b> The conditional probability</a></li>
<li class="chapter" data-level="4.4" data-path="conditional-probability.html"><a href="conditional-probability.html#conditional-contingency-table"><i class="fa fa-check"></i><b>4.4</b> Conditional contingency table</a></li>
<li class="chapter" data-level="4.5" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-independence-1"><i class="fa fa-check"></i><b>4.5</b> Statistical independence</a></li>
<li class="chapter" data-level="4.6" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-dependency"><i class="fa fa-check"></i><b>4.6</b> Statistical dependency</a></li>
<li class="chapter" data-level="4.7" data-path="conditional-probability.html"><a href="conditional-probability.html#diagnostic-test"><i class="fa fa-check"></i><b>4.7</b> Diagnostic test</a></li>
<li class="chapter" data-level="4.8" data-path="conditional-probability.html"><a href="conditional-probability.html#inverse-probabilities"><i class="fa fa-check"></i><b>4.8</b> Inverse probabilities</a></li>
<li class="chapter" data-level="4.9" data-path="conditional-probability.html"><a href="conditional-probability.html#bayes-theorem"><i class="fa fa-check"></i><b>4.9</b> Bayes’ Theorem</a></li>
<li class="chapter" data-level="4.10" data-path="conditional-probability.html"><a href="conditional-probability.html#questions-2"><i class="fa fa-check"></i><b>4.10</b> Questions</a></li>
<li class="chapter" data-level="4.11" data-path="conditional-probability.html"><a href="conditional-probability.html#exercises-2"><i class="fa fa-check"></i><b>4.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html"><i class="fa fa-check"></i><b>5</b> Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="5.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#objective-1"><i class="fa fa-check"></i><b>5.1</b> Objective</a></li>
<li class="chapter" data-level="5.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#relative-frequencies-2"><i class="fa fa-check"></i><b>5.2</b> Relative frequencies</a></li>
<li class="chapter" data-level="5.3" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#random-variable"><i class="fa fa-check"></i><b>5.3</b> Random variable</a></li>
<li class="chapter" data-level="5.4" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#events-of-observing-a-random-variable"><i class="fa fa-check"></i><b>5.4</b> Events of observing a random variable</a></li>
<li class="chapter" data-level="5.5" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-of-random-variables"><i class="fa fa-check"></i><b>5.5</b> Probability of random variables</a></li>
<li class="chapter" data-level="5.6" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-functions"><i class="fa fa-check"></i><b>5.6</b> Probability functions</a></li>
<li class="chapter" data-level="5.7" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-functions-1"><i class="fa fa-check"></i><b>5.7</b> Probability functions</a></li>
<li class="chapter" data-level="5.8" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probabilities-and-relative-frequencies"><i class="fa fa-check"></i><b>5.8</b> Probabilities and relative frequencies</a></li>
<li class="chapter" data-level="5.9" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#mean-or-expected-value"><i class="fa fa-check"></i><b>5.9</b> Mean or expected value</a></li>
<li class="chapter" data-level="5.10" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#variance"><i class="fa fa-check"></i><b>5.10</b> Variance</a></li>
<li class="chapter" data-level="5.11" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-functions-for-functions-of-x"><i class="fa fa-check"></i><b>5.11</b> Probability functions for functions of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="5.12" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-distribution"><i class="fa fa-check"></i><b>5.12</b> Probability distribution</a></li>
<li class="chapter" data-level="5.13" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-function-and-probability-distribution"><i class="fa fa-check"></i><b>5.13</b> Probability function and probability distribution</a></li>
<li class="chapter" data-level="5.14" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#quantiles"><i class="fa fa-check"></i><b>5.14</b> Quantiles</a></li>
<li class="chapter" data-level="5.15" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#summary"><i class="fa fa-check"></i><b>5.15</b> Summary</a></li>
<li class="chapter" data-level="5.16" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#questions-3"><i class="fa fa-check"></i><b>5.16</b> Questions</a></li>
<li class="chapter" data-level="5.17" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#exercises-3"><i class="fa fa-check"></i><b>5.17</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="continous-random-variables.html"><a href="continous-random-variables.html"><i class="fa fa-check"></i><b>6</b> Continous Random Variables</a>
<ul>
<li class="chapter" data-level="6.1" data-path="continous-random-variables.html"><a href="continous-random-variables.html#objective-2"><i class="fa fa-check"></i><b>6.1</b> Objective</a></li>
<li class="chapter" data-level="6.2" data-path="continous-random-variables.html"><a href="continous-random-variables.html#continuous-random-variables"><i class="fa fa-check"></i><b>6.2</b> Continuous random variables</a></li>
<li class="chapter" data-level="6.3" data-path="continous-random-variables.html"><a href="continous-random-variables.html#relative-frequencies-3"><i class="fa fa-check"></i><b>6.3</b> relative frequencies</a></li>
<li class="chapter" data-level="6.4" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-density-function"><i class="fa fa-check"></i><b>6.4</b> probability density function</a></li>
<li class="chapter" data-level="6.5" data-path="continous-random-variables.html"><a href="continous-random-variables.html#total-area-under-the-curve"><i class="fa fa-check"></i><b>6.5</b> Total area under the curve</a></li>
<li class="chapter" data-level="6.6" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probabilities-of-continous-variables"><i class="fa fa-check"></i><b>6.6</b> Probabilities of continous variables</a></li>
<li class="chapter" data-level="6.7" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-distribution-1"><i class="fa fa-check"></i><b>6.7</b> Probability distribution</a></li>
<li class="chapter" data-level="6.8" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-plots"><i class="fa fa-check"></i><b>6.8</b> Probability plots</a></li>
<li class="chapter" data-level="6.9" data-path="continous-random-variables.html"><a href="continous-random-variables.html#mean"><i class="fa fa-check"></i><b>6.9</b> Mean</a></li>
<li class="chapter" data-level="6.10" data-path="continous-random-variables.html"><a href="continous-random-variables.html#variance-1"><i class="fa fa-check"></i><b>6.10</b> Variance</a></li>
<li class="chapter" data-level="6.11" data-path="continous-random-variables.html"><a href="continous-random-variables.html#functions-of-x"><i class="fa fa-check"></i><b>6.11</b> Functions of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="6.12" data-path="continous-random-variables.html"><a href="continous-random-variables.html#exercises-4"><i class="fa fa-check"></i><b>6.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html"><i class="fa fa-check"></i><b>7</b> Discrete Probability Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#objective-3"><i class="fa fa-check"></i><b>7.1</b> Objective</a></li>
<li class="chapter" data-level="7.2" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#probability-mass-function"><i class="fa fa-check"></i><b>7.2</b> Probability mass function</a></li>
<li class="chapter" data-level="7.3" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#probability-model"><i class="fa fa-check"></i><b>7.3</b> Probability model</a></li>
<li class="chapter" data-level="7.4" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#parametric-models"><i class="fa fa-check"></i><b>7.4</b> Parametric models</a></li>
<li class="chapter" data-level="7.5" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#uniform-distribution-one-parameter"><i class="fa fa-check"></i><b>7.5</b> Uniform distribution (one parameter)</a></li>
<li class="chapter" data-level="7.6" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#uniform-distribution-two-parameters"><i class="fa fa-check"></i><b>7.6</b> Uniform distribution (two parameters)</a></li>
<li class="chapter" data-level="7.7" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#bernoulli-trial"><i class="fa fa-check"></i><b>7.7</b> Bernoulli trial</a></li>
<li class="chapter" data-level="7.8" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#binomial-experiment"><i class="fa fa-check"></i><b>7.8</b> Binomial experiment</a></li>
<li class="chapter" data-level="7.9" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#binomial-probability-function"><i class="fa fa-check"></i><b>7.9</b> Binomial probability function</a></li>
<li class="chapter" data-level="7.10" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#negative-binomial-probability-function"><i class="fa fa-check"></i><b>7.10</b> Negative binomial probability function</a></li>
<li class="chapter" data-level="7.11" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#geometric-distribution"><i class="fa fa-check"></i><b>7.11</b> Geometric distribution</a></li>
<li class="chapter" data-level="7.12" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#hypergeometric-model"><i class="fa fa-check"></i><b>7.12</b> Hypergeometric model</a></li>
<li class="chapter" data-level="7.13" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#questions-4"><i class="fa fa-check"></i><b>7.13</b> Questions</a></li>
<li class="chapter" data-level="7.14" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#exercises-5"><i class="fa fa-check"></i><b>7.14</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html"><i class="fa fa-check"></i><b>8</b> Poisson and Exponential Models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#objective-4"><i class="fa fa-check"></i><b>8.1</b> Objective</a></li>
<li class="chapter" data-level="8.2" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#discrete-probability-models-1"><i class="fa fa-check"></i><b>8.2</b> Discrete probability models</a></li>
<li class="chapter" data-level="8.3" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#poissson-experiment"><i class="fa fa-check"></i><b>8.3</b> Poissson experiment</a></li>
<li class="chapter" data-level="8.4" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#poisson-probability-mass-function"><i class="fa fa-check"></i><b>8.4</b> Poisson probability mass function</a></li>
<li class="chapter" data-level="8.5" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#continuous-probability-models"><i class="fa fa-check"></i><b>8.5</b> Continuous probability models</a></li>
<li class="chapter" data-level="8.6" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-process"><i class="fa fa-check"></i><b>8.6</b> Exponential process</a></li>
<li class="chapter" data-level="8.7" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-probability-density"><i class="fa fa-check"></i><b>8.7</b> Exponential probability density</a></li>
<li class="chapter" data-level="8.8" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-distribution"><i class="fa fa-check"></i><b>8.8</b> Exponential Distribution</a></li>
<li class="chapter" data-level="8.9" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#questions-5"><i class="fa fa-check"></i><b>8.9</b> Questions</a></li>
<li class="chapter" data-level="8.10" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exercises-6"><i class="fa fa-check"></i><b>8.10</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="normal-distribution.html"><a href="normal-distribution.html"><i class="fa fa-check"></i><b>9</b> Normal Distribution</a>
<ul>
<li class="chapter" data-level="9.1" data-path="normal-distribution.html"><a href="normal-distribution.html#objective-5"><i class="fa fa-check"></i><b>9.1</b> Objective</a></li>
<li class="chapter" data-level="9.2" data-path="normal-distribution.html"><a href="normal-distribution.html#history"><i class="fa fa-check"></i><b>9.2</b> History</a></li>
<li class="chapter" data-level="9.3" data-path="normal-distribution.html"><a href="normal-distribution.html#normal-density"><i class="fa fa-check"></i><b>9.3</b> normal density</a></li>
<li class="chapter" data-level="9.4" data-path="normal-distribution.html"><a href="normal-distribution.html#definition"><i class="fa fa-check"></i><b>9.4</b> Definition</a></li>
<li class="chapter" data-level="9.5" data-path="normal-distribution.html"><a href="normal-distribution.html#probability-distribution-2"><i class="fa fa-check"></i><b>9.5</b> Probability distribution</a></li>
<li class="chapter" data-level="9.6" data-path="normal-distribution.html"><a href="normal-distribution.html#standard-normal-density"><i class="fa fa-check"></i><b>9.6</b> Standard normal density</a></li>
<li class="chapter" data-level="9.7" data-path="normal-distribution.html"><a href="normal-distribution.html#standard-distribution"><i class="fa fa-check"></i><b>9.7</b> Standard distribution</a></li>
<li class="chapter" data-level="9.8" data-path="normal-distribution.html"><a href="normal-distribution.html#standardization"><i class="fa fa-check"></i><b>9.8</b> Standardization</a></li>
<li class="chapter" data-level="9.9" data-path="normal-distribution.html"><a href="normal-distribution.html#summary-of-probability-models"><i class="fa fa-check"></i><b>9.9</b> Summary of probability models</a></li>
<li class="chapter" data-level="9.10" data-path="normal-distribution.html"><a href="normal-distribution.html#r-functions-of-probability-models"><i class="fa fa-check"></i><b>9.10</b> R functions of probability models</a></li>
<li class="chapter" data-level="9.11" data-path="normal-distribution.html"><a href="normal-distribution.html#questions-6"><i class="fa fa-check"></i><b>9.11</b> Questions</a></li>
<li class="chapter" data-level="9.12" data-path="normal-distribution.html"><a href="normal-distribution.html#exercises-7"><i class="fa fa-check"></i><b>9.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="sampling-distributions.html"><a href="sampling-distributions.html"><i class="fa fa-check"></i><b>10</b> Sampling distributions</a>
<ul>
<li class="chapter" data-level="10.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#objective-6"><i class="fa fa-check"></i><b>10.1</b> Objective</a></li>
<li class="chapter" data-level="10.2" data-path="sampling-distributions.html"><a href="sampling-distributions.html#aleatory-sample"><i class="fa fa-check"></i><b>10.2</b> Aleatory sample</a></li>
<li class="chapter" data-level="10.3" data-path="sampling-distributions.html"><a href="sampling-distributions.html#calculation-of-probabilities"><i class="fa fa-check"></i><b>10.3</b> Calculation of probabilities</a></li>
<li class="chapter" data-level="10.4" data-path="sampling-distributions.html"><a href="sampling-distributions.html#parameter-estimation"><i class="fa fa-check"></i><b>10.4</b> Parameter estimation</a></li>
<li class="chapter" data-level="10.5" data-path="sampling-distributions.html"><a href="sampling-distributions.html#margin-of-error-of-estimates"><i class="fa fa-check"></i><b>10.5</b> Margin of error of estimates</a></li>
<li class="chapter" data-level="10.6" data-path="sampling-distributions.html"><a href="sampling-distributions.html#inference"><i class="fa fa-check"></i><b>10.6</b> Inference</a></li>
<li class="chapter" data-level="10.7" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-mean-distribution"><i class="fa fa-check"></i><b>10.7</b> Sample mean distribution</a>
<ul>
<li class="chapter" data-level="10.7.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-sum"><i class="fa fa-check"></i><b>10.7.1</b> Sample sum</a></li>
</ul></li>
<li class="chapter" data-level="10.8" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-variance-1"><i class="fa fa-check"></i><b>10.8</b> Sample variance</a></li>
<li class="chapter" data-level="10.9" data-path="sampling-distributions.html"><a href="sampling-distributions.html#probabilities-of-the-sample-variance"><i class="fa fa-check"></i><b>10.9</b> Probabilities of the sample variance</a></li>
<li class="chapter" data-level="10.10" data-path="sampling-distributions.html"><a href="sampling-distributions.html#chi2-statistic"><i class="fa fa-check"></i><b>10.10</b> <span class="math inline">\(\chi^2\)</span>-statistic</a></li>
<li class="chapter" data-level="10.11" data-path="sampling-distributions.html"><a href="sampling-distributions.html#questions-7"><i class="fa fa-check"></i><b>10.11</b> Questions</a></li>
<li class="chapter" data-level="10.12" data-path="sampling-distributions.html"><a href="sampling-distributions.html#exercises-8"><i class="fa fa-check"></i><b>10.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html"><i class="fa fa-check"></i><b>11</b> Central limit theorem</a>
<ul>
<li class="chapter" data-level="11.1" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#objective-7"><i class="fa fa-check"></i><b>11.1</b> Objective</a></li>
<li class="chapter" data-level="11.2" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#margin-of-error"><i class="fa fa-check"></i><b>11.2</b> Margin of error</a></li>
<li class="chapter" data-level="11.3" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#example-cables"><i class="fa fa-check"></i><b>11.3</b> Example (Cables)</a></li>
<li class="chapter" data-level="11.4" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#central-limit-theorem-1"><i class="fa fa-check"></i><b>11.4</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="11.5" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#sample-sum-and-clt"><i class="fa fa-check"></i><b>11.5</b> Sample sum and CLT</a></li>
<li class="chapter" data-level="11.6" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#questions-8"><i class="fa fa-check"></i><b>11.6</b> Questions</a></li>
<li class="chapter" data-level="11.7" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#exercises-9"><i class="fa fa-check"></i><b>11.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="maximum-likelihood-and-method-of-moments.html"><a href="maximum-likelihood-and-method-of-moments.html"><i class="fa fa-check"></i><b>12</b> Maximum likelihood and Method of Moments</a>
<ul>
<li class="chapter" data-level="12.1" data-path="maximum-likelihood-and-method-of-moments.html"><a href="maximum-likelihood-and-method-of-moments.html#objective-8"><i class="fa fa-check"></i><b>12.1</b> Objective</a></li>
<li class="chapter" data-level="12.2" data-path="maximum-likelihood-and-method-of-moments.html"><a href="maximum-likelihood-and-method-of-moments.html#statistic"><i class="fa fa-check"></i><b>12.2</b> Statistic</a></li>
<li class="chapter" data-level="12.3" data-path="maximum-likelihood-and-method-of-moments.html"><a href="maximum-likelihood-and-method-of-moments.html#properties"><i class="fa fa-check"></i><b>12.3</b> Properties</a></li>
<li class="chapter" data-level="12.4" data-path="maximum-likelihood-and-method-of-moments.html"><a href="maximum-likelihood-and-method-of-moments.html#maximum-likelihood"><i class="fa fa-check"></i><b>12.4</b> Maximum likelihood</a></li>
<li class="chapter" data-level="12.5" data-path="maximum-likelihood-and-method-of-moments.html"><a href="maximum-likelihood-and-method-of-moments.html#maximum-likelihood-1"><i class="fa fa-check"></i><b>12.5</b> Maximum likelihood</a></li>
<li class="chapter" data-level="12.6" data-path="maximum-likelihood-and-method-of-moments.html"><a href="maximum-likelihood-and-method-of-moments.html#method-of-moments"><i class="fa fa-check"></i><b>12.6</b> Method of Moments</a></li>
<li class="chapter" data-level="12.7" data-path="maximum-likelihood-and-method-of-moments.html"><a href="maximum-likelihood-and-method-of-moments.html#method-of-moments-for-several-parameters"><i class="fa fa-check"></i><b>12.7</b> Method of Moments for several parameters</a></li>
<li class="chapter" data-level="12.8" data-path="maximum-likelihood-and-method-of-moments.html"><a href="maximum-likelihood-and-method-of-moments.html#questions-9"><i class="fa fa-check"></i><b>12.8</b> Questions</a></li>
<li class="chapter" data-level="12.9" data-path="maximum-likelihood-and-method-of-moments.html"><a href="maximum-likelihood-and-method-of-moments.html#exercises-10"><i class="fa fa-check"></i><b>12.9</b> Exercises</a></li>
<li class="chapter" data-level="12.10" data-path="maximum-likelihood-and-method-of-moments.html"><a href="maximum-likelihood-and-method-of-moments.html#method-of-moments-1"><i class="fa fa-check"></i><b>12.10</b> Method of moments</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="interval-estimation.html"><a href="interval-estimation.html"><i class="fa fa-check"></i><b>13</b> Interval estimation</a>
<ul>
<li class="chapter" data-level="13.1" data-path="interval-estimation.html"><a href="interval-estimation.html#objective-9"><i class="fa fa-check"></i><b>13.1</b> Objective</a></li>
<li class="chapter" data-level="13.2" data-path="interval-estimation.html"><a href="interval-estimation.html#estimation-of-the-mean"><i class="fa fa-check"></i><b>13.2</b> Estimation of the mean</a></li>
<li class="chapter" data-level="13.3" data-path="interval-estimation.html"><a href="interval-estimation.html#margin-of-error-1"><i class="fa fa-check"></i><b>13.3</b> Margin of error</a></li>
<li class="chapter" data-level="13.4" data-path="interval-estimation.html"><a href="interval-estimation.html#interval-estimation-for-the-mean"><i class="fa fa-check"></i><b>13.4</b> Interval estimation for the mean</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="interval-estimation.html"><a href="interval-estimation.html#case-1-known-variance"><i class="fa fa-check"></i><b>13.4.1</b> Case 1 (known variance)</a></li>
<li class="chapter" data-level="13.4.2" data-path="interval-estimation.html"><a href="interval-estimation.html#confidence-level"><i class="fa fa-check"></i><b>13.4.2</b> Confidence level</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="interval-estimation.html"><a href="interval-estimation.html#marging-of-error-for-unkown-variance"><i class="fa fa-check"></i><b>13.5</b> Marging of error for unkown variance</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="interval-estimation.html"><a href="interval-estimation.html#theorem-t-statistic"><i class="fa fa-check"></i><b>13.5.1</b> Theorem (T-statistic)</a></li>
<li class="chapter" data-level="13.5.2" data-path="interval-estimation.html"><a href="interval-estimation.html#case-2-unknown-variance"><i class="fa fa-check"></i><b>13.5.2</b> Case 2 (unknown variance)</a></li>
</ul></li>
<li class="chapter" data-level="13.6" data-path="interval-estimation.html"><a href="interval-estimation.html#estimation-of-proportions"><i class="fa fa-check"></i><b>13.6</b> Estimation of proportions</a>
<ul>
<li class="chapter" data-level="13.6.1" data-path="interval-estimation.html"><a href="interval-estimation.html#case-3-proportions"><i class="fa fa-check"></i><b>13.6.1</b> Case 3 (proportions)</a></li>
</ul></li>
<li class="chapter" data-level="13.7" data-path="interval-estimation.html"><a href="interval-estimation.html#estimation-of-the-variance"><i class="fa fa-check"></i><b>13.7</b> Estimation of the variance</a></li>
<li class="chapter" data-level="13.8" data-path="interval-estimation.html"><a href="interval-estimation.html#confidence-interval-for-the-variance"><i class="fa fa-check"></i><b>13.8</b> Confidence interval for the variance</a>
<ul>
<li class="chapter" data-level="13.8.1" data-path="interval-estimation.html"><a href="interval-estimation.html#theorem-chi2"><i class="fa fa-check"></i><b>13.8.1</b> Theorem (<span class="math inline">\(\chi^2\)</span>):</a></li>
<li class="chapter" data-level="13.8.2" data-path="interval-estimation.html"><a href="interval-estimation.html#confidence-interval-for-the-variance-1"><i class="fa fa-check"></i><b>13.8.2</b> Confidence interval for the variance</a></li>
<li class="chapter" data-level="13.8.3" data-path="interval-estimation.html"><a href="interval-estimation.html#case-4-variance"><i class="fa fa-check"></i><b>13.8.3</b> Case 4 (variance)</a></li>
</ul></li>
<li class="chapter" data-level="13.9" data-path="interval-estimation.html"><a href="interval-estimation.html#questions-10"><i class="fa fa-check"></i><b>13.9</b> Questions</a></li>
<li class="chapter" data-level="13.10" data-path="interval-estimation.html"><a href="interval-estimation.html#exercises-11"><i class="fa fa-check"></i><b>13.10</b> Exercises</a></li>
<li class="chapter" data-level="13.11" data-path="interval-estimation.html"><a href="interval-estimation.html#practice"><i class="fa fa-check"></i><b>13.11</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>14</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="14.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#objective-10"><i class="fa fa-check"></i><b>14.1</b> Objective</a></li>
<li class="chapter" data-level="14.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis"><i class="fa fa-check"></i><b>14.2</b> Hypothesis</a></li>
<li class="chapter" data-level="14.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-1"><i class="fa fa-check"></i><b>14.3</b> Hypothesis testing</a></li>
<li class="chapter" data-level="14.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#case-1-known-variance-1"><i class="fa fa-check"></i><b>14.4</b> Case 1 (known variance)</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-with-a-confidence-interval"><i class="fa fa-check"></i><b>14.4.1</b> Hypothesis test with a confidence interval</a></li>
<li class="chapter" data-level="14.4.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-with-acceptancerejection-zones"><i class="fa fa-check"></i><b>14.4.2</b> Hypothesis test with acceptance/rejection zones</a></li>
<li class="chapter" data-level="14.4.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-with-a-p-value"><i class="fa fa-check"></i><b>14.4.3</b> Hypothesis test with a P-value</a></li>
<li class="chapter" data-level="14.4.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#upper-tail-hypothesis"><i class="fa fa-check"></i><b>14.4.4</b> Upper tail hypothesis</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#case-2-unknown-variance-1"><i class="fa fa-check"></i><b>14.5</b> Case 2 (unknown variance)</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#lower-tail-hypothesis"><i class="fa fa-check"></i><b>14.5.1</b> Lower tail hypothesis</a></li>
<li class="chapter" data-level="14.5.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-with-large-n-and-any-distribution"><i class="fa fa-check"></i><b>14.5.2</b> Hypothesis testing with large n and any distribution</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#case-3-proportions-1"><i class="fa fa-check"></i><b>14.6</b> Case 3 (proportions)</a></li>
<li class="chapter" data-level="14.7" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#case-4-variances"><i class="fa fa-check"></i><b>14.7</b> Case 4 (variances)</a></li>
<li class="chapter" data-level="14.8" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#errors-in-hypothesis-testing"><i class="fa fa-check"></i><b>14.8</b> Errors in hypothesis testing</a></li>
<li class="chapter" data-level="14.9" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#exercises-12"><i class="fa fa-check"></i><b>14.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="solutions-to-questions.html"><a href="solutions-to-questions.html"><i class="fa fa-check"></i><b>15</b> Solutions to Questions</a>
<ul>
<li class="chapter" data-level="15.1" data-path="solutions-to-questions.html"><a href="solutions-to-questions.html#chapter-2"><i class="fa fa-check"></i><b>15.1</b> Chapter 2</a></li>
<li class="chapter" data-level="15.2" data-path="solutions-to-questions.html"><a href="solutions-to-questions.html#chapter-3"><i class="fa fa-check"></i><b>15.2</b> Chapter 3</a></li>
<li class="chapter" data-level="15.3" data-path="solutions-to-questions.html"><a href="solutions-to-questions.html#chapter-4"><i class="fa fa-check"></i><b>15.3</b> Chapter 4</a></li>
<li class="chapter" data-level="15.4" data-path="solutions-to-questions.html"><a href="solutions-to-questions.html#chapter-5"><i class="fa fa-check"></i><b>15.4</b> Chapter 5</a></li>
<li class="chapter" data-level="15.5" data-path="solutions-to-questions.html"><a href="solutions-to-questions.html#chapter-7"><i class="fa fa-check"></i><b>15.5</b> Chapter 7</a></li>
<li class="chapter" data-level="15.6" data-path="solutions-to-questions.html"><a href="solutions-to-questions.html#chapter-8"><i class="fa fa-check"></i><b>15.6</b> Chapter 8</a></li>
<li class="chapter" data-level="15.7" data-path="solutions-to-questions.html"><a href="solutions-to-questions.html#chapter-9"><i class="fa fa-check"></i><b>15.7</b> Chapter 9</a></li>
<li class="chapter" data-level="15.8" data-path="solutions-to-questions.html"><a href="solutions-to-questions.html#chapter-10"><i class="fa fa-check"></i><b>15.8</b> Chapter 10</a></li>
<li class="chapter" data-level="15.9" data-path="solutions-to-questions.html"><a href="solutions-to-questions.html#chapter-11"><i class="fa fa-check"></i><b>15.9</b> Chapter 11</a></li>
<li class="chapter" data-level="15.10" data-path="solutions-to-questions.html"><a href="solutions-to-questions.html#chapter-12"><i class="fa fa-check"></i><b>15.10</b> Chapter 12</a></li>
<li class="chapter" data-level="15.11" data-path="solutions-to-questions.html"><a href="solutions-to-questions.html#chapter-13"><i class="fa fa-check"></i><b>15.11</b> Chapter 13</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">EEBE stats</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="hypothesis-testing" class="section level1 hasAnchor" number="14">
<h1><span class="header-section-number">Chapter 14</span> Hypothesis testing<a href="hypothesis-testing.html#hypothesis-testing" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="objective-10" class="section level2 hasAnchor" number="14.1">
<h2><span class="header-section-number">14.1</span> Objective<a href="hypothesis-testing.html#objective-10" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this chapter we will study <strong>hypothesis testing</strong> of means and proportions. We will define what the null hypothesis and the alternative is and how to use data to choose between both.</p>
<p>We will also introduce hypothesis testing of variances and the errors that are made when a hypothesis is tested. These error are known as false positives and false negatives.</p>
</div>
<div id="hypothesis" class="section level2 hasAnchor" number="14.2">
<h2><span class="header-section-number">14.2</span> Hypothesis<a href="hypothesis-testing.html#hypothesis" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>When we run randomized experiments, we often want to test whether the changes we make to the experiment have a real effect. We want, for example, to know if we have been able to influence the experiment. Or, if we have submitted the experiment under a new condition, we want to know if that condition affects the result of the experiment. We usually have an idea of what the data should look like when these changes are not present. Since the results of the experiment are random with and without the change, how can we tell the difference between applying the change or not?</p>
<p>The strategy is to formulate the change or the new condition in terms of the values that the <strong>parameters</strong> of the probability distributions associated with the random experiment can take. We then use the observations from the randomized experiment under the new condition to provide <strong>evidence</strong> about the possible influence on the parameters.</p>
<p><strong>Examples (Tyres)</strong></p>
<p>Tyre manufacturers want to know if the average life of the tyres they produce is at least 20000 km. Let’s try to translate their interest into statistical terms. Imagine a random experiment that consists of measuring how long the useful life of a particular tyre lasts. Therefore, manufacturers are interested in knowing if the average useful life of a tyre is at least 20000 km.</p>
<p>Let us formulate two dichotomous statements, that is, two mutually exclusive situations:</p>
<ol style="list-style-type: lower-alpha">
<li>The mean life of tyres may be <strong>less</strong> than 20 000km</li>
<li>The mean life of tyres may be <strong>greater</strong> than 20000km</li>
</ol>
<p>This means that only one can be true. The question is then how we can use data to decide between situation a. or situation b. Let’s consider that <span class="math inline">\(\mu\)</span> is the mean of the population distribution. Therefore, the statements a. and b. can also be written as</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0: \mu \leq 20000km\)</span></li>
<li><span class="math inline">\(H_1: \mu &gt; 20000km\)</span></li>
</ol>
<p>Where the statement <span class="math inline">\(H_0\)</span> is where the cars do not run for the desired 20000 km while statement <span class="math inline">\(H_1\)</span> is the desired case. <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_1\)</span> are called hypotheses.</p>
<p><strong>Definition</strong></p>
<p>In statistics, a statement (conjecture) about the distribution of a random variable is called a <strong>hypothesis</strong>.</p>
<p>The hypothesis is usually written in two dichotomous statements</p>
<ol style="list-style-type: lower-alpha">
<li><p>The <strong>null</strong> hypothesis: <span class="math inline">\(H_0\)</span> when the conjecture is false usually refers to <strong>status quo</strong>. The data may be explained by the satus quo.</p></li>
<li><p>The <strong>alternative</strong> hypothesis: <span class="math inline">\(H_1\)</span> when the conjecture is true usually refers to <strong>research hypothesis</strong>. The data may be explained by the desired alternative.</p></li>
</ol>
<p><strong>Example (Fertilizer)</strong></p>
<p>So what are the null and the alternative hypothesis for the following situation?</p>
<p>Fertilizer developers want to test whether their new product has a real effect on the growth of plants.</p>
<p>Being <span class="math inline">\(\mu_0\)</span> the mean growth of the plants <strong>without</strong> fertilizer (known) and <span class="math inline">\(\mu\)</span> the mean growth of the plants with the fertilizer (unknown)</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu \leq \mu_0\)</span> (The fertilizer may do nothing: status quo)</li>
<li><span class="math inline">\(H_1:\mu &gt; \mu_0\)</span> (The fertilizer may have the desired effect: research interest)</li>
</ol>
<p><strong>Example (chemotherapy)</strong></p>
<p>Pharmaceutical companies need to know if a novel chemotherapy can cure 90% of cancer patients.</p>
<p>Being <span class="math inline">\(p_0\)</span> the proportion of patients that are cured <strong>without</strong> the chemotherapy (known) and <span class="math inline">\(p\)</span> the proportion that are cures <strong>with</strong> the chemotherapy (unknown)</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:p \leq p_0\)</span> (The chemotherapy may do nothing: status quo)</li>
<li><span class="math inline">\(H_1: p &gt; p_0\)</span> (The chemotherapy may have the desired effect: research interest)</li>
</ol>
<p>Note that our new improved experiment has the parameter <span class="math inline">\(p\)</span> and we want to know how it compares to the experiment without <strong>any improvement</strong> that has the parameter <span class="math inline">\(p_0\)</span>.</p>
<p>We want to decide between <span class="math inline">\(H_0\)</span> and <span class="math inline">\(H_1\)</span>. There are two options:</p>
<ol style="list-style-type: decimal">
<li><p>We reject the alternative hypothesis <span class="math inline">\(H_1\)</span>; that is, we accept the null hypothesis <span class="math inline">\(H_0\)</span>.</p></li>
<li><p>We accept the alternative hypothesis <span class="math inline">\(H_1\)</span> (our interest); that is, we reject the null hypothesis <span class="math inline">\(H_0\)</span>.</p></li>
</ol>
</div>
<div id="hypothesis-testing-1" class="section level2 hasAnchor" number="14.3">
<h2><span class="header-section-number">14.3</span> Hypothesis testing<a href="hypothesis-testing.html#hypothesis-testing-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Let us summarize the different cases, ways and types for testing hypothesis. We will then discuss each condition with a particular example.</p>
<p>Hypotheses can be tested, or decided, using confidence intervals. Therefore, we are going to test hypothesis in the four <strong>cases</strong> that we saw for confidence intervals, namely:</p>
<ul>
<li><p><strong>Case 1</strong>: Hypothesis test for the mean <span class="math inline">\(\mu\)</span>, when <span class="math inline">\(X \rightarrow N(\mu, \sigma^2)\)</span> and we know <span class="math inline">\(\sigma\)</span></p></li>
<li><p><strong>Case 2</strong>: Hypothesis test for the mean <span class="math inline">\(\mu\)</span>, when <span class="math inline">\(X \rightarrow N(\mu, \sigma^2)\)</span> and we do not know <span class="math inline">\(\sigma\)</span></p></li>
<li><p><strong>Case 3</strong>: Hypothesis test for the proportion <span class="math inline">\(p\)</span> when <span class="math inline">\(X \rightarrow Bernoulli(p)\)</span> and both <span class="math inline">\(np\)</span> and <span class="math inline">\(n(1-p)\)</span> <span class="math inline">\(&gt; 5\)</span>.</p></li>
<li><p><strong>Case 4</strong>: Hypothesis test for the variance <span class="math inline">\(\sigma^2\)</span>, when <span class="math inline">\(X \rightarrow N(\mu, \sigma^2)\)</span></p></li>
</ul>
<p>There are three <strong>ways</strong> to test the hypotheses:</p>
<ol style="list-style-type: decimal">
<li>Using <strong>confidence intervals</strong></li>
<li>using a <strong>rejection zone</strong></li>
<li>using a <span class="math inline">\(p-value\)</span>.</li>
</ol>
<p>All three options are equivalent. Finally, there are three <strong>types</strong> of hypothesis that we can test:</p>
<ol style="list-style-type: decimal">
<li><strong>Two</strong> tailed</li>
<li><strong>Upper</strong> tailed</li>
<li><strong>Lower</strong> tailed</li>
</ol>
</div>
<div id="case-1-known-variance-1" class="section level2 hasAnchor" number="14.4">
<h2><span class="header-section-number">14.4</span> Case 1 (known variance)<a href="hypothesis-testing.html#case-1-known-variance-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A <strong>tow tailed</strong> hypothesis contrast is of the form</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu = \mu_0\)</span> (status quo)</li>
<li><span class="math inline">\(H_1:\mu \neq \mu_0\)</span> (research interest)</li>
</ol>
<p>This called two tailed because the alternative hypothesis <span class="math inline">\(H_1\)</span> requires that the mean <span class="math inline">\(\mu\)</span> is either lower or higher than <span class="math inline">\(\mu_0\)</span>. This hypothesis can be tested in different cases. The <strong>case 1</strong> is when</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X\)</span> is a normal variable, and</li>
<li>we know the value of <span class="math inline">\(\sigma^2\)</span></li>
</ol>
<div id="hypothesis-test-with-a-confidence-interval" class="section level3 hasAnchor" number="14.4.1">
<h3><span class="header-section-number">14.4.1</span> Hypothesis test with a confidence interval<a href="hypothesis-testing.html#hypothesis-test-with-a-confidence-interval" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For <strong>case 1</strong> the confidence interval at <span class="math inline">\(95\%\)</span> is</p>
<p><span class="math display">\[(l,u)=(\bar{x}-z_{0.025} \frac{\sigma}{\sqrt{n}}, \bar{x}+z_{0.025} \frac{\sigma}{\sqrt{n}})\]</span></p>
<p><strong>Testing Criteria:</strong></p>
<ul>
<li>If the confidence interval <strong>contains</strong> the null hypothesis</li>
</ul>
<p><span class="math display">\[\mu_0\in (l,u)\]</span> then we <strong>accept</strong> <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence.</p>
<ul>
<li>If the confidence interval does <strong>not contain</strong> the null hypothesis<span class="math display">\[\mu_0\notin (l,u)\]</span> then we <strong>reject</strong> <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence.</li>
</ul>
<p><strong>Example (Cables)</strong></p>
<p>We buy <span class="math inline">\(8\)</span> cables from a manufacturing company that claims that they break with <strong>mean</strong> of <span class="math inline">\(\mu_0=13\)</span> Tons. We are not sure and may want to decide on whether the cables break <strong>on average</strong> at <span class="math inline">\(13\)</span> Tons or not. We formulate the hypothesis contrast</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu = 13\)</span> (The cables <strong>may</strong> break as the manufacturer claims: status quo)</li>
<li><span class="math inline">\(H_1:\mu \neq 13\)</span> (The cables <strong>may not</strong> break as the manufacturer claims: research interest)</li>
</ol>
<p>Since we do no know what is true, let’s start by <strong>assuming</strong> that <strong>the manufacturer is right</strong> and the cables truly satisfy the null hypothesis and therefore</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X \rightarrow N(\mu=13, \sigma^2=0.35^2)\)</span></li>
<li>We know <span class="math inline">\(\sigma^2=0.35^2\)</span></li>
</ol>
<p>To decide between <span class="math inline">\(H_0\)</span> or <span class="math inline">\(H_1\)</span>, we then perform <span class="math inline">\(8\)</span> random experiments: Load a cable until it breaks and record the breaking load. These are the results.</p>
<pre><code>## [1] 13.34642 13.32620 13.01459 13.10811 12.96999 13.55309 13.75557 12.62747</code></pre>
<p>The confidence interval <strong>if</strong> the manufacturer is right, namely if the null hypothesis is true, is</p>
<p><span class="math display">\[(l,u)=(\bar{x}-z_{0.025} \frac{\sigma}{\sqrt{n}}, \bar{x}+z_{0.025} \frac{\sigma}{\sqrt{n}})= (12.97,13.45)\]</span>
The confidence interval tells us that we trust with <span class="math inline">\(95\%\)</span> confidence that the true breaking load of the cables <span class="math inline">\(\mu\)</span> is in the interval. We don’t know the true value of <span class="math inline">\(\mu\)</span> but we see that <span class="math inline">\(\mu=13\)</span> Tons could be it. Since the interval caught <span class="math inline">\(\mu_0\)</span></p>
<p><span class="math display">\[\mu_0\in (12.97,13.45)\]</span></p>
<p>Our conclusion is to accept that <span class="math inline">\(H_0\)</span> could have produced our <strong>observed interval</strong>. We also say that that the data supports with the manufacturer’s claim. More technically, we say that we <strong>do not reject</strong> <span class="math inline">\(H_0\)</span>.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-104-1.png" width="672" /></p>
</div>
<div id="hypothesis-test-with-acceptancerejection-zones" class="section level3 hasAnchor" number="14.4.2">
<h3><span class="header-section-number">14.4.2</span> Hypothesis test with acceptance/rejection zones<a href="hypothesis-testing.html#hypothesis-test-with-acceptancerejection-zones" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>An equivalent way to test the hypothesis is to see if our set of observations are either common or rare if we assume that the null hypothesis is true. Let’s remember the hypothesis contrast</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu = \mu_0\)</span> (status quo)</li>
<li><span class="math inline">\(H_1:\mu \neq \mu_0\)</span> (research interest)</li>
</ol>
<p>To test the hypothesis with a <strong>rejection zone</strong> we compute the standardized statistic</p>
<p><span class="math display">\[Z=\frac{\bar{X}-\mu_0}{\frac{\sigma^2}{\sqrt{n}}}\]</span>
when the null hypothesis is true. Note that we are standardizing with <span class="math inline">\(\mu_0\)</span> (the null hypothesis). We then see if the observed value of <span class="math inline">\(Z\)</span> is within the interval</p>
<p><span class="math display">\[(-z_{0.025}, z_{0.025})\]</span>
Remember that this interval defines the most common values of <span class="math inline">\(Z\)</span> since <span class="math inline">\(P(-z_{0.025} \leq Z \leq z_{0.025})=0.95\)</span></p>
<p>The interval <span class="math inline">\((-z_{0.025}, z_{0.025})\)</span> is called <strong>acceptance interval</strong> of <span class="math inline">\(H_0\)</span> at <span class="math inline">\(95\%\)</span> confidence level.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-105-1.png" width="672" /></p>
<p><strong>Testing criteria:</strong></p>
<ul>
<li>If the observed statistics <span class="math inline">\(z_{obs}\)</span> under the null hypothesis <strong>is</strong> in the acceptance region</li>
</ul>
<p><span class="math display">\[z_{obs} \in (-z_{0.025}, z_{0.025})\]</span></p>
<p>then we <strong>accept</strong> <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence.</p>
<ul>
<li>If the observed statistics <span class="math inline">\(z_{obs}\)</span> under the null hypothesis <strong>is not</strong> in the acceptance region</li>
</ul>
<p><span class="math display">\[z_{obs} \notin (-z_{0.025}, z_{0.025})\]</span> then we <strong>reject</strong> <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence.</p>
<p>The region <span class="math inline">\((-z_{0.025}] \cup[z_{0.025})\)</span> is called the <strong>rejection zone</strong>.</p>
<p><strong>Example (Cables)</strong></p>
<p>If <span class="math inline">\(H_0\)</span> is true then the standardized statistic <span class="math inline">\(\bar{X}\)</span></p>
<p><span class="math display">\[Z=\frac{\bar{X}-13}{\frac{0.35}{\sqrt{8}}}  \rightarrow N(0,1)\]</span>
is an estimation of <span class="math inline">\(\mu_0\)</span> and therefore <span class="math inline">\(Z\)</span> is the standardized error that we make when we perform the estimation. Because we are in <strong>case 1</strong>, <span class="math inline">\(Z\)</span> is standard normal
Since</p>
<p><span class="math display">\[\bar{X} \rightarrow N(13, \frac{0.35^2}{8})\]</span></p>
<p>For <strong>our data</strong> the standardized <strong>observed error</strong> is in the acceptance region</p>
<p><span class="math display">\[z_{obs}=\frac{\bar{x}-13}{\frac{0.35}{\sqrt{8}}}=1.7187 \in (-z_{0.025}, z_{0.025})\]</span>
We conclude that our observed error is a typical observation of <span class="math inline">\(\bar{x}\)</span> when the null hypothesis <span class="math inline">\(\mu_0\)</span> is true. Therefore, we again accept that the data is consistent with the manufacturer’s claim. We also say that we <strong>do not reject</strong> <span class="math inline">\(H_0\)</span>.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-106-1.png" width="672" /></p>
</div>
<div id="hypothesis-test-with-a-p-value" class="section level3 hasAnchor" number="14.4.3">
<h3><span class="header-section-number">14.4.3</span> Hypothesis test with a P-value<a href="hypothesis-testing.html#hypothesis-test-with-a-p-value" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can also contrast the <strong>two tail</strong> hypothesis by calculating the probability that the average of another sample will be even rarer than the average we just observed. Because we are in **case 1*, We know that the standardized statistics <span class="math inline">\(Z\)</span> is standar normal variable then we define the <span class="math inline">\(pvalue\)</span> as</p>
<p><span class="math display">\[pvalue = P(Z \leq -z_{obs}) + P(z_{obs} \leq Z) = 2 (1-\phi(|z_{obs}|))\]</span></p>
<p>That is the probability that when we take another sample of the same size we are able to obtain an even rarer observation. If our observation is already rare then this value will be small.</p>
<p><strong>Testing criteria:</strong></p>
<ul>
<li>If the observed <span class="math inline">\(pvalue\)</span> is</li>
</ul>
<p><span class="math display">\[pvalue \geq \alpha =1-0.95=0.05\]</span></p>
<p>then we <strong>accept</strong> <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence.</p>
<ul>
<li>If the observed <span class="math inline">\(pvalue\)</span> is</li>
</ul>
<p><span class="math display">\[pvalue &lt; \alpha =1-0.95=0.05\]</span>
then we <strong>reject</strong> <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence.</p>
<p><span class="math inline">\(\alpha\)</span> is the significance level. It gives us how much of the distribution we are leaving out, and defines the region that we consider as rare observations.</p>
<p>Remember: We always trust our data. If the null hypothesis says that our data is a <strong>rare</strong> observation we then distrust the null hypothesis, and reject it.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-107-1.png" width="672" /></p>
<p><strong>Example (Cables)</strong></p>
<p>For our data the observed statistic <span class="math inline">\(z_{obs}=1.718714\)</span> and its <strong>p-value</strong> is then</p>
<p><span class="math display">\[pvalue=2 (1-\phi(1.718714))=0.08567\]</span>
R: <code>2*(1-pnorm(1.718714))</code></p>
<p>We conclude that if we performed a new sample is likely that we can get a more extreme result that the one we got. The null hypothesis can tolerate the observed error with <span class="math inline">\(95\%\)</span> confidence. We therefore accept that <span class="math inline">\(H_0\)</span> could have produced our data and say again that its is consistent with the manufacturer’s claim.</p>
<p>In R the entire hypothesis testing can be performed with the function z.test from the library BSDA (that needs to be previously installed)</p>
<div class="sourceCode" id="cb45"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb45-1"><a href="hypothesis-testing.html#cb45-1" tabindex="-1"></a><span class="fu">install.packages</span>(BSDA) </span></code></pre></div>
<div class="sourceCode" id="cb46"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb46-1"><a href="hypothesis-testing.html#cb46-1" tabindex="-1"></a><span class="fu">library</span>(BSDA) </span>
<span id="cb46-2"><a href="hypothesis-testing.html#cb46-2" tabindex="-1"></a><span class="fu">z.test</span>(<span class="fu">c</span>(<span class="fl">13.34642</span>, <span class="fl">13.32620</span>, <span class="fl">13.01459</span>, <span class="fl">13.10811</span>, </span>
<span id="cb46-3"><a href="hypothesis-testing.html#cb46-3" tabindex="-1"></a>         <span class="fl">12.96999</span>, <span class="fl">13.55309</span>, <span class="fl">13.75557</span>, <span class="fl">12.62747</span>), </span>
<span id="cb46-4"><a href="hypothesis-testing.html#cb46-4" tabindex="-1"></a>       <span class="at">mu=</span><span class="dv">13</span>, </span>
<span id="cb46-5"><a href="hypothesis-testing.html#cb46-5" tabindex="-1"></a>       <span class="at">sigma.x=</span><span class="fl">0.35</span>)</span></code></pre></div>
<pre><code>## 
##  One-sample z-Test
## 
## data:  c(13.34642, 13.3262, 13.01459, 13.10811, 12.96999, 13.55309,     13.75557, 12.62747)
## z = 1.7187, p-value = 0.08567
## alternative hypothesis: true mean is not equal to 13
## 95 percent confidence interval:
##  12.97015 13.45521
## sample estimates:
## mean of x 
##  13.21268</code></pre>
</div>
<div id="upper-tail-hypothesis" class="section level3 hasAnchor" number="14.4.4">
<h3><span class="header-section-number">14.4.4</span> Upper tail hypothesis<a href="hypothesis-testing.html#upper-tail-hypothesis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We may be interested in only testing for the fact that our experiment’s means is higher mean than the null’s mean.</p>
<p>Upper-tailed test:</p>
<ul>
<li><span class="math inline">\(H_0:\mu \leq 13\)</span> (<strong>at most</strong> cables break as usual)</li>
<li><span class="math inline">\(H_1:\mu &gt; 13\)</span> (cables break at a <strong>higher</strong> load)</li>
</ul>
<p>This called <strong>upper-tailed</strong> because the alternative hypothesis <span class="math inline">\(H_1\)</span> requires that the mean <span class="math inline">\(\mu\)</span> is <strong>higher</strong> than <span class="math inline">\(\mu_0\)</span>. This hypothesis can be tested in different cases. The <strong>case 1</strong> is when</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X\)</span> is a normal variable, and</li>
<li>we know the value of <span class="math inline">\(\sigma\)</span></li>
</ol>
<p><strong>Testing criteria:</strong></p>
<ol style="list-style-type: decimal">
<li><em>Confidence interval:</em> If the <strong>upper-tailed</strong> confidence interval <strong>contains</strong> the null hypothesis</li>
</ol>
<p><span class="math display">\[\mu_0\in (l,u)=(\bar{x}-z_{0.05} \frac{\sigma}{\sqrt{n}}, \infty)\]</span>
where <span class="math inline">\(z_{0.05}=\phi^{-1}(0.95)=\)</span><code>qnorm(0.95)</code>, then we <strong>accept</strong> <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence. Note that this test is from the point of view of the <strong>data</strong>, we are not centering the confidence interval around <span class="math inline">\(\bar{x}\)</span>, instead we are leaving all the <span class="math inline">\(5\%\)</span> of the rare cases to the left of the average. We are therefore asking if the null hypothesis is lower than the average.</p>
<ol start="2" style="list-style-type: decimal">
<li><em>Rejection/acceptance region:</em> If the observed statistics <span class="math inline">\(z_{obs}\)</span> under the null hypothesis <strong>is</strong> in the acceptance region</li>
</ol>
<p><span class="math display">\[z_{obs}=\frac{\bar{x}-\mu_0}{\frac{\sigma}{\sqrt{n}}} \in (-\infty, z_{0.05})\]</span></p>
<p>then we <strong>accept</strong> <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence. Note that this test is from the point of view of the <strong>null hypothesis</strong>. We are leaving all the <span class="math inline">\(5\%\)</span> of the rare averages to the right of the null hypothesis and therefore ask if the average is higher than the null hypothesis.</p>
<ol start="3" style="list-style-type: decimal">
<li><span class="math inline">\(pvalue\)</span>: If the observed <strong>upper-tailed</strong> <span class="math display">\[pvalue= 1-\phi(z_{obs})\]</span></li>
</ol>
<p><code>1-pnorm(zobs)</code> is greater than <span class="math inline">\(\alpha=1-0.95=0.05\)</span></p>
<p><span class="math display">\[pvalue \geq \alpha =0.05\]</span></p>
<p>then we <strong>accept</strong> <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence. Note that this test is again from the point of view of the <strong>null hypothesis</strong>. We are asking: if we were to take another average what is the probability that is higher than the observed one?</p>
<p><strong>Example (Cables)</strong></p>
<p>In the example of the cables, we may be interested only in the case that the cables are an improved version from what the manufacturer claims. Therefore the upper-tailed hypothesis is</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu \leq 13\)</span> (The cables may break <strong>at most</strong> as the manufacturer claims: status quo)</li>
<li><span class="math inline">\(H_1:\mu &gt; 13\)</span> (The cables may break <strong>at least</strong> as the manufacturer claims: research interest)</li>
</ol>
<p>We will test the higher tail of the distribution.
For the data that we discussed before, we then <strong>reject</strong> <span class="math inline">\(H_0\)</span> at <span class="math inline">\(95\%\)</span> confidence because of any of the three equivalent contrasts:</p>
<ol style="list-style-type: decimal">
<li>The <strong>upper tailed</strong> confidence interval does not contain the null hypothesis <span class="math inline">\(\mu_0=13\)</span></li>
</ol>
<p><span class="math display">\[\mu_0=13 \notin (\bar{x}-z_{0.05} \frac{\sigma}{\sqrt{n}}, \infty)=(13.00914, \infty)\]</span>
where <span class="math inline">\(z_{0.05}=\)</span><code>qnorm(0.95)=1.644854</code></p>
<ol start="2" style="list-style-type: decimal">
<li>We have that the acceptance region for <span class="math inline">\(H_0\)</span> is:</li>
</ol>
<p><span class="math display">\[(-\infty, z_{0.05})=( -\infty,  1.644854)\]</span></p>
<p>and that the observed standardized error is not in the region
<span class="math display">\[z_{obs} =  \frac{13.21268-13}{\frac{0.35}{\sqrt{8}}}=1.7187 \notin ( -\infty,  1.644854)\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>The upper tail <span class="math inline">\(pvalue\)</span> is lower than <span class="math inline">\(\alpha=0.05\)</span>
<span class="math display">\[pvalue=1-\phi(1.7187)=0.04283451 &lt;0.05\]</span></li>
</ol>
<p>where <span class="math inline">\(pvalue=\)</span><code>1-pnorm(1.7187)</code>.</p>
<p>The hypothesis test can be perform in R, changing the parameter alternative to greater:</p>
<div class="sourceCode" id="cb48"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb48-1"><a href="hypothesis-testing.html#cb48-1" tabindex="-1"></a><span class="fu">z.test</span>(<span class="fu">c</span>(<span class="fl">13.34642</span>, <span class="fl">13.32620</span>, <span class="fl">13.01459</span>, <span class="fl">13.10811</span>,</span>
<span id="cb48-2"><a href="hypothesis-testing.html#cb48-2" tabindex="-1"></a>         <span class="fl">12.96999</span>, <span class="fl">13.55309</span>, <span class="fl">13.75557</span>, <span class="fl">12.62747</span>), </span>
<span id="cb48-3"><a href="hypothesis-testing.html#cb48-3" tabindex="-1"></a>       <span class="at">mu=</span><span class="dv">13</span>, <span class="at">alternative=</span><span class="st">&quot;greater&quot;</span>, <span class="at">sigma.x=</span><span class="fl">0.35</span>)</span></code></pre></div>
<pre><code>## 
##  One-sample z-Test
## 
## data:  c(13.34642, 13.3262, 13.01459, 13.10811, 12.96999, 13.55309,     13.75557, 12.62747)
## z = 1.7187, p-value = 0.04283
## alternative hypothesis: true mean is greater than 13
## 95 percent confidence interval:
##  13.00914       NA
## sample estimates:
## mean of x 
##  13.21268</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-112-1.png" width="672" /></p>
</div>
</div>
<div id="case-2-unknown-variance-1" class="section level2 hasAnchor" number="14.5">
<h2><span class="header-section-number">14.5</span> Case 2 (unknown variance)<a href="hypothesis-testing.html#case-2-unknown-variance-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A <strong>tow tailed</strong> hypothesis contrast of the form</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu = \mu_0\)</span> (status quo)</li>
<li><span class="math inline">\(H_1:\mu \neq \mu_0\)</span> (research interest)</li>
</ol>
<p>can be tested when we do not know <span class="math inline">\(\sigma^2\)</span> using <strong>case 2</strong>, namely when</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X\)</span> is a normal variable, <span class="math inline">\(X \rightarrow N(\mu, \sigma^2)\)</span>, and</li>
<li>we do <strong>not</strong> know the value of <span class="math inline">\(\sigma^2\)</span></li>
</ol>
<p>Let’s remember that in this case, then the <strong>standardized error</strong> with respect to the <strong>sample standard deviation</strong> <span class="math inline">\(S\)</span></p>
<p><span class="math display">\[T=\frac{\bar{X}-\mu}{\frac{S}{\sqrt{n}}}\]</span></p>
<p>Follows a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-1\)</span> degrees of freedom. Therefore, we can apply <strong>all three criteria</strong> as in <strong>case 1</strong> but making the substitution of <span class="math inline">\(s\)</span> for <span class="math inline">\(\sigma\)</span> and <span class="math inline">\(Z\)</span> for <span class="math inline">\(T\)</span>.</p>
<p><strong>Testing criteria:</strong></p>
<ol style="list-style-type: decimal">
<li><em>Confidence interval:</em> If the confidence interval <strong>contains</strong> the null hypothesis</li>
</ol>
<p><span class="math display">\[\mu_0\in (l,u)=(\bar{x}-t_{0.025,n-1} \frac{s}{\sqrt{n}}, \bar{x}+t_{0.025,n-1} \frac{s}{\sqrt{n}})\]</span> then we <strong>accept</strong> <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence.</p>
<ol start="2" style="list-style-type: decimal">
<li><em>Rejection/acceptance region:</em> If the observed statistics <span class="math inline">\(t_{obs}\)</span> under the null hypothesis <strong>is</strong> in the acceptance region</li>
</ol>
<p><span class="math display">\[t_{obs}=\frac{\bar{x}-\mu_0}{\frac{s}{\sqrt{n}}} \in (-t_{0.025}, t_{0.025})\]</span></p>
<p>where <span class="math inline">\(t_{0.025}=F_t^{-1}(0.975, n-1)=\)</span><code>qt(0.975, n-1)</code>, then we <strong>accept</strong> <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence.</p>
<ol start="3" style="list-style-type: decimal">
<li><span class="math inline">\(pvalue\)</span>: If the observed <span class="math inline">\(pvalue= 2 (1-F_t(|t_{obs}|))=\)</span><code>2*(1-pt(abs(tobs), n-1))</code> is</li>
</ol>
<p><span class="math display">\[pvalue \geq \alpha =1-0.95=0.05\]</span></p>
<p>then we <strong>accept</strong> <span class="math inline">\(H_0\)</span> with <span class="math inline">\(95\%\)</span> confidence.</p>
<p><strong>Example (Cables)</strong></p>
<p>For the hypothesis contrast for the braking load of the cables</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu = 13\)</span></li>
<li><span class="math inline">\(H_1:\mu \neq 13\)</span></li>
</ol>
<p>We will only assume that the cables are normally distributed</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X \rightarrow N(\mu=13, \sigma^2=?)\)</span></li>
<li>We do not know <span class="math inline">\(\sigma^2\)</span></li>
</ol>
<p>Having obtained the sample</p>
<pre><code>## [1] 13.34642 13.32620 13.01459 13.10811 12.96999 13.55309 13.75557 12.62747</code></pre>
<p>with this data, we accept <span class="math inline">\(H_0\)</span> at <span class="math inline">\(95\%\)</span> significance because of any of following equivalent contrasts:</p>
<ol style="list-style-type: decimal">
<li>The confidence interval</li>
</ol>
<p><span class="math display">\[(\bar{x}-t_{0.025, n-1} \frac{s}{\sqrt{n}}, \bar{x}+t_{0.025, n-1} \frac{s}{\sqrt{n}})=(12.91409, 13.51127)\]</span></p>
<p>contains <span class="math inline">\(H_0:\mu=13\)</span>.</p>
<ol start="2" style="list-style-type: decimal">
<li>The acceptance region for <span class="math inline">\(H_0\)</span> is:</li>
</ol>
<p><span class="math display">\[(-t_{0.025,7}, t_{0.025,7})=( -2.36,  2.36)\]</span></p>
<p>and the observed standardized error from <span class="math inline">\(H_0\)</span> is
<span class="math display">\[t_{obs} =  \frac{13.21268-13}{\frac{0.3571565}{\sqrt{8}}}=1.6843\]</span></p>
<p>within the acceptance region.</p>
<ol start="3" style="list-style-type: decimal">
<li>The <span class="math display">\[pvalue=2(1-F_{t,7}(1.6843))=0.136\]</span></li>
</ol>
<p>is greater then <span class="math inline">\(\alpha=0.05\)</span>. The <span class="math inline">\(pvalue\)</span> is computed R like <code>2*(1-pt(1.6843,7))</code></p>
<p>In R this contrasts are perform with the function t.test:</p>
<div class="sourceCode" id="cb51"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb51-1"><a href="hypothesis-testing.html#cb51-1" tabindex="-1"></a><span class="fu">t.test</span>(<span class="fu">c</span>(<span class="fl">13.34642</span>, <span class="fl">13.32620</span>, <span class="fl">13.01459</span>, <span class="fl">13.10811</span>,</span>
<span id="cb51-2"><a href="hypothesis-testing.html#cb51-2" tabindex="-1"></a>         <span class="fl">12.96999</span>, <span class="fl">13.55309</span>, <span class="fl">13.75557</span>, <span class="fl">12.62747</span>), </span>
<span id="cb51-3"><a href="hypothesis-testing.html#cb51-3" tabindex="-1"></a>       <span class="at">mu=</span><span class="dv">13</span>)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  c(13.34642, 13.3262, 13.01459, 13.10811, 12.96999, 13.55309, 13.75557, 12.62747)
## t = 1.6843, df = 7, p-value = 0.136
## alternative hypothesis: true mean is not equal to 13
## 95 percent confidence interval:
##  12.91409 13.51127
## sample estimates:
## mean of x 
##  13.21268</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-115-1.png" width="672" /></p>
<p><strong>Example (NaCl)</strong></p>
<p><span class="math inline">\(11.6g\)</span> of NaCl is dissolved in <span class="math inline">\(100 g\)</span> of water and has a molar concentration of <span class="math inline">\(1.92 mol/L\)</span></p>
<p>We design a process to remove salt from this concentration and obtain the following results</p>
<pre><code>## [1] 1.716 1.889 1.783 1.849 1.891</code></pre>
<p>We want to test at <span class="math inline">\(0.95\)</span> significance if the process changes the salt concentration in ay direction. Therefore we propose a two-tail hypothesis:</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu=1.92\)</span></li>
<li><span class="math inline">\(H_1:\mu \neq 1.92\)</span></li>
</ol>
<p>We will assume that <span class="math inline">\(X\)</span> is normal and that we do not know the variance <span class="math inline">\(\sigma^2\)</span>. Therefore, we are in <strong>case 2</strong> that we test with a t.test</p>
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="hypothesis-testing.html#cb54-1" tabindex="-1"></a><span class="fu">t.test</span>(<span class="fu">c</span>(<span class="fl">1.716</span>, <span class="fl">1.889</span>, <span class="fl">1.783</span>, <span class="fl">1.849</span>, <span class="fl">1.891</span>), </span>
<span id="cb54-2"><a href="hypothesis-testing.html#cb54-2" tabindex="-1"></a>       <span class="at">mu=</span><span class="fl">1.92</span>, <span class="at">alternative =</span> <span class="st">&quot;two.sided&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  c(1.716, 1.889, 1.783, 1.849, 1.891)
## t = -2.8038, df = 4, p-value = 0.04862
## alternative hypothesis: true mean is not equal to 1.92
## 95 percent confidence interval:
##  1.732122 1.919078
## sample estimates:
## mean of x 
##    1.8256</code></pre>
<div id="lower-tail-hypothesis" class="section level3 hasAnchor" number="14.5.1">
<h3><span class="header-section-number">14.5.1</span> Lower tail hypothesis<a href="hypothesis-testing.html#lower-tail-hypothesis" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>If we are interested only in the case that we are able to remove salt from the concentration then we propose a <strong>lower tail</strong> hypothesis:</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu \geq 1.92\)</span> (After the desalinization process the concentration o salt is at least the initial one: status quo)</li>
<li><span class="math inline">\(H_1:\mu &lt; 1.92\)</span> (After the desalinization process the concentration is lower the initial one: research interest)</li>
</ol>
<p>Note that the lower tail is given by the alternative <span class="math inline">\(H_1\)</span>. We want to test that the average concentration after the process is lower than the initial concentration. The contrast criteria are the same as for the other types of hypothesis. For this type of hypothesis, we will accept the null hypothesis if</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\mu_0\)</span> is in the confidence interval:
<span class="math display">\[\mu_0\in (l,u)=(-\infty, \bar{x}+t_{0.05,n-1} \frac{s}{\sqrt{n}})\]</span></p></li>
<li><p>or, <span class="math inline">\(t_{obs}\)</span> is in the aceptance region:</p></li>
</ol>
<p><span class="math display">\[t_{obs}\in (t_{0.05,n-1}, \infty)\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>or, the <span class="math inline">\(pvalue\)</span> on the lower tail of the distribution.<br />
<span class="math display">\[pvalue=F_t(t_{obs},n-1)\]</span>
is lower than <span class="math inline">\(\alpha=0.05\)</span></li>
</ol>
<p>In any other case, we reject <span class="math inline">\(H_0\)</span> and accept the alternative hypothesis.</p>
<p><strong>Example (NaCl)</strong></p>
<p>For the lower tail contrast</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu \geq 1.92\)</span></li>
<li><span class="math inline">\(H_1:\mu &lt; 1.92\)</span></li>
</ol>
<p>We can assume that the concentration is normal and that we do not know <span class="math inline">\(\sigma^2\)</span>. Therefore, we are in <strong>case 2</strong> for which we only need to change the argument alternative to less in the function t.test.</p>
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="hypothesis-testing.html#cb56-1" tabindex="-1"></a><span class="fu">t.test</span>(<span class="fu">c</span>(<span class="fl">1.716</span>, <span class="fl">1.889</span>, <span class="fl">1.783</span>, <span class="fl">1.849</span>, <span class="fl">1.891</span>), </span>
<span id="cb56-2"><a href="hypothesis-testing.html#cb56-2" tabindex="-1"></a>       <span class="at">mu=</span><span class="fl">1.92</span>, <span class="at">alternative =</span> <span class="st">&quot;less&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  c(1.716, 1.889, 1.783, 1.849, 1.891)
## t = -2.8038, df = 4, p-value = 0.02431
## alternative hypothesis: true mean is less than 1.92
## 95 percent confidence interval:
##      -Inf 1.897376
## sample estimates:
## mean of x 
##    1.8256</code></pre>
<p><strong>Example 2 (soporific)</strong></p>
<p>In some cases, we are not sure about the numerical value of the hypothesis to test, but we know that we want to improve the value of a parameter in two different conditions.</p>
<p>In the original paper of Gosset, he analyzed the effect of two soporific medicines.</p>
<ul>
<li>10 individuals were given <strong>soporific 1</strong> and wrote down the additional hours slept under treatment, with a mean <span class="math inline">\(0.75\)</span></li>
</ul>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="hypothesis-testing.html#cb58-1" tabindex="-1"></a>medicine1 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.7</span>,<span class="sc">-</span><span class="fl">1.6</span>,<span class="sc">-</span><span class="fl">0.2</span>,<span class="sc">-</span><span class="fl">1.2</span>,<span class="sc">-</span><span class="fl">0.1</span>,<span class="fl">3.4</span>,<span class="fl">3.7</span>,<span class="fl">0.8</span>,<span class="dv">0</span>,<span class="dv">2</span>)</span>
<span id="cb58-2"><a href="hypothesis-testing.html#cb58-2" tabindex="-1"></a>medicine1</span></code></pre></div>
<pre><code>##  [1]  0.7 -1.6 -0.2 -1.2 -0.1  3.4  3.7  0.8  0.0  2.0</code></pre>
<ul>
<li>The same 10 individuals were given <strong>soporific 2</strong> and wrote down the additional hours slept under treatment, with a mean <span class="math inline">\(2.33\)</span></li>
</ul>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="hypothesis-testing.html#cb60-1" tabindex="-1"></a>medicine2 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">1.9</span>,<span class="fl">0.8</span>,<span class="fl">1.1</span>,<span class="fl">0.1</span>,<span class="sc">-</span><span class="fl">0.1</span>,<span class="fl">4.4</span>,<span class="fl">5.5</span>,<span class="fl">1.6</span>,<span class="fl">4.6</span>,<span class="fl">3.4</span>)</span>
<span id="cb60-2"><a href="hypothesis-testing.html#cb60-2" tabindex="-1"></a>medicine2</span></code></pre></div>
<pre><code>##  [1]  1.9  0.8  1.1  0.1 -0.1  4.4  5.5  1.6  4.6  3.4</code></pre>
<p>The scientific hypothesis was that soporific 2 was better than soporific 1. For each individual, Gosset computed the difference between the treatments. Taking <span class="math inline">\(X\)</span> as the <strong>difference</strong> between treatments, this was the sample observed for <span class="math inline">\(X\)</span></p>
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="hypothesis-testing.html#cb62-1" tabindex="-1"></a>x <span class="ot">&lt;-</span> medicine2<span class="sc">-</span>medicine1</span>
<span id="cb62-2"><a href="hypothesis-testing.html#cb62-2" tabindex="-1"></a>x</span></code></pre></div>
<pre><code>##  [1] 1.2 2.4 1.3 1.3 0.0 1.0 1.8 0.8 4.6 1.4</code></pre>
<p>finding an average of treatment gain from soporific 2 with respect to soporific 1 of <span class="math inline">\(1.58\)</span>, and <span class="math inline">\(s=1.229995\)</span></p>
<p>The scientific question can be stated as <strong>upper-tailed</strong> paired t-test:</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\mu \leq 0\)</span> (no treatment difference: <span class="math inline">\(\mu_2-\mu_1=0\)</span>)</li>
<li><span class="math inline">\(H_1:\mu &gt; 0\)</span> (treatment 2 higher then treatment 1: <span class="math inline">\(\mu_2-\mu_1&gt;0\)</span>)</li>
</ol>
<p>Where <span class="math inline">\(\mu\)</span> is the mean of the <strong>differences</strong> between treatments.</p>
<p>If we suppose that <span class="math inline">\(X\)</span> is normal and we do not know <span class="math inline">\(\sigma^2\)</span> then we are in <strong>case 2</strong>. the <strong>standardized error</strong> is:</p>
<p><span class="math display">\[T=\frac{\bar{X}}{\frac{S}{\sqrt{n}}}\]</span></p>
<p>and its observation</p>
<p><span class="math display">\[t_{obs}=\frac{\bar{x}}{\frac{s}{\sqrt{n}}}\]</span>
which is also known as the <strong>signal</strong> to <strong>noise</strong> ratio.</p>
<p>we can test the hipothsis in the difference <span class="math inline">\(X=medicine_1-medicine_2\)</span></p>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="hypothesis-testing.html#cb64-1" tabindex="-1"></a><span class="fu">t.test</span>(x,<span class="at">alternative=</span><span class="st">&quot;greater&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  One Sample t-test
## 
## data:  x
## t = 4.0621, df = 9, p-value = 0.001416
## alternative hypothesis: true mean is greater than 0
## 95 percent confidence interval:
##  0.8669947       Inf
## sample estimates:
## mean of x 
##      1.58</code></pre>
<p>or as a paired t-test, where we introduce the each separate condition, and state that the observations are paired</p>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="hypothesis-testing.html#cb66-1" tabindex="-1"></a><span class="fu">t.test</span>(medicine2, medicine1,</span>
<span id="cb66-2"><a href="hypothesis-testing.html#cb66-2" tabindex="-1"></a>       <span class="at">paired =</span> <span class="cn">TRUE</span>,</span>
<span id="cb66-3"><a href="hypothesis-testing.html#cb66-3" tabindex="-1"></a>       <span class="at">alternative=</span><span class="st">&quot;greater&quot;</span>)</span></code></pre></div>
<pre><code>## 
##  Paired t-test
## 
## data:  medicine2 and medicine1
## t = 4.0621, df = 9, p-value = 0.001416
## alternative hypothesis: true mean difference is greater than 0
## 95 percent confidence interval:
##  0.8669947       Inf
## sample estimates:
## mean difference 
##            1.58</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-124-1.png" width="672" /></p>
</div>
<div id="hypothesis-testing-with-large-n-and-any-distribution" class="section level3 hasAnchor" number="14.5.2">
<h3><span class="header-section-number">14.5.2</span> Hypothesis testing with large n and any distribution<a href="hypothesis-testing.html#hypothesis-testing-with-large-n-and-any-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>On many occasions, <span class="math inline">\(X\)</span> is not normally distributed but if we can take large samples <span class="math inline">\(n \ge 30\)</span> then we can use the CLT:</p>
<p>Then the <strong>standardized error</strong> from the null hypothesis can be approximated to a standard distribution</p>
<p><span class="math display">\[Z=\frac{\bar{X}-\mu}{\frac{\sigma}{\sqrt{n}}}  \rightarrow N(0,1)\]</span></p>
<p>and then we proceed as in <strong>case 1</strong>. If <span class="math inline">\(\sigma\)</span> is unknown we then replace it with its estimate <span class="math inline">\(s\)</span> and proceed as in <strong>case 2</strong> using the t-statistic</p>
<p><span class="math display">\[T=\frac{\bar{X}-\mu_0}{\frac{S}{\sqrt{n}}}\]</span></p>
</div>
</div>
<div id="case-3-proportions-1" class="section level2 hasAnchor" number="14.6">
<h2><span class="header-section-number">14.6</span> Case 3 (proportions)<a href="hypothesis-testing.html#case-3-proportions-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>If our random experiment is a Bernoulli trial <span class="math inline">\(X \rightarrow Bernoulli(p)\)</span>, we can formulate hypothesis contrasts for the probability <span class="math inline">\(p\)</span> of and event in the trial. Consider an upper tailed hypothesis</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0: p \leq p_0\)</span> (status quo)</li>
<li><span class="math inline">\(H_1: p&gt; p_0\)</span> (research interest)</li>
</ol>
<p>In this <strong>case 3</strong>, we can test the for the value of the proportion if</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X\)</span> is a Bernoulli trial, and</li>
<li><span class="math inline">\(np\)</span>, <span class="math inline">\(n(1-p)\)</span> are both greater than 5, so we can apply the central limit theorem.</li>
</ol>
<p>Remember that if we take a the sample of <span class="math inline">\(n\)</span> Bernoulli trials <span class="math inline">\((1,0,1,...0)\)</span>, <span class="math inline">\(\bar{X}=\frac{1}{n}\sum_{i=1}^n X_i\)</span> is the relative frequency of ones in the sample. This is an estimator of <span class="math inline">\(p\)</span>.</p>
<p>If we assume that the null hypothesis is true then <span class="math inline">\(X \rightarrow Bernoulli(p_0)\)</span> and the standardized error that we make when we estimate <span class="math inline">\(p_0\)</span> with <span class="math inline">\(\bar{X}\)</span> is</p>
<p><span class="math display">\[Z=\frac{\bar{X}-p_0}{\frac{\sqrt{p_0(1-p_0)}}{\sqrt{n}}}  \rightarrow N(0,1)\]</span></p>
<p><span class="math inline">\(\sigma=\sqrt{p_0(1-p_0)}\)</span> is the standard deviation of <span class="math inline">\(X\)</span> when the null hypothesis is true: <span class="math inline">\(V(X)=\sigma^2=p_0(1-p_0)\)</span>. With this statistics <span class="math inline">\(Z\)</span>, we can accept or reject the null hypothesis using any of the three testing criteria.</p>
<p><strong>Example (process improvement)</strong></p>
<p>We may be satisfied with a new process if <span class="math inline">\(90\%\)</span> of the times we improve the previous process.</p>
<p>If we run a sample of <span class="math inline">\(200\)</span> new processes and find that <span class="math inline">\(188\)</span> times we improved the previous process, can we be satisfied with the new process at <span class="math inline">\(95\%\)</span> confidence?</p>
<p>We then formulate an upper-tailed hypothesis contrast for the null hypothesis <span class="math inline">\(p_0=0.9\)</span>. Therefore, the null and alternative hypotheses are</p>
<ul>
<li><span class="math inline">\(H_0: p \leq p_0=0.9\)</span> (Not satisfactory)</li>
<li><span class="math inline">\(H_1: p&gt; p_0=0.9\)</span> (Satisfactory)</li>
</ul>
<p>We assume that if the null hypothesis is true then</p>
<ol style="list-style-type: decimal">
<li>the distribution of a random experiment is</li>
</ol>
<p><span class="math display">\[X \rightarrow Bernoulli (p_0)\]</span>
2. and check that when <span class="math inline">\(p_0n=180&gt;5\)</span> and <span class="math inline">\((1-p_0)=n=20&gt;5\)</span></p>
<p>And therefore can apply <strong>case 3</strong>.</p>
<p>We can use any of the three criteria to test the hypothesis. In any case, we will <strong>reject</strong> <span class="math inline">\(H_0\)</span> at <span class="math inline">\(95\%\)</span> confidence because:</p>
<ol style="list-style-type: decimal">
<li>The upper tail confidence interval for the <span class="math inline">\(p\)</span> does not include <span class="math inline">\(p_0\)</span></li>
</ol>
<p><span class="math inline">\(p_0=0.9 \notin (\bar{x}-z_{0.05}\big[\frac{p_0(1-p_0)}{n} \big]^{1/2},1)= (0.905,1)\)</span></p>
<ol start="2" style="list-style-type: decimal">
<li>The observed standardized error from the null is not in the acceptance region</li>
</ol>
<p><span class="math display">\[z_{obs}= \frac{\bar{X}-p_0}{\big[\frac{p_0(1-p_0)}{n} \big]^{1/2}} =\frac{0.94-0.90}{\sqrt{0.00045}}=1.88563 \notin (-\infty, z_{0.05})=(-\infty, 1.644)\]</span></p>
<ol start="3" style="list-style-type: decimal">
<li>The upper tail <span class="math inline">\(pvalue\)</span> is lower than <span class="math inline">\(\alpha=0.05\)</span>:</li>
</ol>
<p><span class="math display">\[pvalue=1-\phi(1.885618)=0.02967323&lt;0.05\]</span></p>
<p>in R: <code>1-pnorm(1.885618)</code></p>
<p><img src="_main_files/figure-html/unnamed-chunk-125-1.png" width="672" /></p>
<p>The test can be performed in R using the prop.test function</p>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="hypothesis-testing.html#cb68-1" tabindex="-1"></a><span class="fu">prop.test</span>(<span class="dv">188</span>, <span class="dv">200</span>, <span class="at">p=</span><span class="fl">0.9</span>, <span class="at">alternative =</span> <span class="st">&quot;greater&quot;</span> , <span class="at">correct=</span><span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## 
##  1-sample proportions test without continuity correction
## 
## data:  188 out of 200, null probability 0.9
## X-squared = 3.5556, df = 1, p-value = 0.02967
## alternative hypothesis: true p is greater than 0.9
## 95 percent confidence interval:
##  0.9060689 1.0000000
## sample estimates:
##    p 
## 0.94</code></pre>
</div>
<div id="case-4-variances" class="section level2 hasAnchor" number="14.7">
<h2><span class="header-section-number">14.7</span> Case 4 (variances)<a href="hypothesis-testing.html#case-4-variances" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In many cases, experiments are run to test specific values of the dispersion of data.</p>
<p>Such as</p>
<ul>
<li><p>when complying with strict design standards where measurements must be between certain values.</p></li>
<li><p>when different treatments are applied to different groups, we want to see the dispersion of outcomes between the groups.</p></li>
</ul>
<p>A <strong>tow tailed</strong> hypothesis contrast for the variance is of the form</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\sigma = \sigma_0\)</span> (status quo)</li>
<li><span class="math inline">\(H_1:\sigma \neq \sigma_0\)</span> (research interest)</li>
</ol>
<p>This hypothesis for sigma (<strong>case 4</strong>) can be tested when</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(X\)</span> is a normal variable</li>
</ol>
<p>Remember that if we take a the sample of <span class="math inline">\(n\)</span> Bernoulli trials <span class="math inline">\((1,0,1,...0)\)</span>, <span class="math inline">\(S^2=\frac{1}{n-1}\sum_{i=1}^n (X_i-\bar{X})^2\)</span> is the sample variance. This is an estimator of <span class="math inline">\(\sigma^2\)</span>.</p>
<p>If we assume that the null hypothesis is true then <span class="math inline">\(X \rightarrow N(\mu, \sigma_0)\)</span> and the <strong>error ratio</strong> that we make when we estimate <span class="math inline">\(\sigma^2\)</span> with <span class="math inline">\(s^2\)</span> is</p>
<p><span class="math display">\[W=\frac{(n-1)S^2}{\sigma_0^2}\]</span></p>
<p>when <span class="math inline">\(W=1\)</span> we make no error. <span class="math inline">\(W\)</span> has a <span class="math inline">\(\chi^2\)</span> (chi-squared) distribution with n-1 degrees of freedom.</p>
<p><span class="math display">\[W \rightarrow \chi^2(n-1)\]</span></p>
<p>With <span class="math inline">\(W\)</span>, we can accept or reject the null hypothesis using any of the three testing criteria.</p>
<p><strong>Example (semiconductor)</strong></p>
<p>The production of a semiconductor chip is regulated by a process that requires that the thickness of a particular layer does not vary in more than <span class="math inline">\(\sigma_0=0.6mm\)</span>, from its mean of <span class="math inline">\(25mm\)</span>.</p>
<p>To keep control of the process every so often a sample of <span class="math inline">\(20\)</span> specimens is taken.</p>
<p>On one occasion a sample of the thickness of 20 semiconductors is</p>
<pre><code>##  [1] 24.51239 24.79975 26.35608 25.06134 25.11248 26.49211 25.40100 23.89940
##  [9] 24.40244 24.61227 26.06495 25.31304 25.34867 25.09629 24.51642 26.55461
## [17] 25.43313 23.28904 25.61018 24.58867</code></pre>
<p>The estimated standard deviation for this data is <span class="math inline">\(s=0.8462188\)</span> was the process out of control at <span class="math inline">\(0.99\%\)</span> confidence and should be stopped?</p>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="hypothesis-testing.html#cb71-1" tabindex="-1"></a><span class="fu">sd</span>(x)</span></code></pre></div>
<pre><code>## [1] 0.8462188</code></pre>
<p>We therefore want to contrast the upper tail hypotheses</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0:\sigma^2 \leq \sigma_0^2=0.6^2\)</span> (Process is under control)</li>
<li><span class="math inline">\(H_1:\sigma^2 &gt; \sigma_0^2=0.6^2\)</span> (Process is out of control)</li>
</ol>
<p>Let’s test the hypothesis using the <strong>acceptance region</strong>.</p>
<p>The contrast statistics is <span class="math display">\[W=\frac{(n-1)S^2}{\sigma_0^2} \rightarrow \chi^2(n-1)\]</span></p>
<p>and the threshold limit <span class="math inline">\(\alpha=0.01=0-0.99\)</span>. Therefore, the acceptance region <span class="math inline">\(P(W\leq \chi^2_{0.01,19})=0.99\)</span> is</p>
<p><span class="math display">\[(0, \chi^2_{0.01,19})=(0,36.19)\]</span></p>
<p>In R: <span class="math inline">\(\chi^2_{0.01,19}=\)</span><code>qchisq(0.99,19)</code><span class="math inline">\(= 36.19\)</span></p>
<p>For our data, the observed <strong>standardized error ratio</strong> is:</p>
<p><span class="math display">\[w_{obs}=\frac{19 (0.8462188)^2}{0.60^2}=37.79344\]</span></p>
<p>That falls outside the acceptance region</p>
<p><span class="math display">\[w_{obs}=37.79344\notin (0,36.19)\]</span></p>
<p>Therefore, we reject the null hypothesis and conclude that that yes! the process is out of control.</p>
<p>If we, alternativelly, calculate the upper tailed <span class="math inline">\(pvalue\)</span></p>
<p><span class="math display">\[pvalue=1-F_{\chi^2,19}(37.79344)= 0.006\]</span>
we see that it is lower than <span class="math inline">\(\alpha=0.01\)</span> and reject the null hypothesis.</p>
<p>R: <code>1-pchisq(37.79344, 19)</code></p>
<p><img src="_main_files/figure-html/unnamed-chunk-129-1.png" width="672" /></p>
<p>For testing the hypothesis we can use the varTest function from EnvStats library. If the library is not installed first run</p>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="hypothesis-testing.html#cb73-1" tabindex="-1"></a><span class="fu">install.packages</span>(EnvStats)</span></code></pre></div>
<p>then</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="hypothesis-testing.html#cb74-1" tabindex="-1"></a><span class="fu">library</span>(EnvStats);</span>
<span id="cb74-2"><a href="hypothesis-testing.html#cb74-2" tabindex="-1"></a><span class="fu">varTest</span>(x, <span class="at">sigma.squared =</span> <span class="fl">0.6</span><span class="sc">^</span><span class="dv">2</span>, <span class="at">alternative =</span> <span class="st">&quot;greater&quot;</span>, <span class="at">conf.level =</span> <span class="fl">0.99</span>) </span></code></pre></div>
<pre><code>## 
## Results of Hypothesis Test
## --------------------------
## 
## Null Hypothesis:                 variance = 0.36
## 
## Alternative Hypothesis:          True variance is greater than 0.36
## 
## Test Name:                       Chi-Squared Test on Variance
## 
## Estimated Parameter(s):          variance = 0.7160863
## 
## Data:                            x
## 
## Test Statistic:                  Chi-Squared = 37.79344
## 
## Test Statistic Parameter:        df = 19
## 
## P-value:                         0.006304231
## 
## 99% Confidence Interval:         LCL = 0.3759412
##                                  UCL =       Inf</code></pre>
<p>We also see that <span class="math inline">\(\sigma_0^2=0.6^2=0.36\)</span> is not in the confidence interval, thus rejecting the null hypothesis.</p>
</div>
<div id="errors-in-hypothesis-testing" class="section level2 hasAnchor" number="14.8">
<h2><span class="header-section-number">14.8</span> Errors in hypothesis testing<a href="hypothesis-testing.html#errors-in-hypothesis-testing" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The result of an upper tail hypothesis test may be to <strong>reject</strong> the null hypothesis:</p>
<p><span class="math display">\[H_0: \mu\leq\mu_0\]</span></p>
<p>when <span class="math inline">\(H_0\)</span> is actually <strong>true</strong>. We must bear in mind that the decision is made based on the data. It may well be that the observed statistic has fallen, by chance, far from the null hypothesis, in the rejection zone of <span class="math inline">\(H_0\)</span> even when this is true. When we perform the hypothesis test, we don’t know if <span class="math inline">\(H_0\)</span> is true. If we now know that <span class="math inline">\(H_0\)</span> is true, it is because we are assuming that we have found it out in some other way. Still, the probability of rejecting <span class="math inline">\(H_0\)</span> when it is true is precisely the level of statistical significance <span class="math inline">\(\alpha\)</span>. We call this probability the probability of making a <strong>type 1</strong> error. Taking the example for <strong>case 1</strong>, an upper tail test, and a confidence of <span class="math inline">\(95\%\)</span> we have that</p>
<p><span class="math display">\[\alpha = P(Z&gt; z_{0.05})=0.05\]</span></p>
<p>where <span class="math inline">\(z_{0.05}=\phi^{-1}(0.95)=\)</span> <code>qnorm(0.95)=1.644</code></p>
<p><img src="_main_files/figure-html/unnamed-chunk-132-1.png" width="672" /></p>
<p>A type 1 error is also called a <strong>false positive</strong> because our research interest is in <span class="math inline">\(H_1\)</span>. When we reject <span class="math inline">\(H_0\)</span>, we accept <span class="math inline">\(H_1\)</span> and say that our test is <strong>positive</strong>. Accepting <span class="math inline">\(H_1\)</span> translates to announcing a discovery, so the type 1 error is announcing a discovery when it doesn’t exist: we did it because the data suggested it.</p>
<p>There is another type of error. The result of an upper tail hypothesis test can be <strong>accepting</strong> the null hypothesis:</p>
<p><span class="math display">\[H_0: \mu\leq\mu_0\]</span></p>
<p>when this is <strong>not true</strong>. In this case, it may be that the observed statistic has fallen, due to randomness, close to the null hypothesis, in the zone of acceptance of <span class="math inline">\(H_0\)</span>, when really <span class="math inline">\(H_1\)</span> is true. If we found out somehow that, for example, <span class="math inline">\(\mu\)</span> really does have a value of <span class="math inline">\(\mu_1\)</span> then the alternative hypothesis would be exactly:</p>
<p><span class="math display">\[H_1: \mu=\mu_1\]</span></p>
<p><img src="_main_files/figure-html/unnamed-chunk-133-1.png" width="672" /></p>
<p>If <span class="math inline">\(H_1\)</span> is indeed true (red line, which we don’t know when we perform the hypothesis test) then the observed statistics are <strong>really</strong> random variables <span class="math inline">\(Y\)</span> that are distributed with mean (case 1)</p>
<p><span class="math display">\[E(Y)=\frac{\mu_1-\mu_0}{\frac{\sigma}{\sqrt{n}}}\]</span></p>
<p>and most of them will fall close to this value, therefore, in the rejection area of <span class="math inline">\(H_0\)</span>, validating the hypothesis test. However, there are cases in which the observed statistic falls within the acceptance zone of <span class="math inline">\(H_0\)</span> due to randomness, despite the fact that the statistics are produced by <span class="math inline">\(H_1\)</span>. In these cases we accept <span class="math inline">\(H_0\)</span> when it is not true. This error is called <strong>a type 2 error</strong> or a <strong>false negative</strong>. For case 1, with an upper tailed test and a confidence level of <span class="math inline">\(95\%\)</span>, this is</p>
<p><span class="math display">\[\beta= P(Y &lt; z_{0.05})\]</span>
Where <span class="math inline">\(Y \rightarrow N(\frac{\mu_1-\mu_0}{\sigma/\sqrt{n}},1)\)</span> is the <strong>true distribution</strong> of the observed statistics.</p>
<p><strong>Example (Light bulb)</strong></p>
<p>The energy efficiency of a new light bulb is a normal random variable with a standard deviation of <span class="math inline">\(5\)</span> watts. We consider that the light bulbs we produce are efficient if their average does not exceed <span class="math inline">\(80\)</span> watts, so we propose the hypothesis test</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0 : \mu \geq 80\)</span> (efficient)</li>
<li><span class="math inline">\(H_1 : \mu &lt; 80\)</span> (not efficient)</li>
</ol>
<p>We want to prove that we produce efficient light bulbs and we plan to draw a random sample of size 100, with a statistical significance level of <span class="math inline">\(5\%\)</span>. If previous studies have suggested that light bulbs may average <span class="math inline">\(\mu=\mu_1=79\)</span> watts, what type 2 error do we expect?</p>
<p>The contrast is for <strong>case 1</strong> with a <strong>lower tail</strong>. Therefore the probability of accepting the null hypothesis (we do not produce efficient light bulbs) is</p>
<p><span class="math display">\[\alpha = P(Z&lt; z_{0.95})=0.05\]</span>
and <span class="math inline">\(z_{0.95}=\)</span><code>qnorm(0.05)</code><span class="math inline">\(=-1.644\)</span>.</p>
<p>The type 2 error is therefore</p>
<p><span class="math display">\[\beta= P(Y &gt; -1.644)\]</span></p>
<p>that is, the probability of accepting that we do not produce efficient light bulbs when in fact we do. Because we are in <strong>case 1</strong>, as we know <span class="math inline">\(\sigma\)</span> and the variable is normal, the observed statistics are actually distributed as</p>
<p><span class="math display">\[Y \rightarrow N(\frac{79-80}{5/\sqrt{100}}=-2,1)\]</span> and the type 2 error is</p>
<p><span class="math display">\[\beta = 1-F(-1.644)=0.36\]</span></p>
<p>computed in R as <code>1-pnorm(-1.644,-2,1)=0.36</code>. Therefore, only <span class="math inline">\(\alpha=5\%\)</span> of the times we would announce that we produce efficient light bulbs when they really are not, while <span class="math inline">\(\beta=36\%\)</span> of the times we would announce that we have a production that is not useful when it really does work.</p>
<p>When we carry out a hypothesis test we have two possibilities for each condition</p>
<ul>
<li><span class="math inline">\(H_1\)</span> is actually : <strong>true</strong> (<span class="math inline">\(\mu=\mu_1\)</span>) or <strong>false</strong> (<span class="math inline">\(\mu=\mu_0\)</span>)</li>
<li>The test for <span class="math inline">\(H_1\)</span> is: <strong>positive</strong> (<span class="math inline">\(z_{obs}\)</span> in the acceptance zone of <span class="math inline">\(H_1\)</span>) or <strong>negative</strong> (<span class="math inline">\(z_{obs}\)</span> in the acceptance zone of <span class="math inline">\(H_0\)</span>)</li>
</ul>
<p><strong>Example (PCR)</strong></p>
<p>We do <strong>a</strong> PCR to test for an infection. The hypothesis test is</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(H_0\)</span> no infection</li>
<li><span class="math inline">\(H_1\)</span> there is infection</li>
</ol>
<p>We do the PCR test and it gives us</p>
<ol style="list-style-type: lower-roman">
<li>negative: we reject the infection (<span class="math inline">\(H_1\)</span>)</li>
<li>positive: we accept the infection (<span class="math inline">\(H_1\)</span>)</li>
</ol>
<p>We can write the contingency table for the probabilities of the results of the hypothesis test as</p>
<table>
<thead>
<tr class="header">
<th align="center"></th>
<th align="center"><span class="math inline">\(H_1\)</span> is true</th>
<th align="center"><span class="math inline">\(H_0\)</span> is true</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><strong>The test on <span class="math inline">\(H_1\)</span> is positive</strong></td>
<td align="center"><span class="math inline">\(1-\beta\)</span></td>
<td align="center"><span class="math inline">\(\alpha\)</span></td>
</tr>
<tr class="even">
<td align="center"><strong>The test on <span class="math inline">\(H_1\)</span> is negative</strong></td>
<td align="center"><span class="math inline">\(\beta\)</span></td>
<td align="center"><span class="math inline">\(1-\alpha\)</span></td>
</tr>
<tr class="odd">
<td align="center"><strong>sum</strong></td>
<td align="center">1</td>
<td align="center">1</td>
</tr>
</tbody>
</table>
<p>we therefore have</p>
<ol style="list-style-type: decimal">
<li>The <strong>type 2 error</strong> rate: probability of a false negative (ignore a finding when it is true)</li>
</ol>
<p><span class="math display">\[\beta=P(negative|H_1)\]</span></p>
<ol start="2" style="list-style-type: decimal">
<li><p><strong>True positive</strong> rate: This is the power or sensitivity of a test (affirming a discovery when it is true, the main objective)
<span class="math display">\[1-\beta=P(positive|H_1)\]</span></p></li>
<li><p><strong>Type 1 error</strong> rate: probability of a false positive (state a discovery when it is false)
<span class="math display">\[\alpha=P(positive|H_0)\]</span></p></li>
<li><p><strong>True Negative</strong> rate: This is the specificity of a test (ignore a finding when it is false)
<span class="math display">\[1-\alpha=P(negative|H_0)\]</span></p></li>
</ol>
</div>
<div id="exercises-12" class="section level2 hasAnchor" number="14.9">
<h2><span class="header-section-number">14.9</span> Exercises<a href="hypothesis-testing.html#exercises-12" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="exercise-1-12" class="section level4 hasAnchor" number="14.9.0.1">
<h4><span class="header-section-number">14.9.0.1</span> Exercise 1<a href="hypothesis-testing.html#exercise-1-12" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Imagine we take a random sample of size <span class="math inline">\(n = 41\)</span> of a normal random variable <span class="math inline">\(X\)</span>, and find that the sample average is <span class="math inline">\(10\)</span> and the sample variance is <span class="math inline">\(1.5\)</span>.</p>
<ul>
<li>What is then the confidence interval for the mean of <span class="math inline">\(X\)</span> at <span class="math inline">\(95\%\)</span> confidence level?</li>
</ul>
<p>Consider that <span class="math inline">\(t_{0.025,40}=\)</span> <code>qt(0.975, 40)</code> <span class="math inline">\(\sim 2\)</span>.</p>
<ul>
<li><p>Test the hypothesis that the mean of <span class="math inline">\(X\)</span> is <strong>different</strong> than <span class="math inline">\(10.5\)</span>, using a <span class="math inline">\(5\%\)</span> significance threshold.</p></li>
<li><p>Write the code to calculate the P-value to test the hypothesis that the mean of <span class="math inline">\(\mu\)</span> is <strong>lower</strong> than <span class="math inline">\(10.5\)</span>, using a <span class="math inline">\(5\%\)</span> significance threshold.</p></li>
</ul>
<p>Consider that the code for the T probability distribution with <span class="math inline">\(n-1\)</span> degrees of freedom is <code>pt(tobs, n-1)</code>.</p>
</div>
<div id="exercise-2-12" class="section level4 hasAnchor" number="14.9.0.2">
<h4><span class="header-section-number">14.9.0.2</span> Exercise 2<a href="hypothesis-testing.html#exercise-2-12" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><span class="math inline">\(10\)</span> gas condensates showed the following concentrations of mercury (in <span class="math inline">\(ng/ml\)</span>):</p>
<p><span class="math inline">\(23.3\)</span>, <span class="math inline">\(22.5\)</span>, <span class="math inline">\(21.9\)</span>, <span class="math inline">\(21.5\)</span>, <span class="math inline">\(19.9\)</span>, <span class="math inline">\(21.3\)</span>, <span class="math inline">\(21.7\)</span>, <span class="math inline">\(23.8\)</span>, <span class="math inline">\(22.6\)</span>, <span class="math inline">\(24.7\)</span></p>
<p>Assuming that the mercury concentration is distributed normally across gas condensates, test the hypothesis that condensate does not surpass the toxicity limit established at <span class="math inline">\(24 ng/ml\)</span>.</p>
</div>
<div id="exercise-3-9" class="section level4 hasAnchor" number="14.9.0.3">
<h4><span class="header-section-number">14.9.0.3</span> Exercise 3<a href="hypothesis-testing.html#exercise-3-9" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The manufacturer of gene expression microarrays guarantees that at least <span class="math inline">\(97\%\)</span> of the microarrays they produce have high-quality signals. A customer receives a batch of <span class="math inline">\(200\)</span> pieces and finds that <span class="math inline">\(8\)</span> unperformed.</p>
<p>Should the customer return the lot due to poor quality?</p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="interval-estimation.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="solutions-to-questions.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/13-HypothesisTesting.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
