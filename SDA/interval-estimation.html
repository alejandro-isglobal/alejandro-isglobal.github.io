<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 13 Interval estimation | Statistical Data Analysis for Experimental Sciences</title>
  <meta name="description" content="This is a markdown book titled Statistical Data Analysis for Experimental Sciences by Alejandro Caceres" />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 13 Interval estimation | Statistical Data Analysis for Experimental Sciences" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a markdown book titled Statistical Data Analysis for Experimental Sciences by Alejandro Caceres" />
  <meta name="github-repo" content="alejandro-isglobal/master" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 13 Interval estimation | Statistical Data Analysis for Experimental Sciences" />
  
  <meta name="twitter:description" content="This is a markdown book titled Statistical Data Analysis for Experimental Sciences by Alejandro Caceres" />
  

<meta name="author" content="Alejandro CÃ¡ceres" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="maximum-likelihood.html"/>
<link rel="next" href="hypothesis-testing.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">SDA</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#how-to-read-the-book"><i class="fa fa-check"></i><b>1.1</b> How to read the book</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>1.2</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-description.html"><a href="data-description.html"><i class="fa fa-check"></i><b>2</b> Data description</a>
<ul>
<li class="chapter" data-level="2.1" data-path="data-description.html"><a href="data-description.html#scientific-method"><i class="fa fa-check"></i><b>2.1</b> Scientific method</a></li>
<li class="chapter" data-level="2.2" data-path="data-description.html"><a href="data-description.html#data"><i class="fa fa-check"></i><b>2.2</b> Data</a></li>
<li class="chapter" data-level="2.3" data-path="data-description.html"><a href="data-description.html#types-of-outcomes"><i class="fa fa-check"></i><b>2.3</b> Types of outcomes</a></li>
<li class="chapter" data-level="2.4" data-path="data-description.html"><a href="data-description.html#random-experiments"><i class="fa fa-check"></i><b>2.4</b> Random experiments</a></li>
<li class="chapter" data-level="2.5" data-path="data-description.html"><a href="data-description.html#absolute-frequencies"><i class="fa fa-check"></i><b>2.5</b> Absolute frequencies</a></li>
<li class="chapter" data-level="2.6" data-path="data-description.html"><a href="data-description.html#relative-frequencies"><i class="fa fa-check"></i><b>2.6</b> Relative frequencies</a></li>
<li class="chapter" data-level="2.7" data-path="data-description.html"><a href="data-description.html#bar-chart"><i class="fa fa-check"></i><b>2.7</b> Bar chart</a></li>
<li class="chapter" data-level="2.8" data-path="data-description.html"><a href="data-description.html#pie-chart"><i class="fa fa-check"></i><b>2.8</b> Pie chart</a></li>
<li class="chapter" data-level="2.9" data-path="data-description.html"><a href="data-description.html#ordinal-categorical-outcomes"><i class="fa fa-check"></i><b>2.9</b> Ordinal categorical outcomes</a></li>
<li class="chapter" data-level="2.10" data-path="data-description.html"><a href="data-description.html#absolute-and-relative-cumulative-frequencies"><i class="fa fa-check"></i><b>2.10</b> Absolute and relative cumulative frequencies</a></li>
<li class="chapter" data-level="2.11" data-path="data-description.html"><a href="data-description.html#cumulative-frequency-graph"><i class="fa fa-check"></i><b>2.11</b> Cumulative frequency graph</a></li>
<li class="chapter" data-level="2.12" data-path="data-description.html"><a href="data-description.html#numerical-outcomes"><i class="fa fa-check"></i><b>2.12</b> Numerical outcomes</a></li>
<li class="chapter" data-level="2.13" data-path="data-description.html"><a href="data-description.html#transforming-continuous-data"><i class="fa fa-check"></i><b>2.13</b> Transforming continuous data</a></li>
<li class="chapter" data-level="2.14" data-path="data-description.html"><a href="data-description.html#frequency-table-for-a-continuous-variable"><i class="fa fa-check"></i><b>2.14</b> Frequency table for a continuous variable</a></li>
<li class="chapter" data-level="2.15" data-path="data-description.html"><a href="data-description.html#histogram"><i class="fa fa-check"></i><b>2.15</b> Histogram</a></li>
<li class="chapter" data-level="2.16" data-path="data-description.html"><a href="data-description.html#cumulative-frequency-graph-1"><i class="fa fa-check"></i><b>2.16</b> Cumulative frequency graph</a></li>
<li class="chapter" data-level="2.17" data-path="data-description.html"><a href="data-description.html#summary-statistics"><i class="fa fa-check"></i><b>2.17</b> Summary Statistics</a></li>
<li class="chapter" data-level="2.18" data-path="data-description.html"><a href="data-description.html#average-sample-mean"><i class="fa fa-check"></i><b>2.18</b> Average (sample mean)</a></li>
<li class="chapter" data-level="2.19" data-path="data-description.html"><a href="data-description.html#median"><i class="fa fa-check"></i><b>2.19</b> Median</a></li>
<li class="chapter" data-level="2.20" data-path="data-description.html"><a href="data-description.html#dispersion"><i class="fa fa-check"></i><b>2.20</b> Dispersion</a></li>
<li class="chapter" data-level="2.21" data-path="data-description.html"><a href="data-description.html#sample-variance"><i class="fa fa-check"></i><b>2.21</b> Sample variance</a></li>
<li class="chapter" data-level="2.22" data-path="data-description.html"><a href="data-description.html#interquartile-range-iqr"><i class="fa fa-check"></i><b>2.22</b> Interquartile range (IQR)</a></li>
<li class="chapter" data-level="2.23" data-path="data-description.html"><a href="data-description.html#boxplot"><i class="fa fa-check"></i><b>2.23</b> Boxplot</a></li>
<li class="chapter" data-level="2.24" data-path="data-description.html"><a href="data-description.html#questions"><i class="fa fa-check"></i><b>2.24</b> Questions</a></li>
<li class="chapter" data-level="2.25" data-path="data-description.html"><a href="data-description.html#exercises"><i class="fa fa-check"></i><b>2.25</b> Exercises</a></li>
<li class="chapter" data-level="2.26" data-path="data-description.html"><a href="data-description.html#practice"><i class="fa fa-check"></i><b>2.26</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>3</b> Probability</a>
<ul>
<li class="chapter" data-level="3.1" data-path="probability.html"><a href="probability.html#probability-mesurement"><i class="fa fa-check"></i><b>3.1</b> Probability mesurement</a></li>
<li class="chapter" data-level="3.2" data-path="probability.html"><a href="probability.html#classical-probability"><i class="fa fa-check"></i><b>3.2</b> Classical probability</a></li>
<li class="chapter" data-level="3.3" data-path="probability.html"><a href="probability.html#relative-frequencies-1"><i class="fa fa-check"></i><b>3.3</b> Relative frequencies</a></li>
<li class="chapter" data-level="3.4" data-path="probability.html"><a href="probability.html#frequentist-probability"><i class="fa fa-check"></i><b>3.4</b> Frequentist probability</a></li>
<li class="chapter" data-level="3.5" data-path="probability.html"><a href="probability.html#classical-and-frequentist-probabilities"><i class="fa fa-check"></i><b>3.5</b> Classical and frequentist probabilities</a></li>
<li class="chapter" data-level="3.6" data-path="probability.html"><a href="probability.html#sample-space"><i class="fa fa-check"></i><b>3.6</b> Sample space</a></li>
<li class="chapter" data-level="3.7" data-path="probability.html"><a href="probability.html#events"><i class="fa fa-check"></i><b>3.7</b> Events</a></li>
<li class="chapter" data-level="3.8" data-path="probability.html"><a href="probability.html#algebra-of-events"><i class="fa fa-check"></i><b>3.8</b> Algebra of events</a></li>
<li class="chapter" data-level="3.9" data-path="probability.html"><a href="probability.html#mutually-exclusive-events"><i class="fa fa-check"></i><b>3.9</b> Mutually exclusive events</a></li>
<li class="chapter" data-level="3.10" data-path="probability.html"><a href="probability.html#definition-of-probability"><i class="fa fa-check"></i><b>3.10</b> Definition of probability</a></li>
<li class="chapter" data-level="3.11" data-path="probability.html"><a href="probability.html#probability-table"><i class="fa fa-check"></i><b>3.11</b> Probability table</a></li>
<li class="chapter" data-level="3.12" data-path="probability.html"><a href="probability.html#joint-probabilities"><i class="fa fa-check"></i><b>3.12</b> Joint probabilities</a></li>
<li class="chapter" data-level="3.13" data-path="probability.html"><a href="probability.html#contingency-table"><i class="fa fa-check"></i><b>3.13</b> Contingency table</a></li>
<li class="chapter" data-level="3.14" data-path="probability.html"><a href="probability.html#the-addition-rule"><i class="fa fa-check"></i><b>3.14</b> The addition rule</a></li>
<li class="chapter" data-level="3.15" data-path="probability.html"><a href="probability.html#questions-1"><i class="fa fa-check"></i><b>3.15</b> Questions</a></li>
<li class="chapter" data-level="3.16" data-path="probability.html"><a href="probability.html#exercises-1"><i class="fa fa-check"></i><b>3.16</b> Exercises</a></li>
<li class="chapter" data-level="3.17" data-path="probability.html"><a href="probability.html#practice-1"><i class="fa fa-check"></i><b>3.17</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="conditional-probability.html"><a href="conditional-probability.html"><i class="fa fa-check"></i><b>4</b> Conditional probability</a>
<ul>
<li class="chapter" data-level="4.1" data-path="conditional-probability.html"><a href="conditional-probability.html#joint-probability"><i class="fa fa-check"></i><b>4.1</b> Joint probability</a></li>
<li class="chapter" data-level="4.2" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-independence-and-correlation"><i class="fa fa-check"></i><b>4.2</b> Statistical independence and correlation</a></li>
<li class="chapter" data-level="4.3" data-path="conditional-probability.html"><a href="conditional-probability.html#conditional-probability-1"><i class="fa fa-check"></i><b>4.3</b> Conditional probability</a></li>
<li class="chapter" data-level="4.4" data-path="conditional-probability.html"><a href="conditional-probability.html#conditional-contingency-table"><i class="fa fa-check"></i><b>4.4</b> Conditional contingency table</a></li>
<li class="chapter" data-level="4.5" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-independence"><i class="fa fa-check"></i><b>4.5</b> Statistical independence</a></li>
<li class="chapter" data-level="4.6" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-dependency"><i class="fa fa-check"></i><b>4.6</b> Statistical dependency</a></li>
<li class="chapter" data-level="4.7" data-path="conditional-probability.html"><a href="conditional-probability.html#diagnostic-test"><i class="fa fa-check"></i><b>4.7</b> Diagnostic test</a></li>
<li class="chapter" data-level="4.8" data-path="conditional-probability.html"><a href="conditional-probability.html#inverse-probabilities"><i class="fa fa-check"></i><b>4.8</b> Inverse probabilities</a></li>
<li class="chapter" data-level="4.9" data-path="conditional-probability.html"><a href="conditional-probability.html#bayes-theorem"><i class="fa fa-check"></i><b>4.9</b> Bayesâ Theorem</a></li>
<li class="chapter" data-level="4.10" data-path="conditional-probability.html"><a href="conditional-probability.html#questions-2"><i class="fa fa-check"></i><b>4.10</b> Questions</a></li>
<li class="chapter" data-level="4.11" data-path="conditional-probability.html"><a href="conditional-probability.html#exercises-2"><i class="fa fa-check"></i><b>4.11</b> Exercises</a></li>
<li class="chapter" data-level="4.12" data-path="conditional-probability.html"><a href="conditional-probability.html#practice-2"><i class="fa fa-check"></i><b>4.12</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html"><i class="fa fa-check"></i><b>5</b> Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="5.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#definition-of-a-random-variable"><i class="fa fa-check"></i><b>5.1</b> Definition of a Random Variable</a></li>
<li class="chapter" data-level="5.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#the-value-of-a-random-variable"><i class="fa fa-check"></i><b>5.2</b> The value of a random variable</a></li>
<li class="chapter" data-level="5.3" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-of-random-variables"><i class="fa fa-check"></i><b>5.3</b> Probability of random variables</a></li>
<li class="chapter" data-level="5.4" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-functions"><i class="fa fa-check"></i><b>5.4</b> Probability functions</a></li>
<li class="chapter" data-level="5.5" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-mass-functions"><i class="fa fa-check"></i><b>5.5</b> Probability mass functions</a></li>
<li class="chapter" data-level="5.6" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#mean-or-expected-value"><i class="fa fa-check"></i><b>5.6</b> Mean or expected value</a></li>
<li class="chapter" data-level="5.7" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#variance"><i class="fa fa-check"></i><b>5.7</b> Variance</a></li>
<li class="chapter" data-level="5.8" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-functions-for-functions-of-x"><i class="fa fa-check"></i><b>5.8</b> Probability functions for functions of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="5.9" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-distribution"><i class="fa fa-check"></i><b>5.9</b> Probability distribution</a></li>
<li class="chapter" data-level="5.10" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-function-and-probability-distribution"><i class="fa fa-check"></i><b>5.10</b> Probability function and probability distribution</a></li>
<li class="chapter" data-level="5.11" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#quantiles"><i class="fa fa-check"></i><b>5.11</b> Quantiles</a></li>
<li class="chapter" data-level="5.12" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#summary"><i class="fa fa-check"></i><b>5.12</b> Summary</a></li>
<li class="chapter" data-level="5.13" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#questions-3"><i class="fa fa-check"></i><b>5.13</b> Questions</a></li>
<li class="chapter" data-level="5.14" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#exercises-3"><i class="fa fa-check"></i><b>5.14</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="continous-random-variables.html"><a href="continous-random-variables.html"><i class="fa fa-check"></i><b>6</b> Continous Random Variables</a>
<ul>
<li class="chapter" data-level="6.1" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probabilities-of-continuous-random-variables"><i class="fa fa-check"></i><b>6.1</b> Probabilities of continuous random variables</a></li>
<li class="chapter" data-level="6.2" data-path="continous-random-variables.html"><a href="continous-random-variables.html#relative-frequencies-2"><i class="fa fa-check"></i><b>6.2</b> Relative frequencies</a></li>
<li class="chapter" data-level="6.3" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-density-function"><i class="fa fa-check"></i><b>6.3</b> Probability Density Function</a></li>
<li class="chapter" data-level="6.4" data-path="continous-random-variables.html"><a href="continous-random-variables.html#total-area-under-the-curve"><i class="fa fa-check"></i><b>6.4</b> Total area under the curve</a></li>
<li class="chapter" data-level="6.5" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probabilities-of-continous-variables"><i class="fa fa-check"></i><b>6.5</b> Probabilities of continous variables</a></li>
<li class="chapter" data-level="6.6" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-distribution-1"><i class="fa fa-check"></i><b>6.6</b> Probability distribution</a></li>
<li class="chapter" data-level="6.7" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-plots"><i class="fa fa-check"></i><b>6.7</b> Probability plots</a></li>
<li class="chapter" data-level="6.8" data-path="continous-random-variables.html"><a href="continous-random-variables.html#mean"><i class="fa fa-check"></i><b>6.8</b> Mean</a></li>
<li class="chapter" data-level="6.9" data-path="continous-random-variables.html"><a href="continous-random-variables.html#variance-1"><i class="fa fa-check"></i><b>6.9</b> Variance</a></li>
<li class="chapter" data-level="6.10" data-path="continous-random-variables.html"><a href="continous-random-variables.html#functions-of-x"><i class="fa fa-check"></i><b>6.10</b> Functions of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="6.11" data-path="continous-random-variables.html"><a href="continous-random-variables.html#exercises-4"><i class="fa fa-check"></i><b>6.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html"><i class="fa fa-check"></i><b>7</b> Discrete Probability Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#probability-model"><i class="fa fa-check"></i><b>7.1</b> Probability model</a></li>
<li class="chapter" data-level="7.2" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#parametric-models"><i class="fa fa-check"></i><b>7.2</b> Parametric models</a></li>
<li class="chapter" data-level="7.3" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#uniform-probability-mass-function-one-parameter"><i class="fa fa-check"></i><b>7.3</b> Uniform probability mass function (one parameter)</a></li>
<li class="chapter" data-level="7.4" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#uniform-probability-mass-function-two-parameters"><i class="fa fa-check"></i><b>7.4</b> Uniform probability mass function (two parameters)</a></li>
<li class="chapter" data-level="7.5" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#bernoulli-trial"><i class="fa fa-check"></i><b>7.5</b> Bernoulli trial</a></li>
<li class="chapter" data-level="7.6" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#binomial-experiment"><i class="fa fa-check"></i><b>7.6</b> Binomial experiment</a></li>
<li class="chapter" data-level="7.7" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#binomial-probability-function"><i class="fa fa-check"></i><b>7.7</b> Binomial probability function</a></li>
<li class="chapter" data-level="7.8" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#negative-binomial"><i class="fa fa-check"></i><b>7.8</b> Negative binomial</a></li>
<li class="chapter" data-level="7.9" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#geometric-distribution"><i class="fa fa-check"></i><b>7.9</b> Geometric distribution</a></li>
<li class="chapter" data-level="7.10" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#hypergeometric-model"><i class="fa fa-check"></i><b>7.10</b> Hypergeometric model</a></li>
<li class="chapter" data-level="7.11" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#questions-4"><i class="fa fa-check"></i><b>7.11</b> Questions</a></li>
<li class="chapter" data-level="7.12" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#exercises-5"><i class="fa fa-check"></i><b>7.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html"><i class="fa fa-check"></i><b>8</b> Poisson and Exponential Models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#discrete-probability-models-1"><i class="fa fa-check"></i><b>8.1</b> Discrete probability models</a></li>
<li class="chapter" data-level="8.2" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#poissson-experiment"><i class="fa fa-check"></i><b>8.2</b> Poissson experiment</a></li>
<li class="chapter" data-level="8.3" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#poisson-probability-mass-function"><i class="fa fa-check"></i><b>8.3</b> Poisson probability mass function</a></li>
<li class="chapter" data-level="8.4" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#continuous-probability-models"><i class="fa fa-check"></i><b>8.4</b> Continuous probability models</a></li>
<li class="chapter" data-level="8.5" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-process"><i class="fa fa-check"></i><b>8.5</b> Exponential process</a></li>
<li class="chapter" data-level="8.6" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-probability-density"><i class="fa fa-check"></i><b>8.6</b> Exponential probability density</a></li>
<li class="chapter" data-level="8.7" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-distribution"><i class="fa fa-check"></i><b>8.7</b> Exponential Distribution</a></li>
<li class="chapter" data-level="8.8" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#questions-5"><i class="fa fa-check"></i><b>8.8</b> Questions</a></li>
<li class="chapter" data-level="8.9" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exercises-6"><i class="fa fa-check"></i><b>8.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="normal-distribution.html"><a href="normal-distribution.html"><i class="fa fa-check"></i><b>9</b> Normal Distribution</a>
<ul>
<li class="chapter" data-level="9.1" data-path="normal-distribution.html"><a href="normal-distribution.html#history"><i class="fa fa-check"></i><b>9.1</b> History</a></li>
<li class="chapter" data-level="9.2" data-path="normal-distribution.html"><a href="normal-distribution.html#normal-density"><i class="fa fa-check"></i><b>9.2</b> normal density</a></li>
<li class="chapter" data-level="9.3" data-path="normal-distribution.html"><a href="normal-distribution.html#definition"><i class="fa fa-check"></i><b>9.3</b> Definition</a></li>
<li class="chapter" data-level="9.4" data-path="normal-distribution.html"><a href="normal-distribution.html#probability-distribution-2"><i class="fa fa-check"></i><b>9.4</b> Probability distribution</a></li>
<li class="chapter" data-level="9.5" data-path="normal-distribution.html"><a href="normal-distribution.html#standard-normal-density"><i class="fa fa-check"></i><b>9.5</b> Standard normal density</a></li>
<li class="chapter" data-level="9.6" data-path="normal-distribution.html"><a href="normal-distribution.html#standard-distribution"><i class="fa fa-check"></i><b>9.6</b> Standard distribution</a></li>
<li class="chapter" data-level="9.7" data-path="normal-distribution.html"><a href="normal-distribution.html#standardization"><i class="fa fa-check"></i><b>9.7</b> Standardization</a></li>
<li class="chapter" data-level="9.8" data-path="normal-distribution.html"><a href="normal-distribution.html#questions-6"><i class="fa fa-check"></i><b>9.8</b> Questions</a></li>
<li class="chapter" data-level="9.9" data-path="normal-distribution.html"><a href="normal-distribution.html#exercises-7"><i class="fa fa-check"></i><b>9.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="sampling-distributions.html"><a href="sampling-distributions.html"><i class="fa fa-check"></i><b>10</b> Sampling distributions</a>
<ul>
<li class="chapter" data-level="10.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#random-sample"><i class="fa fa-check"></i><b>10.1</b> Random sample</a></li>
<li class="chapter" data-level="10.2" data-path="sampling-distributions.html"><a href="sampling-distributions.html#parameter-estimation"><i class="fa fa-check"></i><b>10.2</b> Parameter estimation</a></li>
<li class="chapter" data-level="10.3" data-path="sampling-distributions.html"><a href="sampling-distributions.html#law-of-large-numbers"><i class="fa fa-check"></i><b>10.3</b> Law of Large Numbers</a></li>
<li class="chapter" data-level="10.4" data-path="sampling-distributions.html"><a href="sampling-distributions.html#inference"><i class="fa fa-check"></i><b>10.4</b> Inference</a></li>
<li class="chapter" data-level="10.5" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-mean"><i class="fa fa-check"></i><b>10.5</b> Sample mean</a></li>
<li class="chapter" data-level="10.6" data-path="sampling-distributions.html"><a href="sampling-distributions.html#prediction"><i class="fa fa-check"></i><b>10.6</b> Prediction</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#example-pacemaker-prediction"><i class="fa fa-check"></i><b>10.6.1</b> <strong>Example: Pacemaker Prediction</strong></a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="sampling-distributions.html"><a href="sampling-distributions.html#validation"><i class="fa fa-check"></i><b>10.7</b> Validation</a></li>
<li class="chapter" data-level="10.8" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-sum"><i class="fa fa-check"></i><b>10.8</b> Sample Sum</a>
<ul>
<li class="chapter" data-level="10.8.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#example-cables"><i class="fa fa-check"></i><b>10.8.1</b> Example (Cables)</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-variance-1"><i class="fa fa-check"></i><b>10.9</b> Sample Variance</a>
<ul>
<li class="chapter" data-level="10.9.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#example-cables-1"><i class="fa fa-check"></i><b>10.9.1</b> Example (Cables)</a></li>
</ul></li>
<li class="chapter" data-level="10.10" data-path="sampling-distributions.html"><a href="sampling-distributions.html#distribution-of-the-sample-variance"><i class="fa fa-check"></i><b>10.10</b> Distribution of the Sample Variance</a></li>
<li class="chapter" data-level="10.11" data-path="sampling-distributions.html"><a href="sampling-distributions.html#the-chi2-distribution"><i class="fa fa-check"></i><b>10.11</b> The <span class="math inline">\(\chi^2\)</span> Distribution</a></li>
<li class="chapter" data-level="10.12" data-path="sampling-distributions.html"><a href="sampling-distributions.html#questions-7"><i class="fa fa-check"></i><b>10.12</b> Questions</a></li>
<li class="chapter" data-level="10.13" data-path="sampling-distributions.html"><a href="sampling-distributions.html#exercises-8"><i class="fa fa-check"></i><b>10.13</b> Exercises</a>
<ul>
<li class="chapter" data-level="10.13.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#from-estimation-to-inference"><i class="fa fa-check"></i><b>10.13.1</b> From Estimation to Inference</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html"><i class="fa fa-check"></i><b>11</b> Central limit theorem</a>
<ul>
<li class="chapter" data-level="11.1" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#margin-of-error"><i class="fa fa-check"></i><b>11.1</b> Margin of error</a></li>
<li class="chapter" data-level="11.2" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#averages-of-normal-variables"><i class="fa fa-check"></i><b>11.2</b> Averages of normal variables</a></li>
<li class="chapter" data-level="11.3" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#central-limit-theorem-1"><i class="fa fa-check"></i><b>11.3</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="11.4" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#sample-sum-and-clt"><i class="fa fa-check"></i><b>11.4</b> Sample sum and CLT</a></li>
<li class="chapter" data-level="11.5" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#unknown-sigma"><i class="fa fa-check"></i><b>11.5</b> Unknown <span class="math inline">\(\sigma\)</span></a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#example-pacemaker-prediction-1"><i class="fa fa-check"></i><b>11.5.1</b> <strong>Example: Pacemaker Prediction</strong></a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#t-statistic"><i class="fa fa-check"></i><b>11.6</b> T-statistic</a></li>
<li class="chapter" data-level="11.7" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#questions-8"><i class="fa fa-check"></i><b>11.7</b> Questions</a></li>
<li class="chapter" data-level="11.8" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#exercises-9"><i class="fa fa-check"></i><b>11.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html"><i class="fa fa-check"></i><b>12</b> Maximum likelihood</a>
<ul>
<li class="chapter" data-level="12.1" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#statistic"><i class="fa fa-check"></i><b>12.1</b> Statistic</a></li>
<li class="chapter" data-level="12.2" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#properties"><i class="fa fa-check"></i><b>12.2</b> Properties</a></li>
<li class="chapter" data-level="12.3" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#maximum-likelihood-1"><i class="fa fa-check"></i><b>12.3</b> Maximum likelihood</a></li>
<li class="chapter" data-level="12.4" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#maximum-likelihood-2"><i class="fa fa-check"></i><b>12.4</b> Maximum likelihood</a></li>
<li class="chapter" data-level="12.5" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#questions-9"><i class="fa fa-check"></i><b>12.5</b> Questions</a></li>
<li class="chapter" data-level="12.6" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#exercises-10"><i class="fa fa-check"></i><b>12.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="interval-estimation.html"><a href="interval-estimation.html"><i class="fa fa-check"></i><b>13</b> Interval estimation</a>
<ul>
<li class="chapter" data-level="13.1" data-path="interval-estimation.html"><a href="interval-estimation.html#revisiting-parameter-estimation-and-marging-of-error"><i class="fa fa-check"></i><b>13.1</b> Revisiting parameter estimation and marging of error</a></li>
<li class="chapter" data-level="13.2" data-path="interval-estimation.html"><a href="interval-estimation.html#interval-estimation-for-the-mean"><i class="fa fa-check"></i><b>13.2</b> Interval estimation for the mean</a></li>
<li class="chapter" data-level="13.3" data-path="interval-estimation.html"><a href="interval-estimation.html#confidence-interval-estimation"><i class="fa fa-check"></i><b>13.3</b> Confidence Interval Estimation</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="interval-estimation.html"><a href="interval-estimation.html#estimation-of-the-mean-for-normal-variables"><i class="fa fa-check"></i><b>13.3.1</b> Estimation of the mean for normal variables</a></li>
<li class="chapter" data-level="13.3.2" data-path="interval-estimation.html"><a href="interval-estimation.html#estimation-of-the-proportion-for-dichotomic-variables"><i class="fa fa-check"></i><b>13.3.2</b> Estimation of the proportion for dichotomic variables</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="interval-estimation.html"><a href="interval-estimation.html#estimation-of-the-variance"><i class="fa fa-check"></i><b>13.4</b> Estimation of the variance</a></li>
<li class="chapter" data-level="13.5" data-path="interval-estimation.html"><a href="interval-estimation.html#confidence-interval-for-the-variance"><i class="fa fa-check"></i><b>13.5</b> Confidence interval for the variance</a></li>
<li class="chapter" data-level="13.6" data-path="interval-estimation.html"><a href="interval-estimation.html#questions-10"><i class="fa fa-check"></i><b>13.6</b> Questions</a></li>
<li class="chapter" data-level="13.7" data-path="interval-estimation.html"><a href="interval-estimation.html#exercises-11"><i class="fa fa-check"></i><b>13.7</b> Exercises</a></li>
<li class="chapter" data-level="13.8" data-path="interval-estimation.html"><a href="interval-estimation.html#practice-3"><i class="fa fa-check"></i><b>13.8</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>14</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="14.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-formulation"><i class="fa fa-check"></i><b>14.1</b> Hypothesis formulation</a></li>
<li class="chapter" data-level="14.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-1"><i class="fa fa-check"></i><b>14.2</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="14.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-for-the-mean"><i class="fa fa-check"></i><b>14.3</b> Hypothesis testing for the mean</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-with-a-confidence-interval"><i class="fa fa-check"></i><b>14.3.1</b> Hypothesis test with a confidence interval</a></li>
<li class="chapter" data-level="14.3.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-with-acceptancerejection-zones"><i class="fa fa-check"></i><b>14.3.2</b> Hypothesis test with acceptance/rejection zones</a></li>
<li class="chapter" data-level="14.3.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-with-a-p-value"><i class="fa fa-check"></i><b>14.3.3</b> Hypothesis test with a P-value</a></li>
<li class="chapter" data-level="14.3.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#upper-tail-hypothesis"><i class="fa fa-check"></i><b>14.3.4</b> Upper tail hypothesis</a></li>
<li class="chapter" data-level="14.3.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#paired-t-test"><i class="fa fa-check"></i><b>14.3.5</b> Paired t-test</a></li>
<li class="chapter" data-level="14.3.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#lower-tail-hypothesis"><i class="fa fa-check"></i><b>14.3.6</b> Lower tail hypothesis</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-for-the-proportion"><i class="fa fa-check"></i><b>14.4</b> Hypothesis testing for the proportion</a></li>
<li class="chapter" data-level="14.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-for-the-variance"><i class="fa fa-check"></i><b>14.5</b> Hypothesis Testing for the Variance</a></li>
<li class="chapter" data-level="14.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#errors-in-hypothesis-testing"><i class="fa fa-check"></i><b>14.6</b> Errors in hypothesis testing</a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sensitivity-and-specificity"><i class="fa fa-check"></i><b>14.6.1</b> Sensitivity and Specificity</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#exercises-12"><i class="fa fa-check"></i><b>14.7</b> Exercises</a></li>
<li class="chapter" data-level="14.8" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#practice-4"><i class="fa fa-check"></i><b>14.8</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="contingency-tables.html"><a href="contingency-tables.html"><i class="fa fa-check"></i><b>15</b> Contingency tables</a>
<ul>
<li class="chapter" data-level="15.1" data-path="contingency-tables.html"><a href="contingency-tables.html#difference-between-proportions"><i class="fa fa-check"></i><b>15.1</b> Difference between proportions</a></li>
<li class="chapter" data-level="15.2" data-path="contingency-tables.html"><a href="contingency-tables.html#difference-between-proportions-1"><i class="fa fa-check"></i><b>15.2</b> Difference between proportions</a></li>
<li class="chapter" data-level="15.3" data-path="contingency-tables.html"><a href="contingency-tables.html#contingency-table-of-conditional-probabilities"><i class="fa fa-check"></i><b>15.3</b> Contingency table of conditional probabilities</a></li>
<li class="chapter" data-level="15.4" data-path="contingency-tables.html"><a href="contingency-tables.html#test-for-the-difference-between-proportions"><i class="fa fa-check"></i><b>15.4</b> Test for the difference between proportions</a></li>
<li class="chapter" data-level="15.5" data-path="contingency-tables.html"><a href="contingency-tables.html#chi2-test"><i class="fa fa-check"></i><b>15.5</b> <span class="math inline">\(\chi^2\)</span> test</a></li>
<li class="chapter" data-level="15.6" data-path="contingency-tables.html"><a href="contingency-tables.html#fishers-exact-test"><i class="fa fa-check"></i><b>15.6</b> Fisherâs exact test</a></li>
<li class="chapter" data-level="15.7" data-path="contingency-tables.html"><a href="contingency-tables.html#hypergeometric-distribution"><i class="fa fa-check"></i><b>15.7</b> Hypergeometric distribution</a></li>
<li class="chapter" data-level="15.8" data-path="contingency-tables.html"><a href="contingency-tables.html#difference-between-several-proportions"><i class="fa fa-check"></i><b>15.8</b> Difference between several proportions</a></li>
<li class="chapter" data-level="15.9" data-path="contingency-tables.html"><a href="contingency-tables.html#goodness-of-fit"><i class="fa fa-check"></i><b>15.9</b> Goodness of fit</a></li>
<li class="chapter" data-level="15.10" data-path="contingency-tables.html"><a href="contingency-tables.html#questions-11"><i class="fa fa-check"></i><b>15.10</b> Questions</a></li>
<li class="chapter" data-level="15.11" data-path="contingency-tables.html"><a href="contingency-tables.html#practice-5"><i class="fa fa-check"></i><b>15.11</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html"><i class="fa fa-check"></i><b>16</b> Mean differences between two samples</a>
<ul>
<li class="chapter" data-level="16.1" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#difference-in-means-between-two-groups"><i class="fa fa-check"></i><b>16.1</b> Difference in means between two groups</a></li>
<li class="chapter" data-level="16.2" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#data-1"><i class="fa fa-check"></i><b>16.2</b> Data</a></li>
<li class="chapter" data-level="16.3" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#difference-between-means"><i class="fa fa-check"></i><b>16.3</b> Difference between means</a></li>
<li class="chapter" data-level="16.4" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#hypothesis-test"><i class="fa fa-check"></i><b>16.4</b> Hypothesis test</a></li>
<li class="chapter" data-level="16.5" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#estiamtor-of-the-mean-difference"><i class="fa fa-check"></i><b>16.5</b> Estiamtor of the mean difference</a></li>
<li class="chapter" data-level="16.6" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#standardized-error"><i class="fa fa-check"></i><b>16.6</b> Standardized error</a></li>
<li class="chapter" data-level="16.7" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#standardized-error-for-the-null"><i class="fa fa-check"></i><b>16.7</b> Standardized error for the null</a></li>
<li class="chapter" data-level="16.8" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#mean-differences-when-n-is-small"><i class="fa fa-check"></i><b>16.8</b> Mean differences when <span class="math inline">\(n\)</span> is small</a></li>
<li class="chapter" data-level="16.9" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#data-2"><i class="fa fa-check"></i><b>16.9</b> Data</a></li>
<li class="chapter" data-level="16.10" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#difference-between-means-1"><i class="fa fa-check"></i><b>16.10</b> Difference between means</a></li>
<li class="chapter" data-level="16.11" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#hypothesis-test-1"><i class="fa fa-check"></i><b>16.11</b> Hypothesis test</a></li>
<li class="chapter" data-level="16.12" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#estimator-of-the-mean-difference"><i class="fa fa-check"></i><b>16.12</b> Estimator of the mean difference</a></li>
<li class="chapter" data-level="16.13" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#standardized-error-for-the-null-1"><i class="fa fa-check"></i><b>16.13</b> Standardized error for the null</a></li>
<li class="chapter" data-level="16.14" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#mean-differences-with-unequall-variances"><i class="fa fa-check"></i><b>16.14</b> Mean differences with unequall variances</a></li>
<li class="chapter" data-level="16.15" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#data-3"><i class="fa fa-check"></i><b>16.15</b> Data</a></li>
<li class="chapter" data-level="16.16" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#questions-12"><i class="fa fa-check"></i><b>16.16</b> Questions</a></li>
<li class="chapter" data-level="16.17" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#practice-6"><i class="fa fa-check"></i><b>16.17</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html"><i class="fa fa-check"></i><b>17</b> Mean differences across several groups</a>
<ul>
<li class="chapter" data-level="17.1" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#different-means-among-several-conditions"><i class="fa fa-check"></i><b>17.1</b> Different means among several conditions</a></li>
<li class="chapter" data-level="17.2" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#data-4"><i class="fa fa-check"></i><b>17.2</b> Data</a></li>
<li class="chapter" data-level="17.3" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#difference-between-means-2"><i class="fa fa-check"></i><b>17.3</b> Difference between means</a></li>
<li class="chapter" data-level="17.4" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#hypothesis-test-2"><i class="fa fa-check"></i><b>17.4</b> Hypothesis test</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#distribution-of-group-means-under-h_0"><i class="fa fa-check"></i><b>17.4.1</b> Distribution of group means under <span class="math inline">\(H_0\)</span></a></li>
<li class="chapter" data-level="17.4.2" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#sources-of-variation"><i class="fa fa-check"></i><b>17.4.2</b> Sources of variation</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#variance-components-estimators"><i class="fa fa-check"></i><b>17.5</b> Variance components estimators</a></li>
<li class="chapter" data-level="17.6" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#analysis-of-variance-anova"><i class="fa fa-check"></i><b>17.6</b> Analysis of variance (ANOVA)</a></li>
<li class="chapter" data-level="17.7" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#anova-for-two-groups"><i class="fa fa-check"></i><b>17.7</b> ANOVA for Two Groups</a></li>
<li class="chapter" data-level="17.8" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#linear-model"><i class="fa fa-check"></i><b>17.8</b> Linear model</a></li>
<li class="chapter" data-level="17.9" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#way-anova"><i class="fa fa-check"></i><b>17.9</b> 2-way ANOVA</a></li>
<li class="chapter" data-level="17.10" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#data-5"><i class="fa fa-check"></i><b>17.10</b> Data</a></li>
<li class="chapter" data-level="17.11" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#modeling-residuals"><i class="fa fa-check"></i><b>17.11</b> Modeling residuals</a></li>
<li class="chapter" data-level="17.12" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#way-anova-linear-model"><i class="fa fa-check"></i><b>17.12</b> 2-way ANOVA linear model</a></li>
<li class="chapter" data-level="17.13" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#hypothesis-tests"><i class="fa fa-check"></i><b>17.13</b> Hypothesis tests</a></li>
<li class="chapter" data-level="17.14" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#variance-components"><i class="fa fa-check"></i><b>17.14</b> Variance components</a></li>
<li class="chapter" data-level="17.15" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#way-anova-with-interaction"><i class="fa fa-check"></i><b>17.15</b> 2-way ANOVA with interaction</a></li>
<li class="chapter" data-level="17.16" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#linear-model-1"><i class="fa fa-check"></i><b>17.16</b> Linear model</a></li>
<li class="chapter" data-level="17.17" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#hypothesis-tests-1"><i class="fa fa-check"></i><b>17.17</b> Hypothesis tests</a></li>
<li class="chapter" data-level="17.18" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#variance-components-1"><i class="fa fa-check"></i><b>17.18</b> Variance components</a></li>
<li class="chapter" data-level="17.19" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#questions-13"><i class="fa fa-check"></i><b>17.19</b> Questions</a></li>
<li class="chapter" data-level="17.20" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#practice-7"><i class="fa fa-check"></i><b>17.20</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html"><i class="fa fa-check"></i><b>18</b> Regression and Correlation</a>
<ul>
<li class="chapter" data-level="18.1" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#correlations"><i class="fa fa-check"></i><b>18.1</b> Correlations</a></li>
<li class="chapter" data-level="18.2" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#data-6"><i class="fa fa-check"></i><b>18.2</b> Data</a></li>
<li class="chapter" data-level="18.3" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#normal-bivariate"><i class="fa fa-check"></i><b>18.3</b> Normal bivariate</a></li>
<li class="chapter" data-level="18.4" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#estimators"><i class="fa fa-check"></i><b>18.4</b> Estimators</a></li>
<li class="chapter" data-level="18.5" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#correlation-coefficient"><i class="fa fa-check"></i><b>18.5</b> Correlation coefficient</a></li>
<li class="chapter" data-level="18.6" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#hypothesis-contrast"><i class="fa fa-check"></i><b>18.6</b> Hypothesis contrast</a></li>
<li class="chapter" data-level="18.7" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#regression-analysis"><i class="fa fa-check"></i><b>18.7</b> Regression analysis</a></li>
<li class="chapter" data-level="18.8" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#linear-model-2"><i class="fa fa-check"></i><b>18.8</b> Linear model</a></li>
<li class="chapter" data-level="18.9" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#hypothesis-contrast-1"><i class="fa fa-check"></i><b>18.9</b> Hypothesis contrast</a></li>
<li class="chapter" data-level="18.10" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#estimators-1"><i class="fa fa-check"></i><b>18.10</b> Estimators</a></li>
<li class="chapter" data-level="18.11" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#hypothesis-testing-2"><i class="fa fa-check"></i><b>18.11</b> Hypothesis testing</a></li>
<li class="chapter" data-level="18.12" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#stratified-analysis"><i class="fa fa-check"></i><b>18.12</b> Stratified analysis</a></li>
<li class="chapter" data-level="18.13" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#multiple-regression"><i class="fa fa-check"></i><b>18.13</b> Multiple Regression</a></li>
<li class="chapter" data-level="18.14" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#multiple-regression-interaction"><i class="fa fa-check"></i><b>18.14</b> Multiple Regression interaction</a></li>
<li class="chapter" data-level="18.15" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#model-diagnostics"><i class="fa fa-check"></i><b>18.15</b> Model diagnostics</a></li>
<li class="chapter" data-level="18.16" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#questions-14"><i class="fa fa-check"></i><b>18.16</b> Questions</a></li>
<li class="chapter" data-level="18.17" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#practice-8"><i class="fa fa-check"></i><b>18.17</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="apendix.html"><a href="apendix.html"><i class="fa fa-check"></i><b>19</b> Apendix</a>
<ul>
<li class="chapter" data-level="19.1" data-path="apendix.html"><a href="apendix.html#solutions-to-questions"><i class="fa fa-check"></i><b>19.1</b> Solutions to Questions</a></li>
<li class="chapter" data-level="19.2" data-path="apendix.html"><a href="apendix.html#summary-tables-python-and-r-code"><i class="fa fa-check"></i><b>19.2</b> Summary tables, Python and R code</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="apendix.html"><a href="apendix.html#creating-data-frames-and-loading-text-files"><i class="fa fa-check"></i><b>19.2.1</b> Creating Data Frames and Loading Text Files</a></li>
<li class="chapter" data-level="19.2.2" data-path="apendix.html"><a href="apendix.html#python-and-r-functions-for-data-description"><i class="fa fa-check"></i><b>19.2.2</b> Python and R Functions for Data Description</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="apendix.html"><a href="apendix.html#summary-of-common-probability-models"><i class="fa fa-check"></i><b>19.3</b> Summary of common probability models</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="apendix.html"><a href="apendix.html#python-and-r-functions-for-probability-models"><i class="fa fa-check"></i><b>19.3.1</b> Python and R Functions for Probability Models</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="apendix.html"><a href="apendix.html#summary-of-hypothesis"><i class="fa fa-check"></i><b>19.4</b> Summary of hypothesis</a>
<ul>
<li class="chapter" data-level="19.4.1" data-path="apendix.html"><a href="apendix.html#python-and-r-functions-for-hypothesis-tesing"><i class="fa fa-check"></i><b>19.4.1</b> Python and R Functions for Hypothesis tesing</a></li>
<li class="chapter" data-level="19.4.2" data-path="apendix.html"><a href="apendix.html#python-libraries-required"><i class="fa fa-check"></i><b>19.4.2</b> Python Libraries Required</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Data Analysis
for
Experimental Sciences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="interval-estimation" class="section level1 hasAnchor" number="13">
<h1><span class="header-section-number">Chapter 13</span> Interval estimation<a href="interval-estimation.html#interval-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>We perform repeated measurements of a random experiment to learn about the invariant properties that define it. To separate the signal from random variation, we can propose a probabilistic model whose parameters represent abstract properties of the underlying process. These parameters are assumed to remain fixed, while the randomness in the observations is described by the probability distribution over possible outcomes.</p>
<p>The assumption of parameter invariance is often reasonable. For instance, we do not expect the electric charge of an electron to change. However, other quantitiesâsuch as the average height of a populationâmay vary across generations. In more complex or extreme systems, such as city size distributions or gene connectivity networks, parameters like the mean or variance may not even be well defined; these systems may exhibit scale-free behavior.</p>
<p>Given the diversity of experimental settings, the nature of the parameters we estimate can vary widely. To begin, we will consider simpler cases where, under controlled conditions, we can assume that the parameters are fixed. This allows us to define estimators that will tend to cluster around the value of the parameter. In this framework, the only source of variation in parameter estimation comes from the randomness in the sample. For example, when using the average to estimate the mean of a random variable, it is the averageânot the mean of the variableâthat changes across samples.</p>
<p>This setup naturally leads to a central question: How confident can we be that the unknown (but fixed) parameter is close to its estimated value? This is a challenging question, since we do not know the parameterâs location. How can we answer it using only the data we have?</p>
<p>The key idea is to consider what would happen if we repeated the sampling process many times. If we assume a probability model for the data, we can ask: How far would the new estimates typically fall from the original one? If the estimator is unbiased, the spread of its sampling distribution can give us a sense of how close the estimates are likely to be to the true parameter valueâbecause repeated estimates will cluster around it. The approach is known as frequentist, imaging repetitions of the sample.</p>
<p>In this chapter, we introduce the concept of <strong>confidence intervals</strong> for means, proportions, and variances. We will derive formulas for confidence intervals under various conditions, including when the population variance is known or unknown, and when the sample size is large.</p>
<div id="revisiting-parameter-estimation-and-marging-of-error" class="section level2 hasAnchor" number="13.1">
<h2><span class="header-section-number">13.1</span> Revisiting parameter estimation and marging of error<a href="interval-estimation.html#revisiting-parameter-estimation-and-marging-of-error" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The expected value or the mean is a fundamental parameter of the random experiment. The researchers typically ask, if an experiment is repeated, the observations will gather about a number in a consistent manner?</p>
<p><strong>Estimation of the mean</strong></p>
<p>We have seen that whenever we take a random sample <span class="math inline">\((X_1, X_2, ... X_n)\)</span>, the sample mean
<span class="math display">\[\bar{X}=\frac{1}{n}\sum_{i=1}^n X_i\]</span></p>
<p>is an estimator of the mean <span class="math inline">\(\mu\)</span> of the random variable <span class="math inline">\(X\)</span>. That is</p>
<p><span class="math display">\[\bar{x}=\hat{\mu}\]</span>
We take the average (the observation of the sample mean), as the value of <span class="math inline">\(\mu\)</span> we trust the most given our data (maximum likelihood).</p>
<p>The estimator is <strong>unbiased</strong> because its values center about the parameter it is estimating</p>
<ul>
<li><span class="math inline">\(E(\bar{X})=\mu\)</span></li>
</ul>
<p>and <strong>consistent</strong> because as <span class="math inline">\(n\)</span> increases then it is closer to the parameter, as its variance gets smaller</p>
<ul>
<li><span class="math inline">\(V(\bar{X})=\frac{\sigma^2}{n}\)</span></li>
</ul>
<p>where <span class="math inline">\(\sigma^2\)</span> is the variance of <span class="math inline">\(X\)</span>. We call the quantity <span class="math inline">\(\sigma_{\bar{x}}=\frac{\sigma}{\sqrt{n}}\)</span> the <strong>standard error</strong> (<span class="math inline">\(se\)</span>).</p>
<p>Since <span class="math inline">\(\bar{X}\)</span> is a random variable the estimation of the mean changes when we take another sample. Therefore, we know that we are making an error every time we take <span class="math inline">\(\bar{x}\)</span> for <span class="math inline">\(\mu\)</span>.</p>
<p><strong>Margin of error</strong></p>
<p>When deciding whether the <strong>error</strong> in estimation <span class="math display">\[\bar{X}-\mu\]</span> is large or not, we defined the <strong>margin of error</strong>. The margin of error at <span class="math inline">\(5\%\)</span> is the distance <span class="math inline">\(m\)</span> from <span class="math inline">\(\mu\)</span> such that <span class="math inline">\(\bar{X}\)</span> has a probability of <span class="math inline">\(95\%\)</span> to be observed within:</p>
<p><span class="math display">\[P(-m \leq \bar{X}-\mu \leq m)=0.95\]</span></p>
<p><strong>If we assume</strong> that the distribution of <span class="math inline">\(X\)</span> is normal, <span class="math inline">\(X \sim N(\mu, \sigma^2)\)</span>, then the <strong>standardized error</strong> from the mean</p>
<p><span class="math display">\[T=\frac{\bar{X}-\mu}{\frac{S}{\sqrt{n}}}\]</span>
follows a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-1\)</span> degrees of freedom</p>
<p><span class="math display">\[T \sim t_{n-1}\]</span></p>
<p>where <span class="math inline">\(S^2=\frac{1}{n-1} \sum_{i=1}^n (X_i-\bar{X})^2\)</span> is the sample variance. The margin of error <span class="math inline">\(m\)</span> at <span class="math inline">\(5\%\)</span> is given by the</p>
<p><span class="math inline">\(P(\mu-m \leq \bar{X} \leq\mu + m)\)</span>
<span class="math display">\[=P(-\frac{m}{S/\sqrt{n}} \leq T \leq\frac{m}{S/\sqrt{n}})=0.95\]</span></p>
<p>Since <span class="math inline">\(T\)</span> is contained in the interval <span class="math inline">\((-t_{0.025, n-1},t_{0.025, n-1})\)</span> with <span class="math inline">\(95\%\)</span> of the probability, then the margin of error is</p>
<p><span class="math display">\[m=t_{0.025, n-1} \frac{s}{\sqrt{n}}\]</span>
where the limit of the interval <span class="math inline">\(t_{0.025, n-1}\)</span> is the value of <span class="math inline">\(T\)</span> that leaves <span class="math inline">\(2.5\%\)</span> of probability at the right hand side of the <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-1\)</span> degrees of freedom</p>
<pre><code>Python: t.sf(0.025, n-1) 
R: qt(0.025, n-1, lower.tail = FALSE)</code></pre>
<p>Note that the margin of error is the expectation of how far the average will be observed from the mean with <span class="math inline">\(95\%\)</span> of probability. Clearly if the observed average is luckily the mean then the error is zero, the errors will be symmetrical about zero and higher errors will be less probable.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-146-1.png" width="672" /></p>
</div>
<div id="interval-estimation-for-the-mean" class="section level2 hasAnchor" number="13.2">
<h2><span class="header-section-number">13.2</span> Interval estimation for the mean<a href="interval-estimation.html#interval-estimation-for-the-mean" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The problem is that in many experiments we <strong>do not know</strong> <span class="math inline">\(\mu\)</span>. If we are going to collect the first sample of the experiment, we do not have an expectation of how far the average is going to be observed from the mean, nor an expectation of its deviation from it.</p>
<p><strong>Example (CRISPR)</strong></p>
<p>CRISPR-Cas9 is a technology that enables gene editing. CRISPR-Cas system uses a guide RNA to direct the Cas9 enzyme to a specific DNA sequence, where it creates a cut. This allows researchers to disrupt, correct, or insert genetic material at targeted sites in the genome. The first-in-human study using CRISPR-edited cells, assessed the safety and feasibility of editing immune T cells to combat a form of lung cancer that had not responded to standard therapies <span class="citation">(<a href="#ref-Lu2020">Lu et al. 2020</a>)</span>. This is the reported efficiency of editing in the study</p>
<p><span class="math display">\[
\begin{array}{cc}
\mathbf{Patient} &amp; \mathbf{Editing Efficiency (\%)} \\
C-03      &amp; 16                     \\
C-02      &amp; 34                     \\
C-01      &amp; 10                     \\
B-03      &amp; 16                     \\
B-02      &amp; 12                     \\
B-01      &amp; 30                     \\
A-04      &amp; 22                     \\
A-03      &amp; 10                     \\
A-02      &amp; 20                     \\
A-01      &amp; 18                     \\
PreA-02   &amp; 8                      \\
PreA-01   &amp; 16                     \\
\end{array}
\]</span></p>
<p>This data is the repetition of a random experiment 12 times, where the efficiency was the random variable and the observation unit a patient. As the same experimental procedure was applied, it is expected that the efficiency will cluster around some value that represents the CRISPR experiment of the study.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-147-1.png" width="384" /></p>
<p>The observations (crosses) and the average (dot) is all we have. We can assume that if the researchers were to repeat the sample on 12 different patients, the average will not be far from the value that they observed, because the average clusters around the mean. However, we do not know where the mean is.</p>
<p>Nonetheless, we can assume that editing efficiency is normally distributed</p>
<p><span class="math display">\[X \sim N(\mu, \sigma^2)\]</span>
at unknown <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>.</p>
<p>Data suggest that the expected editing efficiency <span class="math inline">\(\mu\)</span> is about <span class="math inline">\(\bar{x}=17.66\)</span>. But, how <strong>confident</strong> are we? after all, we know that when we take the value of <span class="math inline">\(\bar{x}\)</span> for <span class="math inline">\(\mu\)</span>, we know we are making a mistake but do not know how big it actually is. The key is to note that the dispersion of sample (<span class="math inline">\(s\)</span>) will give us an idea on how the average will disperse (<span class="math inline">\(s/\sqrt{n}\)</span>).</p>
<p><strong>Definition</strong></p>
<p>To address the question of where <span class="math inline">\(\mu\)</span> is, we define the <strong>confidence interval</strong> for <span class="math inline">\(\mu\)</span>. From the margin of error equation</p>
<p><span class="math display">\[P(-m \leq \bar{X} - \mu \leq  m)=0.95\]</span>
We solve for <span class="math inline">\(\mu\)</span>, which is indeed <strong>the real unknown</strong></p>
<p><span class="math display">\[P(\bar{X} - m \leq \mu \leq \bar{X} + m)=0.95\]</span></p>
<p>The left and right limits of the inequality are random variables which motivate the definition for the <strong>random confidence interval at <span class="math inline">\(95\%\)</span>:</strong></p>
<p><span class="math display">\[(L,U)=(\bar{X} - m,\bar{X} + m)\]</span></p>
<p>This interval is a new <strong>random variable</strong> and it has by definition a probability of <span class="math inline">\(0.95\)</span> to contain <span class="math inline">\(\mu\)</span>.</p>
<p>The <strong>observed interval</strong> that we obtain from the experiment is (lower case)</p>
<p><span class="math display">\[(l,u)=(\bar{x} - m,\bar{x} + m)\]</span></p>
<p>This interval either contains or it does not contain the parameter <span class="math inline">\(\mu\)</span>: we will <strong>never know</strong>!</p>
<p>However, we can still say that we have a <strong>confidence</strong> of <span class="math inline">\(95\%\)</span> that the interval <span class="math inline">\((l,u)\)</span> has captured the true unknown parameter <span class="math inline">\(\mu\)</span>. Think of a lottery scratch ticket that we are not allow to scratch to see the prize before buying it. The ticket either has or does not have the prize, only that we do not know which case it is. However, we can be confident that the ticked does not have the main prize, because the probabilities of the game (not the instance in my hand) are low.</p>
</div>
<div id="confidence-interval-estimation" class="section level2 hasAnchor" number="13.3">
<h2><span class="header-section-number">13.3</span> Confidence Interval Estimation<a href="interval-estimation.html#confidence-interval-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We can <strong>estimate</strong> confidence intervals when we are able find an standardization of an estimator with a known distribution.</p>
<p>Standardization allows separating the random variation from the parameters, which is not always possible but can be done for some useful and widely applied examples.</p>
<p>Notice that the interval depends of the margin error, which is a parameter (property) of the estimator. As such, the observed interval needs to be computed with a required statistical interpretation and, consequently, it is not a pure datum of the experiment. Hence, confidence intervals are estimated rather then directly observed from the experiment.</p>
<div id="estimation-of-the-mean-for-normal-variables" class="section level3 hasAnchor" number="13.3.1">
<h3><span class="header-section-number">13.3.1</span> Estimation of the mean for normal variables<a href="interval-estimation.html#estimation-of-the-mean-for-normal-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>When the random variable <span class="math inline">\(X\)</span> is a normal variable, we can readily write the confidence interval at <span class="math inline">\(95\%\)</span></p>
<p><span class="math display">\[(l,u)=(\bar{x} - m, \bar{x} + m)\]</span>
where <span class="math display">\[m=t_{0.025, n-1} \frac{s}{\sqrt{n}}\]</span></p>
<p>That is:</p>
<p><span class="math display">\[(l,u)=(\bar{x} - t_{0.025, n-1} \frac{s}{\sqrt{n}}, \bar{x} + t_{0.025, n-1} \frac{s}{\sqrt{n}})\]</span></p>
<p><strong>Example (CRISPR)</strong></p>
<p>In the CRISPR example, we assume that <span class="math inline">\(X\)</span> is normally distributed and from the data we can compute <span class="math inline">\(\bar{x}= 17.66\)</span> and <span class="math inline">\(s=7.9\)</span>.</p>
<p>Then the margin of error is</p>
<p><span class="math display">\[m=t_{0.025, 11} \frac{s}{\sqrt{n}}=2.2\frac{7.9}{\sqrt{12}}=5.04\]</span>
and the <span class="math inline">\(95\%\)</span> confidence interval is</p>
<p><span class="math inline">\((l,u)=(\bar{x} - m, \bar{x} + m)=\)</span> <span class="math display">\[(12.61, 22.71)\]</span></p>
<p>Which means that we are <span class="math inline">\(95\%\)</span> confident that the efficiency of the T-cell editing can be found between <span class="math inline">\(12.6\%\)</span> and <span class="math inline">\(22.7\%\)</span></p>
<pre><code>Python:
from scipy.stats import ttest_1samp
x = [16, 34, 10, 16, 12, 30, 22, 10, 20, 18, 8, 16]
res = ttest_1samp(x, popmean=0)
print(res.confidence_interval)

R:
x &lt;- c(16, 34, 10, 16, 12, 30, 22, 10, 20, 18, 8, 16)
t.test(x)$conf.int
</code></pre>
<p>We can also write the interval as</p>
<p><span class="math display">\[\hat{\mu}=\bar{x}  \pm m =  17.6 \pm 5.0\]</span>
This means that, when estimating the mean by the average, we are confident that the efficiency is between the tenths and twenties of percentage points, and less confident in the figures on percentage units. We have no confidence on the decimal places.</p>
<p>Remember that the confidence interval <span class="math inline">\((l,u)\)</span> (black below) is an observation of the random confidence interval <span class="math inline">\((L,U)\)</span>. Therefore, if we change the sample then <span class="math inline">\((l,u)\)</span> changes (grey below). The frequentist statistician encourages us to imagine selecting a different group of <span class="math inline">\(12\)</span> patients, compute the confidence intervals, and repeat this process an infinite amount of times. Then, about <span class="math inline">\(95\%\)</span> of the confidence intervals will contain the unknown <span class="math inline">\(\mu\)</span>. We just do not know which intervals, including the estimated one, will contain <span class="math inline">\(\mu\)</span>!</p>
<p><img src="_main_files/figure-html/unnamed-chunk-148-1.png" width="384" /></p>
<p>We can say that Lu and colleagues achieved a T-cell editing efficiency of about <span class="math inline">\(17\%\)</span> as they repeated the experiment 12 times in similar conditions. It is clear, however, that other laboratories may obtain different efficiencies, as some of the conditions will change. Therefore, we expect that the parameter <span class="math inline">\(\mu\)</span> will change between laboratories in addition to sampling error. At <span class="math inline">\(17\%\)</span> efficiency, they showed that the treatment appear to be safe for 12 cancer patients, but as efficiency is improved and more patients are recruited then patient safety will need to be updated.</p>
<p><strong>Confidence level</strong></p>
<p>We can change our confidence from <span class="math inline">\(95\%\)</span> to <span class="math inline">\(99\%\)</span>. When we computed the margin of error at <span class="math inline">\(95\%\)</span>, we left out <span class="math inline">\(\alpha=0.05\)</span> probability, <span class="math inline">\(0.025\)</span> on each side of the standardized error.</p>
<p>Now, we can leave out <span class="math inline">\(\alpha=0.01\)</span> probability, <span class="math inline">\(0.005\)</span> on each side. Therefore the <span class="math inline">\(99\%\)</span> confidence interval is</p>
<p><span class="math display">\[(l,u) = (\bar{x} - t_{0.005, n-1}\frac{s}{\sqrt{n}},\bar{x} +  t_{0.005, n-1}\frac{s}{\sqrt{n}})\]</span></p>
<p><img src="_main_files/figure-html/unnamed-chunk-149-1.png" width="672" /></p>
<p>where <span class="math inline">\(t_{0.005, n-1}=F^{-1}(0.995)\)</span> is the inverse of the probability density function for the <span class="math inline">\(t\)</span>-distribution.</p>
<pre><code>Python: t.ppf(1-0.005, n-1) 
R: qt(0.005, n-1, lower.tail = FALSE)</code></pre>
<p><strong>Example (Impact energy)</strong></p>
<p>A metallic material is tested for impact to measure the energy required to cut it at a given temperature. Ten specimens of A238 steel were cut at 60ÂºC at the following impact energies (J):</p>
<p>64.1, 64.7, 64.5, 64.6, 64.5, 64.3, 64.6, 64.8, 64.2, 64.3</p>
<p>If we <strong>assume</strong> that the impact energy is normally distributed we can estimate the <span class="math inline">\(99\%\)</span> confidence interval for the cutting energy, as an intrinsic propioerty of the material. From the data we have</p>
<ul>
<li><span class="math inline">\(\bar{x}=64.46\)</span></li>
<li><span class="math inline">\(s=0.227\)</span></li>
</ul>
<p>we assume</p>
<ul>
<li><span class="math inline">\(\alpha=0.01\)</span> (the confidence limit)</li>
<li><span class="math inline">\(t_{0.005,9}=3.24\)</span> obtained from <span class="math inline">\(t_{0.005,9}=\)</span> <code>t.ppf(1-0.005, 9)</code></li>
</ul>
<p>The confidence interval is then</p>
<p><span class="math inline">\((l,u)=(\bar{x}- t_{0.005,9}\frac{s}{\sqrt{n}},\bar{x}+t_{0.005,9} \frac{s}{\sqrt{n}})\)</span></p>
<p><span class="math display">\[=(64.22, 64.69)\]</span></p>
<pre eval="FALSE"><code>Python:
from scipy import stats
x = [64.1,64.7,64.5,64.6,64.5,64.3,64.6,64.8,64.2,64.3]
res = stats.ttest_1samp(x, popmean=0)
res.confidence_interval(confidence_level=0.99)

R:
x &lt;- c(64.1,64.7,64.5,64.6,64.5,64.3,64.6,64.8,64.2,64.3)
t.test(x, conf.level = 0.99)$conf.int</code></pre>
<p>Note that the confidence interval at <span class="math inline">\(95\%\)</span> is <span class="math inline">\((64.29, 64.62)\)</span>, which is smaller than the <span class="math inline">\(99\%\)</span> interval. The wider intervals with increasing confidence shows the trade-off between confidence and precision.</p>
</div>
<div id="estimation-of-the-proportion-for-dichotomic-variables" class="section level3 hasAnchor" number="13.3.2">
<h3><span class="header-section-number">13.3.2</span> Estimation of the proportion for dichotomic variables<a href="interval-estimation.html#estimation-of-the-proportion-for-dichotomic-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Example (Mendelâs peas)</strong></p>
<p>Mendel first produced a large number of hybrid pea plants. These were plants for which one parent descended from a long line of plants that produced round peas, and the other from a long line that produced wrinkled peas. He then took pairs of these hybrid plants and produced 253 pea plants. He collected a total of 7,324 seeds from the hybrid offspring and observed that 5,474 were round and 1,850 were wrinkled <span class="citation">(<a href="#ref-mendel1901experiments">Mendel 1901</a>)</span>. What is the estimated proportion of round seeds in the offspring observed by Mendel?</p>
<p>The outcome <span class="math inline">\(X_i\)</span> that the <span class="math inline">\(i\)</span>-th seed is a round pea is a Bernoulli trial</p>
<p><span class="math display">\[X_i \sim Bernoulli(p)\]</span>
with mean <span class="math inline">\(\mu=p\)</span> and variance <span class="math inline">\(\sigma^2=p(1-p)\)</span>.</p>
<p>Mendelâs sample would look something like
<span class="math display">\[(x_1,x_2, x_3, ...x_{n=7324})=(0,1,0,.. 1, 0)\]</span> with <span class="math inline">\(5474\)</span> ones and in a total of <span class="math inline">\(7324\)</span> repetitions of the trial. The sample has an average <span class="math display">\[\bar{x}=\frac{1}{7324}\sum_{i=1}^{7324} x_i=\frac{5474}{7324}=0.747\]</span>
Which is nothing but the relative frequency of the round peas. Since, in general, the sample mean is an unbiased estimator of <span class="math inline">\(\mu\)</span>, then, for the Bernoulli trial, this the relative frequency is a point estimate of the parameter <span class="math inline">\(p\)</span></p>
<p><span class="math display">\[\hat{p}=\bar{x}=0.747\]</span></p>
<p>This makes sense because <span class="math inline">\(\bar{x}\)</span> is the observed relative frequency of ones <span class="math inline">\(f_1\)</span> in the sample. And as such, it is an estimator of the probability of observing a one in a Bernoulli trial</p>
<p><span class="math display">\[f_1 =\hat{P}(X=1)\]</span>
However, how confident are we about this estimation? That is, how confident are we to take the relative frequency as the value of the probability? We want a confidence interval for <span class="math inline">\(p\)</span>.</p>
<p><strong>Confidence intervals for proportions</strong></p>
<p>When <span class="math inline">\(n\hat{p}&gt;5\)</span> and <span class="math inline">\(n(1-\hat{p})&gt;5\)</span>, the <strong>standardized error</strong> of estimating <span class="math inline">\(p\)</span> with <span class="math inline">\(\bar{X}\)</span> can be approximated to a standard normal variable with the help of the central limit theorem, using De Moivreâ normal approximation of the Binomial.</p>
<p><span class="math display">\[Z=\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}= \frac{\bar{X}-p}{\big[\frac{p(1-p)}{n} \big]^{1/2}}\sim N(0,1)\]</span>
Therefore the margin of error <span class="math inline">\(m\)</span> at <span class="math inline">\(95\%\)</span> is</p>
<p><span class="math display">\[m=  z_{0.025}\frac{\sqrt{p(1-p)}}{\sqrt{n}}\]</span>
Since we do not know what the value of <span class="math inline">\(p\)</span> is then we will estimate it with <span class="math inline">\(\bar{x}\)</span> and then
<span class="math display">\[m=  z_{0.025}\frac{\sqrt{\bar{x}(1-\bar{x})}}{\sqrt{n}}\]</span>
Which is a good approximation when the central limit theorem starts to hold. Therefore, an approximate <span class="math inline">\(95\%\)</span> CI interval of <span class="math inline">\(p\)</span> is:</p>
<p><span class="math display">\[CI=(l,u)=(\bar{x}-z_{0.025}\big[\frac{\bar{x}(1-\bar{x})}{n} \big]^{1/2},  \bar{x}+z_{0.025}\big[\frac{\bar{x}(1-\bar{x})}{n} \big]^{1/2})\]</span>
Note that we could not solve exactly the margin of error without reference to the parameter <span class="math inline">\(p\)</span>. We were able to introduce an estimate because the central limit theorem achieves a suitable standardization when <span class="math inline">\(n\)</span> is large. More accurate confidence intervals for small <span class="math inline">\(n\)</span> or far from <span class="math inline">\(p=1\)</span> and <span class="math inline">\(p=0\)</span> have been developed.</p>
<p><strong>Example (Mendelâs peas)</strong></p>
<p>In Mendelâs experiments, he counted <span class="math inline">\(5474\)</span> rounded peas in a total of <span class="math inline">\(7324\)</span> total seeds and he therefore obtained</p>
<ul>
<li><p><span class="math inline">\(\bar{x}=0.747\)</span> (relative frequency as a point estimate of the proportion)</p></li>
<li><p><span class="math inline">\(z_{0.025}=1.96\)</span> (using <code>norm.sf(0.025)</code>).</p></li>
</ul>
<p>Therefore the <span class="math inline">\(95\%\)</span> confidence interval for <span class="math inline">\(p\)</span> is</p>
<p><span class="math inline">\((l,u)=(0.747-0.013, 0.747+0.013)\)</span></p>
<p><span class="math display">\[=(0.734, 0.760)\]</span></p>
<pre eval="FALSE"><code>Python:
from statsmodels.stats.proportion import
proportion_confint(5474, 7324)

R:
prop.test(5474, 7324)$conf.int</code></pre>
<p>The estimated probability of observing a round pea is</p>
<p><span class="math display">\[\hat{p} = 0.747 \pm 0.013\]</span></p>
<p>which validates Mendelâs first law, as it aligns closely with the theoretical value <strong>deduced</strong> for <span class="math inline">\(p\)</span>. Let <span class="math inline">\(A\)</span> represent the allele for round peas. In Mendelâs experiments, all offspring were produced from hybrid parents carrying alleles <span class="math inline">\((A, A&#39;)\)</span>. Since the round trait is dominant, a pea will be round if it inherits at least one <span class="math inline">\(A\)</span> allele. This corresponds to the event <span class="math inline">\((A_m \cup A_f)\)</span>, which occurs in three out of four possible allele combinations. Therefore, the theoretical probability of a round pea is <span class="math inline">\(p = 3/4 = 0.75\)</span>, a value that is well captured by the <strong>inferred</strong> confidence interval of the relative frequency.</p>
<p>Mendelâs success lay in identifying a simple biological system where probabilities could be reasoned and predictions made about where relative frequencies would cluster. However, it is important to remember that this reasoning was grounded in prior observation, experimentation, and reflection on empirical data. A map cannot be drawn without first exploring the territory.</p>
</div>
</div>
<div id="estimation-of-the-variance" class="section level2 hasAnchor" number="13.4">
<h2><span class="header-section-number">13.4</span> Estimation of the variance<a href="interval-estimation.html#estimation-of-the-variance" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The variance is another fundamental parameter of the random experiment. The random experiment will be characterized by a variability that may be intrinsic of the observation unit or a characteristic of the experimental error when measuring an outcome. Researchers in this case may ask, if an experiment is repeated, how far the observations will be from the mean?</p>
<p>We have seen that whenever we take a random sample <span class="math inline">\((X_1, X_2, ... X_n)\)</span>, the sample variance
<span class="math display">\[S^2=\frac{1}{n-1}\sum_{i=1}^n (X_i-\bar{X})^2\]</span>
is an estimator of the variance <span class="math inline">\(\sigma^2\)</span> of the random variable <span class="math inline">\(X\)</span>. The estimator is <strong>unbiased</strong> because its values are centered about the parameter it is estimating</p>
<p><span class="math display">\[E(S^2)=\sigma^2\]</span></p>
<p>and it is also <strong>consistent</strong>. We can then take a the value of <span class="math inline">\(s^2\)</span> from a particular sample as the value of <span class="math inline">\(\sigma^2\)</span>, which is a characteristic of random experiment. That is</p>
<p><span class="math display">\[s^2=\hat{\sigma}^2\]</span></p>
<p>Since <span class="math inline">\(S^2\)</span> is a random variable the estimation of the variance changes when we take another sample.</p>
<p><strong>Example (impact energy)</strong></p>
<p>A metallic material is tested for impact to measure the energy required to cut it at a given temperature. Ten specimens of A238 steel were cut at 60ÂºC at the following impact energies (J):</p>
<p>64.1, 64.7, 64.5, 64.6, 64.5, 64.3, 64.6, 64.8, 64.2, 64.3</p>
<p>While the cutting energy appears to cluster about a value, the specimens show variability on their energies. Some are cut easier than others. How stable is the cutting energy of the specimens? what is estimation of the variance of these data?</p>
<ul>
<li>The sample variance is <span class="math inline">\(s^2=0.051\)</span></li>
</ul>
<pre><code>Python:
import numpy as np
x = [64.1, 64.7, 64.5, 64.6, 64.5, 64.3, 64.6, 64.8, 64.2, 64.3]
np.var(x, ddof=1)

R: 
x &lt;- c(64.1, 64.7, 64.5, 64.6, 64.5, 64.3, 64.6, 64.8, 64.2, 64.3)
var(x)</code></pre>
<p>How confident can we be on the decimals places of this estimation? What is the confidence interval for the variance?</p>
</div>
<div id="confidence-interval-for-the-variance" class="section level2 hasAnchor" number="13.5">
<h2><span class="header-section-number">13.5</span> Confidence interval for the variance<a href="interval-estimation.html#confidence-interval-for-the-variance" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>To compute a confidence interval of the variance, we need a statistics that is a function of <span class="math inline">\(S^2\)</span> and allows to measure the standardize error we make when we estimate <span class="math inline">\(\sigma^2\)</span> by <span class="math inline">\(s^2\)</span>.</p>
<p><strong>If we assume</strong> that the distribution of <span class="math inline">\(X\)</span> is normal, <span class="math inline">\(X \sim N(\mu, \sigma^2)\)</span>, then the <strong>standardized error</strong> from the variance</p>
<p><span class="math display">\[W=\frac{S^2(n-1)}{\sigma^2}\]</span>
follows a <span class="math inline">\(\chi^2\)</span> distribution with <span class="math inline">\(n-1\)</span> degrees of freedom</p>
<p><span class="math display">\[W \sim \chi^2_{n-1}\]</span></p>
<p>This is an error rate that if the observed sample variance <span class="math inline">\(s^2\)</span> is luckily the variance <span class="math inline">\(\sigma^2\)</span> then the rate is <span class="math inline">\((n-1)\)</span>. The errors will distribute asymmetrical about <span class="math inline">\((n-1)\)</span> and higher errors and those close to <span class="math inline">\(0\)</span> will be less probable.</p>
<p>Using this error rate, we will look for a <span class="math inline">\(95\%\)</span> confidence interval <span class="math inline">\((L,U)\)</span> of <span class="math inline">\(\sigma^2\)</span> such that the random interval <span class="math display">\[P(L \leq \sigma^2 \leq U)=0.95\]</span></p>
<p>captures <span class="math inline">\(\sigma^2\)</span> with <span class="math inline">\(95\%\)</span> of probability.</p>
<p>We start by determining the values that capture the <span class="math inline">\(95\%\)</span> of the <span class="math inline">\(\chi^2\)</span>-distribution</p>
<p><span class="math display">\[P(\chi^2_{0.975,n-1} \leq W \leq \chi^2_{0.025,n-1})=0.95\]</span></p>
<p><img src="_main_files/figure-html/unnamed-chunk-150-1.png" width="672" /></p>
<p>Replacing the value of <span class="math inline">\(W\)</span></p>
<p><span class="math display">\[P(\chi^2_{0.975,n-1} \leq \frac{S^2}{\sigma^2}(n-1) \leq \chi^2_{0.025,n-1})=0.95\]</span></p>
<p>and solving for <span class="math inline">\(\sigma^2\)</span></p>
<p><span class="math display">\[P(\frac{S^2 (n-1)}{\chi^2_{0.025,n-1}}\leq \sigma^2 \leq \frac{S^2(n-1)}{\chi^2_{0.975,n-1}})=0.95\]</span></p>
<p>We find a random interval that captures <span class="math inline">\(\sigma^2\)</span>
with <span class="math inline">\(95\%\)</span> confidence</p>
<p><span class="math display">\[(L,U) = (\frac{S^2 (n-1)}{\chi^2_{0.025,n-1}},\frac{S^2(n-1)}{\chi^2_{0.975,n-1}})\]</span></p>
<p>The <strong>observed</strong> <span class="math inline">\(95\%\)</span> confidence interval (script size) is</p>
<p><span class="math display">\[(l,u) = (\frac{s^2 (n-1)}{\chi^2_{0.025,n-1}},\frac{s^2(n-1)}{\chi^2_{0.975,n-1}})\]</span></p>
<p>where</p>
<ul>
<li><p><span class="math inline">\(\chi^2_{0.975,n-1}=\)</span> <code>chi2.sf(0.975, df=n-1)</code> is the value of <span class="math inline">\(W\)</span> that leaves <span class="math inline">\(0.975\)</span> probability to the right hand side.</p></li>
<li><p><span class="math inline">\(\chi^2_{0.025,n-1}=\)</span><code>chi2.sf(0.025, df=n-1)</code> is the value of <span class="math inline">\(W\)</span> that leaves <span class="math inline">\(0.025\)</span> probability to the right hand side.</p></li>
</ul>
<p><strong>Example (impact energy)</strong></p>
<p>Ten specimens of A238 steel were cut at 60ÂºC at finding a sample variance <span class="math inline">\(s^2=0.05155556\)</span>. To estimate the confidence interval for the variance we compute</p>
<ul>
<li><p><span class="math inline">\(\chi^2_{0.975,n-1}=2.700389\)</span></p></li>
<li><p><span class="math inline">\(\chi^2_{0.025,n-1}=19.02277\)</span></p></li>
</ul>
<pre><code>Python:
chi2.ppf(1 - 0.975, df=9) 
chi2.ppf(1 - 0.025, df=9)

R: 
qchisq(0.975, 9, lower.tail = FALSE)
qchisq(0.025, 9, lower.tail = FALSE)</code></pre>
<p>Therefore</p>
<p><span class="math display">\[(l,u)= (\frac{0.227^2 (10-1)}{19.02277},\frac{0.227^2(10-1)}{2.700389})=(0.02,0.17)\]</span></p>
<p>We find that we can be <span class="math inline">\(95\%\)</span> confident to have captured <span class="math inline">\(\sigma^2\)</span> within this interval.</p>
<p>Note that the interval for the variance is <strong>not symmetric</strong> and we cannot formulate it as an estimate <span class="math inline">\(\pm\)</span> margin of error. Given an average, we can then estimate with <span class="math inline">\(s\)</span> the expected distance of a subsequent observation of the random experiment, that is its standard deviation <span class="math inline">\(\sigma\)</span>. The confidence interval for the standard deviation will be the square root of the the interval for the variance, and will give us the best and the worst case at which we can expect the observation to fall (orange) from either side of the mean.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-151-1.png" width="384" /></p>
</div>
<div id="questions-10" class="section level2 hasAnchor" number="13.6">
<h2><span class="header-section-number">13.6</span> Questions<a href="interval-estimation.html#questions-10" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>1)</strong> The margin of error at <span class="math inline">\(95\%\)</span> confidence of a normal variable is</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> <span class="math inline">\(\frac{s}{\sqrt{n}}\)</span>;
<strong><span class="math inline">\(\qquad\)</span>b:</strong> <span class="math inline">\(1.96\times se\)</span>;
<strong><span class="math inline">\(\qquad\)</span>c:</strong> <span class="math inline">\(\frac{\sigma}{\sqrt{n}}\)</span>;
<strong><span class="math inline">\(\qquad\)</span>d:</strong> <span class="math inline">\(\sigma\)</span></p>
<p><strong>2)</strong> when we talk about <span class="math inline">\(z_{0.025}\)</span> we mean:</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> The value of a normal standard variable that has accumulated up to <span class="math inline">\(99.75\%\)</span> of probability;
<strong><span class="math inline">\(\qquad\)</span>b:</strong> The value of a normal standard variable that has accumulates up to <span class="math inline">\(0.25\%\)</span> of probability;
<strong><span class="math inline">\(\qquad\)</span>c:</strong> The probability of a standard variable up to <span class="math inline">\(99.75\%\)</span>;
<strong><span class="math inline">\(\qquad\)</span>d:</strong> The probability of a standard variable up to <span class="math inline">\(0.25\%\)</span></p>
<p><strong>3)</strong> The random confident interval <span class="math inline">\((L,U)\)</span> for the mean at <span class="math inline">\(95\%\)</span></p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> is a two dimensional parameter of the sample distribution;
<strong><span class="math inline">\(\qquad\)</span>b:</strong> gives the limits where <span class="math inline">\(\mu\)</span> has a probability of occurring <span class="math inline">\(95\%\)</span> of the times;
<strong><span class="math inline">\(\qquad\)</span>c:</strong> is an estimate of the average;
<strong><span class="math inline">\(\qquad\)</span>d:</strong> captures <span class="math inline">\(\mu\)</span> <span class="math inline">\(95\%\)</span> of the times</p>
<p><strong>4)</strong> A confidence interval for the mean written as <span class="math inline">\(\hat{\mu}=56.99 \pm 0.01\)</span></p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> indicates that we are <span class="math inline">\(\%99\)</span> confident that the mean is <span class="math inline">\(56.99\)</span>;
<strong><span class="math inline">\(\qquad\)</span>b:</strong> indicates that we cannot trust the last decimal place on the estimation of the mean;
<strong><span class="math inline">\(\qquad\)</span>c:</strong> indicates that the mean of the population is at <span class="math inline">\(56.99\)</span> with error <span class="math inline">\(0.01\)</span>;
<strong><span class="math inline">\(\qquad\)</span>d:</strong> indicates that we can trust the unit figure (<span class="math inline">\(6\)</span>) on the estimation of the mean</p>
<p><strong>5)</strong>If we know the value of <span class="math inline">\(\mu\)</span> and find that the confidence interval did not catch it then</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> the confidence interval is not well computed;
<strong><span class="math inline">\(\qquad\)</span>b:</strong> it is a rare observation of the confidence interval;
<strong><span class="math inline">\(\qquad\)</span>c:</strong> the confidence interval does not estimate the mean;
<strong><span class="math inline">\(\qquad\)</span>f:</strong> there is little probability of finding the mean in the confidence interval</p>
</div>
<div id="exercises-11" class="section level2 hasAnchor" number="13.7">
<h2><span class="header-section-number">13.7</span> Exercises<a href="interval-estimation.html#exercises-11" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="exercise-1-10" class="section level4 hasAnchor" number="13.7.0.1">
<h4><span class="header-section-number">13.7.0.1</span> Exercise 1<a href="interval-estimation.html#exercise-1-10" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In a scientific paper, the authors report a <span class="math inline">\(95\%\)</span> confidence interval of <span class="math inline">\((228, 232)\)</span> for the natural frequency (Hz) of a metallic beam. They used a sample of size <span class="math inline">\(25\)</span> and considered that the measurements were distributed normally.</p>
<ul>
<li><p>What is the mean and the standard deviation of the measurements?</p></li>
<li><p>Compute the <span class="math inline">\(99\%\)</span> confidence interval.</p></li>
</ul>
<p>hints:</p>
<ul>
<li><p>in R <span class="math inline">\(t_{0.025, 24}=\)</span> <code>t.ppf(1-0.025, 24)</code><span class="math inline">\(\sim 2\)</span></p></li>
<li><p>in R <span class="math inline">\(t_{0.005, 24}=\)</span><code>t.ppf(1-0.005, 24)</code><span class="math inline">\(\sim 2.8\)</span></p></li>
</ul>
</div>
<div id="exercise-2-10" class="section level4 hasAnchor" number="13.7.0.2">
<h4><span class="header-section-number">13.7.0.2</span> Exercise 2<a href="interval-estimation.html#exercise-2-10" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>compute <span class="math inline">\(95\%\)</span> CI the mean of a normal variable with known variance <span class="math inline">\(\sigma^2=9\)</span> and <span class="math inline">\(\bar{x}=22\)</span>, using a sample of size <span class="math inline">\(36\)</span>.</p>
</div>
<div id="exercise-3-8" class="section level4 hasAnchor" number="13.7.0.3">
<h4><span class="header-section-number">13.7.0.3</span> Exercise 3<a href="interval-estimation.html#exercise-3-8" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>This year, <span class="math inline">\(17\)</span> of <span class="math inline">\(1000\)</span> of patients with influenza developed complications.</p>
<ul>
<li><p>Compute the <span class="math inline">\(99\%\)</span> confidence interval for the proportion of complications.</p></li>
<li><p>The previous year <span class="math inline">\(2\%\)</span> showed complications. Can we say with <span class="math inline">\(99\%\)</span> confidence that this year there is a significant drop in influenza complications?</p></li>
</ul>
</div>
<div id="exercise-4-6" class="section level4 hasAnchor" number="13.7.0.4">
<h4><span class="header-section-number">13.7.0.4</span> Exercise 4<a href="interval-estimation.html#exercise-4-6" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>What is the confidence interval for population variance of a normal variable if we take a random sample of size <span class="math inline">\(n=10\)</span> and observe a sample variance of <span class="math inline">\(0.5\)</span>?</p>
</div>
</div>
<div id="practice-3" class="section level2 hasAnchor" number="13.8">
<h2><span class="header-section-number">13.8</span> Practice<a href="interval-estimation.html#practice-3" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Load misophonia data <code><a href="https://alejandro-isglobal.github.io/SDA/data/data_0.txt" class="uri">https://alejandro-isglobal.github.io/SDA/data/data_0.txt</a></code></p>
<ul>
<li><p>Compute the confidence interval for the mean of the cephalometric measures. (âAngulo_convexidadâ, âprotusion.mandibularâ, âAngulo_cuelloYtercioâ, âSubnasal_Hâ)</p></li>
<li><p>Compute the confidence interval for the proportion of misophonic (âMisofoniaâ), and depression (âdepresion.dicâ).</p></li>
<li><p>Compute the confidence interval for the variance of the age (âEdadâ). What is the confidence interval for the standard deviation of the population?</p></li>
</ul>
<p><a href="https://colab.research.google.com/drive/13El5aoycT_6Wasvyx427TvglygiSPMpF?usp=sharing">Solutions</a></p>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Lu2020" class="csl-entry">
Lu, You, Jie Xue, Tao Deng, Ying Zhou, Xiaohu Yu, Xin Xu, Zheng Liu, et al. 2020. <span>âSafety and Feasibility of <span>CRISPR</span>-Edited <span>T</span> Cells in Patients with Refractory Non-Small-Cell Lung Cancer.â</span> <em>Nature Medicine</em> 26 (5): 732â40. <a href="https://doi.org/10.1038/s41591-020-0840-3">https://doi.org/10.1038/s41591-020-0840-3</a>.
</div>
<div id="ref-mendel1901experiments" class="csl-entry">
Mendel, Gregor. 1901. <em>Experiments in Plant Hybridisation</em>. Translated by William Bateson. Cambridge: Cambridge University Press.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="maximum-likelihood.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="hypothesis-testing.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/13-InervalEstimation.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
