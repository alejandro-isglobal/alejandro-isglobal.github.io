% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{book}
\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math} % this also loads fontspec
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else
  % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}
\usepackage{booktabs}
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\usepackage[]{natbib}
\bibliographystyle{plainnat}
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same}
\hypersetup{
  pdftitle={EEBE Estadística},
  pdfauthor={Alejandro Cáceres (alejandro.caceres.dominguez@upc.edu)},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{EEBE Estadística}
\author{Alejandro Cáceres (\href{mailto:alejandro.caceres.dominguez@upc.edu}{\nolinkurl{alejandro.caceres.dominguez@upc.edu}})}
\date{2024-02-07}

\begin{document}
\maketitle

{
\setcounter{tocdepth}{1}
\tableofcontents
}
\hypertarget{objetivo}{%
\chapter{Objetivo}\label{objetivo}}

Este es el curso de introducción a la estadística de la EEBE (UPC).

La estadística es un \textbf{lenguaje} que permite afrontar problemas nuevos, sobre los que no tenemos solución, y en donde interviene la \textbf{aleatoridad}.

En este curso trataremos los \textbf{conceptos fundamentales} de estadística.

\begin{itemize}
\item
  3 horas de \textbf{teoría} por semana: Explicaremos los conceptos, haremos ejercicios.
\item
  6 horas de \textbf{estudio individual} por semana: Notas notas de curso y los recursos en ATENEA.
\item
  2 horas de Solución de problemas con \textbf{R}: Sesiones presenciales con ordenador (Prácticas).
\end{itemize}

Las fechas de exámenes y material de estudio adicional se pueden encontrar en \textbf{ATENEA metacurso}:

\includegraphics{./figures/notas.JPG}

Objetivos de evaluación:

\textbf{Q1} (10\%): Prueba en ordenador duración 2h en las fechas indicadas.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Dominio de comandos básicos en R (Prácticas)
\item
  Capacidad de calcular estadísticos descriptivos y gráficos, en situaciones concretas (Teoría/Práctica)
\item
  Conocimiento sobre la regresión lineal (Prácticas)
\end{enumerate}

\textbf{EP1} (25\%): Prueba escrita (2-3 problemas)

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Capacidad de interpretación de enunciados en fórmulas de probabilidad (Teoría).
\item
  Conocimiento de las herramientas básicas para solucionar problemas de probabilidad conjunta y probabilidad condicional (Teoría).
\item
  Dominio matemático de funciones de probabilidad para calcular sus propiedades básicas (Teoría).
\end{enumerate}

\textbf{Q2} (20\%): Prueba en ordenador duración 2h en horario de clase en las fechas indicadas

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Capacidad de identificación de modelos de probabilidad en problemas concretos (Teoría/Práctica).
\item
  Uso de funciones de R para calcular probabilidades de modelos probabilísticos (Práctica/Teoría)
\item
  Capacidad de identificación de un estadístico de muestreo y sus propiedades (Teoría/Práctica)
\item
  Conocimiento de cómo calcular la probabilidad de los estadísticos de muestreo (Teoría/Práctica)
\item
  Uso de comandos en R para calcular probabilidades y hacer simulaciones de muestras aleatorias (Prácticas)
\end{enumerate}

\textbf{EP2} (40\%): Prueba escrita (2-3 problemas)

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Capacidad matemática para determinar estimadores puntuales de modelos de probabilidad.
\item
  Conociemiento de las propiedades de los estimadores puntuales.
\item
  Conocimiento de los intervalos de confianza y sus propiedades (Teoría).
\item
  Capacidad de identificar el tipo de intervalo de confianza en un problema concreto (Teoría).
\item
  Capacidad de interpretación del tipo
  de hipótesis a usar en un problema concreto (Teoría).
\item
  Uso de comandos en R para resolver problemas de intervalos de confianza y prueabas de hipótesis (Práctica).
\end{enumerate}

\textbf{CG} (5\%): Prueba escrita (2 preguntas sobre un texto)

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  Capacidad de expresión escrita sobre un tema relacionado a la estadística.
\end{enumerate}

coordinadores:

\begin{itemize}
\tightlist
\item
  Luis Mujica (\href{mailto:luis.eduardo.mujica@upc.edu}{\nolinkurl{luis.eduardo.mujica@upc.edu}})
\item
  Pablo Buenestado (\href{mailto:pablo.buenestado@upc.edu}{\nolinkurl{pablo.buenestado@upc.edu}})
\end{itemize}

\hypertarget{lectura-recomendada}{%
\section{Lectura recomendada}\label{lectura-recomendada}}

\begin{itemize}
\item
  Los apuntes de clase se nuestra sección estarán accesibles en ATENEA en pdf y en html.
\item
  Douglas C. Montgomery and George C. Runger. ``Applied Statistics and Probability for Engineers'' 4th Edition. Wiley 2007.
\end{itemize}

\hypertarget{descripciuxf3n-de-datos}{%
\chapter{Descripción de datos}\label{descripciuxf3n-de-datos}}

En este capítulo, presentaremos herramientas para describir datos.

Lo haremos utilizando tablas, figuras y estadísticos descriptivos de tendencia central y dispersión.

También presentaremos conceptos clave en estadística como experimentos aleatorios, observaciones, resultados y frecuencias absolutas y relativas.

\hypertarget{muxe9todo-cientuxedfico}{%
\section{Método científico}\label{muxe9todo-cientuxedfico}}

Uno de los objetivos del método científico es proporcionar un marco para resolver los problemas que surgen en el estudio de los fenómenos naturales o en el diseño de nuevas tecnologías.

Los humanos modernos han desarrollado un \textbf{método} durante miles de años que todavía está en desarrollo.

El método tiene tres actividades humanas principales:

\begin{itemize}
\tightlist
\item
  \emph{Observación} caracterizada por la adquisición de \textbf{datos}
\item
  \emph{Razón} caracterizada por el desarrollo de \textbf{modelos} matemáticos
\item
  \emph{Acción} caracterizada por el desarrollo de nuevos \textbf{experimentos} (tecnología)
\end{itemize}

Su compleja interacción y resultados son la base de la \emph{actividad científica}.

\includegraphics{./figures/stats.JPG}

\hypertarget{estaduxedstica}{%
\section{Estadística}\label{estaduxedstica}}

La estadística se ocupa de la interacción entre \emph{modelos} y \emph{datos} (la parte inferior de la figura).

Las preguntas de tipo estadístico son:

\begin{itemize}
\tightlist
\item
  ¿Cuál es el mejor modelo para mis datos (inferencia)?
\item
  ¿Cuáles son los datos que produciría un determinado modelo (predicción)?
\end{itemize}

\hypertarget{datos}{%
\section{Datos}\label{datos}}

Los datos se presentan en forma de observaciones.

Una \textbf{Observación} o \emph{Realización} es la adquisición de un número o una característica de un experimento.

Por ejemplo, tomemos la serie de números que se producen por la repetición de un experimento (1: éxito, 0: fracaso)

\ldots{} 1 0 0 1 0 \textbf{1} 0 1 1 \ldots{}

El número en negrita es \textbf{una observación} en una repetición del experimento

Un \textbf{resultado} es una \textbf{posible} observación que es el resultado de un experimento.

\textbf{1} es un resultado, \textbf{0} es el otro resultado del experimento.

Recuerda que la observación es \textbf{concreta} es el número que obtienes un día en el laboratorio. El resultado \textbf{abstracto} es una de las características del tipo de experimento que estás realizando.

\hypertarget{tipos-de-resultado}{%
\section{Tipos de resultado}\label{tipos-de-resultado}}

En estadística nos interesan principalmente dos tipos de resultados.

\begin{itemize}
\item
  \textbf{Categóricos}: Si el resultado de un experimento es una cualidad. Pueden ser nominales (binario: sí, no; múltiple: colores) u ordinales cuando las cualidades pueden jerarquizarse (gravedad de una enfermedad).
\item
  \textbf{Numéricos}: Si el resultado de un experimento es un número. El número puede ser discreto (número de correos electrónicos recibidos en una hora, número de leucocitos en sangre) o continuo (estado de carga de la batería, temperatura del motor).
\end{itemize}

\hypertarget{experimentos-aleatorios}{%
\section{Experimentos aleatorios}\label{experimentos-aleatorios}}

Se puede decir que el tema de estudio de la estadística son los experimentos aleatorios, el medio por el cual producimos datos.

\textbf{Definición:}

Un \textbf{experimento aleatorio} es un experimento que da diferentes resultados cuando se repite de la misma manera.

Los experimentos aleatorios son de diferentes tipos, dependiendo de cómo se realicen:

\begin{itemize}
\tightlist
\item
  en el mismo objeto (persona): temperatura, niveles de azúcar.
\item
  sobre objetos diferentes pero de la misma medida: el peso de un animal.
\item
  sobre eventos: el número de huracanes por año.
\end{itemize}

\hypertarget{frecuencias-absolutas}{%
\section{Frecuencias absolutas}\label{frecuencias-absolutas}}

Cuando repetimos un experimento aleatorio con resultados \textbf{categóricos}, registramos una lista de resultados.

Resumimos las observaciones contando cuántas veces vimos un resultado particular.

\textbf{Frecuencia absoluta}:

\[n_i\]

es el número de veces que observamos el resultado \(i\).

\textbf{Ejemplo (leucocitos)}

Extraigamos un leucocito de \textbf{un} donante y anotemos su tipo. Repitamos el experimento \(N=119\) veces.

\begin{verbatim}
(célula T, célula T, neutrófilo, ..., célula B)
\end{verbatim}

La segunda \textbf{célula T} en negrita es la segunda observación. La última \textbf{célula B} es la observación número 119.

Podemos listar los \textbf{resultados} (categorías) en una \textbf{tabla de frecuencia}:

\begin{verbatim}
##      outcome ni
## 1     T Cell 34
## 2     B cell 50
## 3   basophil 20
## 4   Monocyte  5
## 5 Neutrophil 10
\end{verbatim}

De la tabla, podemos decir que, por ejemplo, \(n_1=34\) es el número total de células T observadas en la repetición del experimento. También notamos que el número total de repeticiones \(N=\sum_i n_i=119\).

\hypertarget{frecuencias-relativas}{%
\section{Frecuencias relativas}\label{frecuencias-relativas}}

También podemos resumir las observaciones calculando la \textbf{proporción} de cuántas veces vimos un resultado en particular.

\[f_i=n_i/N\] donde \(N\) es el número total de observaciones

En nuestro ejemplo se registraron \(n_1=34\) células T, por lo que nos preguntamos por la proporción de células T del total de \(119\). Podemos agregar estas proporciones \(f_i\) en la tabla las frecuencias.

\begin{verbatim}
##      outcome ni         fi
## 1     T Cell 34 0.28571429
## 2     B cell 50 0.42016807
## 3   basophil 20 0.16806723
## 4   Monocyte  5 0.04201681
## 5 Neutrophil 10 0.08403361
\end{verbatim}

Las frecuencias relativas son \textbf{fundamentales} en estadística. Dan la proporción de un resultado en relación con los otros resultados. Más adelante las entenderemos como las observaciones de las probabilidades.

Para las frecuencias absolutas y relativas tenemos las propiedades

\begin{itemize}
\tightlist
\item
  \(\sum_{i=1..M} n_i = N\)
\item
  \(\sum_{i=1..M} f_i = 1\)
\end{itemize}

donde \(M\) es el número de resultados.

\hypertarget{diagrama-de-barras}{%
\section{Diagrama de barras}\label{diagrama-de-barras}}

Cuando tenemos muchos resultados y queremos ver cuáles son los más probables, podemos usar un gráfico de barras que es una cifra de \(n_i\) Vs los resultados.

\includegraphics{_main_files/figure-latex/unnamed-chunk-3-1.pdf}

\hypertarget{gruxe1fico-de-sectores-pie}{%
\section{Gráfico de sectores (pie)}\label{gruxe1fico-de-sectores-pie}}

También podemos visualizar las frecuencias relativas con un gráfico de sectores.

El área del círculo representa el 100\% de las observaciones (proporción = 1) y las secciones las frecuencias relativas de cada resultado.

\includegraphics{_main_files/figure-latex/unnamed-chunk-4-1.pdf}

\hypertarget{variables-categuxf3ricas-ordinales}{%
\section{Variables categóricas ordinales}\label{variables-categuxf3ricas-ordinales}}

El tipo de leucocito de los ejemplos anteriores es una variable nominal \textbf{categórica}. Cada observación pertenece a una categoría (cualidad). Las categorías no siempre tienen un orden determindado.

A veces, las variables \textbf{categóricas} se pueden \textbf{ordenar} cuando cumplen una clasificación natural. Esto permite introducir \textbf{frecuencias acumulativas}.

\textbf{Ejemplo (misofonía)}

Este es un estudio clínico en 123 pacientes que fueron examinados por su grado de misofonía. La misofnía es ansiedad/ira descontrolada producida por ciertos sonidos.

Cada paciente fue evaluado con un cuestionario (AMISO) y se clasificaron en 4 grupos diferentes según la gravedad.

Los resultados del estudio son

\begin{verbatim}
##   [1] 4 2 0 3 0 0 2 3 0 3 0 2 2 0 2 0 0 3 3 0 3 3 2 0 0 0 4 2 2 0 2 0 0 0 3 0 2
##  [38] 3 2 2 0 2 3 0 0 2 2 3 3 0 0 4 3 3 2 0 2 0 0 0 2 2 0 0 2 3 0 1 3 2 4 3 2 3
##  [75] 0 2 3 2 4 1 2 0 2 0 2 0 2 2 4 3 0 3 0 0 0 2 2 1 3 0 0 3 2 1 3 0 4 4 2 3 3
## [112] 3 0 3 2 1 2 3 3 4 2 3 2
\end{verbatim}

Cada observación es el resultado de un experimento aleatorio: medición del nivel de misofonía en un paciente. Esta serie de datos se puede resumir en términos de los resultados en la tabla de frecuencia

\begin{verbatim}
##   outcome ni         fi
## 1       0 41 0.33333333
## 2       1  5 0.04065041
## 3       2 37 0.30081301
## 4       3 31 0.25203252
## 5       4  9 0.07317073
\end{verbatim}

\hypertarget{frecuencias-acumuladas-absolutas-y-relativas}{%
\section{Frecuencias acumuladas absolutas y relativas}\label{frecuencias-acumuladas-absolutas-y-relativas}}

La gravedad de la misofonía es \textbf{categórica} \textbf{ordinal} porque sus resultados pueden ordenarse en relación con su grado.

Cuando los resultados se pueden ordenar, es útil preguntar cuántas observaciones se obtuvieron hasta un resultado dado. Llamamos a este número la \textbf{frecuencia acumulada absoluta} hasta el resultado \(i\):
\[N_i=\sum_{k=1..i} n_k\]
También es útil para calcular la \textbf{proporción} de las observaciones que se obtuvo hasta un resultado dado

\[F_i=\sum_{k=1..i} f_k\]

Podemos agregar estas frecuencias en la \textbf{tabla de frecuencias}

\begin{verbatim}
##   outcome ni         fi  Ni        Fi
## 0       0 41 0.33333333  41 0.3333333
## 1       1  5 0.04065041  46 0.3739837
## 2       2 37 0.30081301  83 0.6747967
## 3       3 31 0.25203252 114 0.9268293
## 4       4  9 0.07317073 123 1.0000000
\end{verbatim}

Por lo tanto, el \textbf{67 \%} de los pacientes tenían misofonía hasta la gravedad \textbf{2} y el \textbf{37 \%} de los pacientes tenían una gravedad inferior o igual a \textbf{1}.

\hypertarget{gruxe1fica-de-frecuencia-acumulada}{%
\section{Gráfica de frecuencia acumulada}\label{gruxe1fica-de-frecuencia-acumulada}}

\(F_i\) es una cantidad importante porque nos permite definir la acumulación de probabilidades hasta niveles intermedios.

La probabilidad de un nivel intermedio \(x\) (\(i\leq x< i+1\)) es solo la acumulación hasta el nivel inferior \(F_x=F_i\).

\(F_x\) es por lo tanto una función de rango \textbf{continuo}. Podemos dibujarla con respecto a los resultados.

\includegraphics{_main_files/figure-latex/unnamed-chunk-8-1.pdf}

Por lo tanto, podemos decir que el \textbf{67 \%} de los pacientes tenían misofonía hasta gravedad \(2.3\), aunque \(2.3\) no es un resultado observado.

\hypertarget{variables-numuxe9ricas}{%
\section{Variables numéricas}\label{variables-numuxe9ricas}}

El resultado de un experimento aleatorio puede producir un número. Si el número es \textbf{discreto}, podemos generar una tabla de frecuencias, con frecuencias absolutas, relativas y acumulativas, e ilustrarlas con gráficos de barras, de sectores y acumulativos.

Cuando el número es \textbf{continuo} las frecuencias no son útiles, lo más probable es que observemos o no un número contínuo en particular.

\textbf{Ejemplo (misofonía)}

Los investigadores se preguntaron si la convexidad de la mandíbula afectaría la gravedad de la misofonía. La hipótesis científica es que el ángulo de convexidad de la mandíbula puede influir en el oído y su sensibilidad. Estos son los resultados de la convexidad de la mandíbula (grados) para cada paciente:

\begin{verbatim}
##   [1]  7.97 18.23 12.27  7.81  9.81 13.50 19.30  7.70 12.30  7.90 12.60 19.00
##  [13]  7.27 14.00  5.40  8.00 11.20  7.75  7.94 16.69  7.62  7.02  7.00 19.20
##  [25]  7.96 14.70  7.24  7.80  7.90  4.70  4.40 14.00 14.40 16.00  1.40  9.76
##  [37]  7.90  7.90  7.40  6.30  7.76  7.30  7.00 11.23 16.00  7.90  7.29  6.91
##  [49]  7.10 13.40 11.60 -1.00  6.00  7.82  4.80 11.00  9.00 11.50 16.00 15.00
##  [61]  1.40 16.80  7.70 16.14  7.12 -1.00 17.00  9.26 18.70  3.40 21.30  7.50
##  [73]  6.03  7.50 19.00 19.01  8.10  7.80  6.10 15.26  7.95 18.00  4.60 15.00
##  [85]  7.50  8.00 16.80  8.54  7.00 18.30  7.80 16.00 14.00 12.30 11.40  8.50
##  [97]  7.00  7.96 17.60 10.00  3.50  6.70 17.00 20.26  6.64  1.80  7.02  2.46
## [109] 19.00 17.86  6.10  6.64 12.00  6.60  8.70 14.05  7.20 19.70  7.70  6.02
## [121]  2.50 19.00  6.80
\end{verbatim}

\hypertarget{transformando-datos-continuos}{%
\section{Transformando datos continuos}\label{transformando-datos-continuos}}

Como los resultados continuos no se pueden contar (de manera informativa), los transformamos en variables categóricas ordenadas.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Primero cubrimos el rango de las observaciones en intervalos regulares del mismo tamaño (contenedores)
\end{enumerate}

\begin{verbatim}
## [1] "[-1.02,3.46]" "(3.46,7.92]"  "(7.92,12.4]"  "(12.4,16.8]"  "(16.8,21.3]"
\end{verbatim}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Luego mapeamos cada observación a su intervalo: creando una variable categórica \textbf{ordenada}; en este caso con 5 resultados posibles
\end{enumerate}

\begin{verbatim}
##   [1] "(7.92,12.4]"  "(16.8,21.3]"  "(7.92,12.4]"  "(3.46,7.92]"  "(7.92,12.4]" 
##   [6] "(12.4,16.8]"  "(16.8,21.3]"  "(3.46,7.92]"  "(7.92,12.4]"  "(3.46,7.92]" 
##  [11] "(12.4,16.8]"  "(16.8,21.3]"  "(3.46,7.92]"  "(12.4,16.8]"  "(3.46,7.92]" 
##  [16] "(7.92,12.4]"  "(7.92,12.4]"  "(3.46,7.92]"  "(7.92,12.4]"  "(12.4,16.8]" 
##  [21] "(3.46,7.92]"  "(3.46,7.92]"  "(3.46,7.92]"  "(16.8,21.3]"  "(7.92,12.4]" 
##  [26] "(12.4,16.8]"  "(3.46,7.92]"  "(3.46,7.92]"  "(3.46,7.92]"  "(3.46,7.92]" 
##  [31] "(3.46,7.92]"  "(12.4,16.8]"  "(12.4,16.8]"  "(12.4,16.8]"  "[-1.02,3.46]"
##  [36] "(7.92,12.4]"  "(3.46,7.92]"  "(3.46,7.92]"  "(3.46,7.92]"  "(3.46,7.92]" 
##  [41] "(3.46,7.92]"  "(3.46,7.92]"  "(3.46,7.92]"  "(7.92,12.4]"  "(12.4,16.8]" 
##  [46] "(3.46,7.92]"  "(3.46,7.92]"  "(3.46,7.92]"  "(3.46,7.92]"  "(12.4,16.8]" 
##  [51] "(7.92,12.4]"  "[-1.02,3.46]" "(3.46,7.92]"  "(3.46,7.92]"  "(3.46,7.92]" 
##  [56] "(7.92,12.4]"  "(7.92,12.4]"  "(7.92,12.4]"  "(12.4,16.8]"  "(12.4,16.8]" 
##  [61] "[-1.02,3.46]" "(12.4,16.8]"  "(3.46,7.92]"  "(12.4,16.8]"  "(3.46,7.92]" 
##  [66] "[-1.02,3.46]" "(16.8,21.3]"  "(7.92,12.4]"  "(16.8,21.3]"  "[-1.02,3.46]"
##  [71] "(16.8,21.3]"  "(3.46,7.92]"  "(3.46,7.92]"  "(3.46,7.92]"  "(16.8,21.3]" 
##  [76] "(16.8,21.3]"  "(7.92,12.4]"  "(3.46,7.92]"  "(3.46,7.92]"  "(12.4,16.8]" 
##  [81] "(7.92,12.4]"  "(16.8,21.3]"  "(3.46,7.92]"  "(12.4,16.8]"  "(3.46,7.92]" 
##  [86] "(7.92,12.4]"  "(12.4,16.8]"  "(7.92,12.4]"  "(3.46,7.92]"  "(16.8,21.3]" 
##  [91] "(3.46,7.92]"  "(12.4,16.8]"  "(12.4,16.8]"  "(7.92,12.4]"  "(7.92,12.4]" 
##  [96] "(7.92,12.4]"  "(3.46,7.92]"  "(7.92,12.4]"  "(16.8,21.3]"  "(7.92,12.4]" 
## [101] "(3.46,7.92]"  "(3.46,7.92]"  "(16.8,21.3]"  "(16.8,21.3]"  "(3.46,7.92]" 
## [106] "[-1.02,3.46]" "(3.46,7.92]"  "[-1.02,3.46]" "(16.8,21.3]"  "(16.8,21.3]" 
## [111] "(3.46,7.92]"  "(3.46,7.92]"  "(7.92,12.4]"  "(3.46,7.92]"  "(7.92,12.4]" 
## [116] "(12.4,16.8]"  "(3.46,7.92]"  "(16.8,21.3]"  "(3.46,7.92]"  "(3.46,7.92]" 
## [121] "[-1.02,3.46]" "(16.8,21.3]"  "(3.46,7.92]"
\end{verbatim}

Por tanto, en lugar de decir que el primer paciente tenía un ángulo de convexidad de \(7.97\), decimos que su ángulo estaba entre el intervalo (o \textbf{bin}) \((7.92,12.4]\).

Ningún otro paciente tenía un ángulo de \(7.97\), pero muchos tenían ángulos entre \((7.92,12.4]\).

\hypertarget{tabla-de-frecuencias-para-una-variable-continua}{%
\section{Tabla de frecuencias para una variable continua}\label{tabla-de-frecuencias-para-una-variable-continua}}

Para una partición regular dada del intervalo de resultados en intervalos, podemos producir una tabla de frecuencias como antes

\begin{verbatim}
##        outcome ni         fi  Ni         Fi
## 1 [-1.02,3.46]  8 0.06504065   8 0.06504065
## 2  (3.46,7.92] 51 0.41463415  59 0.47967480
## 3  (7.92,12.4] 26 0.21138211  85 0.69105691
## 4  (12.4,16.8] 20 0.16260163 105 0.85365854
## 5  (16.8,21.3] 18 0.14634146 123 1.00000000
\end{verbatim}

\hypertarget{histograma}{%
\section{Histograma}\label{histograma}}

El histograma es la gráfica de \(n_i\) o \(f_i\) Vs los resultados en intervalos (bins). El histograma depende del tamaño de los bins.

\includegraphics{_main_files/figure-latex/unnamed-chunk-13-1.pdf}

Este es un histograma con 20 bins.

\includegraphics{_main_files/figure-latex/unnamed-chunk-14-1.pdf}

Vemos que la mayoría de las personas tienen ángulos dentro de \((7, 8]\)

\hypertarget{gruxe1fica-de-frecuencia-acumulada-1}{%
\section{Gráfica de frecuencia acumulada}\label{gruxe1fica-de-frecuencia-acumulada-1}}

También podemos graficar \(F_x\) contra los resultados. Como \(F_x\) es de rango continuo, podemos ordenar las observaciones (\(x_1 <... x_j < x_{j+1} < x_n\)) y por lo tanto

\[F_x = \frac{k}{n}\]

para \(x_{k} \leq x < x_{k+1}\).

\(F_x\) se conoce como la \textbf{distribución} de los datos. \(F_x\) no depende del tamaño del bin. Sin embargo, su \textbf{resolución} depende de la cantidad de datos.

\includegraphics{_main_files/figure-latex/unnamed-chunk-15-1.pdf}

\hypertarget{estaduxedsticas-de-resumen}{%
\section{Estadísticas de resumen}\label{estaduxedsticas-de-resumen}}

Las estadísticas de resumen son números calculados a partir de los datos que nos dicen características importantes de las variables numéricas (discretas o continuas).

Por ejemplo, tenemos estadísticas que describen los valores extremos:

\begin{itemize}
\tightlist
\item
  \textbf{mínimo}: el resultado mínimo observado
\item
  \textbf{máximo}: el resultado máximo observado
\end{itemize}

\hypertarget{promedio-media-muestral}{%
\section{Promedio (media muestral)}\label{promedio-media-muestral}}

Una estadística importante que describe el valor central de los resultados (dónde esperar la mayoría de las observaciones) es el \textbf{promedio}

\[\bar{x}=\frac{1}{N} \sum_{j=1..N} x_j\]

donde \(x_j\) es la \textbf{observación} \(j\) de un total de \(N\).

\textbf{Ejemplo (Misofonía)}

La convexidad promedio se puede calcular directamente a partir de las \textbf{observaciones}

\(\bar{x}= \frac{1}{N}\sum_j x_j\)

\(= \frac{1}{N}(7.97 + 18.23 + 12.27... + 6.80) = 10.19894\)

Para variables \textbf{categóricamente ordenadas}, podemos usar las frecuencias relativas para calcular el promedio

\(\bar{x}=\frac{1}{N}\sum_{i=1...N} x_j=\frac{1}{N}\sum_{i=1...M} x_i*n_ {i}\)
\[=\sum_{i=1...M} x_i*f_{i}\]

donde pasamos de sumar \(N\) \textbf{observaciones} a sumar \(M\) \textbf{resultados}.

La forma \(\bar{x}= \sum_{i = 1...M} x_i f_i\) muestra que el promedio es el \textbf{centro de gravedad} de los resultados. Como si cada resultado tuviera una densidad de masa dada por \(f_i\).

\textbf{Ejemplo (Misofonía)}

La \textbf{severidad} promedio de la misofonía en el estudio se puede calcular a partir de las frecuencias relativas de los \textbf{resultados}

\begin{verbatim}
##   outcome ni         fi
## 1       0 41 0.33333333
## 2       1  5 0.04065041
## 3       2 37 0.30081301
## 4       3 31 0.25203252
## 5       4  9 0.07317073
\end{verbatim}

\(\bar{x}=0*f_{0}+1*f_{1}+2*f_{2}+3*f_{3}+4*f_{4}=1.691057\)

\hypertarget{promedio}{%
\section{Promedio}\label{promedio}}

El promedio es también el centro de gravedad de las variables continuas. Ese es el punto donde las frecuencias reativas se equilibran.

\includegraphics{_main_files/figure-latex/unnamed-chunk-17-1.pdf}

\hypertarget{mediana}{%
\section{mediana}\label{mediana}}

Otra medida de centralidad es la mediana. La mediana \(x_m\), o \(q_{0.5}\), es el valor por debajo del cual encontramos la mitad de las observaciones. Cuando ordenamos las observaciones \(x_1 <... x_j < x_{j+1} < x_N\), las contamos hasta encontrar la mitad de ellas. \(x_m\) es tal que

\[\sum_{i\leq m} 1 = \frac{N}{2}\]
\textbf{Ejemplo (Misofonía)}

Si ordenamos los ángulos de convexidad, vemos que \(62\) observaciones (individuos) (\(N/2 \sim 123/2\)) están por debajo de \(7.96\). La \textbf{convexidad mediana} es por lo tanto \(q_{0.5}=x_{62}=7.96\)

\begin{verbatim}
##  [1] -1.00 -1.00  1.40  1.40  1.80  2.46  2.50  3.40  3.50  4.40  4.60  4.70
## [13]  4.80  5.40  6.00  6.02  6.03  6.10  6.10  6.30  6.60  6.64  6.64  6.70
## [25]  6.80  6.91  7.00  7.00  7.00  7.00  7.02  7.02  7.10  7.12  7.20  7.24
## [37]  7.27  7.29  7.30  7.40  7.50  7.50  7.50  7.62  7.70  7.70  7.70  7.75
## [49]  7.76  7.80  7.80  7.80  7.81  7.82  7.90  7.90  7.90  7.90  7.90  7.94
## [61]  7.95  7.96
\end{verbatim}

\begin{verbatim}
##  [1]  7.96  7.97  8.00  8.00  8.10  8.50  8.54  8.70  9.00  9.26  9.76  9.81
## [13] 10.00 11.00 11.20 11.23 11.40 11.50 11.60 12.00 12.27 12.30 12.30 12.60
## [25] 13.40 13.50 14.00 14.00 14.00 14.05 14.40 14.70 15.00 15.00 15.26 16.00
## [37] 16.00 16.00 16.00 16.14 16.69 16.80 16.80 17.00 17.00 17.60 17.86 18.00
## [49] 18.23 18.30 18.70 19.00 19.00 19.00 19.00 19.01 19.20 19.30 19.70 20.26
## [61] 21.30
\end{verbatim}

\begin{verbatim}
## [1] 7.96
\end{verbatim}

En términos de frecuencias, \(q_{0.5}\) hace que la frecuencia acumulada \(F_x\) sea igual a \(0.5\)

\[\sum_{i = 0, ... m} f_i =F_{q_{0.5}}=0.5\]
o

\[q_{0.5}=F^{-1}(0.5)\]

En el gráfico de distribución, la mediana es el valor de \(x\) en el que se encuentra la mitad del máximo de \(F\).

\includegraphics{_main_files/figure-latex/unnamed-chunk-20-1.pdf}

El promedio y la mediana no siempre son iguales.

\includegraphics{_main_files/figure-latex/unnamed-chunk-21-1.pdf}

\hypertarget{dispersiuxf3n}{%
\section{Dispersión}\label{dispersiuxf3n}}

Otras estadísticas de resumen importantes de las observaciones son las de \textbf{dispersión}.

Muchos experimentos pueden compartir su media, pero difieren en cuán \textbf{dispersos} son los valores.

La dispersión de las observaciones es una medida del \textbf{ruido}.

\includegraphics{_main_files/figure-latex/unnamed-chunk-22-1.pdf} \includegraphics{_main_files/figure-latex/unnamed-chunk-22-2.pdf}

\hypertarget{variaciuxf3n-de-la-muestra}{%
\section{Variación de la muestra}\label{variaciuxf3n-de-la-muestra}}

La dispersión sobre la media se mide con la varianza muestral

\[s^2=\frac{1}{N-1} \sum_{j=1..N} (x_j-\bar{x})^2\]

Este número, mide la distancia cuadrada promedio de las \textbf{observaciones} al promedio. La razón de \(N-1\) se explicará cuando hablemos de inferencia, cuando estudiemos la dispersión de \(\bar{x}\), además de la dispersión de las observaciones.

En términos de las frecuencias de las variables \textbf{categóricas y ordenadas}

\[s^2=\frac{N}{N-1} \sum_{i=1... M} (x_i-\bar{x})^2 f_i\]

\(s^2\) se puede considerar como el \textbf{momento de inercia} de las observaciones.

La raíz cuadrada de la varianza de la muestra se denomina \textbf{desviación estándar} \(s\).

\textbf{Ejemplo (Misofonía)}

La desviación estándar del ángulo de convexidad es

\(s= [\frac{1}{123-1}((7.97-10.19894)^2+ (18.23-10.19894)^2\)
\(+ (12.27-10.19894)^2 + ...)]^{1/2} = 5.086707\)

La convexidad de la mandíbula se desvía de su media en \(5.086707\).

\hypertarget{rango-intercuartuxedlico-iqr}{%
\section{Rango intercuartílico (IQR)}\label{rango-intercuartuxedlico-iqr}}

La dispersión de los datos también se puede medir con respecto a la mediana usando el \textbf{rango intercuartílico}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Definimos el \textbf{primer} cuartil como el valor \(x_m\) que hace que la frecuencia acumulada \(F_{q_{0.25}}\) sea igual a \(0.25\) (\(x\) donde hemos acumulado una cuarta parte de las observaciones)
\end{enumerate}

\[F_{q_{0.25}}=0.25\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Definimos el \textbf{tercer} cuartil como el valor \(x_m\) que hace que la frecuencia acumulada \(F_{q_{0.75}}\) sea igual a \(0.75\) (\(x\) donde hemos acumulado tres cuartos de observaciones)
\end{enumerate}

\[F_{q_{0.75}}=0.75\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  El \textbf{rango intercuartílico} (IQR) es \(IQR=q_{0.75} - q_{0.25}\). Esa es la distancia entre el tercer y el primer cuartil y captura el \(50\%\) central de las observaciones
\end{enumerate}

\includegraphics{_main_files/figure-latex/unnamed-chunk-23-1.pdf}

\hypertarget{diagrama-de-caja}{%
\section{Diagrama de caja}\label{diagrama-de-caja}}

El rango intercuartílico, la mediana y los \(5\%\) y \(95\%\) de los datos se pueden visualizar en un \textbf{diagrama de caja}.

En el diagrama de caja, los valores de los resultados están en el eje y. El IQR es la caja, la mediana es la línea del medio y los bigotes marcan los \(5\%\) y \(95\%\) de los datos.

\includegraphics{_main_files/figure-latex/unnamed-chunk-24-1.pdf}

\hypertarget{preguntas}{%
\section{Preguntas}\label{preguntas}}

\textbf{1)} En el siguiente diagrama de caja, el primer cuartil y el segundo cuartil de los datos son:

\textbf{\(\qquad\)a:} \((-1.00, 21.30)\); \textbf{\(\qquad\)b:} \((-1.00, 7.02)\); \textbf{\(\qquad\)c:} \((7.02, 7.96)\); \textbf{\(\qquad\)d:} \((7.02, 14.22)\)

\includegraphics{./figures/box.png}

\textbf{2)} La principal desventaja de un histograma es que:

\textbf{\(\qquad\)a:} Depende del tamaño del bin; \textbf{\(\qquad\)b:} No se puede utilizar para variables categóricas;
\textbf{\(\qquad\)c:} No se puede usar cuando el tamaño del bin es pequeño;
\textbf{\(\qquad\)d:} Se usa solo para frecuencias relativas;

\textbf{3)} Si las frecuencias acumuladas relativas de un experimento aleatorio con resultados \(\{1,2,3,4\}\) son: \(F(1)=0.15, \qquad F(2)=0.60, \qquad F(3)=0.85, \qquad F(4)=1\).

Entonces la frecuencia relativa para el resultado \(3\) es

\textbf{\(\qquad\)a:} \(0.15\); \textbf{\(\qquad\)b:} \(0.85\); \textbf{\(\qquad\)c:} \(0.45\); \textbf{\(\qquad\)d:} \(0.25\)

\textbf{4)} En una muestra de tamaño \(10\) de un experimento aleatorio obtuvimos los siguientes datos:

\(8,\qquad 3,\qquad 3,\qquad 7,\qquad 3,\qquad 6,\qquad 5,\qquad 10,\qquad 3,\qquad 8\).

El primer cuartil de los datos es:

\textbf{\(\qquad\)a:} \(3.5\); \textbf{\(\qquad\)b:} \(4\); \textbf{\(\qquad\)c:} \(5\); \textbf{\(\qquad\)d:} \(3\)

\textbf{5)} Imaginemos que recopilamos datos para dos cantidades que no son mutuamente excluyentes, por ejemplo, el sexo y la nacionalidad de los pasajeros de un vuelo. Si queremos hacer un solo gráfico circular para los datos, ¿cuál de estas afirmaciones es verdadera?

\textbf{\(\qquad\)a:} Solo podemos hacer un gráfico circular de nacionalidad porque tiene más de dos resultados posibles; \textbf{\(\qquad\)b:} Podemos hacer un gráfico circular para una variable nueva que marca el sexo \textbf{y} la nacionalidad; \textbf{\(\qquad\)c:} Podemos hacer un gráfico circular para la variale sexo o la variable nacionalidad; \textbf{\(\qquad\)d:} Solo podemos elegir si hacemos un gráfico circular para el sexo o un gráfico circular para la nacionalidad.

\hypertarget{ejercicios}{%
\section{Ejercicios}\label{ejercicios}}

\hypertarget{ejercicio-1}{%
\subsubsection{Ejercicio 1}\label{ejercicio-1}}

Hemos realizado un experimento 8 veces con los siguientes resultados

\begin{verbatim}
## [1]  3  3 10  2  6 11  5  4
\end{verbatim}

Responde las siguientes cuestiones:

\begin{itemize}
\tightlist
\item
  Calcula las frecuencias relativas de cada resultado.
\item
  Calcula las frecuencias acumuladas de cada resultado.
\item
  ¿Cuál es el promedio de las observaciones?
\item
  ¿Cuál es la mediana?
\item
  ¿Cuál es el tercer cuartil?
\item
  ¿Cuál es el primer cuartil?
\end{itemize}

\hypertarget{ejercicio-2}{%
\subsubsection{Ejercicio 2}\label{ejercicio-2}}

Hemos realizado un experimento 10 veces con los siguientes resultados

\begin{verbatim}
##  [1] 2.875775 7.883051 4.089769 8.830174 9.404673 0.455565 5.281055 8.924190
##  [9] 5.514350 4.566147
\end{verbatim}

Considera 10 bins de tamaño 1: {[}0,1{]}, (1,2{]}\ldots(9,10).

Responde las siguientes cuestiones:

\begin{itemize}
\item
  Calcula las frecuencias relativas de cada resultado y dibuja el histograma
\item
  Calcula las frecuencias acumulativas de cada resultado y dibuja la gráfica acumulativa.
\item
  Dibuja un diagrama de caja .
\end{itemize}

\hypertarget{probabilidad}{%
\chapter{Probabilidad}\label{probabilidad}}

En este capítulo introduciremos el concepto de probabilidad a partir de frecuencias relativas.

Definiremos los eventos como los elementos sobre los que se aplica la probabilidad. Los eventos compuestos se definirán usando álgebra de conjuntos.

Luego discutiremos el concepto de probabilidad condicional derivado de la probabilidad conjunta de dos eventos.

\hypertarget{experimentos-aleatorios-1}{%
\section{Experimentos aleatorios}\label{experimentos-aleatorios-1}}

Recordemos el objetivo básico de la estadística. La estadística se ocupa de los datos que se presentan en forma de observaciones.

\begin{itemize}
\tightlist
\item
  Una \textbf{observación} es la adquisición de un número o una característica de un experimento
\end{itemize}

Las observaciones son realizaciones de \textbf{resultados}.

\begin{itemize}
\tightlist
\item
  Un \textbf{resultado} es una posible observación que es el resultado de un experimento.
\end{itemize}

Al realizar experimentos, a menudo obtenemos resultados diferentes. La descripción de la variabilidad de los resultados es uno de los objetivos de la estadística.

\begin{itemize}
\tightlist
\item
  Un \textbf{experimento aleatorio} es un experimento que da diferentes resultados cuando se repite de la misma manera.
\end{itemize}

La pregunta filosófica detrás es ¿Cómo podemos conocer algo si cada vez que lo miramos cambia?

\hypertarget{probabilidad-de-mediciuxf3n}{%
\section{Probabilidad de medición}\label{probabilidad-de-mediciuxf3n}}

Nos gustaría tener una medida para el resultado de un experimento aleatorio que nos diga \textbf{cuán seguros} estamos de observar el resultado cuando realicemos un \textbf{futuro} experimento aleatorio.

Llamaremos a esta medida la probabilidad del resultado y le asignaremos valores:

\begin{itemize}
\item
  0, cuando estamos seguros de que la observación \textbf{no} ocurrirá.
\item
  1, cuando estamos seguros de que la observación sucederá.
\end{itemize}

\hypertarget{probabilidad-cluxe1sica}{%
\section{Probabilidad clásica}\label{probabilidad-cluxe1sica}}

\textbf{Siempre que} un experimento aleatorio tenga \(M\) resultados posibles que son todos \textbf{igualmente probables}, la probabilidad de cada resultado \(i\) es \[P_i=\frac{1}{M}\].

La probabilidad clásica fue defendida por Laplace (1814).

Dado que cada resultado es \textbf{igualmente probable} en este tipo de experimento, declaramos una completa ignorancia y lo mejor que podemos hacer es distribuir equitativamente la misma probabilidad para cada resultado.

\begin{itemize}
\tightlist
\item
  No observamos \(P_i\)
\item
  Deducimos \(P_i\) de nuestra razón y no necesitamos realizar ningún experimento para conocerla.
\end{itemize}

\textbf{Ejemplo (dado):}

¿Cuál es la probabilidad de que obtengamos \(2\) en el lanzamiento de un dado?

\(P_2=1/6=0.166666\).

\hypertarget{frecuencias-relativas-1}{%
\section{Frecuencias relativas}\label{frecuencias-relativas-1}}

¿Qué sucede con los experimentos aleatorios cuyos posibles resultados \textbf{no} son igualmente probables?

¿Cómo podemos entonces definir las probabilidades de los resultados?

\textbf{Ejemplo (experimento aleatorio)}

Imaginemos que repetimos un experimento aleatorio \(8\) veces y obtenemos las siguientes observaciones

8 4 12 7 10 7 9 12

\begin{itemize}
\tightlist
\item
  ¿Qué tan seguro estamos de obtener el resultado \(12\) en la siguiente observación?
\end{itemize}

La tabla de frecuencias es

\begin{verbatim}
##   outcome ni    fi
## 1       4  1 0.125
## 2       7  2 0.250
## 3       8  1 0.125
## 4       9  1 0.125
## 5      10  1 0.125
## 6      12  2 0.250
\end{verbatim}

\includegraphics{_main_files/figure-latex/unnamed-chunk-28-1.pdf}
La \textbf{frecuencia relativa} \(f_i=\frac{n_i}{N}\) parece una medida de probabilidad razonable porque

\begin{itemize}
\tightlist
\item
  es un número entre \(0\) y \(1\).
\item
  mide la proporción del total de observaciones que observamos de un resultado particular.
\end{itemize}

Como \(f_{12}=0.25\) entonces estaríamos un cuarto seguros, una de cada 4 observaciones, de obtener \(12\).

\textbf{Pregunta}: ¿Qué tan bueno es \(f_i\) como medida de certeza del resultado \(i\)?

\textbf{Ejemplo (experimento aleatorio con mas repeticiones)}

Digamos que repetimos el experimento 100000 veces más:

La tabla de frecuencias es ahora

\begin{verbatim}
##    outcome    ni      fi
## 1        2  2807 0.02807
## 2        3  5607 0.05607
## 3        4  8435 0.08435
## 4        5 11070 0.11070
## 5        6 13940 0.13940
## 6        7 16613 0.16613
## 7        8 13806 0.13806
## 8        9 10962 0.10962
## 9       10  8402 0.08402
## 10      11  5581 0.05581
## 11      12  2777 0.02777
\end{verbatim}

y el gráfico de barras es

\includegraphics{_main_files/figure-latex/unnamed-chunk-30-1.pdf}

Aparecieron nuevos resultados y \(f_{12}\) ahora es solo \(0.027\), y entonces estamos sólo un \(\sim 3\%\) seguros de obtener \(12\) en el próximo experimento. Las probabilidades medidas por \(f_i\) cambian con \(N\).

\hypertarget{frecuencias-relativas-en-el-infinito}{%
\section{Frecuencias relativas en el infinito}\label{frecuencias-relativas-en-el-infinito}}

Una observación crucial es que si medimos las probabilidades de \(f_i\) en valores crecientes de \(N\) ¡\textbf{convergen}!

En este gráfico cada sección vertical da la frecuencia relativa de cada observación. Vemos que después de \(N=1000\) (\(log10(N)=3\)) las proporciones apenas varían con mas \(N\).

\includegraphics{_main_files/figure-latex/unnamed-chunk-31-1.pdf}
Encontramos que cada una de las frecuencias relativas \(f_i\) converge a un valor constante

\[lim_{N\rightarrow \infty} f_i = P_i\]

\hypertarget{probabilidad-frecuentista}{%
\section{Probabilidad frecuentista}\label{probabilidad-frecuentista}}

Llamamos \textbf{Probabilidad} \(P_i\) al límite cuando \(N \rightarrow \infty\) de la \textbf{frecuencia relativa} de observar el resultado \(i\) en un experimento aleatorio.

Defendida por Venn (1876), la definición frecuentista de probabilidad se deriva de datos/experiencia (empírica).

\begin{itemize}
\tightlist
\item
  No observamos \(P_i\), observamos \(f_i\)
\item
  \textbf{Estimamos} \(P_i\) con \(f_i\) (normalmente cuando \(N\) es grande), escribimos: \[\hat{P_i}=f_i\]
\end{itemize}

Similar a la relación entre \textbf{observación} y \textbf{resultado}, tenemos la relación entre \textbf{frecuencia relativa} y \textbf{probabilidad} como un valor concreto de una cantidad abstracta.

\hypertarget{probabilidades-cluxe1sicas-y-frecuentistas}{%
\section{Probabilidades clásicas y frecuentistas}\label{probabilidades-cluxe1sicas-y-frecuentistas}}

Tenemos situaciones en las que se puede usar la probabilidad clásica para encontrar el límite de frecuencias relativas.

\begin{itemize}
\tightlist
\item
  Si los resultados son \textbf{igualmente probables}, la probabilidad clásica nos da el límite:
\end{itemize}

\[P_i=lim_{N\rightarrow \infty} \frac{n_i}{N}=\frac{1}{M}\]

\begin{itemize}
\tightlist
\item
  Si los resultados en los que estamos interesados pueden derivarse de otros resultados \textbf{igualmente probables}; Veremos más sobre esto cuando estudiemos los modelos de probabilidad.
\end{itemize}

\textbf{Ejemplo (suma de dos dados)}

Nuestro ejemplo anterior se basa en la \textbf{suma de dos dados}.
Si bien realizamos el experimento muchas veces, anotamos los resultados y calculamos las \textbf{frecuencias relativas}, podemos conocer el valor exacto de probabilidad.

Esta probabilidad \textbf{se deduce} del hecho de que el resultado de cada dado es \textbf{igualmente probable}. A partir de esta suposición, podemos encontrar que (Ejercicio 1)

\[
    P_i= 
\begin{cases}
   \frac{i-1}{36},& i \in \{2,3,4,5,6, 7\} \\
\frac{13-i}{36},& i \in \{8,9,10,11,12\} \\ 
\end{cases}
\]

La motivación de la definición frecuentista es \textbf{empírica} (datos) mientras que la de la definición clásica es \textbf{racional} (modelos). A menudo combinamos ambos enfoques (inferencia y deducción) para conocer las probabilidades de nuestro experimento aleatorio.

\includegraphics{./figures/prob.JPG}

\hypertarget{definiciuxf3n-de-probabilidad}{%
\section{Definición de probabilidad}\label{definiciuxf3n-de-probabilidad}}

Una probabilidad es un número que se asigna a cada resultado posible de un experimento aleatorio y satisface las siguientes propiedades o \textbf{axiomas}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  cuando los resultados \(E_1\) y \(E_2\) son mutuamente excluyentes; es decir, solo uno de ellos puede ocurrir, entonces la probabilidad de observar \(E_1\) \textbf{o} \(E_1\), escrito como \(E_1\cup E_2\), es su suma:
  \[P(E_1\cup E_2) = P(E_1) + P(E_2)\]
\item
  cuando \(S\) es el conjunto de todos los resultados posibles, entonces su probabilidad es \(1\) (al menos se observa algo): \[P(S)=1\]
\item
  La probabilidad de cualquier resultado está entre 0 y 1 \[P(E) \in [0,1]\]
\end{enumerate}

Propuesto por Kolmogorov's hace menos de 100 años (1933)

\hypertarget{tabla-de-probabilidades}{%
\section{Tabla de probabilidades}\label{tabla-de-probabilidades}}

Las propiedades de Kolmogorov son las reglas básicas para construir una \textbf{tabla de probabilidad}, de manera similar a la tabla de frecuencia relativa.

\textbf{Ejemplo (Dado)}

La tabla de probabilidad para el lanzamiento de un dado

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
resultado & Probabilidad \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(1\) & 1/6 \\
\(2\) & 1/6 \\
\(3\) & 1/6 \\
\(4\) & 1/6 \\
\(5\) & 1/6 \\
\(6\) & 1/6 \\
\(P(1 \cup 2\cup ... \cup 6)\) & 1 \\
\end{longtable}

Verifiquemos los axiomas:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  Donde \(1 \cup 2\) es, por ejemplo, el \textbf{evento} de lanzar un \(1\) \textbf{o} un \(2\). Entonces \[P(1 \cup 2)=P(1)+P(2)=2/6\]
\item
  Como \(S=\{1,2,3,4,5,6\}\) se compone de resultados \textbf{mutuamente excluyentes}, entonces
\end{enumerate}

\[P(S)=P(1\cup 2\cup ... \cup 6) = P(1)+P(2)+ ...+P(n)=1\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Las probabilidades de cada uno de resultados están entre \(0\) y \(1\).
\end{enumerate}

\hypertarget{espacio-muestral}{%
\section{Espacio muestral}\label{espacio-muestral}}

El conjunto de todos los resultados posibles de un experimento aleatorio se denomina \textbf{espacio muestral} y se denota como \(S\).

El espacio muestral puede estar formado por resultados categóricos o numéricos.

\emph{Por ejemplo:}

\begin{itemize}
\tightlist
\item
  temperatura humana: \(S = (36, 42)\) grados Celsius.
\item
  niveles de azúcar en humanos: \(S=(70-80) mg/dL\)
\item
  el tamaño de un tornillo de una línea de producción: \(S=(70-72) mm\)
\item
  número de correos electrónicos recibidos en una hora: \(S =\{1, ...\infty \}\)
\item
  el lanzamiento de un dado: \(S=\{1, 2, 3, 4, 5, 6\}\)
\end{itemize}

\hypertarget{eventos}{%
\section{Eventos}\label{eventos}}

Un \textbf{evento} \(A\) es un \textbf{subconjunto} del espacio muestral. Es una \textbf{colección} de resultados.

\emph{Ejemplos de eventos:}

\begin{itemize}
\tightlist
\item
  El evento de una temperatura saludable: \(A=37-38\) grados Celsius
\item
  El evento de producir un tornillo con un tamaño: \(A=71.5mm\)
\item
  El evento de recibir más de 4 emails en una hora: \(A=\{4, \infty \}\)
\item
  El evento de obtener un número menor o igual a 3 en la tirada de a dice: \(A=\{1,2,3\}\)
\end{itemize}

Un evento se refiere a un posible conjunto de \textbf{resultados}.

\hypertarget{uxe1lgebra-de-eventos}{%
\section{Álgebra de eventos}\label{uxe1lgebra-de-eventos}}

Para dos eventos \(A\) y \(B\), podemos construir los siguientes eventos derivados utilizando las operaciones básicas de conjuntos:

\begin{itemize}
\tightlist
\item
  Complemento \(A'\): el evento de \textbf{no} \(A\)
\item
  Unión \(A \cup B\): el evento de \(A\) \textbf{o} \(B\)
\item
  Intersección \(A \cap B\): el evento de \(A\) \textbf{y} \(B\)
\end{itemize}

\textbf{Ejemplo (dado)}

Lancemos un dado y veamos los eventos (conjunto de resultados):

\begin{itemize}
\tightlist
\item
  un número menor o igual a tres \(A:\{1,2,3\}\)
\item
  un número par \(B:\{2,4,6\}\)
\end{itemize}

Veamos como podemos construir nuevos eventos con las operaciones de conjuntos:

\begin{itemize}
\tightlist
\item
  un número no menor de tres: \(A':\{4,5,6\}\)
\item
  un número menor o igual a tres \textbf{o} par: \(A \cup B: \{1,2,3,4,6\}\)
\item
  un número menor o igual a tres \textbf{y} par \(A \cap B: \{2\}\)
\end{itemize}

\hypertarget{resultados-mutuamente-excluyentes}{%
\section{Resultados mutuamente excluyentes}\label{resultados-mutuamente-excluyentes}}

Los resultados como tirar \(1\) y \(2\) en un dado son eventos que no pueden ocurrir al mismo tiempo. Decimos que son \textbf{mutuamente excluyentes}.

En general, dos eventos denotados como \(E_1\) y \(E_2\) son mutuamente excluyentes cuando

\[E_1\cap E_2=\emptyset\]

\emph{Ejemplos:}

\begin{itemize}
\item
  El resultado de tener una gravedad de misofonía de \(1\) y una gravedad de \(4\).
\item
  Los resultados de obtener \(12\) y \(5\) al sumar el lanzamiento de dos dados.
\end{itemize}

De acuerdo con las propiedades de Kolmogorov, solo los resultados \textbf{mutuamente excluyentes} se pueden organizar en \textbf{tablas de probabilidad}, como en las tablas de frecuencias relativas.

\hypertarget{probabilidades-conjuntas}{%
\section{Probabilidades conjuntas}\label{probabilidades-conjuntas}}

La \textbf{probabilidad conjunta} de \(A\) y \(B\) es la probabilidad de \(A\) y \(B\). Eso es \[P(A \cap B)\] o \(P(A,B)\).

Para escribir probabilidades conjuntas de eventos no mutuamente excluyentes (\(A \cap B \neq \emptyset\)) en una tabla de probabilidad, notamos que siempre podemos descomponer el espacio muestral en conjuntos \textbf{mutuamente excluyentes} que involucran las intersecciones:

\(S=\{A\cap B, A \cap B', A'\cap B, A'\cap B'\}\)

\textbf{Consideremos el diagrama de Ven} para el ejemplo donde \(A\) es el evento que corresponde a sacar número menor o igual que 3 y \(B\) corresponde a un número par:

Las \textbf{marginales} de \(A\) y \(B\) son la probabilidad de \(A\) y la probabilidad de \(B\), respectivamente:

\begin{itemize}
\tightlist
\item
  \(P(A)=P(A\cap B') + P(A \cap B)=2/6+1/6=3/6\)
\item
  \(P(B)=P(A'\cap B) +P(A \cap B)=2/6+1/6=3/6\)
\end{itemize}

Podemos ahora escribir la \textbf{tabla de probabilidad} para las probabilidades conjuntas

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
Resultado & Probabilidad \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\((A \cap B)\) & \(P(A \cap B)=1/6\) \\
\((A\cap B')\) & \(P(A \cap B')=2/6\) \\
\((A' \cap B)\) & \(P(A' \cap B)=2/6\) \\
\((A' \cap B')\) & \(P(A' \cap B')=1/6\) \\
suma & \(1\) \\
\end{longtable}

Cada resultado tiene \(dos\) valores (uno para la característica del tipo \(A\) y otro para el tipo \(B\))

\hypertarget{tabla-de-contingencia}{%
\section{Tabla de contingencia}\label{tabla-de-contingencia}}

La tabla de probabilidad conjunta también se puede escribir en una \textbf{tabla de contingencia}

\begin{longtable}[]{@{}cccc@{}}
\toprule\noalign{}
& \(B\) & \(B'\) & suma \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(A\) & \(P(A \cap B )\) & \(P(A\cap B' )\) & \(P(A)\) \\
\(A'\) & \(P(A'\cap B )\) & \(P(A'\cap B' )\) & \(P(A')\) \\
suma & \(P(B)\) & \(P(B')\) & 1 \\
\end{longtable}

Donde las marginales son las sumas en las márgenes de la tabla, por ejemplo:

\begin{itemize}
\tightlist
\item
  \(P(A)=P(A \cap B') + P(A \cap B)\)
\item
  \(P(B)=P(A' \cap B) +P(A \cap B)\)
\end{itemize}

En nuestro ejemplo, la tabla de contingencia es

\begin{longtable}[]{@{}cccc@{}}
\toprule\noalign{}
& \(B\) & \(B'\) & suma \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(A\) & \(1/6\) & \(2/6\) & \(3/6\) \\
\(A'\) & \(2/6\) & \(1/6\) & \(3/6\) \\
suma & \(3/6\) & \(3/6\) & 1 \\
\end{longtable}

\hypertarget{la-regla-de-la-suma}{%
\section{La regla de la suma:}\label{la-regla-de-la-suma}}

La regla de la suma nos permite calcular la probabilidad de \(A\) o \(B\), \(P(A \cup B)\), en términos de la probabilidad de \(A\) y \(B\), \(P(A \cap B)\). Podemos hacer esto de tres maneras equivalentes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  Usando las marginales y la probabilidad conjunta
  \[P(A \cup B)=P(A) + P(B) - P(A\cap B)\]
\item
  Usando solo probabilidades conjuntas
  \[P(A \cup B)=P(A \cap B)+P(A\cap B')+P(A'\cap B)\]
\item
  Usando el complemento de la probabilidad conjunta
  \[P(A \cup B)=1-P(A'\cap B')\]
\end{enumerate}

\textbf{Ejemplo (dado)}

Tomemos los eventos \(A:\{1,2,3\}\), sacar un número menor o igual que \(3\), y \(B:\{2,4,6\}\), sacar un número par en el lanzamiento de un dado.

Por lo tanto:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  \(P(A \cup B)=P(A) + P(B) - P(A\cap B)=3/6+3/6-1/6=5/6\)
\item
  \(P(A \cup B)=P(A \cap B)+P(A\cap B')+P(A'\cap B)=1/6+2/6+2/6=5/6\)
\item
  \(P(A \cup B)=1-P(A'\cap B')= 1-1/6=5/6\)
\end{enumerate}

En la tabla de contingencia \(P(A \cup B)\) corresponde a las casillas en negrita (método 2 arriba), o todas menos el 1/6 de abajo a la derecha (método 3).

\begin{longtable}[]{@{}ccc@{}}
\toprule\noalign{}
& \(B\) & \(B'\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(A\) & \textbf{1/6} & \textbf{2/6} \\
\(A'\) & \textbf{2/6} & \emph{1/6} \\
\end{longtable}

\hypertarget{preguntas-1}{%
\section{Preguntas}\label{preguntas-1}}

Recopilamos la edad y categoría de 100 deportistas en una competición

\begin{longtable}[]{@{}ccc@{}}
\toprule\noalign{}
& \(edad:junior\) & \(edad:senior\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(categoria:1ra\) & \(14\) & \(12\) \\
\(categoria:2a\) & \(21\) & \(18\) \\
\(categoria:3a\) & \(22\) & \(13\) \\
\end{longtable}

\textbf{1)} ¿Cuál es la probabilidad estimada de que un deportista sea de 2ª categoría y senior?

\textbf{\(\qquad\)a:} \(18/100\); \textbf{\(\qquad\)b:} \(18/43\); \textbf{\(\qquad\)c:} \(18\); \textbf{\(\qquad\)d:} \(18/39\)

\textbf{2)} ¿Cuál es la probabilidad estimada de que el atleta no esté en la tercera categoría y sea senior?

\textbf{\(\qquad\)a:} \(35/100\); \textbf{\(\qquad\)b:} \(30/100\); \textbf{\(\qquad\)c:} \(22/100\); \textbf{\(\qquad\)d:} \(13/100\)

\textbf{3)} ¿Cuál es la probabilidad marginal de la tercera categoría?

\textbf{\(\qquad\)a:} \(13/100\); \textbf{\(\qquad\)b:} \(35/100\); \textbf{\(\qquad\)c:} \(22/100\); \textbf{\(\qquad\)d:} \(13/22\)

\textbf{4)} ¿Cuál es la probabilidad marginal de ser senior?

\textbf{\(\qquad\)a:} \(13/100\); \textbf{\(\qquad\)b:} \(43/100\); \textbf{\(\qquad\)c:} \(43/57\); \textbf{\(\qquad\)d:} \(57/100\)

\textbf{5)} ¿Cuál es la probabilidad de ser senior o de tercera categoría?

\textbf{\(\qquad\)a:} \(65/100\); \textbf{\(\qquad\)b:} \(86/100\); \textbf{\(\qquad\)c:} \(78/100\); \textbf{\(\qquad\)d:} \(13/100\)

\hypertarget{ejercicios-1}{%
\section{Ejercicios}\label{ejercicios-1}}

\hypertarget{probabilidad-cluxe1sica-ejercicio-1}{%
\subsubsection{Probabilidad clásica: Ejercicio 1}\label{probabilidad-cluxe1sica-ejercicio-1}}

\begin{itemize}
\item
  Escribe la tabla de \textbf{probabilidad conjunta} para los \textbf{resultados} de lanzar dos dados; en las filas escribe los resultados del primer dado y en las columnas los resultados del segundo dado.
\item
  ¿Cuál es la probabilidad de sacar \((3,4)\)? (R:1/36)
\item
  ¿Cuál es la probabilidad de tirar \(3\) y \(4\) con cualquiera de los dos dados? (R:2/36)
\item
  ¿Cuál es la probabilidad de tirar \(3\) en el primer dado o \(4\) en el segundo? (A:11/36)
\item
  ¿Cuál es la probabilidad de tirar \(3\) o \(4\) con cualquier dado? (R:20/36)
\item
  Escribe la \textbf{tabla de probabilidad} para el resultado de la \textbf{suma} de dos dados. Supon que el resultado de cada dado es \textbf{igualmente probable}. Verifica que es:
\end{itemize}

\[
    P_i= 
\begin{cases}
   \frac{i-1}{36},& i \in \{2,3,4,5,6, 7\} \\
\frac{13-i}{36},& i \in \{8,9,10,11,12\} \\ 
\end{cases}
\]

\hypertarget{probabilidad-frecuentista-ejercicio-2}{%
\subsubsection{Probabilidad frecuentista: Ejercicio 2}\label{probabilidad-frecuentista-ejercicio-2}}

El resultado de un experimento aleatorio es medir la gravedad de la misofonía \textbf{y} el estado de depresión de un paciente.

\begin{itemize}
\tightlist
\item
  Gravedad de la misofonía: \(S_M:\{M_0,M_1,M_2,M_3,M_4\}\)
\item
  Depresión: \(S_D:\{D', D\}\))
\end{itemize}

Escribe la tabla de contingencia para las frecuencias absolutas (\(n_{M,D}\)) para un estudio sobre un total de 123 pacientes en el que se observó

\begin{itemize}
\tightlist
\item
  100 individuos no tuvieron depresión.
\item
  Ningún individuo con misofonía 4 y sin depresión.
\item
  5 individuos con misofonía de grado 1 y sin depresión.
\item
  El mismo número que el caso anterior para individuos con depresión y sin misofonía.
\item
  25 individuos sin depresión y grado 3 de misofonía.
\item
  El número de misofónicos sin depresión para los grados 2 y 0 se repartieron a cantiaddes iguales.
\item
  El número de individuos con depresión y misofonía incrementó progresivamente
  en múltiplos de tres, empezando en 0 individuos para grado 1.
\end{itemize}

Reponde las siguientes preguntas:

\begin{itemize}
\tightlist
\item
  ¿Cuantos individuos tuvieron misofonía? (R:83)
\item
  ¿Cuantos individuos tuvieron misofonía de grado 3? (R:31)
\item
  ¿Cuantos individuos tuvieron misofonía de grado 2 sin depresión? (R:35)
\end{itemize}

Escribe las tabla de consingencia para frecuencias relativas \(f_{M,D}\). Supongamos que \(N\) es grande y que las frecuencias absolutas \textbf{estiman} las probabilidades \(f_{M,D}=\hat{P}(M \cap D)\). Responde las siguientes preguntas:

\begin{itemize}
\tightlist
\item
  ¿Cuál es la probabilidad marginal de misofonía de gravedad 2? (R: 0.3)
\item
  ¿Cuál es la probabilidad de no ser misofónico \textbf{y} no estar deprimido? (R:0.284)
\item
  ¿Cuál es la probabilidad de ser misofónico \textbf{o} estar deprimido? (R: 0.715)
\item
  ¿Cuál es la probabilidad de ser misofónico \textbf{y} estar deprimido? (R: 0.146)
\item
  Describir en lenguaje hablado los resultados con probabilidad 0.
\end{itemize}

\hypertarget{ejercicio-3}{%
\subsubsection{Ejercicio 3}\label{ejercicio-3}}

Hemos realizado un experimento aleatorio \(10\) veces, que consiste en anotar el sexo y el estado vital de pacientes con algún tipo de cáncer después de 10 años del diagnóstico. Obtuvimos los siguientes resultados

\begin{verbatim}
##         A     B
## 1    male  dead
## 2    male  dead
## 3    male  dead
## 4  female alive
## 5    male  dead
## 6  female alive
## 7  female  dead
## 8  female alive
## 9    male alive
## 10   male alive
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Crea la tabla de contingencia para el número (\(n_{i,j}\)) de observaciones de cada resultado (\(A,B\))
\item
  Crea la tabla de contingencia para la frecuencia relativa (\(f_{i,j}\)) de los resultados
\item
  ¿Cuál es la frecuencia marginal de ser hombre? (R/0.6)
\item
  ¿Cuál es la frecuencia marginal de estar vivo? (R/0.5)
\item
  ¿Cuál es la frecuencia de estar vivo \textbf{o} ser mujer? (R/0.6)
\end{itemize}

\hypertarget{teoruxeda-ejercicio-4}{%
\subsubsection{Teoría: Ejercicio 4}\label{teoruxeda-ejercicio-4}}

\begin{itemize}
\item
  De la segunda forma de la regla de la suma, obtener la primera y la tercera forma.
\item
  ¿Cuál es la regla de la suma de la tercera forma para la probabilidad de tres eventos \(P(A \cup B \cup C)\)?
\end{itemize}

\hypertarget{probabilidad-condicional}{%
\chapter{Probabilidad condicional}\label{probabilidad-condicional}}

En este capítulo, introduciremos la probabilidad condicional.

Usaremos la probabilidad condicional para definir la independencia estadística.

Discutiremos el teorema de Bayes y discutiremos una de sus principales aplicaciones, que es la eficacia de predicción de una herramienta de diagnóstico.

\hypertarget{probabilidad-conjunta}{%
\section{Probabilidad conjunta}\label{probabilidad-conjunta}}

Recordemos que la probabilidad conjunta de dos eventos \(A\) y \(B\) se define como su intersección

\[P( A,B )=P(A \cap B)\]

Ahora, imagina experimentos aleatorios que miden dos tipos diferentes de resultados.

\begin{itemize}
\item
  altura y peso de un individuo: \((h, w)\)
\item
  tiempo y posición de una carga eléctrica: \((p, t)\)
\item
  el lanzamiento de dos dados: (\(n_1\),\(n_2\))
\item
  cruzar dos semáforos en verde: (\(\bar{R_ 1}\) , \(\bar{R_2}\))
\end{itemize}

A menudo nos interesa saber si los valores de un resultado \textbf{condicionan} los valores del otro.

\hypertarget{independencia-estaduxedstica}{%
\section{Independencia estadística}\label{independencia-estaduxedstica}}

En muchos casos, estamos interesados en saber si dos eventos a menudo tienden a ocurrir juntos. Queremos poder discernir entre dos casos.

\begin{itemize}
\item
  \textbf{Independencia} entre eventos. Por ejemplo, sacar un 1 en un dado no hace más probable sacar otro 1 en un segundo dado.
\item
  \textbf{Correlación} entre eventos. Por ejemplo, si un hombre es alto, probablemente sea pesado.
\end{itemize}

\textbf{Ejemplo (conductor)}

Realizamos un experimento para averiguar si observar fallas estructurales en un material afecta su conductividad.

Los datos se verían como

\begin{longtable}[]{@{}ccc@{}}
\toprule\noalign{}
Conductor & Estructura & Conductividad \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(c_1\) & con fallas & defectuosa \\
\(c_2\) & sin fallas & sin defectos \\
\(c_3\) & con fallas & defectuosa \\
\ldots{} & \ldots{} & \ldots{} \\
\(c_i\) & sin fallas & defectuosa* \\
\ldots{} & \ldots{} & \ldots{} \\
\ldots{} & \ldots{} & \ldots{} \\
\(c_n\) & con fallas & sin defectos* \\
\end{longtable}

Podemos esperar que la conductividad defectuosa ocurra más a menudo con fallas que sin fallas si las fallas afectan la conductividad.

Imaginemos que a partir de los datos obtenemos la siguiente tabla de contingencia de \textbf{probabilidades conjuntas} estimadas

\begin{longtable}[]{@{}cccc@{}}
\toprule\noalign{}
& con fallas (F) & sin fallas (F') & suma \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
defectuoso (D) & \(0.005\) & \(0.045\) & \(0.05\) \\
sin defectos (D') & \(0.095\) & \(0.855\) & \(0.95\) \\
suma & \(0.1\) & \(0.9\) & 1 \\
\end{longtable}

donde, por ejemplo, la probabilidad conjunta de \(F\) y \(D\) es

\begin{itemize}
\tightlist
\item
  \(P(D,F)=0.005\)
\end{itemize}

y las probabilidades marginales son

\begin{itemize}
\tightlist
\item
  \(P(D)=P(D, F) + P(D, F')=0.05\)
\item
  \(P(F)=P(D, F) + P(D', F)= 0.1\).
\end{itemize}

\hypertarget{la-probabilidad-condicional}{%
\section{La probabilidad condicional}\label{la-probabilidad-condicional}}

La conductividad defectuosa es \textbf{independiente} de tener fallas estructurales en el material si la probabilidad de tener conductividad defectuosa (\(D\)) es la misma \textbf{ya sea} que tenga fallas (\(F\)) o no (\(F'\)) .

Consideremos primero solamente los materiales que tienen fallas.

Dentro de aquellos materiales que tienen fallas (\(F\)), ¿cuál es la probabilidad estimada de que sean defectuosos?

\(\hat{P}(D|F)=\frac{n_{F,D}}{n_{F}}=\frac{n_{F,D}/n}{n_{F}/n}= \frac{f_{F,D}}{f_{F}}\)
\[= \frac{\hat{P}(F,D)}{\hat{P}(F)}\]
Por lo tanto, en el límite cuando \(N \rightarrow \infty\), tenemos

\[P(D|F)=\frac{P(F, D)}{P(D)}=\frac{P(F \cap D)}{P(D)}\]
\textbf{Definición:}

La \emph{probabilidad condicional} de un evento \(B\) dado un evento \(A\), indicado como \(P(A|B)\), es
\[P(A|B) = \frac{P(A\cap B)}{P(B)}\]
Podemos probar que la probabilidad condicional satisface los axiomas de probabilidad. La probabilidad condicional se puede entender como una probabilidad con un espacio muestral dado por \(B\): \(S_B\). En nuestro ejemplo, los materiales con fallas.

\hypertarget{tabla-de-contingencia-condicional}{%
\section{Tabla de contingencia condicional}\label{tabla-de-contingencia-condicional}}

Si dividimos las columnas de la tabla de probabilidad conjunta por las probabilidades marginales de los efectos condicionantes (\(F\) y \(F'\)), podemos escribir \textbf{una tabla de contingencia condicional}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3438}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3438}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3125}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
F
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
F'
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
D & P(D {\textbar{}} F) & P(D {\textbar{}} F') \\
D' & P(D' {\textbar{}} F) & P(D' {\textbar{}} F') \\
suma & 1 & 1 \\
\end{longtable}

Donde las probabilidades por columnas suman uno. La primera columna muestra las probabilidades de ser defectuoso o no solo de que los materiales que tienen fallas (primera condición: \(F\)). La segunda columna muestra las probabilidades solo para los materiales que no tienen fallas (segunda condición: \(F'\)).

Las probabilidades condicionales son las probabilidades del evento dentro de cada condición. Las leemos como:

\begin{itemize}
\item
  \(P(D|F)\): Probabilidad de tener conductividad defectuosa \textbf{si} tiene fallas
\item
  \(P(D'|F)\): Probabilidad de no tener conductividad defectuosa \textbf{si} tiene fallas
\item
  \(P(D|F')\): Probabilidad de tener conductividad defectuosa \textbf{si} no tiene fallas
\item
  \(P(D'|F')\) Probabilidad de no tener conductividad defectuosa \textbf{si} no tiene fallas
\end{itemize}

\hypertarget{independencia-estaduxedstica-1}{%
\section{Independencia estadística}\label{independencia-estaduxedstica-1}}

En nuestro ejemplo, la tabla de contingencia condicional es

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3438}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3438}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3125}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
F
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
F'
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
D & P(D{\textbar{}}F) = 0.05 & P(D{\textbar{}}F')=0.05 \\
D' & P(D'{\textbar{}}F)=0.95 & P(D'{\textbar{}}F')=0.95 \\
suma & 1 & 1 \\
\end{longtable}

¡Observamos que las probabilidades marginales y condicionales son las mismas!

\begin{itemize}
\tightlist
\item
  \(P(D|F)=P(D|F')=P(D)\)
\item
  \(P(D'|F)=P(D'|F')=P(D')\)
\end{itemize}

Esto quiere decir que la probabilidad de observar un conductor defectuoso \textbf{no} depende tener una falla estructural o no.

Concluimos que la conductividad defectuosa no se ve afectada por tener una falla estructural.

\textbf{Definición}

Dos eventos \(A\) y \(B\) son estadísticamente independientes si ocurre cualquiera de los casos equivalentes

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  \(P(A|B)=P(A)\); \(A\) es independiente de \(B\)
\item
  \(P(B|A)=P(B)\); \(B\) es independiente de \(A\)
\end{enumerate}

y por la definición de probabilidad condicional

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  \(P(A\cap B)=P(A|B)P(B)=P(A)P(B)\)
\end{enumerate}

Esta tercera forma es un enunciado sobre las probabilidades conjuntas. Dice que podemos obtener probabilidades conjuntas por la multiplicación de las marginales.

En nuestra tabla de probabilidad conjunta original

\begin{longtable}[]{@{}cccc@{}}
\toprule\noalign{}
& F & F' & suma \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
D & \(0.005\) & \(0.045\) & \(0.05\) \\
D' & \(0.095\) & \(0.855\) & \(0.95\) \\
suma & \(0.1\) & \(0.9\) & 1 \\
\end{longtable}

podemos confirmar que todas las entradas de la matriz son el producto de las marginales. Por ejemplo: \(P(F)P(D)= P(D \cap F)\) y \(P(D')P(F')=P(D' \cap F')\). Por lo tanto, ser defectuoso es independiente de tener un defecto.

\textbf{Ejemplo (Monedas)}

Queremos confirmar que los resultados de lanzar dos monedas son independientes. Consideramos que todos los resultados son igualmente probables:

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
resultado & Probabilidad \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\((H,T)\) & 1/4 \\
\((H,H)\) & 1/4 \\
\((T,T)\) & 1/4 \\
\((T,H)\) & 1/4 \\
suma & 1 \\
\end{longtable}

donde \((H,T)\) es, por ejemplo, el evento de cara en la primera moneda y cruz en la segunda moneda. La tabla de contingencia para las probabilidades conjuntas es:

\begin{longtable}[]{@{}cccc@{}}
\toprule\noalign{}
& H & T & suma \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
H & \(1/4\) & \(1/4\) & \(1/2\) \\
T & \(1/4\) & \(1/4\) & \(1/2\) \\
suma & \(1/2\) & \(1/2\) & 1 \\
\end{longtable}

De esta tabla vemos que la probabilidad de obtener una cara y luego una cruz es el producto de las marginales \(P(H, T)=P(H)*P(T)=1/4\). Por lo tanto, el evento de cara en la primera moneda y cruz en la segunda son independientes.

Si elaboramos la tabla de contingencia condicional sobre el lanzamiento de la primera moneda veremos que obtener cruz en la segunda moneda no está condicionado por haber obtenido cara en la primera moneda: \(P(T|H)=P(T) =1/2\)

\hypertarget{dependencia-estaduxedstica}{%
\section{Dependencia estadística}\label{dependencia-estaduxedstica}}

Un ejemplo importante de dependencia estadística se encuentra en el desempeño de \textbf{herramientas de diagnóstico}, donde queremos determinar el estado de un sistema (s) con resultados

\begin{itemize}
\tightlist
\item
  inadecuado (si)
\item
  adecuado (no)
\end{itemize}

con una prueba (t) con resultados

\begin{itemize}
\tightlist
\item
  positivo
\item
  negativo
\end{itemize}

Por ejemplo, probamos una batería para saber cuánto tiempo puede durar. Tensamos un cable para saber si resiste llevar cierta carga. Realizamos una PCR para ver si alguien está infectado.

\hypertarget{prueba-de-diagnuxf3stico}{%
\section{Prueba de diagnóstico}\label{prueba-de-diagnuxf3stico}}

Consideremos diagnosticar una infección con una nueva prueba. Estado de infección:

\begin{itemize}
\tightlist
\item
  si (infectado)
\item
  no (no infectado)
\end{itemize}

Prueba:

\begin{itemize}
\tightlist
\item
  positivo
\item
  negativo
\end{itemize}

La \textbf{tabla de contingencia condicional} es lo que obtenemos en un ambiente controlado (laboratorio)

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3438}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3438}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3125}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Infección: si
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Infección: No
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Test: positivo & P(positivo {\textbar{}} si) & P(positivo {\textbar{}} no) \\
Test: negativo & P(negativo {\textbar{}} si) & P(negativo {\textbar{}} no) \\
suma & 1 & 1 \\
\end{longtable}

Miremos las entradas de la tabla
1) Tasa de verdaderos positivos (Sensibilidad): La probabilidad de dar positivo \textbf{si} tiene la enfermedad \(P(positivo|si)\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\item
  Tasa de verdaderos negativos (Especificidad): La probabilidad de dar negativo \textbf{si} no tiene la enfermedad \(P(negativo|no)\)
\item
  Tasa de falsos positivos: la probabilidad de dar positivo \textbf{si} no tiene la enfermedad \(P(positivo|no)\)
\item
  Tasa de falsos negativos: la probabilidad de dar negativo \textbf{si} tiene la enfermedad \(P(negativo|si)\)
\end{enumerate}

Alta correlación (dependencia estadística) entre la prueba y la infección significa valores altos de las probabilidades 1 y 2 \textbf{y} valores bajos para las probabilidades 3 y 4.

\textbf{Ejemplo (COVID)}

Ahora consideremos una situación real. En los días iniciales de la pandemia de coronavirus no había una medida de la eficacia de las PCR para detectar el virus. Uno de los primeros estudios publicados (\url{https://www.nejm.org/doi/full/10.1056/NEJMp2015897}) encontró que

\begin{itemize}
\tightlist
\item
  Las PCR tuvieron una sensibilidad del 70\%, en condición de infección.
\item
  Las PCR tuvieron una especificidad del 94\%, en condición de no infección.
\end{itemize}

La tabla de contingencia condicional es

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3438}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3438}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3125}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Infección: si
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Infección: No
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Test: positivo & P(positivo{\textbar{}}si)=0.7 & P(positivo{\textbar{}}no)=0.06 \\
Test: negativo & P(negativo{\textbar{}}si)=0.3 & P(negativo{\textbar{}}no)=0.94 \\
suma & 1 & 1 \\
\end{longtable}

Por lo tanto, los errores en las pruebas de diagnóstico fueron:

\begin{itemize}
\tightlist
\item
  La tasa de falsos positivos es \(P(positivo|no)=0.06\)
\item
  La tasa de falsos negativos es \(P(negativo|si)=0.3\)
\end{itemize}

\hypertarget{probabilidades-inversas}{%
\section{Probabilidades inversas}\label{probabilidades-inversas}}

Nos interesa encontrar la probabilidad de estar infectado si la prueba da positivo: \[P(si|positivo)\]

Para eso:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Recuperamos la tabla de contingencia para probabilidades conjuntas, multiplicando por las marginales
\end{enumerate}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2619}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2619}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2381}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2381}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Infección: si
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Infección: No
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
suma
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Test: positivo & P(positivo {\textbar{}} si)P(si) & P(positivo {\textbar{}} no)P(no) & P(positivo) \\
Test: negativo & P(negativo {\textbar{}} si)P(si) & P(negativo {\textbar{}} no) P(no) & P(negativo) \\
suma & P(si) & P(no) & 1 \\
\end{longtable}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Usamos la definición de probabilidades condicionales para filas en lugar de columnas (dividimos por la marginal de los resultados de la prueba)
\end{enumerate}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2619}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2619}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2381}}
  >{\centering\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2381}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Infección: si
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
Infección: No
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
suma
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Test: positivo & P(si{\textbar{}}positivo) & P(sin{\textbar{}}positivo) & 1 \\
Test: negativo & P(si{\textbar{}}negativo) & P(sin{\textbar{}}negativo) & 1 \\
\end{longtable}

Por ejemplo:

\[P(si|positivo)=\frac{P(positivo|si)P(si)}{P(positivo)}\]

Para aplicar esta fórmula necesitamos las marginales \(P(si)\) (incidencia) y \(P(positivo)\).

\begin{itemize}
\item
  Para encontrar \(P(si)\), necesitamos un nuevo estudio: el primer estudio de prevalencia en España mostró que durante el confinamiento \(P(si)=0.05\), \(P(no)=0.95\), antes del verano de 2020.
\item
  Para encontrar \(P(positivo)\), podemos usar la definición de probabilidad marginal y condicional:
\end{itemize}

\(P(positivo)=P(positivo \cap si) + P(positivo \cap no)\)
\[= P(positivo|si)P(si)+P(positivo|no)P(no)\]
Esta última relación de las marginales se llama \textbf{regla de probabilidad total}.

\hypertarget{teorema-de-bayes}{%
\section{Teorema de Bayes}\label{teorema-de-bayes}}

Después de sustituir la regla de probabilidad total en \(P(si|positivo)\), tenemos

\[P(si|positivo)=\frac{P(positivo|si)P(si)}{P(positivo|si)P(si)+P(positivo|no)P(no)}\]
Esta expresión se conoce como \textbf{teorema de Bayes}. Nos permite invertir los condicionales:

\[P(positivo|si) \rightarrow P(si|positivo)\]
O \textbf{evaluar} una prueba en una condición controlada (infección) y luego usarla para \textbf{inferir} la probabilidad de la condición cuando la prueba es positiva.

\textbf{Ejemplo (COVID)}:

El rendimiento de la prueba fue:

\begin{itemize}
\item
  Sensibilidad: \(P(positivo|si)=0.70\)
\item
  Tasa de falsos positivos: \(P(positivo|no)=1- P(negativo|no)=0.06\)
\end{itemize}

El estudio en población española dio:

\begin{itemize}
\tightlist
\item
  \(P(si)=0.05\)
\item
  \(P(no)=1-P(si)=0.95\).
\end{itemize}

Por lo tanto, la probabilidad de estar infectado en caso de dar positivo era:

\[P(si|positivo)=0.38\]

Concluimos que en ese momento las PCR no eran muy buenas para \textbf{confirmar} infecciones.

Sin embargo, apliquemos ahora el teorema de Bayes a la probabilidad de no estar infectado si la prueba fue negativa.

\[P(no|negativo) = \frac{P(negativo|no) P(no)}{P(negativo|no) P(no)+P(negativo|si)P(si)}\]

La sustitución de todos los valores da

\[P(no|negativo)=0.98\]

Por lo tanto, las pruebas eran buenas para \textbf{descartar} infecciones y un requisito justo para viajar.

\textbf{Teorema de Bayes}

En general, podemos tener más de dos eventos condicionantes. Por lo tanto, el teorema de Baye dice:

Si \(E1, E2, ..., Ek\) son \(k\) eventos mutuamente excluyentes y exhaustivos y \(B\) es cualquier evento, entonces la probabilidad inversa \(P(Ei|B)\) es

\[P(Ei|B)=\frac{P(B|Ei)P(Ei)}{P(B|E1)P(E1) +...+ P(B|Ek)P(Ek)} \]
El denominador es la regla de probabilidad total para la marginal \(P(B)\), en términos de las marginales \(P(E1), P(E2), ... P(Ek)\).

\[P(B)=P(B|E1)P(E1) +...+ P(B|Ek)P(Ek)\]

\textbf{Árbol condicional}

La regla de probabilidad total también se puede ilustrar usando un árbol \textbf{condicional}.

\includegraphics{./figures/treetot.PNG}

\textbf{Regla de probabilidad total} para la marginal de \(B\): ¿De cuántas maneras puedo obtener el resultado \(B\)?

\(P(B)=P(B|A)P(A)+P(B|A')P(A')\)

\hypertarget{preguntas-2}{%
\section{Preguntas}\label{preguntas-2}}

Recopilamos la edad y categoría de 100 deportistas en una competición

\begin{longtable}[]{@{}ccc@{}}
\toprule\noalign{}
& \(junior\) & \(senior\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(1er\) & \(14\) & \(12\) \\
\(2do\) & \(21\) & \(18\) \\
\(3er\) & \(22\) & \(13\) \\
\end{longtable}

\textbf{1)} ¿Cuál es la probabilidad estimada de que el atleta esté en la tercera categoría si el atleta es junior?

\textbf{\(\qquad\)a:} \(22\); \textbf{\(\qquad\)b:} \(22/100\); \textbf{\(\qquad\)c:} \(22/57\); \textbf{\(\qquad\)d:} \(22/35\);

\textbf{2)} ¿Cuál es la probabilidad estimada de que el atleta sea junior y esté en 1ra categoría si el atleta no está en 3ra categoría?

\textbf{\(\qquad\)a:} \(14/35\); \textbf{\(\qquad\)b:} \(14/65\); \textbf{\(\qquad\)c:} \(14/100\); \textbf{\(\qquad\)d:} \(14/26\)

\textbf{3)} Una prueba diagnóstica tiene una probabilidad de \(8/9\) de detectar una enfermedad si los pacientes están enfermos y una probabilidad de \(3/9\) de detectar la enfermedad si los pacientes están sanos. Si la probabilidad de estar enfermo es \(1/9\). ¿Cuál es la probabilidad de que un paciente esté enfermo si una prueba detecta la enfermedad?

\textbf{\(\qquad\)a:} \(\frac{8/9}{8/9+3/9}*1/9\); \textbf{\(\qquad\)b:} \(\frac{3/9}{8/9+3/9}*1/9\); \textbf{\(\qquad\)c:} \(\frac{3/9*8/9}{8/9*1/9+3/9*8/9}\); \textbf{\(\qquad\)d:} \(\frac{8/9*1/9}{8/9*1/9+3/9*8/9}\);

\textbf{4)} Como se comenta en las notas, una prueba PCR para coronavirus tenía una sensibilidad del 70 \% y una especificidad del 94 \% y en España durante el confinamiento hubo una incidencia del 5 \%. Con estos datos, ¿cuál era la probabilidad de dar positivo en España (\(P(positivo)\))

\textbf{\(\qquad\)a:} \(0.035\); \textbf{\(\qquad\)b:} \(0.092\); \textbf{\(\qquad\)c:} \(0.908\); \textbf{\(\qquad\)d:} \(0.95\)

\textbf{5)} Con los mismos datos que en la pregunta 4, dar positivo en la PCR y estar infectado no son eventos independientes porque:

\textbf{\(\qquad\)a:} La sensibilidad es del 70\%; \textbf{\(\qquad\)b:} La sensibilidad y la tasa de falsos positivos son diferentes; \textbf{\(\qquad\)c:} La tasa de falsos positivos es del 0.06\%; \textbf{\(\qquad\)d:} la especificidad es del 96\%

\hypertarget{ejercicios-2}{%
\section{Ejercicios}\label{ejercicios-2}}

\hypertarget{ejercicio-1-1}{%
\subsubsection{Ejercicio 1}\label{ejercicio-1-1}}

Se prueba el rendimiento de una máquina para producir varillas de torneado de alta calidad. Estos son los resultados de las pruebas

\begin{longtable}[]{@{}ccc@{}}
\toprule\noalign{}
& Redondeado: si & Redondeado: No \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
superficie lisa: si & 200 & 1 \\
superficie lisa: no & 4 & 2 \\
\end{longtable}

\begin{itemize}
\item
  ¿Cuál es la probabilidad estimada de que la máquina produzca una varilla que no satisfaga ningún control de calidad? (R: 2/207)
\item
  ¿Cuál es la probabilidad estimada de que la máquina produzca una varilla que no satisfaga al menos un control de calidad? (R: 7/207)
\item
  ¿Cuál es la probabilidad estimada de que la máquina produzca varillas de superficie redondeada y alisada? (R: 200/207)
\item
  ¿Cuál es la probabilidad estimada de que la barra sea redondeada si la barra es lisa? (R: 200/201)
\item
  ¿Cuál es la probabilidad estimada de que la varilla sea lisa si es redondeada? (R: 200/204)
\item
  ¿Cuál es la probabilidad estimada de que la varilla no sea ni lisa ni redondeada si no satisface al menos un control de calidad? (R: 2/7)
\item
  ¿Son eventos independientes la lisa y la redondez? (No)
\end{itemize}

\hypertarget{ejercicio-2-1}{%
\subsubsection{Ejercicio 2}\label{ejercicio-2-1}}

Desarrollamos un test para detectar la presencia de bacterias en un lago. Encontramos que si el lago contiene la bacteria, la prueba es positiva el 70\% de las veces. Si no hay bacterias, la prueba es negativa el 60\% de las veces. Implementamos la prueba en una región donde sabemos que el 20\% de los lagos tienen bacterias.

\begin{itemize}
\tightlist
\item
  ¿Cuál es la probabilidad de que un lago que dé positivo esté contaminado con bacterias? (R: 0.30)
\end{itemize}

\hypertarget{ejercicio-3-1}{%
\subsubsection{Ejercicio 3}\label{ejercicio-3-1}}

Se prueba el rendimiento de dos máquinas para producir varillas de torneado de alta calidad. Estos son los resultados de las pruebas

\textbf{Máquina 1}

\begin{longtable}[]{@{}ccc@{}}
\toprule\noalign{}
& Redondeado: si & Redondeado: No \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
superficie lisa: si & 200 & 1 \\
superficie lisa: no & 4 & 2 \\
\end{longtable}

\textbf{Máquina 2}

\begin{longtable}[]{@{}ccc@{}}
\toprule\noalign{}
& Redondeado: si & Redondeado: No \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
superficie lisa: si & 145 & 4 \\
superficie lisa: no & 8 & 6 \\
\end{longtable}

\begin{itemize}
\tightlist
\item
  ¿Cuál es la probabilidad de que la barra sea redondeada? (R: 357/370)
\item
  ¿Cuál es la probabilidad de que la varilla haya sido producida por la máquina 1? (R: 207/370)
\item
  ¿Cuál es la probabilidad de que la varilla no sea lisa? (R: 20/370)
\item
  ¿Cuál es la probabilidad de que la varilla sea lisa o redondeada o producida por la máquina 1? (R: 364/370)
\item
  ¿Cuál es la probabilidad de que la varilla quede redondeada si es alisada y de la máquina 1? (R: 200/201)
\item
  ¿Cuál es la probabilidad de que la varilla no esté redondeada si no está alisada y es de la máquina 2? (R: 6/14)
\item
  ¿Cuál es la probabilidad de que la varilla haya salido de la máquina 1 si está alisada y redondeada? (R: 200/345)
\item
  ¿Cuál es la probabilidad de que la varilla haya venido de la máquina 2 si no pasa al menos uno de los controles de calidad? (R:0.72)
\end{itemize}

\hypertarget{ejercicio-4}{%
\subsubsection{Ejercicio 4}\label{ejercicio-4}}

Queremos cruzar una avenida con dos semáforos. La probabilidad de encontrar el primer semáforo en rojo es 0.6. Si paramos en el primer semáforo, la probabilidad de parar en el segundo es 0.15. Mientras que la probabilidad de detenernos en el segundo si no nos detenemos en el primero es 0.25.

Cuando intentamos cruzar ambos semáforos:

\begin{itemize}
\tightlist
\item
  ¿Cuál es la probabilidad de tener que detenerse en cada semáforo? (R:0.09)
\item
  ¿Cuál es la probabilidad de tener que parar en al menos un semáforo? (R:0.7)
\item
  ¿Cuál es la probabilidad de tener que detenerse en un solo semáforo? (R:0.61)
\item
  Si paré en el segundo semáforo, ¿cuál es la probabilidad de que tuviera que parar en el primero? (R: 0.47)
\item
  Si tuviera que parar en cualquier semáforo, ¿cuál es la probabilidad de que tuviera que hacerlo dos veces? (R: 0.12)
\item
  ¿Parar en el primer semáforo es un evento independiente de detenerse en el segundo semáforo? (No)
\end{itemize}

Ahora, deseamos cruzar una avenida con tres semáforos. La probabilidad de encontrarnos con el primer semáforo en rojo es del 0.6, y la probabilidad de encontrar el segundo semáforo en rojo depende únicamente de la probabilidad del primer semáforo. De manera similar, la probabilidad de encontrar un semáforo en rojo en el tercer semáforo depende solo de las probabilidades del segundo. Como antes, la probabilidad de detenernos en un semáforo es del 0.15 si nos detuvimos en el semáforo anterior. Si no nos detuvimos en el semáforo anterior, la probabilidad de detenernos en el siguiente semáforo es del 0.25.

\begin{itemize}
\tightlist
\item
  ¿Cuál es la probabilidad de tener que parar en cada semáforo? (R:0.013)
\item
  ¿Cuál es la probabilidad de tener que parar en al menos un semáforo? (R:0.775)
\item
  ¿Cuál es la probabilidad de tener que detenerse en un solo semáforo? (R:0.5425)
\end{itemize}

consejos:

\begin{itemize}
\item
  Si la probabilidad de que un semáforo esté en rojo depende únicamente del anterior, entonces
  \(P(R_3|R_2,R_1)=P(R_3|R_2,\bar{R}_1)=P(R_3|R_2)\) y \(P(R_3|\bar{R}_2,R_1)=P(R_3 |\bar{R}_2,\bar{R}_1)=P(R_3|\bar{R}_2)\)
\item
  La probabilidad conjunta de encontrar tres semáforos en rojo se puede escribir como:
  \(P(R_1,R_2,R_3)=P(R_3|R_2)P(R_2|R_1)P(R_1)\)
\end{itemize}

\hypertarget{ejercicio-5}{%
\subsubsection{Ejercicio 5}\label{ejercicio-5}}

Una prueba de calidad en un ladrillo aleatorio se define por los eventos:

\begin{itemize}
\tightlist
\item
  Pasar la prueba de calidad: \(E\), no pasar la prueba de calidad: \(\bar{E}\)
\item
  Defectuoso: \(D\), no defectuoso: \(\bar{D}\)
\end{itemize}

Si la prueba diagnóstica tiene sensibilidad \(P(E|\bar{D})=0.99\) y especificidad \(P(\bar{E}|D)=0.98\), y la probabilidad de pasar la prueba es \(P(E) =0.893\) entonces

\begin{itemize}
\item
  ¿Cuál es la probabilidad de que un ladrillo elegido al azar sea defectuoso \(P(D)\)? (R:0.1)
\item
  ¿Cuál es la probabilidad de que un ladrillo que ha pasado la prueba sea realmente defectuoso? (R:0.022)
\item
  La probabilidad de que un ladrillo no sea defectuoso \textbf{y} que no pase la prueba (R:0.009)
\item
  ¿Son \(D\) y \(\bar{E}\) estadísticamente independientes? (No)
\end{itemize}

\hypertarget{variables-aleatorias-discretas}{%
\chapter{Variables aleatorias discretas}\label{variables-aleatorias-discretas}}

\hypertarget{objetivo-1}{%
\section{Objetivo}\label{objetivo-1}}

En este capítulo definiremos las variables aleatorias y estudiaremos variables aleatorias \textbf{discretas}.

Definiremos la función de masa de probabilidad y sus principales propiedades de media y varianza. Siguiendo el proceso de abstracción de las frecuencias relativas en probabilidades, también definimos la distribución de probabilidad como el caso límite de la frecuencia relativa acumulada.

\hypertarget{frecuencias-relativas-2}{%
\section{Frecuencias relativas}\label{frecuencias-relativas-2}}

Las frecuencias relativas de los resultados de un experimento aleatorio son una medida de su propensión. Podemos usarlos como estimadores de sus probabilidades, cuando repetimos el experimento aleatorio muchas veces (\(n \rightarrow \infty\)).

Definimos tendencia central (promedio), dispersión (varianza muestral) y la distribución de frecuencias de los datos (\(F_i\)).

En términos de probabilidades, ¿cómo se definen estas cantidades?

\includegraphics{./figures/randomvar.JPG}

\hypertarget{variable-aleatoria}{%
\section{Variable aleatoria}\label{variable-aleatoria}}

Definimos las frecuencias relativas sobre las \textbf{observaciones} de los experimentos. Ahora definimos las cantidades equivalentes para las probabilidades en términos de los \textbf{resultados} de los experimentos. Nos ocuparemos únicamente de resultados de tipo numérico.

Una \textbf{variable aleatoria} es un símbolo que representa un \textbf{resultado numérico} de un experimento aleatorio. Escribimos la variable aleatoria en \textbf{mayúsculas} (es decir, \(X\)).

\textbf{Definición:}

Una \textbf{variable aleatoria} es una función que asigna un \textbf{número} real a un \textbf{evento} del espacio muestral de un experimento aleatorio.

Recuerda que un evento puede ser un resultado o una colección de resultados.

Cuando la variable aleatoria toma un \textbf{valor}, indica la realización de un \textbf{evento} de un experimento aleatorio.

\emph{Ejemplo:}

Si \(X \in \{0,1\}\), entonces decimos que \(X\) es una variable aleatoria que puede tomar los valores \(0\) o \(1\).

\hypertarget{eventos-de-observar-una-variable-aleatoria}{%
\section{Eventos de observar una variable aleatoria}\label{eventos-de-observar-una-variable-aleatoria}}

Hacemos la distinción entre variables en el espacio modelo con letras mayúsculas, como entidades abstractas, y la realización de un evento o resultado particular. Por ejemplo:

\begin{itemize}
\tightlist
\item
  \(X=1\) es el \textbf{evento} de observar la variable aleatoria \(X\) con valor \(1\)
\item
  \(X=2\) es el \textbf{evento} de observar la variable aleatoria \(X\) con valor \(2\)
\end{itemize}

\ldots{}

\textbf{En general:}

\begin{itemize}
\tightlist
\item
  \(X=x\) es el \textbf{evento} de observar la variable aleatoria \(X\) (\(X\) mayúscula) con valor \(x\) (\(x\) pequeño).
\end{itemize}

\hypertarget{probabilidad-de-variables-aleatorias}{%
\section{Probabilidad de variables aleatorias}\label{probabilidad-de-variables-aleatorias}}

Nos interesa asignar probabilidades a los eventos de observar un valor particular de una variable aleatoria.

Por ejemplo, para los dados escribiremos la tabla de probabilidad como

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
\(X\) & Probabilidad \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(1\) & \(P(X=1)=1/6\) \\
\(2\) & \(P(X=2)=1/6\) \\
\(3\) & \(P(X=3)=1/6\) \\
\(4\) & \(P(X=4)=1/6\) \\
\(5\) & \(P(X=5)=1/6\) \\
\(6\) & \(P(X=6)=1/6\) \\
\end{longtable}

donde hacemos explícitos los eventos de que la variable toma un resultado dado \(X=x\).

\hypertarget{funciones-de-probabilidad}{%
\section{Funciones de probabilidad}\label{funciones-de-probabilidad}}

Debido a que \(x\) (minúscula) es una variable numérica, las probabilidades de la variable aleatoria se pueden dibujar

\includegraphics{_main_files/figure-latex/unnamed-chunk-35-1.pdf}

o escrir como una función

\[f(x)=P(X=x)=1/6\]

\hypertarget{funciones-de-probabilidad-1}{%
\section{Funciones de probabilidad}\label{funciones-de-probabilidad-1}}

Podemos \textbf{crear} cualquier tipo de función de probabilidad si satisfacemos las reglas de probabilidad de Kolmogorov:

Para una variable aleatoria discreta \(X \in \{x_1 , x_2 , .. , x_M\}\), una \textbf{función de masa de probabilidad} que se usa para calcular probabilidades

\begin{itemize}
\tightlist
\item
  \(f(x_i)=P(X=x_i)\)
\end{itemize}

siempre es positiva

\begin{itemize}
\tightlist
\item
  \(f(x_i)\geq 0\)
\end{itemize}

y su suma sobre todos los valores de la variable es \(1\):

\begin{itemize}
\tightlist
\item
  \(\sum_{i=1}^M f(x_i)=1\)
\end{itemize}

Donde \(M\) es el número de resultados posibles.

Ten en cuenta que la definición de \(X\) y su función de masa de probabilidad es general \textbf{sin referencia} a ningún experimento. Las funciones viven en el espacio modelo (abstracto).

Aquí tenemos un ejemplo

\includegraphics{_main_files/figure-latex/unnamed-chunk-36-1.pdf}

\(X\) y \(f(x)\) son objetos abstractos que pueden corresponder o no a un experimento. Tenemos la libertad de construirlos como queramos siempre que respetemos su definición.

Las funciones de masa de probabilidad tienen algunas \textbf{propiedades} que se derivan exclusivamente de su definición.

\hypertarget{probabilidades-y-frecuencias-relativas}{%
\section{Probabilidades y frecuencias relativas}\label{probabilidades-y-frecuencias-relativas}}

\textbf{Considera el ejemplo}

Haz el siguiente experimento: En una urna pon \(8\) bolas y:

\begin{itemize}
\tightlist
\item
  marca \(1\) bola con el número \(-2\)
\item
  marca \(2\) bolas con el número \(-1\)
\item
  marca \(2\) bolas con el número \(0\)
\item
  marca \(2\) bolas con el número \(1\)
\item
  marca \(1\) bolas con el número \(2\)
\end{itemize}

Y considere realizar el siguiente \textbf{experimento aleatorio:} Tome una bola y lea el número.

A partir de la probabilidad clásica, podemos escribir la tabla de probabilidades, para lo cual no necesitamos realizar ningún experimento

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
\(X\) & \(P(X=x)\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(-2\) & \(1/8=0.125\) \\
\(-1\) & \(2/8=0.25\) \\
\(0\) & \(2/8=0.25\) \\
\(1\) & \(2/8=0.25\) \\
\(2\) & \(1/8=0.125\) \\
\end{longtable}

Ahora, realicemos el experimento \(30\) veces y escribamos la tabla de frecuencia

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
\(X\) & \(f_i\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(-2\) & \(0.132\) \\
\(-1\) & \(0.262\) \\
\(0\) & \(0.240\) \\
\(1\) & \(0.248\) \\
\(2\) & \(0.118\) \\
\end{longtable}

La probabilidad frecuentista nos dice
\[lim_{N \rightarrow \infty} f_i = f(x_i)=P(X=x_i)\]
Entonces, si no conocíamos el montaje del experimento (caja negra), lo mejor que podemos hacer es \textbf{estimar} las probabilidades con las frecuencias, obtenidas de \(N\) repeticiones del experimento aleatorio:

\[f_i = \hat{P}_i\]

\includegraphics{_main_files/figure-latex/unnamed-chunk-37-1.pdf}

Cada vez que estimamos las probabilidades, nuestras estimaciones \(\hat{P}_i=f_i\) cambian. Pero \(P_i\) es una cantidad abstracta que nunca cambia. A medida que aumenta \(N\), nos acercamos más a ella.

\hypertarget{la-media-o-el-valor-esperado}{%
\section{La media o el valor esperado}\label{la-media-o-el-valor-esperado}}

Cuando discutimos las estadísticas de resumen de los datos, definimos el \textbf{centro} de las observaciones como un valor alrededor del cual se concentran las frecuencias de los resultados.

Usamos el \textbf{promedio} para medir el centro de gravedad de los \textbf{datos}. En términos de las frecuencias relativas de los valores de los resultados discretos, escribimos el promedio como

\(\bar{x}= \sum_{i=1}^M x_i \frac{n_i}{N}=\) \[\sum_{i=1}^M x_i f_i\]

\textbf{Definición}

La \textbf{media} (\(\mu\)) o valor esperado de una variable aleatoria discreta \(X\), \(E(X)\), con función de masa \(f(x)\) está dada por

\[ \mu = E(X)= \sum_{i=1}^M x_i f(x_i) \]

\includegraphics{./figures/mu.png}

Es el centro de gravedad de las \textbf{probabilidades}: El punto donde se equilibran las cargas de probabilidad.

De la definición tenemos

\[\bar{x} \rightarrow \mu\] en el \textbf{límite} cuando
\(N \rightarrow \infty\) como la frecuencia tiende a la función de masa de probabilidad \(f_i \rightarrow f(x_i)\).

\textbf{Ejemplo}

¿Cuál es la media de \(X\) si su función de masa de probabilidad \(f(x)\) está dada por

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
\(X\) & \(f(x)=P(X=x)\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(0\) & \(1/16\) \\
\(1\) & \(4/16\) \\
\(2\) & \(6/16\) \\
\(3\) & \(4/16\) \\
\(4\) & \(1/16\) \\
\end{longtable}

\includegraphics{_main_files/figure-latex/unnamed-chunk-38-1.pdf}

\[ \mu =E(X)=\sum_{i=1}^m x_i f(x_i) \]

\(E(X)=\)\textbf{0} * 1/16 + \textbf{1} * 4/16 + \textbf{2} * 6/16 + \textbf{3} * 4/16 + \textbf{4} * 1/16 =2

La media \(\mu\) es el centro de gravedad de la función de masa de probabilidad y \textbf{no cambia}. Sin embargo, el promedio \(\bar{x}\) es el centro de gravedad de las observaciones (frecuencias relativas) \textbf{cambia} con diferentes datos.

\hypertarget{varianza}{%
\section{Varianza}\label{varianza}}

Cuando discutimos los estadísticos de resumen, también definimos la dispersión de las observaciones como una distancia promedio de los datos al promedio.

\textbf{Definición}

La varianza, escrita como \(\sigma^2\) o \(V(X)\), de una variable aleatoria discreta \(X\) con función de masa \(f(x)\) viene dada por

\[\sigma^2 = V(X)= \sum_{i=1}^M (x_i-\mu)^2 f(x_i)\]
\(\sigma=\sqrt{V(X)}\) se llama la \textbf{desviación estándar} de la variable aleatoria.

La varianza es la dispersión de las \textbf{probabilidades} con respecto a la media: El momento de inercia de las probabilidades sobre la media.

\textbf{Ejemplo}

¿Cuál es la varianza de \(X\) si su función de masa de probabilidad \(f(x)\) está dada por

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
\(X\) & \(f(x)=P(X=x)\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(0\) & \(1/16\) \\
\(1\) & \(4/16\) \\
\(2\) & \(6/16\) \\
\(3\) & \(4/16\) \\
\(4\) & \(1/16\) \\
\end{longtable}

\[\sigma^2 =V(X)=\sum_{i=1}^m (x_i-\mu)^2 f(x_i)\]

\(V(X)=\)\textbf{(0-2)}\(^2\)* 1/16 + \textbf{(1-2)}\(^2\)* 4/16 + \textbf{(2- 2)}\(^2\)* 6/16 + \textbf{(3-2)}\(^2\)* 4/16 + \textbf{(4-2)}\(^2\)* 1/ 16 = 1

\[V(X)=\sigma^2=1\]
\[\sigma=1\]

\hypertarget{funciones-de-probabilidad-para-funciones-de-x}{%
\section{\texorpdfstring{Funciones de probabilidad para funciones de \(X\)}{Funciones de probabilidad para funciones de X}}\label{funciones-de-probabilidad-para-funciones-de-x}}

En muchas ocasiones, estaremos interesados en resultados que sean función de las variables aleatorias. Quizás nos interese el cuadrado del número de contagios de gripe, o la raíz cuadrada del número de correos electrónicos en una hora.

\textbf{Definición}

Para cualquier función \(h\) de una variable aleatoria \(X\), con función de masa \(f(x)\), su valor esperado viene dado por

\[ E[h(X)]= \sum_{i=1}^M h(x_i) f(x_i) \]

Esta es una definición importante que nos permite probar tres propiedades de la media y la varianza que se usan con frecuencia:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  La media de una función lineal es la función lineal de la media: \[E(a\times X +b)= a\times E(X) +b\] para \(a\) y \(b\) escalares (números ).
\item
  La varianza de una función lineal de \(X\) es:\[V(a\times X +b)= a^2\times V(X)\]
\item
  La varianza \textbf{con respecto al origen} es la varianza \textbf{con respecto a la media} más la media al cuadrado: \[E(X^2)=V(X)+E(X)^2\]
\end{enumerate}

\textbf{Ejemplo}

¿Cuál es la varianza \(X\) con respecto al origen, \(E(X^2)\), si su función de masa de probabilidad \(f(x)\) está dada por

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
\(X\) & \(f(x)=P(X=x)\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(0\) & \(1/16\) \\
\(1\) & \(4/16\) \\
\(2\) & \(6/16\) \\
\(3\) & \(4/16\) \\
\(4\) & \(1/16\) \\
\end{longtable}

\[E(X^2) =\sum_{i=1}^m x_i^2 f(x_i)\]

\(E(X^2)=\)\textbf{(0)}\(^2\)* 1/16 + \textbf{(1)}\(^2\)* 4/16 + \textbf{(2)} \(^2\)* 6/16 + \textbf{(3)}\(^2\)* 4/16 + \textbf{(4)}\(^2\)* 1/16 =5

También podemos verificar:

\[E(X^2)=V(X)+E(X)^2\]

\(5=1+2^2\)

\hypertarget{distribuciuxf3n-de-probabilidad}{%
\section{Distribución de probabilidad}\label{distribuciuxf3n-de-probabilidad}}

Cuando discutimos las estadísticas de resumen, también definimos la \textbf{distribución} de frecuencias (o la frecuencia acumulada relativa) \(F_i\). \(F_i\) es una cantidad importante porque es una función continua \(F_x\) es por lo tanto una función de rango \textbf{continuo}, incluso si los resultados son discretos.

\textbf{Definición:}

La función de \textbf{distribución de probabilidad} se define como

\[F(x)=P(X\leq x)=\sum_{x_i\leq x} f(x_i) \]

Esa es la probabilidad acumulada hasta un valor dado \(x\)

\(F(x)\) satisface por lo tanto satisface:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  \(0\leq F(x) \leq 1\)
\item
  Si \(x \leq y\), entonces \(F(x) \leq F(y)\)
\end{enumerate}

Para la función de masa de probabilidad:

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
\(X\) & \(f(x)=P(X=x)\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(0\) & \(1/16\) \\
\(1\) & \(4/16\) \\
\(2\) & \(6/16\) \\
\(3\) & \(4/16\) \\
\(4\) & \(1/16\) \\
\end{longtable}

La distribución de probabilidad es:

\[
    F(x)=
\begin{cases}
    1/16,& \text{if } 0 \leq x < 1\\
    5/16,& 1\leq x < 2\\
    11/16,& 2\leq x < 3\\
    15/16,& 4\leq x < 5\\
    16/16,&  x \leq 5\\
\end{cases}
\]

Para \(X \in \mathbb{Z}\)

\includegraphics{_main_files/figure-latex/unnamed-chunk-39-1.pdf}

\hypertarget{funciuxf3n-de-probabilidad-y-distribuciuxf3n-de-probabilidad}{%
\section{Función de probabilidad y distribución de probabilidad}\label{funciuxf3n-de-probabilidad-y-distribuciuxf3n-de-probabilidad}}

La función de probabilidad y la distribución son equivalentes. Podemos obtener uno del otro y viceversa.

\[f(x_i)=F(x_i)-F(x_{i-1})\]

con

\[f(x_1)=F(x_1)\]

para \(X\) tomando valores en \(x_1 \leq x_2 \leq ... \leq x_n\)

\textbf{Ejemplo}

De la distribución de probabilidad:

\[
    F(x)=
\begin{cases}
    1/16,& \text{if } 0 \leq x < 1\\
    5/16,& 1\leq x < 2\\
    11/16,& 2\leq x < 3\\
    15/16,& 4\leq x < 5\\
    16/16,&  x \leq 5\\
\end{cases}
\]

Podemos obtener la función masa de probabilidad.

\(f(0)=F(0)=1/16\)
\(f(1)=F(1)-f(0)=5/32-1/32=4/16\)
\(f(2)=F(2)-f(1)-f(0)=F(2)-F(1)=6/16\)
\(f(3)=F(3)-f(2)-f(1)-f(0)=F(3)-F(2)=4/16\)
\(f(4)=F(4)-F(3)=1/16\)

\hypertarget{cuantiles}{%
\section{Cuantiles}\label{cuantiles}}

Finalmente, podemos usar la distribución de probabilidad \(F(x)\) para definir la mediana y los cuartiles de la variable aleatoria \(X\).

En general, definimos el \textbf{q-cuantil} como el valor \(x_{p}\) \textbf{bajo} el cual hemos acumulado q*100\% de la probabilidad

\[q=\sum_{i=1}^pf(x_i) = F (x_p)\]

\begin{itemize}
\tightlist
\item
  La \textbf{mediana} es valor \(x_m\) tal que \(q=0.5\)
\end{itemize}

\[F(x_{m})=0.5\]

\begin{itemize}
\tightlist
\item
  El cuantil \(0.05\) es el valor \(x_{r}\) tal que \(q=0.05\)
\end{itemize}

\[F(x_{r})=0.05\]

\begin{itemize}
\tightlist
\item
  El cuantil de \(0,25\) es el \textbf{primer cuartil} el valor \(x_{s}\) tal que \(q=0.25\)
\end{itemize}

\[F(x_{s})=0.25\]

\hypertarget{resumen}{%
\section{Resumen}\label{resumen}}

\includegraphics{./figures/randomvarsum.JPG}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.4348}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3043}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2609}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
nombres de cantidades
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
modelo (no observado)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
datos (observados)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
función de masa de probabilidad // frecuencia relativa & \(f(x_i)=P(X=x_i)\) & \(f_i=\frac{n_i}{N}\) \\
distribución de probabilidad // frecuencia relativa acumulada & \(F(x_i)=P(X \leq x_i)\) & \(F_i=\sum_{k\leq i} f_k\) \\
media // promedio & \(\mu=E(X)=\sum_{i=1}^M x_i f(x_i)\) & \(\bar{x}=\sum_{j=1}^N x_j/N\) \\
varianza // varianza de la muestra & \(\sigma^2=V(X)=\sum_{i=1}^M (x_i-\mu)^2 f(x_i)\) & \(s^2=\sum_{j=1}^N (x_j-\bar{x})^2/(N-1)\) \\
desviación estándar // muestra sd & \(\sigma=\sqrt{V(X)}\) & \(s\) \\
varianza con respecto al origen // 2º momento muestral & \(E(X^2)=\sum_{i=1}^M x_i^2 f(x_i)\) & \(m_2= \sum_{j=1}^N x_j^2/n\) \\
\end{longtable}

Ten en cuenta:

\begin{itemize}
\tightlist
\item
  \(i=1...M\) es un \textbf{resultado} de la variable aleatoria \(X\).
\item
  \(j=1...N\) es una \textbf{observación} de la variable aleatoria \(X\).
\end{itemize}

Propiedades:

\begin{itemize}
\tightlist
\item
  \(\sum_{i=1...N} f(x_i)=1\)
\item
  \(f(x_i)=F(x_i)-F(x_{i-1})\)
\item
  \(E(a\times X +b)= a\times E(X) +b\); for \(a\) and \(b\) scalars.
\item
  \(V(a\times X +b)= a^2\times V(X)\)
\item
  \(E(X^2)=V(X)+E(X)^2\)
\end{itemize}

\hypertarget{preguntas-3}{%
\section{Preguntas}\label{preguntas-3}}

\textbf{1)} Para una función de masa de probabilidad no es cierto que

\textbf{\(\qquad\)a:} la suma de los valores de su imagen es 1; \textbf{\(\qquad\)b:} sus valores pueden interpretarse como probabilidades de eventos;
\textbf{\(\qquad\)c:} siempre es positiva;
\textbf{\(\qquad\)d:} no puede tomar el valor 1;

\textbf{2)} El valor de una variable aleatoria representa

\textbf{\(\qquad\)a:} una observación de un experimento aleatorio; \textbf{\(\qquad\)b:} la frecuencia de un resultado de un experimento aleatorio;
\textbf{\(\qquad\)c:} un resultado de un experimento aleatorio;
\textbf{\(\qquad\)d:} una probabilidad de un resultado;

\textbf{3)} El valor estimado de una probabilidad \(\hat{P_i}\) es igual a la probabilidad \(P_i\) cuando el número de repeticiones del experimento aleatorio es

\textbf{\(\qquad\)a:} grande; \textbf{\(\qquad\)b:} infinito;
\textbf{\(\qquad\)c:} pequeño
\textbf{\(\qquad\)d:} cero;

\textbf{4)} Si una función de masa de probabilidad es simétrica alrededor de \(x=0\)

\textbf{\(\qquad\)a:} La media es menor que la mediana; \textbf{\(\qquad\)b:} La media es mayor que la mediana;
\textbf{\(\qquad\)c:} La media y la mediana son iguales;
\textbf{\(\qquad\)d:} La media y la mediana son diferentes de 0;

\textbf{5)} La media y la varianza

\textbf{\(\qquad\)a:} son inversamente proporcionales; \textbf{\(\qquad\)b:} son valores esperados de funciones de \(X\);
\textbf{\(\qquad\)c:} de una función lineal son la función lineal de la media y la función lineal de la varianza;
\textbf{\(\qquad\)d:} cambia cuando repetimos el experimento aleatorio;

\hypertarget{ejercicios-3}{%
\section{Ejercicios}\label{ejercicios-3}}

\hypertarget{ejercicio-1-2}{%
\subsubsection{Ejercicio 1}\label{ejercicio-1-2}}

Ponemos en una urna papeletas con letras de la a la f.~Considera el sorteo que da \(0\) euros a las dos primeras letras del abecedario, \(1.5\) euros a las dos siguientes, y \(2\) y \(3\) euros a las siguientes.

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\item
  ¿cuál es la función de masa de probabilidad y función de distribución de probabilidad de para los premios en dinero del juego?
\item
  ¿cuál es el valor esperado del premio? (R:1.3)
\item
  ¿cuál es la varianza del premio? (R:1.13)
\item
  ¿cuál es la probabilidad de ganar 2 o mas euros? (R:2/6)
\end{enumerate}

\hypertarget{ejercicio-2-2}{%
\subsubsection{Ejercicio 2}\label{ejercicio-2-2}}

Dada la función de masa de probabilidad

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
\(x\) & \(f(x)=P(X=x)\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
10 & 0.1 \\
12 & 0.3 \\
14 & 0.25 \\
15 & 0.15 \\
17 & ? \\
20 & 0.15 \\
\end{longtable}

\begin{itemize}
\tightlist
\item
  ¿Cuál es su valor esperado y su desviación estándar? (R: 14,2; 2,95)
\end{itemize}

\hypertarget{ejercicio-3-2}{%
\subsubsection{Ejercicio 3}\label{ejercicio-3-2}}

Dada la distribución de probabilidad para una variable discreta \(X\)

\[
    F(x)= 
\begin{cases}
0, & x < -1 \\
0.2,& x \in [-1,0)\\
0.35,& x \in [0,1)\\
0.45,& x \in [1,2)\\
1,& x \geq 2\\
\end{cases}
\]

\begin{itemize}
\tightlist
\item
  encuentra \(f(x)\)
\item
  encuentra \(E(X)\) y \(V(X)\) (R:1; 1.5)
\item
  cuál es el valor esperado y la varianza de \(Y=2X+3\) (R:5, 6)
\item
  ¿Cuál es la mediana y el primer y tercer cuartil de \(X\)? (R:2,0,2)
\end{itemize}

\hypertarget{ejercicio-4-1}{%
\subsubsection{Ejercicio 4}\label{ejercicio-4-1}}

Estamos probando un sistema para transmitir imágenes digitales. Primero consideramos el experimento de enviar \(3\) píxeles y tener como resultados \textbf{posibles} eventos como \((0,1,1)\). Este es el evento de recibir el primer píxel sin error, el segundo con error y el tercero con error.

\begin{itemize}
\item
  Enumera en una columna el espacio muestral del experimento aleatorio.
\item
  En la segunda columna asigna la variable aleatoria que cuenta el número de errores transmitidos para cada resultado
\end{itemize}

Considera que tenemos un canal totalmente ruidoso, es decir, cualquier resultado de tres píxeles es igualmente probable.

\begin{itemize}
\item
  ¿Cuál es la probabilidad de recibir errores de \(0\), \(1\), \(2\) o \(3\) en la transmisión de \(3\) píxeles? (R: 1/8; 3/8; 3/8; 1/8)
\item
  Dibuja la función de masa de probabilidad para el número de errores
\item
  ¿Cuál es el valor esperado para el número de errores? (R:1.5)
\item
  ¿Cuál es su varianza? (R: 0,75)
\item
  Dibuja la distribución de probabilidad
\item
  ¿Cuál es la probabilidad de transmitir al menos 1 error? (R:7/8)
\end{itemize}

\hypertarget{variables-aleatorias-continuas}{%
\chapter{Variables aleatorias continuas}\label{variables-aleatorias-continuas}}

\hypertarget{objetivo-2}{%
\section{Objetivo}\label{objetivo-2}}

En este capítulo estudiaremos variables aleatorias continuas.

Definiremos la función de densidad de probabilidad, su media y varianza. De forma similar a las variables aleatorias discretas, definiremos la función de distribución de probabilidad.

\hypertarget{variables-aleatorias-continuas-1}{%
\section{Variables aleatorias continuas}\label{variables-aleatorias-continuas-1}}

En el capítulo pasado usamos las probabilidades de variables aleatorias discretas para definir la función de masa de probabilidad \[f(x)=P(X= x)\]

Donde la probabilidad de que la variable aleatoria tome el valor \(x\) la entendemos como el valor de su frecuencia relativa, cuando el número de repeticiones del experimiento aleatorio tiende a infinito.

Cuando hablamos de datos continous vimos que teníamos que transformarlos en variables discretas (bins) para producir tablas de frecuencias relativas o histogramas. Veamos cómo definir las probabilidades de las variables continuas teniendo en cuenta estas particiones.

\textbf{Ejemplo (misofonía)}

Reconsideremos el ángulo de convexidad de los pacientes con misofonía (Sección 2.21). El ángulo de convexidas de 123 pacientes fue medido. Entendimos cada medición como el resultado de un experimento aleatorio que repetimos 123 veces y que podíamos describir en una tabla de frecuencias o en un histograma.

Para hacer esto, redefinimos los resultados como pequeños intervalos regulares (bins) y calculamos la frecuencia relativa de cada intervalo.

\begin{verbatim}
##        outcome ni         fi
## 1 [-1.02,3.46]  8 0.06504065
## 2  (3.46,7.92] 51 0.41463415
## 3  (7.92,12.4] 26 0.21138211
## 4  (12.4,16.8] 20 0.16260163
## 5  (16.8,21.3] 18 0.14634146
\end{verbatim}

\hypertarget{frecuencias-relativas-3}{%
\section{frecuencias relativas}\label{frecuencias-relativas-3}}

Por lo tanto, definimos la probabilidad de observar un intervalo \(i\) como la frecuencia relativa del intervalo cuando \(N \rightarrow \infty\)

\[ f_i =\frac{ n_ i }{ N} \rightarrow P( x_i \leq X \leq x_i + \Delta x)\]

Esta probabilidad depende de la longitud de los bins \(\Delta x\).

Si hacemos los bins cada vez más pequeños, las frecuencias se hacen más pequeñas y, por lo tanto,

\[P(x_i \leq X \leq x_i + \Delta x) \rightarrow 0\] cuando \(\Delta x \rightarrow 0\) porque \(n_i \rightarrow 0\)

Veamos cómo las frecuencias relativas se hacen más pequeñas cuando dividimos el rango de \(X\) en \(20\) bins

\begin{verbatim}
##          outcome ni         fi
## 1  [-1.02,0.115]  2 0.01626016
## 2   (0.115,1.23]  0 0.00000000
## 3    (1.23,2.34]  3 0.02439024
## 4    (2.34,3.46]  3 0.02439024
## 5    (3.46,4.58]  2 0.01626016
## 6    (4.58,5.69]  4 0.03252033
## 7     (5.69,6.8] 11 0.08943089
## 8     (6.8,7.92] 34 0.27642276
## 9    (7.92,9.04] 12 0.09756098
## 10   (9.04,10.2]  4 0.03252033
## 11   (10.2,11.3]  3 0.02439024
## 12   (11.3,12.4]  7 0.05691057
## 13   (12.4,13.5]  2 0.01626016
## 14   (13.5,14.6]  6 0.04878049
## 15   (14.6,15.7]  4 0.03252033
## 16   (15.7,16.8]  8 0.06504065
## 17     (16.8,18]  4 0.03252033
## 18     (18,19.1]  9 0.07317073
## 19   (19.1,20.2]  3 0.02439024
## 20   (20.2,21.3]  2 0.01626016
\end{verbatim}

\hypertarget{funciuxf3n-de-densidad-de-probabilidad}{%
\section{función de densidad de probabilidad}\label{funciuxf3n-de-densidad-de-probabilidad}}

Definimos una cantidad en un punto \(x\) que es \textbf{la probabilidad por unidad de distancia} de que una observación esté en el bin \textbf{infinitesimal} entre \(x\) y \(x+dx\)

\[f(x)= \frac{ P(x\leq X \leq x+dx )}{dx}\]

\(f(x)\) se llama la \textbf{función de densidad de probabilidad}.

Por lo tanto, la probabilidad de observar \(X\) entre \(x\) y \(x+dx\)
está dada por

\[P( x\leq X \leq x+dx )= f(x) dx\]

\textbf{Definición}

Para una variable aleatoria continua \(X\), una función de \textbf{densidad de probabilidad} es tal que

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Es positiva:
\end{enumerate}

\[f(x) \geq 0\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  La probabilidad de observar \textbf{cualquier} valor de \(x\) es 1:
\end{enumerate}

\[\int_{-\infty}^{\infty} f(x) dx = 1\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  La probabilidad de observar un valor dentro de un intervalo es el \textbf{área bajo la curva}:
\end{enumerate}

\[ P( a\leq X \leq b)=\int_{a}^{b} f(x) dx\]

Las propiedades aseguran que \(f(x)dx\) satisfacen las propiedades de probabilidad de Kolmogorov.

La función de densidad de probabilidad es un paso más en la abstracción de probabilidades en la que añadimos el límite continuo

\[dx \rightarrow 0\]

Todas las propiedades de las probabilidades se traducen en términos de densidades y por lo tanto cambiamos sumatorios por integrales

\[\sum \rightarrow \int\]

Las densidades de probabilidad son cantidades matemáticas que no necesariamente representan experimientos aleatorios.

Un interés fundamental en estadística es describir las densidades que describen nuestro experimento aleatorio concreto.

\hypertarget{uxe1rea-total-bajo-la-curva}{%
\section{Área total bajo la curva}\label{uxe1rea-total-bajo-la-curva}}

\textbf{Ejemplo (gotas de lluvia)}

tomemos una \textbf{densidad de probabilidad} que podría describir la variable aleatoria que mide dónde cae una gota de lluvia en una canaleta de \(100\) cm de longitud.

\[
    f(x)= 
\begin{cases}
    \frac{1}{100},& \text{si } x\in (0,100)\\
    0,& de\, otra\, forma 
\end{cases}
\]

Verifiquemos que la función satisface las tres propiedades de una densidad de probabilidad.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  es evidente a partir de la definición que \(f(x) \geq 0\)
\item
  La probabilidad de observar \textbf{cualquier valor} de \(X\) es el \textbf{área total bajo la curva}
\end{enumerate}

\(P( -\infty \leq X \leq \infty )= \int_{-\infty }^{\infty } f(x) dx = 100*0.01= 1\)

\includegraphics{_main_files/figure-latex/unnamed-chunk-42-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  La probabilidad de observar \(X\) en un intervalo es el \textbf{área bajo la curva} dentro del intervalo
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \(P( 20 \leq X \leq 60) = \int_{20}^{60} f(x) dx = (60-20)*0.01=0.4\)
\end{itemize}

\includegraphics{_main_files/figure-latex/unnamed-chunk-43-1.pdf}

\hypertarget{probabilidades-de-variables-continuas}{%
\section{Probabilidades de variables continuas}\label{probabilidades-de-variables-continuas}}

Para variables continuas, calculamos la probabilidad de que la variable esté en un intervalo dado. Eso es

\[P( a \leq X \leq b)\]
Recordemos que para variables continuas, la probabilidad de que el experimento nos dé un número real particular es cero: \(P(X= a)= 0\)

La probabilidad \(P( a \leq X \leq b)\) es el área bajo la curva de \(f(x)\) entre \(a\) y \(b\)

\begin{itemize}
\tightlist
\item
  \(P( a \leq X \leq b) = \int_{a}^{b} f(x) dx\)
\end{itemize}

\includegraphics{_main_files/figure-latex/unnamed-chunk-44-1.pdf}

\hypertarget{distribuciuxf3n-de-probabilidad-1}{%
\section{Distribución de probabilidad}\label{distribuciuxf3n-de-probabilidad-1}}

La \textbf{distribución de probabilidad} \(F(c)\) definida como la acumulación de probabilidad hasta el resultado \(C\)

\(F(c) = P( X \leq c)\)

se puede utilizar para calcular la probabilidad \(P( a \leq X \leq b)\).

Si consideramos que:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  la probabilidad acumulada hasta \(b\) está dada por
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \(F(b) = P( X \leq b)=\int_{-\infty }^bf(x)dx\)
\end{itemize}

\includegraphics{_main_files/figure-latex/unnamed-chunk-45-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  la probabilidad acumulada hasta \(a\) es
\end{enumerate}

\begin{itemize}
\tightlist
\item
  \(F(a) = P( X \leq a)\)
\end{itemize}

\includegraphics{_main_files/figure-latex/unnamed-chunk-46-1.pdf}

Entonces, la probabilidad entre \(a\) y \(b\) viene dada por la diferencia en el valor de la distribución de probabilidad

\begin{itemize}
\tightlist
\item
  \(P( a\leq X \leq b) = \int_a^b f(x)dx=F(b)-F(a)\)
\end{itemize}

\includegraphics{_main_files/figure-latex/unnamed-chunk-47-1.pdf}

\textbf{Definición}

La \textbf{distribución de probabilidad} de una variable aleatoria continua se define como

\[F(a)= P( X\leq a) =\int_{-\infty } ^af(x)dx\]

y tiene las siguientes propiedades:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Está entre \(0\) y \(1\):
\end{enumerate}

\[F(-\infty )= 0\,\, y \,\,F(\infty )=1\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Siempre aumenta:
\end{enumerate}

\[F(a)\leq F(b)\]

si \(a \leq b\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Se puede utilizar para calcular probabilidades:
\end{enumerate}

\[P( a \leq X \leq b)=F(b)-F(a)\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Recupera la densidad de probabilidad:
\end{enumerate}

\[f(x)=\frac{ dF (x )}{ dx}\]

Usamos \textbf{distribuciones de probabilidad} para \textbf{calcular probabilidades} de una variable aleatoria dentro de intervalos, y su derivada es la función de densidad de probabilidad.

\textbf{Ejemplo (gotas de lluvia)}

Para la función de densidad uniforme:

\[
    f(x)= 
\begin{cases}
    \frac{1}{100},& \text{si } x\in (0,100)\\
    0,& de\, otra\, forma 
\end{cases}
\]

Encontramos que la distribución de probabilidad es

\[
    F(a)= 
\begin{cases}
    0,& \text{si } a \leq 0 \\
    \frac{a}{100},& \text{si } a\in (0,100)\\
    1, & \text{si } 100 \leq a \\
    \\
\end{cases}
\]

\newpage

\hypertarget{gruxe1ficas-de-probabilidad}{%
\section{Gráficas de probabilidad}\label{gruxe1ficas-de-probabilidad}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Podemos dibujar la probabilidad de una variable aleatoria en un intervalo como el \emph{área} bajo la curva de la \textbf{densidad}. Por ejemplo
\end{enumerate}

\[P(20<X< 60)\]

\includegraphics{_main_files/figure-latex/unnamed-chunk-48-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  También podemos dibujar la probabilidad \(P(20<X< 60)\) como la \emph{diferencia} en los valores de la \textbf{distribución}
\end{enumerate}

\includegraphics{_main_files/figure-latex/unnamed-chunk-49-1.pdf}

\hypertarget{media}{%
\section{Media}\label{media}}

Como en el caso discreto, la \textbf{media} mide el centro de masa de las probabilidades

\textbf{Definición}

Supongamos que \(X\) es una variable aleatoria continua con función de probabilidad \textbf{densidad} \(f(x)\). El valor medio o esperado de \(X\), denotado como \(\mu\) o \(E(X)\), es

\[\mu=E(X)=\int_{-\infty}^\infty x f(x) dx\]

Es la versión continua del centro de gravedad.

\textbf{Ejemplo (gotas de lluvia)}

La variable aleatoria con densidad de probabilidad

\[
    f(x)= 
\begin{cases}
    \frac{1}{100},& \text{si } x\in (0,100)\\
    0,& de\, otra\, forma 
\end{cases}
\]

Tiene un valor esperado en

\[E(X)=50\]

\includegraphics{_main_files/figure-latex/unnamed-chunk-50-1.pdf}

\hypertarget{varianza-1}{%
\section{Varianza}\label{varianza-1}}

Como en el caso discreto, la varianza mide la dispersión de probabilidades sobre la media

\textbf{Definición}

Supongamos que \(X\) es una variable aleatoria continua con función de densidad de probabilidad \(f(x)\). La varianza de \(X\), denotada como \(\sigma^2\) o \(V(X)\), es

\[\sigma^2=V(X)=\int_{-\infty}^\infty (x-\mu)^2 f(x) dx\]

Es la versión continua del momento de inercia.

\hypertarget{funciones-de-x}{%
\section{\texorpdfstring{Funciones de \(X\)}{Funciones de X}}\label{funciones-de-x}}

En muchas ocasiones, estaremos interesados en resultados que sean función de las variables aleatorias. Tal vez nos interese el cuadrado de la elongación de un muelle, o la raíz cuadrada de la temperatura de un motor.

\textbf{Definición}

Para cualquier función \(h\) de una variable aleatoria \(X\), con función de masa \(f(x)\), su valor esperado viene dado por

\[E[h(X)]= \int_{-\infty}^{\infty} h(x) f(x)dx\]
De esta definición recuperamos las mismas propiedades que en el caso discreto

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  La media de una función lineal es la función lineal de la media: \[ E( a\times X +b)= a\times E(X) +b\] para \(a\) y \(b\) escalares.
\item
  La varianza de una función lineal de \(X\) es:
\end{enumerate}

\[V(a\times X +b)= a^2\times V(X)\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  La varianza sobre el origen es la varianza sobre la media más la media al cuadrado:
\end{enumerate}

\[E(X^2)= V(X)+E(X)^2\]

\hypertarget{ejercicios-4}{%
\section{Ejercicios}\label{ejercicios-4}}

\hypertarget{ejercicio-1-3}{%
\subsubsection{Ejercicio 1}\label{ejercicio-1-3}}

Para la densidad de probabilidad

\[
    f(x)= 
\begin{cases}
    \frac{1}{100},& \text{si } x\in (0,100)\\
    0,& de\, otra\, forma 
\end{cases}
\]

\begin{itemize}
\tightlist
\item
  calcular la media (R:50)
\item
  calcular la varianza usando \(E(X^2)= V(X)+E(X)^2\) (R:100\^{}2/12)
\item
  calcula \(P( \mu-\sigma \leq X \leq \mu+\sigma)\) (R: 0.57)
\item
  ¿Cuáles son el primer y tercer cuartiles? (R: 25; 75)
\end{itemize}

\includegraphics{_main_files/figure-latex/unnamed-chunk-51-1.pdf}

\hypertarget{ejercicio-2-3}{%
\subsubsection{Ejercicio 2}\label{ejercicio-2-3}}

Dado

\[
    f(x)= 
\begin{cases}
0, & x < 0 \\
ax, & x \in [0,3] \\
b, & x \in (3,5) \\
\frac{b}{3}(8-x),& x \in [5,8]\\
0, & x > 8 \\
\end{cases}
\]

\begin{itemize}
\item
  ¿Cuáles son los valores de \(a\) y \(b\) tales que \(f(x)\) es una función de densidad de probabilidad continua ? (R: 1/15; 1/5)
\item
  ¿Cuál es la media de \(X\)? (R:4)
\end{itemize}

\hypertarget{ejercicio-3-3}{%
\subsubsection{Ejercicio 3}\label{ejercicio-3-3}}

Para la densidad de probabilidad

\[
    f(x)= 
\begin{cases}
    \lambda e^{-\lambda x},& \text{si } x \geq 0\\
    0,& de\, otra\, forma 
\end{cases}
\]

\begin{itemize}
\tightlist
\item
  Confirmar que se trata de una densidad de probabilidad
\item
  Calcular la media (R: 1/\(\lambda\))
\item
  Calcule el valor esperado de \(X^2\) (R: 2/\(\lambda^2\))
\item
  Calcular la varianza (R: 1/\(\lambda^2\))
\item
  Hallar la distribución de probabilidad \(F(a)\) (R: \(1- exp( -\lambda a)\))
\item
  Encuentra la mediana (R: \(\log{ 2}\) /\(\lambda\))
\end{itemize}

\hypertarget{ejercicio-4-2}{%
\subsubsection{Ejercicio 4}\label{ejercicio-4-2}}

Dada la distribución acumulativa de una variable aleatoria \(X\)

\[
    F(x)= 
\begin{cases}
0, & x  < -1 \\
\frac{1}{80}(17+16x-x^2),& x \in [-1,7)\\
1,& x \geq 7\\
\end{cases}
\]

calcular:

\begin{itemize}
\tightlist
\item
  \(P(X> 0)\) (R:63/80)
\item
  \(E(X)\) (R:1.93)
\item
  \(P(X>0|X< 2)\) (R:28/45)
\end{itemize}

\hypertarget{modelos-de-probabilidad-para-variables-aletorias-discretas}{%
\chapter{Modelos de probabilidad para variables aletorias discretas}\label{modelos-de-probabilidad-para-variables-aletorias-discretas}}

\hypertarget{objetivo-3}{%
\section{Objetivo}\label{objetivo-3}}

En este capítulo veremos algunas funciones de masa de probabilidad que se utilizan para describir experimentos aleatorios comunes.

Introduciremos el concepto de parámetro y por tanto de modelos paramétricos.

En particular, discutiremos las funciones de probabilidad uniforme y de Bernoulli y cómo se usan para derivar las funciones de probabilidad binomial y binomial negativa. También hableramos del modelo hipergeométrico.

\hypertarget{funciuxf3n-de-probabilidad}{%
\section{Función de probabilidad}\label{funciuxf3n-de-probabilidad}}

Recordemos que una función de masa de probabilidad de una \textbf{variable aleatoria discreta} \(X\) con valores posibles \(x_1 , x_2 , .. , x_M\) es \textbf{cualquier función} tal que

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Nos permite calcular probabilidades para todos los resultados
\end{enumerate}

\[f(x_i)=P(X=x_i)\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Siempre es positiva:
\end{enumerate}

\[f(x_i)\geq 0\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  La probabilidad de obtener algo en el experimento aleatorio es \(1\)
\end{enumerate}

\[\sum_{i=1}^M f(x_i)=1\]

Estudiamos dos \textbf{propiedades importantes:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  La media como medida de tendencia central:
\end{enumerate}

\[E(X)= \sum_{i=1}^M x_i f(x_i)\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  La varianza como medida de dispersión:
\end{enumerate}

\[V(X)= \sum_{i=1}^M (x_i-\mu)^2 f(x_i)\]

\hypertarget{modelo-de-probabilidad}{%
\section{Modelo de probabilidad}\label{modelo-de-probabilidad}}

Un \textbf{modelo de probabilidad} es una función de masa de probabilidad que puede representar las probabilidades de un experimento aleatorio.

\textbf{Ejemplos:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  La función de masa de probabilidad definida por
\end{enumerate}

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
\(X\) & \(f(x)\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(-2\) & \(1/8\) \\
\(-1\) & \(2/8\) \\
\(0\) & \(2/8\) \\
\(1\) & \(2/8\) \\
\(2\) & \(1/8\) \\
\end{longtable}

Representa la probabilidad de sacar \textbf{una} bola de una urna donde hay dos bolas con etiquetas: \(-1, 0, 1\) y una bola con etiquetas: \(-2, 2\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  \(f(x)=P(X=x)=1/6\) representa la probabilidad de los resultados de \textbf{un} lanzamiento de un dado.
\end{enumerate}

\hypertarget{modelos-paramuxe9tricos}{%
\section{Modelos paramétricos}\label{modelos-paramuxe9tricos}}

Cuando tenemos un experimento aleatorio con \(M\) resultados posibles, necesitamos encontrar \(M\) números para determinar la función de masa de probabilidad. Como en el ejemplo 1 anterior, necesitábamos \(5\) valores en la columna \(f(x)\) de la tabla de probabilidad.

Sin embargo, \textbf{en muchos casos}, podemos formular funciones de probabilidad \(f(x)\) que dependen únicamente de \textbf{muy pocos} números. Al igual que en el ejemplo 2 anterior, solo necesitábamos saber cuántos resultados posibles puede dar un dado.

\textbf{Ejemplo (probabilidad clásica):}

Un experimento aleatorio con \(M\) resultados igualmente probables tiene una función de masa de probabilidad:
\[f(x)=P(X=x)=1/M\]

Sólo necesitamos saber \(M\).

Los números que \textbf{necesitamos saber} para determinar completamente una función de probabilidad se llaman \textbf{parámetros}.

\hypertarget{distribuciuxf3n-uniforme-un-paruxe1metro}{%
\section{Distribución uniforme (un parámetro)}\label{distribuciuxf3n-uniforme-un-paruxe1metro}}

El ejemplo anterior es la interpretación clásica de la probabilidad y define nuestro primer modelo paramétrico.

\textbf{Definición}

Una variable aleatoria \(X\) con resultados \(\{1,...M\}\) tiene una \textbf{distribución uniforme} discreta si todos sus resultados \(M\) tienen la misma probabilidad

\[f(x)=\frac{1}{M}\]

\(M\) es el parámetro natural del modelo. Una vez que definimos \(M\) para un experimento, elegimos una función de masa de probabilidad particular. La función anterior es realmente una \textbf{familia} de funciones que dependen de \(M\): \(f(x; M)\).

La media y la varianza de una variable que sigue una distribución uniforme son:

\[E(X)= \frac{M+1}{2}\]

y

\[V(X)= \frac{M^2-1}{12}\]

Nota: \(E(X)\) y \(V(X)\) también son \textbf{parámetros}. Si conocemos alguno de ellos, entonces podemos determinar completamente la distribución. Por ejemplo:

\[f(x)=\frac{1}{2E(X)-1}\]

Veamos algunas funciones de masa de probabilidad en la familia de modelos paramétricos uniformes:

\includegraphics{_main_files/figure-latex/unnamed-chunk-52-1.pdf}

\hypertarget{distribuciuxf3n-uniforme-dos-paruxe1metros}{%
\section{Distribución uniforme (dos parámetros)}\label{distribuciuxf3n-uniforme-dos-paruxe1metros}}

Consideremos ahora un nuevo modelo de probabilidad \textbf{uniforme} con \textbf{dos parámetros}: los resultados mínimo y máximo.

Si la variable aleatoria toma valores en \(\{a, a+1, ...b\}\), donde \(a\) y \(b\) son números enteros y todos los resultados son igualmente probables, entonces

\[f(x)=\frac{1}{b-a+1}\]

porque \(M=b-a+1\).

Entonces decimos que \(X\) se distribuye uniformemente entre \(a\) y \(b\) y escribimos

\[X \rightarrow Unif(a,b)\]

\textbf{Propiedades:}

Si \(X\) se distribuye uniformemente entre \(a\) y \(b\)

\[X \rightarrow Unif(a,b)\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Su media es
\end{enumerate}

\[E(X)= \frac{b+a}{2}\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Su varianza es
\end{enumerate}

\[V(X)= \frac{(b-a+1)^2-1}{12}\]

Para probar esto cambia las variables \(X=Y+a-1\), \(y \in \{1,...M\}\).

\textbf{Funciones de masa de probabilidad}

Veamos algunas funciones de masa de probabilidad en la familia de modelos paramétricos uniformes:

\includegraphics{_main_files/figure-latex/unnamed-chunk-53-1.pdf}

\textbf{Ejemplo (clases escolares):}

¿Cuál es la probabilidad de observar a un niño de una edad particular en una escuela primaria (si todas las clases tienen la misma cantidad de niños)?

Del diseño del experimento sabemos: \(a=6\) y \(b=11\) entonces

\[X \rightarrow Unif(a=6, b=11)\] eso es

\[f(x)=\frac{1}{6}\] para \(x\in \{6,7,8,9,10,11\}\), y \(0\) en caso contrario.

La media y la varianza de esta función de masa de probabilidad es:

\begin{itemize}
\tightlist
\item
  \(E(X)=8.5\)
\item
  \(V(X)=2.916667\)
\end{itemize}

Recuerda

\begin{itemize}
\item
  El valor esperado es la \textbf{media} \(\mu=8.5\)
\item
  La \textbf{desviación estándar} \(\sigma=1.707825\) es la distancia promedio desde la media y se calcula a partir de la raíz cuadrada de la varianza.
\end{itemize}

\includegraphics{_main_files/figure-latex/unnamed-chunk-54-1.pdf}

\textbf{Parámetros y Modelos:}

Un \textbf{modelo} es una función particular \(f(x)\) que \textbf{describe} nuestro experimento.

Si el modelo es una función \textbf{conocida} que depende de algunos parámetros, al cambiar el valor de los parámetros producimos una \textbf{familia de modelos}: \(f(x; a,b)\).

El conocimiento de \(f(x)\) se reduce al conocimiento del valor de los parámetros \(a\), \(b\).

Idealmente, el modelo y los parámetros son \textbf{interpretables}.

En nuestro ejemplo, \(a\) representa la edad mínima en la escuela y \(b\) la edad máxima. Pueden considerarse como las \textbf{propiedades físicas} del experimento.

\hypertarget{ensayo-de-bernoulli}{%
\section{Ensayo de Bernoulli}\label{ensayo-de-bernoulli}}

Ahora considermos un modelo con solo dos resultados posibles (\(A\) y \(B\)) que tienen probabilidades \textbf{desiguales}

\textbf{Ejemplos:}

\begin{itemize}
\item
  Anotar el sexo de un paciente que acude a urgencias de un hospital (\(A:masculino\) y \(B:femenino\)).
\item
  Registrar si una máquina fabricada es defectuosa o no (\(A:defectuosa\) y \(B:no\,\,defectuosa\)).
\item
  Dar en el blanco (\(A:éxito\) y \(B:fracaso\)).
\item
  Transmitir un píxel correctamente (\(A:sí\) y \(B:no\)).
\end{itemize}

En estos ejemplos, la probabilidad del resultado \(A\) suele ser \textbf{desconocida}.

\textbf{Modelo de probabilidad:}

Introduciremos la probabilidad de un resultado (\(A\)) como el \textbf{parámetro} del modelo. El modelo se puede escribir en diferentes formas.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  Como una tabla de probabilidad:
\end{enumerate}

\begin{longtable}[]{@{}cc@{}}
\toprule\noalign{}
\(Resultado\) & \(P_i\) \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\(A\) & \(p\) \\
\(B\) & \(1-p\) \\
\end{longtable}

\begin{itemize}
\tightlist
\item
  \(i \in \{A,B\}\)
\item
  resultado \(A\) (éxito): tiene probabilidad \(p\) (parámetro)
\item
  resultado \(B\) (fracaso): tiene una probabilidad \(1-p\)
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Como función de masa de probabilidad de la variable aleatoria \(K\) tomando valores \(\{0, 1\}\) para \(B\) y \(A\), respectivamente.
\end{enumerate}

\[
    f(k)= 
\begin{cases}
    1-p,&  k=0\, (event\, B)\\
    p,& k=1\, (event\, A) 
\end{cases}
\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  Como una función de \(k\)
\end{enumerate}

\[f(k; p)=p^k(1-p)^{1-k} \]

para \(k=(0,1)\).

Entonces decimos que \(K\) sigue una distribución de Bernoulli con parámetro \(p\)
\[K \rightarrow Bernoulli(p)\]

\textbf{Propiedades:}

Si \(K\) sigue una distribución de Bernoulli, entonces

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  su media es
\end{enumerate}

\[E(K)=p\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  su varianza es
\end{enumerate}

\[V(K)=(1-p)p\]

Ten en cuenta que la probabilidad del resultado \(A\) es el parámetro \(p\)
que es lo mismo que su valor en \(k=1\): \(f(1)=P(k=1)\). El parámetro determina completamente la función de masa de probabilidad, incluidas su media y varianza.

Veamos algunas funciones de masa de probabilidad en la familia de modelos paramétricos uniformes:

\includegraphics{_main_files/figure-latex/unnamed-chunk-55-1.pdf}

\hypertarget{experimento-binomial}{%
\section{Experimento binomial}\label{experimento-binomial}}

Si estamos interesados en predecir \textbf{frecuencias absolutas} cuando conocemos el parámetro \(p\) de un ensayo particular de Bernoulli, entonces

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  \textbf{repetimos} el ensayo de Bernoulli \(n\) veces y contamos cuantas veces obtuvimos \(A\); es decir, calculamos la frecuencia absoluta de \(A\): \(N_A\).
\item
  definimos una \textbf{variable aleatoria} \(X=N_A\) tomando valores \(x \in {0,1,...n}\)
\end{enumerate}

Cuando repetimos \(n\) veces una ensayo de Bernoulli, observamos un valor para \(n_A\). Si realizamos otros \(n\) ensayos de Bernoulli, entonces \(n_A\) cambia de valor. \(X=N_A\) es por lo tanto una variable aleatoria y \(X=n_A\) es su observación.

\textbf{Ejemplos (Algunos experimentos binomiales):}

\begin{itemize}
\item
  Anotamos el sexo de \(n=10\) pacientes que acuden a urgencias de un hospital. ¿Cuál es la probabilidad de que \(9\) (\(X=9\)) pacientes sean hombres cuando \(p=0.8\)?
\item
  Intentamos \(n=5\) veces de dar en un blanco (\(A:éxito\) y \(B:fracaso\)). ¿Cuál es la probabilidad de que alcancemos el objetivo \(5\) (\(X=5\)) veces cuando normalmente lo hacemos el \(25\%\) de las veces (\(p=0.25\))?
\item
  Transmitimos \(n=100\) píxeles correctamente (\(A:sí\) y \(B:no\)). ¿Cuál es la probabilidad de que \(2\) (\(X=2\)) píxeles sean errores, cuando la probabilidad de error es \(p=0.1\)?
\end{itemize}

\hypertarget{funciuxf3n-de-probabilidad-binomial}{%
\section{Función de probabilidad binomial}\label{funciuxf3n-de-probabilidad-binomial}}

Supongamos que \textbf{sabemos} el valor real del parámetro del ensayo de Bernoulli \(p\).

Cuando repetimos un ensayo de Bernoulli y paramos en la repetición número \(n\), ¿el valor \(x\) que obtenemos es un valor común o es raro? ¿cuál es su función de masa de probabilidad \(P(X=x)=f(x)\)?

\textbf{Ejemplo (transmisión de píxeles):}

¿Cuál es la probabilidad de observar errores \(X=x\) al transmitir \(n=4\) píxeles, si la probabilidad de error es \(p\)?

Consideremos que

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  Una variable aleatoria del \textbf{experimento de transmisión} es el vector \[(K_1, K_2, K_3, K_4)\] donde una observación puede ser \((K_1=0, K_2=1, K_3=0, K_4= 1)\) o \((0, 1, 0, 1)\).
\item
  Cada \[K_i \rightarrow Bernoulli(p)\] \(k_i \in \{0, 1\}\)
\item
  \(X=N_A\) se puede calcular como la suma \[X=\sum_{i=1}^4 K_i\] \(x\in \{0,1,2,3,4\}\). Por ejemplo \(X=2\) para el resultado \((0, 1, 0, 1)\).
\end{enumerate}

Ahora veamos las probabilidades del número de \textbf{errores} y luego las generalizaremos.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  ¿Cuál es la probabilidad de observar \(4\) \textbf{errores} (\(X=4\))?
\end{enumerate}

La probabilidad de observar \(4\) errores es la probabilidad de observar un error en \(1^{er}\) \textbf{y} \(2^{o}\) \textbf{y} \(3^{o}\) \textbf{y} \(4 ^{o}\) píxel:

\[P(X=4)=P(1,1,1,1)=p*p*p*p=p^4\]

porque \(K_i\) son \textbf{independientes}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  ¿Cuál es la probabilidad de observar \(0\) \textbf{errores} (\(X=0\))?
\end{enumerate}

La probabilidad de errores \(0\) es la probabilidad conjunta de observar \textbf{ningún error} en \textbf{cualquier} transmisión:

\[P(X=0)=P(0,0,0,0)=(1-p)(1-p)(1-p)(1-p)=(1-p)^4\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  ¿Cuál es la probabilidad de observar \(3\) \textbf{errores}?
\end{enumerate}

La probabilidad de \(3\) errores es la \textbf{suma} de la probabilidad de observar \(3\) errores en \textbf{eventos diferentes}:

\[P(X=3)=P(0,1,1,1)+P(1,0,1,1)+P(1,1,0,1)+P(1,1,1, 0)=4p^3(1-p)^1\]
porque todos estos eventos son \textbf{mutuamente excluyentes}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{3}
\tightlist
\item
  Por lo tanto, la probabilidad de \(x\) \textbf{errores} es
\end{enumerate}

\[
    f(x)= 
\begin{cases}
    1*p^0(1-p)^4,&  x=0 \\
    4*p^1(1-p)^3,&  x=1 \\
    6*p^2(1-p)^2,&  x=2 \\
    4*p^3(1-p)^1,&  x=3 \\
    1*p^4(1-p)^0,&  x=4 \\
\end{cases}
\]

o más en breve

\[f(x)=\binom 4 xp^x(1-p)^{4-x}\]
para \(x=0,1,2,3,4\)

donde \(\binom 4 x\) es el número de \textbf{posibles resultados} (transmisiones de \(4\) píxeles) con \(x\) errores.

\textbf{Definición:}

La función de \textbf{probabilidad binomial} es la función de masa de probabilidad de observar \(x\) resultados de tipo \(A\) en \(n\) ensayos independientes de Bernoulli, donde \(A\) tiene la misma probabilidad \(p\) en cada ensayo.

La función está dada por

\(f(x)=\binom nxp^x(1-p)^{nx}\), \(x=0,1,...n\)

\(\binom nx= \frac{n!}{x!(nx)!}\) se denomina \textbf{coeficiente binomial} y da el número de formas en que se pueden obtener \(x\) eventos de tipo \(A\) en un conjunto de \(n\).

Cuando una variable \(X\) tiene una función de probabilidad binomial decimos que se distribuye binomialmente y escribimos

\[X\rightarrow Bin(n,p)\]

donde \(n\) y \(p\) son parámetros.

Veamos algunas funciones de masa de probabilidad en la familia de modelos paramétricos binomiales:

\includegraphics{_main_files/figure-latex/unnamed-chunk-56-1.pdf}

\textbf{Propiedades:}

Si una variable aleatoria \(X\rightarrow Bin(n,p)\) entonces

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  su media es
\end{enumerate}

\[E(X)=np\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  su varianza es
\end{enumerate}

\[V(X)=np(1-p)\]

Estas propiedades se pueden demostrar por el hecho de que \(X\) es la suma de \(n\) variables de Bernoulli independientes. Por lo tanto,

\(E(X)=E(\sum_{i=1}^n K_i)=np\)

y

\(V(X)=V(\sum_{i=1}^n K_i)=n(1-p)p\)

\textbf{Ejemplo (transmisión de píxeles):}

\begin{itemize}
\item
  El valor esperado para el número de errores en la transmisión de \(4\) píxeles es \(np=4*0.1=0.4\) cuando la probabilidad de error es \(0.1\).
\item
  La varianza es \(n(1-p)p=0.36\)
\item
  ¿Cuál es la probabilidad de observar \(4\) errores?
\end{itemize}

Dado que estamos repitiendo una ensayo de Bernoulli \(n=4\) veces y contando el número de eventos de tipo \(A\) (errores), cuando \(P(A)=p=0.1\) entonces

\[X \rightarrow Bin(n=4, p=0.1)\]
Eso es \[f(x)=\binom 4 x 0.1^x(1-0.1)^{4-x}\]

\(P(X=4)=f(4)=\binom 4 4 0.1^4 0.9^{0}=0.1^4=10^{-4}\)

En R dbinom(4,4,0.1)

\begin{itemize}
\tightlist
\item
  ¿Cuál es la probabilidad de observar \(2\) errores?
\end{itemize}

\(P(X=2)=\binom 4 2 0.1^2 0.9^2=0.0486\)

En R dbinom(2,4,0.1)

\textbf{Ejemplo (encuestas de opinión):}

\begin{itemize}
\tightlist
\item
  ¿Cuál es la probabilidad de observar \textbf{como máximo} \(8\) votantes del partido de gobierno en una encuesta electoral de tamaño \(10\), si la probabilidad de un voto para el partido es de \(0.9\)?
\end{itemize}

Para este caso

\[X \rightarrow Bin(n=10, p=0.9)\]

Eso es \[f(x)=\binom {10} x 0.9^x(0.1)^{4-x}\]

Queremos calcular:
\(P(X\le 8)=F(8)= \sum_{i=1..8} f(x_i)=0.2639011\)

en R pbinom(8,10, 0.9)

\hypertarget{funciuxf3n-de-probabilidad-binomial-negativa}{%
\section{Función de probabilidad binomial negativa}\label{funciuxf3n-de-probabilidad-binomial-negativa}}

Ahora imaginemos que estamos interesados en contar los píxeles bien transmitidos antes de que ocurra un \textbf{número dado} de errores. Digamos que podemos \textbf{tolerar} \(r\) errores en la transmisión.

Nuestro experimento aleatorio ahora es: Repetir las pruebas de Bernoulli hasta que observemos que el resultado \(A\) aparece \(r\) veces.

El resultado del experimento es el número de eventos \(B\) es decir \(n_B=y\).

Estamos interesados en encontrar la probabilidad de observar un número particular de eventos \(B\), \(P(Y=y)\), donde \(Y=N_B\) es la variable aleatoria.

\textbf{Ejemplo (transmisión de píxeles):}

¿Cuál es la probabilidad de observar \(y\) píxeles bien transmitidos (\(B\)) antes de \(r\) errores (\(A\))?

Primero encontremos la probabilidad de \textbf{un} evento de transmisión \textbf{en particular} con \(y\) número de píxeles correctos (\(B\)) y \(r\) número de errores (\(A\)).

\[(0,0,1,., 0,1,...0,1)\]

donde consideramos que hay \(y\) ceros y \(r\) unos. Por lo tanto, observamos \(y\) píxeles correctos en un total de \(y + r\) píxeles.

La probabilidad de este evento es:

\[P(0,0,1,., 0,1,...0,1)=p^r(1-p)^y\]

Recuerda que \(p\) es la probabilidad de error (\(A\)).

¿Cuántos \textbf{eventos de transmisión} pueden tener \(y\) píxeles correctos (0) antes de \(r\) errores (1)?

Ten en cuenta que

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  El último pixel es fijo (marca el final de la transmisión)
\item
  El número total de formas en que \(y\) el número de ceros se puede asignar en \(y + r-1\) píxeles es: \(\binom {y + r-1} y\)
\end{enumerate}

Por lo tanto, la probabilidad de observar \(y\) 1 antes de \(r\) 0 (cada 1 con probabilidad \(p\)) es

\[P(Y=y)=f(y)=\binom {y+r-1} yp^r(1-p)^y\]

para \(y=0,1,...\)

Entonces decimos que \(Y\) sigue una distribución binomial negativa y escribimos

\[Y\rightarrow NB(r,p)\]

donde \(r\) y \(p\) son parámetros que representan la tolerancia y la probabilidad de un solo error (evento \(A\)).

\textbf{Propiedades:}

Una variable aleatoria \(Y\rightarrow NB(r,p)\) tiene

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  media \[E(Y)= r\frac{1-p}{p}\]
\item
  y varianza \[V(Y)= r\frac{1-p}{p^2}\]
\end{enumerate}

Veamos algunas funciones de masa de probabilidad en la familia de modelos paramétricos binomiales negativos:

\includegraphics{_main_files/figure-latex/unnamed-chunk-57-1.pdf}

\textbf{Ejemplo (sitio web)}

Un sitio web tiene tres servidores. Un servidor opera a la vez y solo cuando falla una solicitud se usa otro servidor.

Si se sabe que la probabilidad de que falle una solicitud es \(p=0.0005\), entonces

\begin{itemize}
\tightlist
\item
  ¿Cuál es el número esperado de solicitudes exitosas antes de que las tres computadoras fallen?
\end{itemize}

Ya que estamos repitiendo un ensayo de Bernoulli hasta \(r=3\) se observan eventos de tipo \(A\) (fallo) (cada uno con \(P(A)=p=0.0005\)) y estamos contando el número de eventos de tipo \(B\) (solicitudes exitosas) entonces

\[Y \rightarrow NB(r=3, p=0.0005)\]

Por lo tanto, el número esperado de solicitudes antes de que el sistema falle es:

\(E(Y)=r\frac{1-p}{p}=3\frac{1-0.0005}{0.0005}=5997\)

Ten en cuenta que en realidad hay pruebas de \(6000\).

\begin{itemize}
\tightlist
\item
  ¿Cuál es la probabilidad de observar \(5\) solicitudes exitosas antes de que el sistema falle?
\end{itemize}

\(f(5)=\binom {7} 5 0.0005^3 0.9995^5=2.618444 \times 10^{-9}\)

\begin{itemize}
\tightlist
\item
  ¿Cuál es la probabilidad de tratar con un máximo de \(5\) solicitudes exitosas antes de que el sistema falle?
\end{itemize}

En R esto se calcula con dnbinom(5,3,0.0005)

Por lo tanto, queremos calcular la distribución de probabilidad en \(5\):

\(F(5)=P(Y\leq 5)=\Sigma_{y=0}^5 f(y)\)

\(=\sum_{y=0}^5\binom {y+2} y 0.0005^r0.9995^y\)

\(=\binom{2} 0 0.0005^3 0.9995^0 +\binom{3} 1 0.0005^3 0.9995^1\)

\(+\binom {4} 2 0.0005^3 0.9995^2 +\binom {5} 3 0.0005^3 0.9995^3\)

\(+\binom {6} 4 0.0005^3 0.9995^4 +\binom {7} 5 0.0005^3 0.9995^5\)

\(= 6.9\times 10^{-9}\)

En R esto se calcula con pnbinom(5,3,0.0005)

\textbf{Ejemplos}

\begin{itemize}
\tightlist
\item
  ¿Cuál es la probabilidad de observar \(10\) píxeles correctos antes de \(2\) errores, si la probabilidad de error es \(0.1\)?
\end{itemize}

\(f(10; r=2, p=0.1)=0.03835463\)

en R dnbinom(10, 2, 0.1)

\begin{itemize}
\tightlist
\item
  ¿Cuál es la probabilidad de que entren \(2\) chicas antes que \(4\) chicos entren a clase si la probabilidad de que entre un chico es de \(0.55\)?
\end{itemize}

\(f(2; r=4, p=0.55)=0.1853\)

en R dnbinom(2, 4, 0.55)

\hypertarget{distribuciuxf3n-geomuxe9trica}{%
\section{Distribución geométrica}\label{distribuciuxf3n-geomuxe9trica}}

Llamamos \textbf{distribución geométrica} a la distribución \textbf{binomial negativa} con \(r=1\)

La probabilidad de observar \(B\) eventos antes de observar el \textbf{primer} evento de tipo \(A\) es

\[P(Y=y)=f(y)= p(1-p)^y\]

\[Y\rightarrow Geom(p)\]
que tiene

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  media \[E(Y)= \frac{1-p}{p}\]
\item
  y varianza \[V(Y)= \frac{1-p}{p^2}\]
\end{enumerate}

\hypertarget{modelo-hipergeomuxe9trico}{%
\section{Modelo hipergeométrico}\label{modelo-hipergeomuxe9trico}}

El \textbf{modelo hipergeométrico} surge cuando queremos contar el número de eventos de tipo \(A\) que se extraen de una población finita.

El modelo general es considerar \(N\) bolas totales en una urna. Marquemos \(K\) con la etiqueta \(A\) y \(NK\) con la etiqueta \(B\). Saquemos \(n\) bolas una por una sin reemplazo en la urna y luego contemos cuántos \(A\) obtuvimos.

El modelo \textbf{Binomial} se puede derivar del modelo \textbf{Hipergeométrico} cuando consideramos que \(N\) es infinito, o que cada vez que sacamos una bola la volvemos a colocar en la urna.

\textbf{Ejemplo (varicela):}

Una escuela de \(N=600\) niños tiene una epidemia de varicela. Testamos a \(n=200\) niños y observamos que \(x=17\) dieron positivo. Si supiéramos que un total de \(K=64\) estaban realmente infectados en la escuela, ¿cuál es la probabilidad de nuestra observación?

\textbf{Definición:}

La probabilidad de obtener \(x\) casos (tipo \(A\)) en una muestra de \(n\) extraída de una población de \(N\) donde \(K\) son casos (tipo \(A\)).

\(P(X=x)=P(una\,muestra) \times (Número\, de\, formas\, de\, obteniendo\, x)\)

\[=\frac{1}{\binom N n}\binom K x \binom {NK} {nx}\]

donde \(k \in \{\max(0, n+KN), ... \min(K, n) \}\)

Entonces decimos que \(X\) sigue una distribución hipergeométrica y escribimos

\[X \rightarrow Hipergeom(N,K,n)\]
El modelo hipergeométrico tiene tres parámetros.

\textbf{Propiedades:}

Si \(X \rightarrow Hypergeometric(N,K,n)\) entonces tiene

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  media \[E(X) = n \frac{K}{N} = np\]
\item
  y varianza \[V(X) = np(1-p)\frac{Nn}{N-1}\]
\end{enumerate}

cuando \(p=\frac{K}{N}\) es la proporción de casos (\(A\)) en una población de tamaño \(N\). Ten en cuenta que cuando \(N \rightarrow \infty\) recuperamos las propiedades binomiales.

Veamos algunas funciones de masa de probabilidad en la familia de modelos paramétricos hipergeométricos:

\includegraphics{_main_files/figure-latex/unnamed-chunk-58-1.pdf}

\includegraphics{_main_files/figure-latex/unnamed-chunk-59-1.pdf}

\textbf{Ejemplo (varicela):}

\begin{itemize}
\tightlist
\item
  ¿Cuál es la probabilidad ver como mucho \(17\) casos de varicela en una muestra de \(200\) alumnos de una ecuela de \(600\) alumnos donde \(64\) están infectados?
\end{itemize}

La probabilidad que necesitamos calcular es
\(P(X \leq 17)=F(17)\)

donde \(X \rightarrow Hypergeometric(N=600,K=64,n=200)\)

en R phyper(17, 64, 600-64, 200)=0.140565

La solución es la adición de las agujas azules en el gráfico.

\includegraphics{_main_files/figure-latex/unnamed-chunk-60-1.pdf}

\hypertarget{preguntas-4}{%
\section{Preguntas}\label{preguntas-4}}

\textbf{1)} ¿Cuál es el valor esperado y la varianza del número de fallos en \(100\) prototipos, cuando la probabilidad de un fallo es de \(0.25\)?

\textbf{\(\qquad\)a:} \(0.25\), \(0.1875\);
\textbf{\(\qquad\)b:} \(25\), \(0.1875\);
\textbf{\(\qquad\)c:} \(0.25\), \(18.75\);
\textbf{\(\qquad\)d:} \(25\), \(18.75\)

\textbf{2)} ¿Qué modelo de probabilidad describe mejor el número de mesas disponibles a la hora de la cena en un restaurante?

\textbf{\(\qquad\)a:} Binomial;
\textbf{\(\qquad\)b:} Uniforme;
\textbf{\(\qquad\)c:} Binomial negativo;
\textbf{\(\qquad\)d:} Hipergeométrico

\textbf{3)} El valor esperado de una distribución Binomial no es

\textbf{\(\qquad\)a:} \(n\) veces el valor esperado de un Bernoulli;
\textbf{\(\qquad\)b:} el valor esperado de un Hipergeométrico, cuando la población es muy grande;
\textbf{\(\qquad\)c:} \(np\);
\textbf{\(\qquad\)d:} el límite de la frecuencia relativa cuando el número de repeticiones es grande

\textbf{4)} Las encuestas de opinión para las elecciones de EE. UU. dan una probabilidad de \(0.55\) de que un votante esté a favor del partido republicano. Si realizamos nuestra propia encuesta y preguntamos a 100 personas al azar en la calle, ¿cómo calcularías la probabilidad de que en nuestra encuesta los demócratas ganen las elecciones?

\textbf{\(\qquad\)a:}pbinom(x=49, n=100, p=0.55)=0.13;
\textbf{\(\qquad\)b:}1-pbinom(x=49, n=100, p=0.55)=0.86;
\textbf{\(\qquad\)c:}pbinom(x=51, n=100, p=0.45)=0.90; \textbf{\(\qquad\)d:}1-pbinom(x=51, n=100, p=0.45)=0.095

\textbf{5)} En un examen un alumno cuando no sabe la respuesta elige al azar una de las cuatro respuestas en una pregunta de selección múltiple. Si no sabe \(10\) preguntas, ¿cuál es la probabilidad de que al mas de \(5\) preguntas (\(>5\)) sean correctas?

\textbf{\(\qquad\)a:}dbinom(x=4, n=10, p=0.25); \textbf{\(\qquad\)b:}pbinom(x=4, n=10, p=0.75); \textbf{\(\qquad\)c:}dbinom(x=4, n=10, p=0.75); \textbf{\(\qquad\)d:}1-pbinom(x=4, n=10, p=0.25)

\hypertarget{ejercicios-5}{%
\section{Ejercicios}\label{ejercicios-5}}

\hypertarget{ejercicio-1-4}{%
\subsubsection{Ejercicio 1}\label{ejercicio-1-4}}

Si el 25\% de los tornillo producidos por una máquina son defectuosos, determina la probabilidad de que, de
5 tornillos elegidos al azar

\begin{itemize}
\tightlist
\item
  ningún tornillo sea defectuoso (R:0.2373)
\item
  1 tornillo sea defectuoso (R:0.3955)
\item
  2 tornillos sean defectuosos (R:0.2636)
\item
  como máximo 2 tornillos sean defectuosos (R:0.8964)
\end{itemize}

\hypertarget{ejercicio-2-4}{%
\subsubsection{Ejercicio 2}\label{ejercicio-2-4}}

En una población, la probabilidad de que nazca un niño es \(p=0.51\). Considera una familia de 4 hijos.

\begin{itemize}
\tightlist
\item
  ¿Cuál es la probabilidad de que una familia tenga un solo niño? (R: 0.240)
\item
  ¿Cuál es la probabilidad de que una familia tenga una sola niña? (R: 0.259)
\item
  ¿Cuál es la probabilidad de que una familia tenga solo un niño o solo una niña? (R: 0.4999)
\item
  ¿Cuál es la probabilidad de que la familia tenga por mucho dos niños? (R: 0.6723)
\item
  ¿Cuál es la probabilidad de que la familia tenga al menos dos niños? (R: 0.7023)
\item
  ¿Cuál es el mínimo número de hijos que debe tener una familia para que la probabilidad de tener al menos una niña sea mayor a \(0.75\)?(R:\(n=3 \geq\log(0.25)/\log(0.51)=2.05\))
\end{itemize}

\hypertarget{ejercicio-3-4}{%
\subsubsection{Ejercicio 3}\label{ejercicio-3-4}}

Un motor de búsqueda falla al recuperar información con una probabilidad de \(0.1\)

\begin{itemize}
\item
  Si nuestro sistema recibe \(50\) solicitudes de búsqueda, ¿cuál es la probabilidad de que el sistema no responda a tres de ellas? (R: 0.1385651)
\item
  ¿Cuál es la probabilidad de que el motor complete con éxito \(15\) búsquedas antes del primer fallo? (R:0.020)
\item
  Consideramos que un motor de búsqueda funciona suficientemente bien cuando es capaz de encontrar información como mínimo para \(10\) solicitudes por cada \(2\) fallos. ¿Cuál es la probabilidad de que en un ensayo de fiabilidad nuestro buscador sea satisfactorio? (R: 0.659)
\end{itemize}

\hypertarget{modelos-de-poisson-y-exponencial}{%
\chapter{Modelos de Poisson y Exponencial}\label{modelos-de-poisson-y-exponencial}}

\hypertarget{objetivo-4}{%
\section{Objetivo}\label{objetivo-4}}

En este capítulo veremos dos modelos de probabilidad estrechamente relacionados: los modelos \textbf{Poisson} y \textbf{exponencial}.

El modelo de Poisson es para variables aleatorias discretas, mientras que la función exponencial es para variables aleatorias \textbf{continuas}

\hypertarget{modelos-de-probabilidad-para-variables-discretas}{%
\section{Modelos de probabilidad para variables discretas}\label{modelos-de-probabilidad-para-variables-discretas}}

En el capítulo anterior construimos modelos complejos a partir de modelos simples. En cada etapa, introdujimos algún concepto novedoso:

\textbf{Uniforme}: interpretación clásica de la probabilidad
\(\downarrow\)
\textbf{Bernoulli}: Introducción de un \textbf{parámetro} \(p\) (familia de modelos)
\(\downarrow\)
\textbf{Binomial}: Introducción a la \textbf{Repetición} de un experimento aleatorio (\(n\) ensayos de Bernoulli)
\(\downarrow\)
\textbf{Poisson}: Repetición de un experimento aleatorio dentro de un intervalo continuo, sin \textbf{control} sobre cuándo/dónde ocurre el ensayo de Bernoulli.

El último modelo es para procesos de Poisson que describen la repetición de un experimento aleatorio con la aleatoriedad adicional del momento en que la repeticiones se producen.

\hypertarget{experimento-de-poissson}{%
\section{Experimento de Poissson}\label{experimento-de-poissson}}

Imagina que estamos observando eventos que \textbf{dependen} de \textbf{intervalos} de tiempo o distancia.

Por ejemplo:

\begin{itemize}
\tightlist
\item
  coches que llegan a un semáforo
\item
  mensajes que recibimos en el teléfono móvil
\item
  impurezas que ocurren al azar en un alambre de cobre
\end{itemize}

Supongamos que los eventos son resultados de ensayos de Bernoulli \textbf{independientes}, cada uno de los cuales aparece aleatoriamente en un intervalo continuo, y queremos \textbf{contarlos}.

¿Cuál es la probabilidad de observar \(X\) eventos en una unidad de intervalo (tiempo o distancia)?

\textbf{Ejemplo (Impurezas en un alambre):}

Imaginemos que algunas impurezas se depositan al azar a lo largo de un cable de cobre. Quieremos contar el número de impurezas en un centímetro de alambre (\(X\)).

Considera que sabemos que en promedio hay \(10\) impurezas por centímetro \(\lambda=10/cm\).

¿Cuál es la probabilidad de observar \(X=5\) impurezas en una muestra de un centímetro en particular?

\hypertarget{funciuxf3n-de-masa-de-probabilidad-de-poisson}{%
\section{Función de masa de probabilidad de Poisson}\label{funciuxf3n-de-masa-de-probabilidad-de-poisson}}

Para calcular la función masa de probabilidad \(f(x)=P(X=x)\) del ejemplo anterior dividimos el centímetro en micrómetros (\(0.0001cm\)).

Los micrómetros son lo suficientemente pequeños como para

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  que hay ao no haya una impureza en cada micrómetro
\item
  cada micrómetro se pueda considerar como un \textbf{ensayo de Bernoulli}
\end{enumerate}

\includegraphics{./figures/Pois.JPG}

\textbf{De la función binomial a la función de probabilidad de Poisson}

La probabilidad de observar \(X\) impurezas en \(n=10,000\mu\) (1cm) sigue aproximadamente una distribución binomial

\[f(x) \sim \binom nxp^x(1-p)^{nx}\]

donde \(p\) es la probabilidad de encontrar una impureza en un micrómetro.

Dado que el valor esperado de una variable Binomial es \(E(X)=np\). Este es el número promedio de impurezas por 1 cm o \(\lambda=np\). Por lo tanto, sustituimos \(p=\lambda/n\)

\[f(x) \sim \binom nx \big(\frac{\lambda}{n}\big)^x(1-\frac{\lambda}{n})^{nx}\]

Dado que \textbf{podría} haber todavía dos impurezas en un micrómetro, necesitamos aumentar la partición del alambre y \(n \rightarrow \infty\).

Luego en el límite:

\[f(x)= \frac{e^{-\lambda}\lambda^x}{x!}\]

Donde \(\lambda\) es constante porque es la densidad de impurezas por centímetro, una \textbf{propiedad física} del sistema. \(\lambda\) es por lo tanto el \textbf{parámetro} del modelo de probabilidad.

\textbf{Detalles de la derivación:}

Para \(f(x) \sim \binom nx \big(\frac{\lambda}{n}\big)^x(1-\frac{\lambda}{n})^{nx}\)

en el límite (\(n \rightarrow \infty\))

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  \(\frac{1}{n^x}\binom n x =\frac{1}{n^x}\frac{n!}{x! (n-x)!}=\frac{(n-x)!(n-x+1)...(n-1)n}{n^x x! (n-x)!}=\frac{n(n-1)..(n-x+1)}{n^x x!} \rightarrow \frac{1}{x!}\)
\item
  \((1-\frac{\lambda}{n})^{n} \rightarrow e^{-\lambda}\) (definition of exponential)
\item
  \((1-\frac{\lambda}{n})^{-x} \rightarrow 1\)
\end{enumerate}

Poniendo todo junto entonces:

\(f(x)= \frac{e^{-\lambda}\lambda^x}{x!}\)

\textbf{Definición}

Dado

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  un intervalo en los números reales
\item
  hay eventos que ocurren al azar en el intervalo
\item
  se conoce el número promedio de eventos en el intervalo (\(\lambda\))
\item
  si se puede encontrar una pequeña partición regular del intervalo tal que en cada partición la podamos considerar como un ensayo de Bernoulli.
\end{enumerate}

Entonces, la variable aleatoria \(X\) que cuenta eventos a lo largo del intervalo es una variable \textbf{Poisson} con función de masa de probabilidad
\[f(x)= \frac{e^{-\lambda}\lambda^x}{x!}, \lambda>0\]

\textbf{Propiedades:}
Cuando \(X \rightarrow Poiss(\lambda)\) tiene

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  media \[E(X)= \lambda\]
\item
  y varianza \[V(X)= \lambda\]
\end{enumerate}

\textbf{Ejemplos}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  ¿Cuál es la probabilidad de recibir 4 correos electrónicos en una hora, cuando el promedio de correos electrónicos en una hora es de \(1\)?
\end{enumerate}

Tenemos que la varible es de Poisson: \(X \rightarrow Poiss(\lambda)\) con \(\lambda=1\) y su función de masa de probabilidad es:

\[f(x)= \frac{e^{-1}1^x}{x!}\]
Por lo tanto la probabilidad de que la variable tome valor 4 es \(P(X=4)\):

\(f(4; \lambda=1)= \frac{e^{-1}1^4}{4!}=0.01532831\)

in R dpois(4,1)

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  ¿Cuál es la probabilidad de recibir 4 correos electrónicos en \textbf{tres horas}, cuando el promedio de correos electrónicos en una hora es de \(1\)?
\end{enumerate}

La unidad sobre la cual hacemos los conteos ha cambiado de 1 hora a 2 horas, por lo tanto tenemos que \textbf{re-escalar} \(\lambda\). Si antes el promedio de correos era \(\lambda=1\) en una hora, el promedio de correos en tres horas es ahora 3: \(\lambda_{3h}=3\lambda_{1h}=3*1=3\)

Tenemos que la varible es de Poisson: \(X \rightarrow Poiss(\lambda_{3h})\) con \(\lambda_{3h}=3\) y su función de masa de probabilidad es:

\[f(x)= \frac{e^{-3}3^x}{x!}\]
Por lo tanto la probabilidad de que la variable tome valor 4 es \(P(X=4)\):

\(f(4; \lambda=3)= \frac{e^{-3}3^4}{4!}=0.1680314\)

in R dpois(4,3)

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  ¿Cuál es la probabilidad de contar \textbf{al menos} \(10\) automóviles que llegan a un peaje en un minuto, cuando el promedio de automóviles que llegan a un peaje en un minuto es de \(5\);
\end{enumerate}

Tenemos que la varible es de Poisson: \(X \rightarrow Poiss(\lambda)\) con \(\lambda=5\) y su función de masa de probabilidad es:

\[f(x)= \frac{e^{-5}5^x}{x!}\]

\(P(X\geq 10)=1-P(X < 10)=1-P(X \leq 9)=1-F(9; \lambda=5)=1-\sum_{x=0, ...10}f(x; \lambda=5)=0.03182806\)

en R 1-ppois(9,5)

Veamos algunas funciones de masa de probabilidad en la familia de modelos paramétricos de Poisson:

\includegraphics{_main_files/figure-latex/unnamed-chunk-61-1.pdf}

\hypertarget{modelos-de-probabilidad-para-variables-continuas}{%
\section{Modelos de probabilidad para variables continuas}\label{modelos-de-probabilidad-para-variables-continuas}}

Los modelos de probabilidad para variables continuas son \textbf{funciones de densidad} de probabilidad \(f(x)\) que \textbf{creemos} describen experimentos aleatorios reales.

La función de densidad de probabilidad \(f(x)\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  es positiva
\end{enumerate}

\[f(x) \geq 0\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  nos permite calcular probabilidades usando el área bajo la curva:
\end{enumerate}

\[P(a\leq X \leq b)=\int_{a}^{b} f(x) dx\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  es tal que la probabilidad de que obtengamos cualquier resultado es \(1\):
\end{enumerate}

\[\int_{-\infty}^{\infty} f(x) dx = 1\]

\hypertarget{experimento-exponencial}{%
\section{Experimento exponencial}\label{experimento-exponencial}}

Volvamos a un \textbf{proceso de Poisson} definido por la probabilidad

\[f(k)=\frac{e^{-\lambda}\lambda^k}{k!}, \lambda>0\]

para el número de eventos (\(k\)) en un intervalo.

Consideremos ahora que estamos interesados en la duración/tiempo que debemos esperar hasta que ocurra el \textbf{primer} conteo.

Podemos preguntarnos por la probabilidad de que el primer evento ocurra después de la duración/tiempo \(X\).

Por lo tanto, dado que \(X\) es una variable aleatoria \textbf{continua}, buscamos su función de densidad de probabilidad \(f(x)\).

\hypertarget{densidad-de-probabilidad-exponencial}{%
\section{Densidad de probabilidad exponencial}\label{densidad-de-probabilidad-exponencial}}

La probabilidad de \(0\) eventos \textbf{si} un intervalo tiene unidad \(x\) (rescalando como en el ejemplo 2) es

\[f(0|x)=\frac{e^{-x\lambda}(x\lambda)^0}{0!}\]

o

\[f(0|x)=e^{-x\lambda}\]

Podemos tratar esto como la probabilidad condicional de \(0\) eventos dada una distancia \(x\): \(f(K=0|X=x)\) y aplicar el teorema de Bayes para invertirlo:

\[f(x|0)=C f(0|x)=C e^{-x\lambda}\]

Esta es la \textbf{probabilidad de observar una distancia} \(x\) para \(0\) eventos. Esta es la distancia hasta el primer evento.

\textbf{Definición}

En un proceso de Poisson con parámetro \(\lambda\) la probabilidad de esperar una distancia/tiempo \(X\) entre dos conteos viene dada por la \textbf{densidad de probabilidad}

\[f(x)= C e^{-x\lambda}\]

\begin{itemize}
\item
  \(C\) es una constante que asegura: \(\int_{-\infty}^{\infty} f(x) dx =1\)
\item
  por integración \(C=\lambda\)
\end{itemize}

Por lo tanto:

\[f(x)=\lambda e^{-\lambda x}, x\geq 0\]

\(\lambda\) es el parámetro del modelo, también conocido como \textbf{tasa de decaimiento}.

\textbf{Propiedades:}

Cuando \(X \rightarrow Exp(\lambda)\) entonces

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  tiene media
\end{enumerate}

\[E(X)=\frac{1}{\lambda}\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  y varianza
  \[V(Y)=\frac{1}{\lambda^2}\]
\end{enumerate}

Veamos un par de densidades de probabilidad en la familia exponencial

\includegraphics{_main_files/figure-latex/unnamed-chunk-62-1.pdf}

\hypertarget{distribuciuxf3n-exponencial}{%
\section{Distribución exponencial}\label{distribuciuxf3n-exponencial}}

Consideremos las siguientes preguntas:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  En un proceso de Poisson ¿Cuál es la probabilidad de observar un intervalo \textbf{menor} que \(a\) hasta el primer evento?
\end{enumerate}

Recuerda que esta probabilidad \(F(a)=P(X \leq a)\) es la densidad de probabilidad

\[F(a)=\lambda\int_\infty^ae^{-x\lambda}dx=1-e^{-a\lambda}\]
2) En un proceso de Poisson ¿Cuál es la probabilidad de observar un intervalo \textbf{mayor} que \(a\) hasta el primer evento?

\[P(X > a)=1- P(X \leq a)= 1- F(a) = e^{-a\lambda}\]

Veamos un par de distribuciones exponenciales de la familia exponencial

\includegraphics{_main_files/figure-latex/unnamed-chunk-63-1.pdf}

La mediana \(x_m\) es tal que \(F(x_m)=0.5\). Eso es \(x_m=\frac{\log(2)}{\lambda}\)

\textbf{Ejemplos}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  ¿Cuál es la probabilidad de que tengamos que esperar un bus por más de \(1\) hora cuando en promedio hay dos buses por hora?
\end{enumerate}

\[P(X > 1)=1-P(X \le 1) = 1-F(1,\lambda=2)=0.1353353\]

En R 1-pexp(1,2)

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  ¿Cuál es la probabilidad de tener que esperar menos de \(2\) segundos para detectar una partícula cuando la tasa de desintegración radiactiva es de \(2\) partículas por segundo; \(F(2,\lambda=2)\)
\end{enumerate}

\[P(X\le 2)=F(2,\lambda=2)=0.9816844\]

En R pexp(2,2)

\hypertarget{preguntas-5}{%
\section{Preguntas}\label{preguntas-5}}

\textbf{1)} Durante la Segunda Guerra Mundial, en un día de bombardeo sobre Londres, el valor eperado de que cayera una bomba en \(1.5km^2\) era de \(0.92\). La probabilidad de que en Hyde Park, de área aproximadamente \(1.5km^2\), cayeran como mucho dos bombas era de

\textbf{\(\qquad\)a:}1-ppois(x=2, lambda=0.92);
\textbf{\(\qquad\)b:}ppois(x=2, lambda=0.92); \textbf{\(\qquad\)c:}1-dpois(x=2, lambda=0.92); \textbf{\(\qquad\)d:}dpois(x=2, lambda=0.92)

\textbf{2)} La probabilidad de que un pasajero tenga que esperar menos de 20 minutos hasta que llegue el próximo taxi a su parada está mejor descrita por

\textbf{\(\qquad\)a:} Un modelo de Poisson sobre el número de taxis que pasan cada 20 minutos;
\textbf{\(\qquad\)b:} Una distribución exponencial con \(\lambda=1/20\) ;
\textbf{\(\qquad\)c:} Un modelo binomial que cuenta el número de taxis cada 20 minutos
\textbf{\(\qquad\)d:} Una distribución uniforme entre 0 y 20 minutos;

\textbf{3)} A partir de la distribución de probabilidad exponencial de la siguiente figura, ¿cuál es el valor más posible de la mediana?

\textbf{\(\qquad\)a:} \(2\); \textbf{\(\qquad\)b:} \(3\); \textbf{\(\qquad\)c:} \(4\); \textbf{\(\qquad\)d:} \(5\)

\includegraphics{./figures/exp.png}

\hypertarget{ejercicios-6}{%
\section{Ejercicios}\label{ejercicios-6}}

\hypertarget{ejercicio-1-5}{%
\subsubsection{Ejercicio 1}\label{ejercicio-1-5}}

El promedio de llamadas telefónicas por hora que ingresan a la centralita de una empresa es de \(150\). Encuentra la probabilidad de que durante un minuto en particular haya

\begin{itemize}
\tightlist
\item
  0 llamadas telefónicas (R:0.082)
\item
  1 llamada telefónica (R:0.205)
\item
  4 o menos llamadas (R:0.891)
\item
  más de 6 llamadas telefónicas (R:0.0141)
\end{itemize}

\hypertarget{ejercicio-2-5}{%
\subsubsection{Ejercicio 2}\label{ejercicio-2-5}}

La cantidad promedio de partículas radiactivas que golpean un contador Geiger en una planta de energía nuclear bajo control es de \(2.3\) por minuto.

\begin{itemize}
\item
  ¿Cuál es la probabilidad de contar exactamente \(2\) partículas en un minuto? (R:0.265)
\item
  ¿Cuál es la probabilidad de detectar exactamente \(10\) partículas en \(5\) minutos? (R:0.112)
\item
  ¿Cuál es la probabilidad de al menos un conteo en dos minutos? (R:0.9899)
\item
  ¿Cuál es la probabilidad de tener que esperar menos de \(1\) segundo para detectar una partícula radiactiva, después de encender el detector? (R:0.037)
\item
  Sospechamos que una planta nuclear tiene una fuga radiactiva si esperamos menos de \(1\) segundo para detectar una partícula radiactiva, después de encender el detector. ¿Cuál es la probabilidad de que cuando visitemos \(5\) plantas que están bajo control, sospechemos que al menos una tiene una fuga? (R:0.1744).
\end{itemize}

\hypertarget{distribuciuxf3n-normal}{%
\chapter{Distribución normal}\label{distribuciuxf3n-normal}}

\hypertarget{objetivo-5}{%
\section{Objetivo}\label{objetivo-5}}

En este capítulo introduciremos la distribución de probabilidad normal.

Hablaremos de su origen y de sus principales propiedades.

\hypertarget{historia}{%
\section{Historia}\label{historia}}

En 1801, Gauss analizó los datos obtenidos sobre la posición de Ceres, un gran asteroide entre Marte y Júpiter.

En ese momento, la gente sospechaba que era un nuevo planeta, ya que se movía día a día contra las estrellas fijas. En enero, se podía ver en el horizonte justo antes del amanecer. Sin embargo, a medida que pasaban los días, Ceres salía cada vez más tarde hasta que ya no se pudo ver más debido a la salida del Sol.

Gauss entendió que las medidas para la posición de Ceres tenían errores.

Por lo tanto, estaba interesado en descubrir cómo se \textbf{distribuían} las observaciones para poder encontrar la órbita más \textbf{probable}. Con la órbita, podía derivar la masa del objeto y luego decidir si era un planeta o sólo un gran asteroide.

Los datos estaban disponibles sólo para el mes de enero. Después de lo cual Ceres desaparecería. Quería \textbf{predecir} hacia dónde deberían apuntar los astrónomos sus telescopios para encontrarlo seis meses después al anochecer, una vez que hubiera pasado por detrás del Sol.

Gauss tuvo que dar cuenta de los errores en la posición de ceres en un día determinado debido a la medición

\includegraphics{./figures/ceres.JPG}

Gauss supuso que

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  los errores pequeños eran más probables que los errores grandes
\item
  el error a una distancia \(-\epsilon\) del varlor en la posición de Ceres era igualmente probable que una distancia \(\epsilon\)
\item
  la pisición más \textbf{verosimil} (que nos creemos más) de Ceres en un momento dado en el cielo era el \textbf{promedio} de múltiples mediciones de altitud en esa latitud.
\end{enumerate}

Eso fue suficiente para mostrar que las desviaciones de las observaciones \(y\) \textbf{de la órbita} satisfacian la ecuación

\[\frac{df(y)}{dy}=-Cyf(y)\]
con \(C\) una costante positiva. La solución de esta ecuación diferencial es:

\[f(y)=\frac{\sqrt{C}}{\sqrt{2\pi}}e^{-\frac{Cy^2}{2}}\]

*The evolution of the normal distribution, Saul Stahl, Mathemetics Magazine, 2006.

\hypertarget{densidad-normal}{%
\section{Densidad normal}\label{densidad-normal}}

Densidad de probabilidad de Gauss da la distribución de los errores de medición desde la posición \textbf{real} pero \textbf{desconocida} de Ceres en el cielo. Hagamos un par de cambios en la función.

1- Escribamos la densidad de errores desde el horizonte usando la variable aleatoria \(X\), o sea \(y=x-\mu\). \(\mu\) es la posición \textbf{real} pero \textbf{desconocida} de Ceres desde el horizonte. Después de un cambio de variable encontramos la función de densidad de probabilidad:

\[f(x)=\frac{\sqrt{C}}{\sqrt{2\pi}}e^{-C(x-\mu)^2}\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  Cambiemos de nombre la variable \(C\) por \(\frac{1}{\sigma^2}\)
\end{enumerate}

Entonces, llegamos a la siguente definición.

\hypertarget{definiciuxf3n}{%
\section{Definición}\label{definiciuxf3n}}

Una variable aleatoria \(X\) definida en los números reales tiene una densidad \textbf{Normal} si toma la forma

\[f(x; \mu, \sigma^2)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}, x \in {\mathbb R}\]

La variable tiene

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  media
\end{enumerate}

\[E(X) = \mu\]

que para Gauss representaba la posición real de Ceres.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  y varianza
  \[V (X) = \sigma^2\]
\end{enumerate}

que representaba la dispersión del error en las observaciones, que depende de la calidad del telescopio.

\(\mu\) y \(\sigma\) son los \textbf{dos parámetros} que describen completamente la función de densidad normal y su \textbf{interpretación} depende del experimento aleatorio.

Cuando \(X\) sigue una densidad Normal, es decir, se distribuye normalmente, escribimos

\[X\rightarrow N(\mu,\sigma^2)\]

Veamos algunas densidades de probabilidad en el modelo paramétrico normal

\includegraphics{_main_files/figure-latex/unnamed-chunk-64-1.pdf}

\hypertarget{distribuciuxf3n-de-probabilidad-2}{%
\section{Distribución de probabilidad}\label{distribuciuxf3n-de-probabilidad-2}}

La distribución de probabilidad de la densidad Normal:

\[F(a)=P(Z \leq a)\]

es la función de \textbf{error} definida por el área bajo la curva de \(-\infty\) a \(a\)

\[F(a)=\int_{-\infty}^{a}\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu) ^2}{2\sigma^2}} dx\]
La función se encuentra en la mayoría de los programas de computadora y no tiene una forma cerrada de funciones conocidas.

\textbf{Ejemplo (altura de mujeres)}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  ¿Cuál es la probabilidad de que una mujer de la población tenga una altura máxima de \(150 cm\) si las mujeres tienen una altura media de \(165 cm\) con una desviación estándar de \(8 cm\)?
\end{enumerate}

\(P(X\le 150)=F(150, \mu=165, \sigma=8)=0.03039636\)

en R pnorm(150, 165, 8)

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  ¿Cuál es la probabilidad de que la altura de una mujer en la población esté entre \(165cm\) y \(170cm\)?
\end{enumerate}

\(P(165 \le X \le 170)=F(170, \mu=165, \sigma=8)-F(165, \mu=165, \sigma=8)=0.2340145\)

en R pnorm(170, 165, 8)-pnorm(165, 165, 8)

Veamos la función de distribución de probabilidad

\includegraphics{_main_files/figure-latex/unnamed-chunk-65-1.pdf}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  ¿Cuál es el primer cuartíl para altura de las mujeres?
\end{enumerate}

El primer cuartíl se define como:

\(F(x_{0.25}, \mu=165, \sigma=8)=0.25\)

o

\(x_{0.25}=F^{-1}(0.25, \mu=165, \sigma=8)=159.6041\)

en R qnorm(0.25, 165, 8)

\textbf{Propiedades de la distribución Normal}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  la media \(\mu\) es también la mediana ya que divide las medidas en dos
\item
  Los valores de \(x\) que caen más allá de 2\(\sigma\) se consideran \textbf{raros} \(5\%\)
\item
  Los valores de \(x\) que caen más allá de 3\(\sigma\) se consideran \textbf{extremadamente raros} \(0.2\%\)
\end{enumerate}

\includegraphics{./figures/probs.png}

\textbf{Ejemplo (altura de mujeres)}

Podemos definir los límites de \textbf{observaciones comunes} para la distribución de la altura de las mujeres en la población.

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  a una distancia de una desviación estándar de la media, encontramos \(68\%\) de la población
\end{enumerate}

\[P(165-8 \leq X \leq 165+8)=P(157 \leq X \leq 173)=F(173)-F(157)=0.68\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  a una distancia de dos desviaciones estándar de la media, encontramos \(95\%\) de la población
\end{enumerate}

\[P(165-2 \times 8 \leq X \leq 165+2\times 8)=F(181)-F(149)=0.95\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  a una distancia de tres desviaciones estándar de la media, encontramos \(99.7\%\) de la población
\end{enumerate}

\[P(165-3 \times 8 \leq X \leq 165+3\times 8)=F(189)-F(141)=0.997\]

\includegraphics{_main_files/figure-latex/unnamed-chunk-66-1.pdf}

\hypertarget{densidad-normal-estuxe1ndar}{%
\section{Densidad normal estándar}\label{densidad-normal-estuxe1ndar}}

La densidad normal estándar es la densidad particular de la familia normal

\[f(x; \mu, \sigma^2)=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}, x \in {\mathbb R}\]

Por lo tanto, es la densidad con

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  media
\end{enumerate}

\[E(X)= \mu = 0\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  y varianza
\end{enumerate}

\[V (X)= \sigma^2 =1\]

Cuando una variable aleatoria sigue una densidad de probabilidad normal, decimos que se distribuye normalmente y escribimos

\[X \rightarrow N(0,1)\]

\hypertarget{distribuciuxf3n-estuxe1ndar}{%
\section{Distribución estándar}\label{distribuciuxf3n-estuxe1ndar}}

La distribución estándar es:

\[\phi(a)=F_{N(0,1)}(a)=P(Z \leq a)\]

es la función \textbf{error} definida por

\[\phi(a)=\int_{-\infty}^{a} \frac{1}{\sqrt{2\pi}}e^{-\frac{z^2}{2}} dz\]

Debido a que la distribución estándar es especial y aparecerá con frecuencia, usamos la letra \(\phi\) para ello.

\includegraphics{./figures/st.png}

Puedes encontrarla en la mayoría de los programas de computadora. En R es pnorm(x) con los parámetros predeterminados, 0 y 1.

Normalmente definimos los límites de las \textbf{observaciones más comunes} para la variable estándar

\includegraphics{./figures/phi.JPG}

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  El rango intercuartílico \[P(-0.67 \leq X \leq 0.67)=0.50\]
\end{enumerate}

en R: c(qnorm(0.25), qnorm(0.75))

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{1}
\tightlist
\item
  El rango del \(95\%\) \[P(-1.96 \leq X \leq 1.96)=0.95\]
\end{enumerate}

en R: c(qnorm(0.025), qnorm(0.975))

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\setcounter{enumi}{2}
\tightlist
\item
  El rango del \(99\%\) \[P(-2.58 \leq X \leq 2.58)=0.99\]
\end{enumerate}

en R: c(qnorm(0.005), qnorm(0.995))

\includegraphics{_main_files/figure-latex/unnamed-chunk-67-1.pdf}

\hypertarget{estandarizaciuxf3n}{%
\section{Estandarización}\label{estandarizaciuxf3n}}

Todas las variables normales se pueden \textbf{estandarizar}. Esto significa que si \(X \rightarrow N(\mu, \sigma^2)\), entonces podemos transformar la variable a
una \textbf{variable estandarizada}

\[Z=\frac{X-\mu}{\sigma}\]

que tendrá densidad:

\[f(z)=\frac{1}{ \sqrt{2\pi}}e^{-\frac{z^2}{2}}\]
Por lo tanto, para cualquier \(X \rightarrow N(\mu, \sigma^2)\)

\[Z=\frac{X-\mu}{\sigma} \rightarrow N(0, 1) \]

\includegraphics{./figures/stand.png}

Puedes demostrar esto reemplazando \(x=\sigma z+\mu\) y \(dx=\sigma dz\) en la expresión de probabilidad que tenemos

\(P(x\leq X \leq x +dx)=P(z\leq Z \leq z +dz)\)
\[=\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}dx\] \[=\frac{1}{ \sqrt{2\pi}}e^{-\frac{z^2}{2}} dz\]

La probabilidad de \textbf{cualquier variable normal} \(X\rightarrow N(\mu, \sigma^2)\) se puede calcular usando la distribución estándar

\(F(a)=P(X<a)=P(\frac{X-\mu}{\sigma}<\frac{a-\mu}{\sigma})\)
\[=P(Z < \frac{a-\mu}{\sigma})= \phi \big(\frac{a-\mu}{\sigma}\big)\]

Para calcular \(P(a\leq X \leq b)\), usamos la propiedad de las distribuciones de probabilidad

\(F(b)-F(a)=P(X\leq b)-P(X\leq a)\)

\[=\phi \big(\frac{b-\mu}{\sigma}\big)-\phi \big(\frac{a-\mu}{\sigma}\big)\]

\hypertarget{resumen-de-modelos-de-probabilidad}{%
\section{Resumen de modelos de probabilidad}\label{resumen-de-modelos-de-probabilidad}}

\begin{longtable}[]{@{}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1905}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1905}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1667}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1429}}
  >{\centering\arraybackslash}p{(\columnwidth - 10\tabcolsep) * \real{0.1429}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\centering
Modelo
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
X
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
rango de x
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
f(x)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
E(X)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
V(X)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Uniforme & número entero o real & \([a,b]\) & \(\frac{1}{n}\) & \(\frac{b+a}{2}\) & \(\frac{(b-a+1)^2-1}{12}\) \\
Bernoulli & evento A (1) & 0,1 & \((1-p)^{1-x}p^x\) & \(p\) & \(p(1-p)\) \\
Binomial & \# de eventos A en \(n\) repeticiones de ensayos de Bernoulli & 0,1,\ldots{} & \(\binom nx (1-p)^{nx}p^x\) & \(np\) & \(np(1-p)\) \\
Binomial negativo para eventos & \# de eventos B (0) en repeticiones de Bernoulli antes de \(r\) eventos A (1) & 0,1,.. & \(\binom {x+r-1} x (1-p)^xp^r\) & \(\frac{r(1-p)}{p}\) & \(\frac{r(1-p)}{p^2}\) \\
Hipergeométrico & \# de eventos A en una muestra \(n\) de la población \(N\) con \(K\) numero de As & \(\max(0, n+KN)\), \ldots{} \(\min(K, n)\) & \(\frac{1}{\binom N n}\binom K x \binom {N-K} {n-x}\) & \(n*\frac{N}{K}\) & \(n \frac{N}{K} (1-\frac{N}{K})\frac{Nn}{N-1}\) \\
Poisson & \# de eventos A en un intervalo & 0,1, .. & \(\frac{e^{-\lambda}\lambda^x}{x!}\) & \(\lambda\) & \(\lambda\) \\
Exponencial & Intervalo entre dos eventos A & \([0,\infty)\) & \(\lambda e^{-\lambda x}\) & \(\frac{1}{\lambda}\) & \(\frac{1}{\lambda^2}\) \\
Normal & medida con errores simétricos cuyo valor más probable es la media & \((-\infty, \infty)\) & \(\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2 }}\) & \(\mu\) & \(\sigma^2\) \\
\end{longtable}

\hypertarget{funciones-r-de-modelos-de-probabilidad}{%
\section{Funciones R de modelos de probabilidad}\label{funciones-r-de-modelos-de-probabilidad}}

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}
  >{\centering\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.3333}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
modelo
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
R f(x)
\end{minipage} & \begin{minipage}[b]{\linewidth}\centering
R F(x)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Uniforme (continuo) & dunif(x, a, b) & punif(x, a, b) \\
Binomial & dbinom(x,n,p) & pbimon(x,n,p) \\
Binomial negativo para eventos & dnbinom(x,r,p) & pnbinom(x,r,p) \\
Hipergeométrico & dhyper(x, K, N-K, n) & phyper(x, K, N-K, n) \\
Poisson & dpois(x, lambda) & ppois(x, lambda) \\
Exponencial & dexp(x, lambda) & pexp(x, lambda) \\
normales & dnorm(x, mu, sigma) & pnomr(x, mu, sigma) \\
\end{longtable}

\hypertarget{preguntas-6}{%
\section{Preguntas}\label{preguntas-6}}

\textbf{1)} Para una variable normal estándar

\textbf{\(\qquad\)a:} \(50\%\) de sus observaciones están entre \((-0.67,0.67)\);
\textbf{\(\qquad\)b:} \(2\%\) de sus observaciones son inferiores a \(-2.58\);
\textbf{\(\qquad\)c:} \(5\%\) de sus observaciones son superiores a \(1.96\);
\textbf{\(\qquad\)d:} \(25\%\) de sus observaciones están entre \((-1.96,-0.67)\)

\textbf{2)} si sabemos que \(\phi(-0.8416212)=0.2\) entonces que es \(\phi(0.8416212)\)

\textbf{\(\qquad\)a:} \(0.1\);
\textbf{\(\qquad\)b:} \(0.2\);
\textbf{\(\qquad\)c:} \(0.8\);
\textbf{\(\qquad\)d:} \(0.9\)

\textbf{3)} el tercer cuartil de una variable normal con media \(10\) y desviación estándar \(2\) es

\textbf{\(\qquad\)a:} qnorm(1/3, 10, 2)=9.138545;
\textbf{\(\qquad\)b:} qnorm(1-0.75, 10, 2)=8.65102 ;
\textbf{\(\qquad\)c:} qnorm(1-1/3, 10, 2)=10.86145 ;
\textbf{\(\qquad\)d:} qnorm(0.75, 10, 2)= 11.34898

\textbf{4)} la probabilidad de que una variable normal con media \(10\) y desviación estándar \(2\) esté en \((-\infty,10)\) es

\textbf{\(\qquad\)a:} 0.25;
\textbf{\(\qquad\)b:} 0.5;
\textbf{\(\qquad\)c:} 0.75;
\textbf{\(\qquad\)d:} 1:

\textbf{5)} No es cierto que para una variable normal estándar

\textbf{\(\qquad\)a:} su media y mediana son iguales; \textbf{\(\qquad\)b:} la distribución de probabilidad estándar se puede utilizar para calcular sus probabilidades; \textbf{\(\qquad\)c:} su rango intercuartílico es el doble de su desviación estándar; \textbf{\(\qquad\)d:} \(5\%\) de sus observaciones están a una distancia desde \(0\) mas grande que su desviación estándar

\hypertarget{ejercicios-7}{%
\section{Ejercicios}\label{ejercicios-7}}

\hypertarget{ejercicio-1-6}{%
\subsubsection{Ejercicio 1}\label{ejercicio-1-6}}

Encuentra el área bajo la curva normal estándar en los siguientes casos:

\begin{itemize}
\tightlist
\item
  Entre \(z=0.81\) y \(z=1.94\) (R:0.182)
\item
  A la derecha de \(z=-1.28\) (R:0.899)
\item
  A la derecha de \(z=2.05\) o a la izquierda de \(z=-1.44\) (R:0.0951)
\end{itemize}

\hypertarget{ejercicio-2-6}{%
\subsubsection{Ejercicio 2}\label{ejercicio-2-6}}

\begin{itemize}
\item
  ¿Cuál es la probabilidad de que la altura de un hombre sea al menos
  \(165\)cm si la media poblacional es \(175\)cm y la desviación estándar es \(10\)cm? (R:0.841)
\item
  ¿Cuál es la probabilidad de que la altura de un hombre esté entre
  \(165\)cm y \(185\)cm? (R:0.682)
\item
  ¿Cuál es la altura que define el \(5\%\) de los hombres más pequeños? (R:158.55)
\end{itemize}

\hypertarget{distribuciones-de-muestreo}{%
\chapter{Distribuciones de muestreo}\label{distribuciones-de-muestreo}}

\hypertarget{objetivo-6}{%
\section{Objetivo}\label{objetivo-6}}

En este capítulo, vamos a estudiar las estimaciones de la media y la varianza de las distribuciones normales utilizando \textbf{muestras aleatorias}.

Introduciremos la \textbf{media muestral} y la \textbf{varianza muestral} como variables aleatorias que estiman los parámetros de la distribución normal.

La media muestral y la varianza muestral tienen funciones de densidad de probabilidad, estas se denominan \textbf{funciones de densidad muestral}.

\hypertarget{muestra-aleatoria}{%
\section{Muestra aleatoria}\label{muestra-aleatoria}}

\textbf{Ejemplo (Cables)}

Imagina que un cliente le pide a tu empresa metalúrgica que le venda cables a \(8\) que pueden transportar hasta \(96\) Toneladas; eso es \(12\) Toneladas cada uno. Debes garantizar que ninguno de ellos romperá con este peso.

Tienes en \textbf{existencia} un conjunto de cables que podrían servir, pero no estás seguro. Por lo que tomas \(8\) cables aleatoriamente, y los cargas hasta que se rompen.

Decimos que tomas una \textbf{muestra aleatoria} de tamaño \(8\), lo que significa que repites el experimento aleatorio \(8\) veces. Aquí están los resultados

\begin{verbatim}
## [1] 13.34642 13.32620 13.01459 13.10811 12.96999 13.55309 13.75557 12.62747
\end{verbatim}

\includegraphics{_main_files/figure-latex/unnamed-chunk-69-1.pdf}

\textbf{Definición:}

Una \textbf{muestra aleatoria} de tamaño \(n\) es la \textbf{repetición} de un experimento aleatorio \(n\) \textbf{independientes} veces.

\begin{itemize}
\tightlist
\item
  Una muestra aleatoria es una \textbf{variable aleatoria} \(n\)-dimensional
\end{itemize}

\[(X_1, X_2, ... X_n)\]

donde \(X_i\) es la \emph{i-ésima} repetición del experimento aleatorio con distribución común \(f(x; \theta)\) para cualquier \(i\)

\begin{itemize}
\tightlist
\item
  \textbf{Una observación} de una muestra aleatoria es el conjunto de \(n\) valores obtenidos de los experimentos
\end{itemize}

\[(x_1, x_2, ... x_n)\]
Nuestra \textbf{observación} de la muestra de tamaño \(8\) cables fue

\begin{verbatim}
## [1] 13.34642 13.32620 13.01459 13.10811 12.96999 13.55309 13.75557 12.62747
\end{verbatim}

\textbf{Ejemplo (Cables)}

En la muestra observada de la carga de rotura de los cables se observó que

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  Ninguno de ellos rompió en \(12\) Toneladas.
\item
  Hubo uno que rompió en \(12.62747\) Toneladas.
\end{enumerate}

¿Te arriesgas y vendes una muestra aleatoria de \(8\) cables de tu stock? ¿Qué sucede si su empresa es responsable de la rotura de un cable y tiene que pagar una multa elevada?

Para garantizar al cliente que los cables no se romperán a \(12\) Toneladas, nos gustaría ver que \(P(X \leq 12)\) es razonablemente bajo.

\hypertarget{cuxe1lculo-de-probabilidades}{%
\section{Cálculo de probabilidades}\label{cuxe1lculo-de-probabilidades}}

Para calcular probabilidades necesitamos:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Un modelo de probabilidad (función de probabilidad)
\item
  Los parámetros del modelo (los valores de la función de probabilidad)
\end{enumerate}

Vamos a \textbf{suponer} que la carga de rotura de los cables sigue una función de densidad de probabilidad \textbf{normal}.

\[X \rightarrow N(x; \mu, \sigma^2)\]

Para calcular \(P(X \leq 12)\), necesitamos los parámetros \(\mu\) y \(\sigma^2\). ¿Cómo podemos estimar los parámetros de la muestra observada?

\hypertarget{estimaciuxf3n-de-los-paruxe1metros}{%
\section{Estimación de los parámetros}\label{estimaciuxf3n-de-los-paruxe1metros}}

Para encontrar valores probables para los parámetros usamos datos. Por lo tanto, tomamos una \textbf{muestra aleatoria}. Es decir, repetimos el experimento \(n\) veces, recolectamos datos y los usamos para estimar los parámetros.

\textbf{Estimación de la media y la varianza}

Recordemos que para una variable aleatoria discreta, definimos la media como

\[\mu=\sum_{i}^m x_if(x_i)\]

que es el centro de gravedad de las \textbf{probabilidades}, donde \(f(x_i)\) es la función de probabilidad. Esta definición fue motivada por el centro de gravedad de las \textbf{observaciones}

\[\bar{x}= \frac{1}{n} \sum_{i}^n x_i = \sum_{i}^m x_if_i\]

que definimos como \textbf{promedio}, y donde \(f_i\) son las frecuencias relativas. Recuerda que \(n\) es el número de observaciones (puede ser tan grande como queramos) y \(m\) es el número de resultados posibles (normalmente fijado por el espacio muestral). Discutimos que cuando \(n \rightarrow \infty\) entonces

\[\hat{P}(X=x)=f_i\]
Esto significa que las probabilidades pueden ser \textbf{estimadas} (poniéndose un \textbf{sombrero}) por las frecuencias relativas cuando \(n\) es grande, porque \(lim_{n\rightarrow \infty}f_i=f(x_i)\). Por lo tanto, también deberíamos tener que la \textbf{media} \(\mu\) puede ser estimada por el \textbf{promedio} \(\bar{x}\)

\[\hat{\mu}=\bar{x}= \sum_{i}^m x_i\hat{P}(X=x)\]

Asi pues, podemos tomar el centro de la función de probabilidad como el centro de gravedad de los datos. Al hacer esto cometeremos un error que podemos asumir, como explicaremos luego.

Con la varianza

\[\sigma^2=\sum_{i}^m (x_i-\mu)^2f(x_i)\]

tenemos una situación similar. En el límite cuando \(n \rightarrow \infty\)

\[\hat{\sigma}^2=s^2=\frac{1}{n-1}\sum_{i=1}^n (x_i-\bar{x})^2\]

y suponemos que el momento de inercia de los datos es cercano al momento de inercia de las probabilidades.

\textbf{Ejemplo (Cables)}

Suponiendo que la carga de rotura de nuestro cable es una variable aleatoria normal

\[X \rightarrow N(x; \mu, \sigma^2)\]

\textbf{usamos} las estimaciones \(\bar{x}_{stock}=13,21\) (mean(x)) y \(s^2=0.3571565^2\) (sd( x)\^{}2) como los valores de \(\mu\) y \(\sigma^2\). De tal forma que el modelo \textbf{ajustado} es

\[X \rightarrow N(x; \mu=13.21, \sigma^2=0.3571565^2)\]
En este problema \textbf{no sabíamos} \(\mu\) o \(\sigma\) y, por lo tanto, estamos adivinando su valor y el modelo subyacente

\includegraphics{_main_files/figure-latex/unnamed-chunk-71-1.pdf}

¿Cuál es la probabilidad de que el cable se rompa a \(12\) Toneladas?

Como \[X \rightarrow N(x; \mu=13.21, \sigma^2=0.3571565^2)\]

entonces

\[P(X \leq 12)= F(12; \mu=13.21, \sigma^2=0.1275608)\]

En R pnorm(12,13.21, 0.3571565)\(=0.000352188\)

Dada la muestra \textbf{observada}, existe una probabilidad estimada de \(0.03\%\) de que un solo cable se rompa en \(12\) Toneladas. Tenemos un argumento probabilístico para vender los cables.

\hypertarget{margen-de-error-de-las-estimaciones}{%
\section{Margen de error de las estimaciones}\label{margen-de-error-de-las-estimaciones}}

Cuando estimamos los parámetros usando datos, como al tomar el valor de \[\hat{\mu}=\bar{x}\]

por el valor de \(\mu\); y el valor de

\[\hat{\sigma}^2=s^2\]
por el valor de \(\sigma^2\), sabemos que estamos \textbf{cometiendo un error}. Sabemos que si tomamos otra muestra de tamaño \(8\) cables \textbf{la estimación cambiará}, porque el promedio \(\bar{x}\) cambiará.

¿Podemos tener una idea de cuán grande es el error de nuestra estimación?

Lo primero que debemos darnos cuenta es que el valor numérico que obtenemos para \[\bar{x}\] es la observación de una \textbf{variable aleatoria} \[\bar{X}\]

\textbf{Definición}

La \textbf{media muestral} (o promedio) de una muestra aleatoria de tamaño \(n\) se define como

\[\bar{X}=\frac{1}{n}\sum_{i=1}^n X_i\]

El promedio es una \textbf{variable aleatoria} que en nuestra muestra de tamaño \(8\) tomó el valor

\[\bar{x}_{stock}=13.21\]

Si tomamos otra muestra, este número cambiará.

\textbf{La media como estimador}

El número \(\bar{x}\) se puede usar para \textbf{estimar} el parámetro desconocido \(\mu\) porque la variable aleatoria \(\bar{X}\) satisface estas dos propiedades importantes

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  es \textbf{insesgada}: \[E(\bar{X})=\mu\]
\item
  es \textbf{consistente}: \[lim_{n \rightarrow \infty} V(\bar{X}) = 0\]
\end{enumerate}

La primera propiedad se tiene porque
\[E(\bar{X})=E\big(\frac{1}{n}\sum_{i=1}^n X_i\big)=E(X)=\mu\]

La segunda propiedad se tien porque
\[V(\bar{X})=V\big(\frac{1}{n}\sum_{i=1}^n X_i\big)=\frac{V(\sum_{i=1}^ nX_i)}{n^2}=\frac{V(X)}{n}=\frac{\sigma^2}{n}\]

Que utiliza el hecho de que cada experimento aleatorio en la muestra es independiente y por lo tanto \(V(\sum_{i=1}^n X_i)=nV(X)\).

\emph{Estimación de \(\mu\)}

Como consecuencia de las propiedades 1 y 2, entendemos que el valor \(\bar{x}\) \textbf{se concentra más y más cerca} de \(\mu\) a medida que aumenta \(n\). Esto significa que el error que cometemos cuando tomamos un valor de \(\bar{x}\) como la estimación de \(\mu\)

\[\bar{x}=\hat{\mu}\]

se vuelve más y más pequeño a medida que la muestra se hace más y más grande porque la varianza de \(\bar{x}\) disminuye cuando \(n\) aumenta.

\hypertarget{inferencia}{%
\section{Inferencia}\label{inferencia}}

Sabemos que cuando tomamos muestras grandes, nuestro error es pequeño. Sin embargo, para un valor dado de \(n\) queremos tener una \textbf{medida del error}. Por lo tanto, nos preguntamos por la \textbf{probabilidad de cometer un error} de un tamaño dado cuando estimamos \(\mu\) con \(\bar{x}\).

Cuando calculamos probabilidades en un estimador, decimos que estamos haciendo una \textbf{inferencia}. Los problemas de inferencia suelen surgir cuando nos interesa calcular la probabilidad de cometer un error al estimar \(\mu\) con \(\bar{x}\).

Para calcular probabilidades necesitamos

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Un modelo de probabilidad (función de probabilidad)
\item
  Los parámetros del modelo (los valores de la función de probabilidad)
\end{enumerate}

¿Cuáles son las funciones de probabilidad de \(\bar{X}\) y \(S^2\) para que podamos calcular sus probabilidades?

Estas funciones de probabilidad se denominan \textbf{funciones de probabilidad de muestreo}, porque se derivan de un experimento de muestreo.

\textbf{Ejemplo (cables)}

Hagamos una pregunta de inferencia. Imagina que nuestros cables están \textbf{certificados} para romperse con una carga promedio de \(\mu = 13\) Toneladas con varianza \(\sigma^2=0.35^2\).

Si tomamos una muestra aleatoria de \(8\) cables, ¿Cuál es la probabilidad de que la media de la muestra \(\bar{X}\) esté dentro de un \textbf{margen de error} de \(0.25\) Toneladas de la media \(\mu\)?

\[P(- 0.25\leq \bar{X}-\mu \leq 0.25)\]

Para calcular esta probabilidad, necesitamos conocer la función de probabilidad de \(\bar{X}\).

\hypertarget{distribuciuxf3n-media-muestral}{%
\section{Distribución media muestral}\label{distribuciuxf3n-media-muestral}}

\textbf{Teorema:} Si \(X\) sigue una distribución normal \[X \rightarrow N(\mu, \sigma^2)\]

entonces \(\bar{X}\) es normal

\[\bar{X} \rightarrow N(\mu, \frac{\sigma^2}{n})\]
y \(\bar{X}\) tiene

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\item
  media
  \[E(\bar{X})=\mu\]
  decimos que \(\bar{X}\) es insesgado porque su valor esperado es \(\mu\)
\item
  varianza
  \[V(\bar{X})=\frac{\sigma^2}{n}\]
  Decimos que \(\bar{X}\) es consistente porque tiende a cero cuando \(n\) es grande.
\end{enumerate}

Llamamos \(se=\sqrt{V(\bar{X})}\) al \textbf{error estándar} de la media muestral. El error estándar también se escribe como \(\sigma_{\bar{x}}\). Ten en cuenta que este es el error que esperamos cuando usamos \(\bar{x}\) como el valor de \(\mu\), y es el sesgo que necesitábamos corregir para \(S_n^2\).

Entonces, si \textbf{sabemos} \(\mu\) y \(\sigma\), podemos calcular las \textbf{probabilidades de} \(\bar{X}\) usando la distribución normal.

Recuerda que tenemos \textbf{dos funciones de probabilidad}:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  La función de probabilidad de \(X\) también se conoce como la función de probabilidad de la \textbf{población}
\item
  La función de probabilidad de \(\bar{X}\) es una función de probabilidad de la \textbf{muestra}.
\end{enumerate}

\textbf{Ejemplo (cables)}

\emph{Densidades de probabilidad para \(X\) y \(\bar{X}\)}

En nuestro nuevo problema, ahora \textbf{sabemos} \(\mu\) y \(\sigma\) y la función de probabilidad de la \textbf{población}

\[X \rightarrow N(\mu=13, \sigma^2=0.35^2)\]

\includegraphics{_main_files/figure-latex/unnamed-chunk-72-1.pdf}

Dado que \(X\) es normal, entonces \(\bar{X}\) es normal y, por lo tanto, también conocemos la función de probabilidad de la media muestral \(\bar{X}\)

\[\bar{X} \rightarrow N(13, \frac{0.35^2}{8})\]

que tiene media y varianza

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  \(E(\bar{X})=\mu=13\)
\item
  \(V(\bar{X})=\frac{\sigma^2}{n}=\frac{0.35^2}{8}=0.01530169\)
\end{enumerate}

\includegraphics{_main_files/figure-latex/unnamed-chunk-73-1.pdf}

Finalmente queremos calcular \textbf{la probabilidad} de que nuestra estimación tenga un margen de error de \(0.25\). Esa es una distancia de \(0.25\) de la media. Eso es \[P(-0.25 \leq \bar{X} - 13\leq 0.25)=P(12.75 \leq \bar{X} \leq 13.25)\]

\(=F(13.25; \mu, \sigma^2/n)-F(12.75; \mu, \sigma^2/n)\)

En R podemos calcularlo como:

pnorm(13.25, 13, 0.1237)-pnorm(12.75, 13, 0.1237)=0.956.

Recuerda: \(se=\sigma_{\bar{x}}=\sqrt{0.01530169}=0.1237\)

Por lo tanto el \(95.6\%\) de los promedios \(\bar{X}\) de muestras aleatorias de tamaño \(8\) están a una distancia de \(0.25\) de la media \(\mu=13\).

Si vendemos nuestro proceso para construir los cables, podemos decirles a los nuevos fabricantes que cuando sigan nuestras instrucciones, pueden probar el proceso tomando una muestra de tamaño \(8\) cables. En ese caso, pueden esperar que el promedio de la muestra caiga entre \((12.75, 13.25)\) alrededor de \(95\%\) de las veces.

\includegraphics{_main_files/figure-latex/unnamed-chunk-74-1.pdf}

Cuando realizamos el muestreo aleatorio observamos:

\begin{verbatim}
## [1] 13.34642 13.32620 13.01459 13.10811 12.96999 13.55309 13.75557 12.62747
\end{verbatim}

Asumiendo que \(\mu=13\) entonces nuestro \textbf{error observado} en la estimación de la media es la diferencia

\[\bar{x}_{stock}-\mu=13.21-13=0.21\]

Lo cual está dentro del margen de error de \(95.6\%\) y por lo tanto, debemos considerar que el proceso de fabricación está funcionando como se esperaba.

\includegraphics{_main_files/figure-latex/unnamed-chunk-76-1.pdf}

\hypertarget{suma-muestral}{%
\subsection{Suma muestral}\label{suma-muestral}}

Si estamos interesados en usar todos los \(8\) cables al mismo tiempo para transportar un total de \(96\) Toneladas, entonces deberíamos considerar \textbf{sumar} sus contribuciones individuales.

La \textbf{suma muestral} es la \textbf{estadística}

\[Y=n \bar{X}=\sum_{i=1}^n X_i\]

Una \textbf{estadística} es cualquier función de la muestra aleatoria \((X_1, ... X_n)\).

\textbf{Teorema:} si \(X\) sigue una distribución normal
\[X \rightarrow N(\mu, \sigma^2)\]

entonces \(Y\) es normal

\[Y \rightarrow N(n\mu, n\sigma^2)\]

\(Y\) tiene

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  media \[E(Y)=n\mu\]
\item
  varianza \[V(Y)=n\sigma^2\]
\end{enumerate}

\textbf{Ejemplo (suma de cables)}

¿Cuál es la probabilidad de que cuando juntamos todos los cables, puedan llevar un peso total entre \(102=8(13 - 0.25)\) y \(106=8(13+ 0.25)\) Toneladas?

\textbf{Sabemos} que para nuestros cables \[X \rightarrow N(\mu=13, \sigma^2=0.35^2)\] entonces

\[Y \rightarrow N(n\mu=104, n\sigma^2=8\times 0.35^2)\]

con media y varianza

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  \(E(Y)=n\mu=104\)
\item
  \(V(Y)=n\sigma^2=8\times 0.35^2=0.98\); \(\sqrt{V(Y)}=0.9899495\)
\end{enumerate}

Queremos calcular \[P(102 \leq Y \leq 106)\]

\(=F(102; n\mu, n\sigma^2)-F(106; n\mu, n\sigma^2)\)

En R podemos calcularlo como:

pnorm(106, 104, 0.9899495)-pnorm(102, 104, 0.9899495)=0.956.

Por lo tanto \(95.6\%\) del peso total que pueden llevar \(8\) cables están entre \(102\) y \(106\) Toneladas, o una distancia de \(8*0.25=2\) Toneladas de la media total \(n\mu=104\).

\hypertarget{variaza-muestral}{%
\section{Variaza muestral}\label{variaza-muestral}}

Al estimar la varianza

\[s^2=\hat{\sigma}\]

También cometemos un error. ¿Cómo podemos estimar el error que cometemos?

\textbf{Definición}

La \textbf{varianza muestral} \(S^2\) de una muestra aleatoria de tamaño \(n\)

\[S^2= \frac{1}{n-1}\sum_{i=1}^n (X_i-\bar{X})^2\]

es la dispersión de las medidas al rededor de \(\bar{X}\). En nuestra muestra de tamaño \(8\), \(S^2\) tomó el valor

\[s_{stock}^2=\frac{1}{n-1}\sum_{i=1}^n (x_i-\bar{x})^2=0.1275608\]

\(S^2\) es

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  insesgada: \(E(S^2)=V(X)=\sigma^2\)
\item
  consistente: \(n \rightarrow \infty\), \(V(\bar{S^2}) \rightarrow 0\)
\end{enumerate}

y por lo tanto \(S^2\) estima consistentemente \(\sigma^2\)

Podemos tomar un valor de \(s^2\) como estimación para \(\sigma^2\) o

\[s^2=\hat{\sigma}^2\]
De manera similar a \(\hat{\mu}\), el error de esta estimación se hace cada vez más pequeño a medida que \(n\) se hace cada vez más grande.

\textbf{La varianza muestral insesgada (¿por qué dividimos entre n-1?)}

Podríamos proponer estimar \(\sigma^2\) dividiendo las diferencias cuadráticas de \(\bar{X}\) por \(n\)

\[S_n^2=\frac{1}{n}\sum_{i=1}^n (X_i-\bar{X})^2\]

\(S_n^2\) es por lo tanto

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  \textbf{sesgada}: \(E(S_n^2) = \sigma^2-\frac{\sigma^2}{n} \neq \sigma^2\)
\item
  pero consistente \(V(S_n^2) \rightarrow 0\) cuando \(n\rightarrow \infty\)
\end{enumerate}

El término de sesgo \(\frac{\sigma^2}{n}\) surge porque \(S_n^2\) mide la dispersión al rededor de \(\bar{X}\) y no al rededor de \(\mu\). Recuerda que el error que cometemos cuando sustituimos \(\bar{x}\) por \(\mu\) es la varianza de \(\bar{X}\): \(\sigma^2/n\). Corrijamos el sesgo, escribiendo la ecuación 1 anterior como:

\[E(\frac{n}{n-1}S_n^2)=\sigma^2\]

Podemos definir la \textbf{varianza muestral} (corregida) \[S^2=\frac{n}{n-1}S_n^2=\frac{1}{n-1}\sum_{i=1}^n (X_i-\bar{X})^2\]

que es un estimador insesgado de \(\sigma^2\) porque \(E(S^2)=\sigma^2\).

También podemos tener problemas de inferencia cuando estamos interesados en la probabilidad de la \textbf{varianza muestral} \(S^2\).

Considera un proceso de control de calidad que requiera que los cables se produzcan cerca del valor especificado \(\mu\). No queremos cables que se rompan demasiado lejos de la media.

Si una muestra de tamaño \(8\) cables está muy dispersa (\(S^2>0.3\)), detenemos la producción: el proceso está fuera de control.

¿Cuál es la probabilidad de que la varianza muestral de una muestra de tamaño \(8\) cables sea mayor que los \(0.3\) requeridos?

\hypertarget{probabilidades-de-la-varianza-muestral}{%
\section{Probabilidades de la varianza muestral}\label{probabilidades-de-la-varianza-muestral}}

\textbf{Teorema:} Si \(X\) sigue una distribución normal
\[X \rightarrow N(\mu, \sigma^2)\]

La \textbf{estadística}:

\[W=\frac{(n-1)S^2}{\sigma^2} \rightarrow \chi^2(n-1)\]

tiene una distribución \(\chi^2\) (chi-cuadrado) con \(df=n-1\) grados de libertad dada por

\[f(w)=C_n w^{\frac{n-3}{2}} e^{-\frac{w}{2}}\]

dónde:

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  \(C_n=\frac{1}{2^{(n-1)/2\sqrt{\pi(n-1)}}}\) asegura \(\int_{-\infty}^{\infty} f (t)dt=1\)
\item
  \(\Gamma(x)\) es el factorial de Euler para números reales
\end{enumerate}

Si \textbf{sabemos} el valor de \(\sigma\), podemos calcular las probabilidades de \(S^2\) usando la distribución \(\chi^2\) para \(W\).

\hypertarget{chi2-estaduxedstica}{%
\section{\texorpdfstring{\(\chi^2\)-estadística}{\textbackslash chi\^{}2-estadística}}\label{chi2-estaduxedstica}}

La densidad de probabilidad \(\chi^2\) tiene un parámetro \(df=n-1\), llamado grados de libertad. Veamos algunas densidades de probabilidad en la familia de modelos de probabilidad \(\chi^2\)

\includegraphics{_main_files/figure-latex/unnamed-chunk-77-1.pdf}

\textbf{Ejemplo (variaciones en la rotura del cable)}

Si \textbf{sabemos} que nuestros cables
\[X \rightarrow N(\mu=13, \sigma^2=0.35^2)\]

entonces

\[W=\frac{(n-1)S^2}{\sigma^2}= \frac{7S^2}{0.35^2} \rightarrow \chi^2(n-1)\]

podemos calcular \[P(S^2 > 0.3)=P(\frac{(n-1)S^2}{\sigma^2} > \frac{(n-1)0.3}{\sigma^2 })\]
\(=P(W > \frac{7*0.3}{0.35^2})=P(W > 17.14286)\)

\(=1-P(W \leq 17.14286)\)

\(= 1- F_{\chi^2,df=7}(17.14286)=0.016\)

En R
1-pchisq(17.14286, df=7)=0.016

Solo hay una probabilidad de \(1\%\) de obtener un valor superior a \(s^2=0.3\). Por lo tanto, \(s^2>0.3\) parece ser un buen criterio para detener la producción y revisar el proceso.

Si tomamos una muestra aleatoria y obtenemos un valor de \(s ^2\) que es mayor que \(0.3\), será una observación rara si todo está bien. Solemos creer que los valores observados son comunes, no raros, por lo que podemos pensar que algo no está bien.

Cuando realizamos el muestreo aleatorio observamos:

\begin{verbatim}
## [1] 13.34642 13.32620 13.01459 13.10811 12.96999 13.55309 13.75557 12.62747
\end{verbatim}

Por lo tanto, nuestro valor observado fue \(s^2_{stock}=0.1275608\)

La muestra no está muy dispersa porque \(s^2_{stock} < 0.3\) y creemos que todo está bien y la producción está bajo control.

\hypertarget{preguntas-7}{%
\section{Preguntas}\label{preguntas-7}}

\textbf{1)} La media muestral es un estimador insesgado de la media poblacional porque

\textbf{\(\qquad\)a:} El valor esperado de la media muestral es la media poblacional;
\textbf{\(\qquad\)b:} El valor esperado de la media poblacional es la media muestral;
\textbf{\(\qquad\)c:} El error estándar tiende a cero cuando \(n\) tiende a infinito;
\textbf{\(\qquad\)d:} La varianza de la media muestral tiende a cero cuando \(n\) tiende a infinito;

\textbf{2)} ¿Por qué se usa la estadística \(S^2=\frac{1}{n-1}\sum_{i=1}^{n}(X_i -\bar{X})^2\) en su lugar de \(S_n^2=\frac{1}{n}\sum_{i=1}^{n}(X_i -\bar{X})^2\) para estimar la varianza de una variable aleatoria?

\textbf{\(\qquad\)a:} porque su varianza es \(0\);
\textbf{\(\qquad\)b:} porque es un estimador consistente de \(\sigma^2\);
\textbf{\(\qquad\)c:} porque es un estimador insesgado de \(\sigma^2\);
\textbf{\(\qquad\)d:} porque es la distancia cuadrática promedio a la media muestral (\(\bar{X}\));

\textbf{3)} ¿Cuál es la varianza de la media muestral \(\bar{X}=\frac{1}{n}\sum_{i=1}^n X_i\)?

\textbf{\(\qquad\)a:}\(\sigma\);
\textbf{\(\qquad\)b:}\(\frac{\sigma}{\sqrt{n}}\);
\textbf{\(\qquad\)c:}\(\sigma^2\);
\textbf{\(\qquad\)d:}\(\frac{\sigma^2}{n}\);

\textbf{4)} ¿Cuál es la media y la varianza de la suma muestral?

\textbf{\(\qquad\)a:}\(\mu\), \(n\sigma\);
\textbf{\(\qquad\)b:}\(n\mu\),\(n\sigma\);
\textbf{\(\qquad\)c:}\(\mu\), \(n\sigma^2\);
\textbf{\(\qquad\)d:}\(n\mu\), \(n\sigma^2\);

\textbf{5)} Una pregunta de inferencia implica:

\textbf{\(\qquad\)a:} calcular el valor esperado de un estimador;
\textbf{\(\qquad\)b:} estimar el valor de un parámetro;
\textbf{\(\qquad\)c:} calcular una probabilidad de un estimador;
\textbf{\(\qquad\)d:} ajustar un modelo de probabilidad;

\hypertarget{ejercicios-8}{%
\section{Ejercicios}\label{ejercicios-8}}

\hypertarget{ejercicio-1-7}{%
\subsubsection{Ejercicio 1}\label{ejercicio-1-7}}

Una empresa de electrónica fabrica resistencias que tienen una resistencia media de 100 ohmios y
una desviación estándar de 10 ohmios. La distribución de la resistencia es normal.

\begin{itemize}
\item
  ¿Cuál es la media muestral de \(n=25\) resistencias? (R:100)
\item
  ¿Cuál es la varianza de la media muestral de \(n=25\) resistencias? (R:4)
\item
  ¿Cuál es el error estándar de la media muestral de \(n=25\) resistencias? (R:2)
\item
  Encuentra la probabilidad
  que una muestra aleatoria de \(n = 25\) resistencias tenga una resistencia promedio de menos de \(95\) ohmios (R: 0.0062)
\end{itemize}

\hypertarget{ejercicio-2-7}{%
\subsubsection{Ejercicio 2}\label{ejercicio-2-7}}

Un modelo de batería carga una media de \(75\%\) de su capacidad en una hora con una desviación estándar de \(15\%\).

\begin{itemize}
\item
  Si la carga de la batería es una variable normal, ¿cuál es la probabilidad de que la diferencia de carga entre la media muestral de \(25\) baterías y la carga media sea como mucho de \(5\%\)? (R:0.9044)
\item
  Si cargamos \(100\) baterías, ¿cuál es esa probabilidad? (R:0.9991)
\item
  Si en cambio solo cargamos \(9\) baterías, ¿qué carga \(c\) es superada por la media muestral con probabilidad de \(0.015\)? (R:85.850)
\end{itemize}

\hypertarget{teorema-central-del-luxedmite}{%
\chapter{Teorema central del límite}\label{teorema-central-del-luxedmite}}

\hypertarget{objetivo-7}{%
\section{Objetivo}\label{objetivo-7}}

En este capítulo introduciremos el \textbf{margen de errores} al estimar la media de la distribución de la población por el promedio.

Discutiremos cómo el \textbf{Teorema central del límite } nos permitirá calcular el margen de error para cualquier tipo de distribución si la muestra es grande.

También introducirá la estadística t, para calcular el margen de error cuando la muestra es pequeña pero la distribución de la población es normal.

\hypertarget{margen-de-error}{%
\section{Margen de error}\label{margen-de-error}}

Al decidir si el error de estimación de \(\mu\) por la media muestral \(\bar{x}\) es grande o no, generalmente lo comparamos con una tolerancia \textbf{predefinida}.

El \textbf{margen de error} a nivel de \(5\%\) es la distancia \(m\) de \(\bar{X}\) de \(\mu\) que captura \(95\%\) de las estimaciones:

\[P(-m \leq \bar{X}-\mu \leq m)=P(\mu-m \leq \bar{X} \leq\mu + m)=0.95\]

Esto significa que \(95\%\) de los posibles resultados de \(\bar{X}\) están a una distancia \(m\) de \(\mu\)

\hypertarget{ejemplo-cables}{%
\section{Ejemplo (cables)}\label{ejemplo-cables}}

Si tomamos una muestra de cables de \(8\) de una población de cables cuya carga de ruptura sigue una distribución normal con parámetros \textbf{conocidos} \(\mu=13\) y \(\sigma^2=0.35^2\),

\[X \rightarrow N(\mu=13, \sigma^2=0.35^2)\]

¿Cuál es el margen de error cuando estimamos \(\mu\) por \(\bar{x}\)?

\textbf{Calculando el maging de error de una variable normal}

Queremos saber el número \(m\) en la ecuación

\[P(\mu-m \leq \bar{X} \leq\mu + m)=0.95\]

Para resolver esta ecuación necesitamos dos pasos. \textbf{Primero}, necesitamos saber la \textbf{distribución} de \(\bar{X}\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Cuando \(X\) es normal \(X \rightarrow N(\mu, \sigma^2)\) entonces
\end{enumerate}

\[\bar{X} \rightarrow N(\mu, \frac{\sigma^2}{n})\]
\textbf{Entonces} necesitamos \textbf{estandarizar} \(\bar{X}\). Recuerda que para estandarizar una variable normal \textbf{restamos su media} y la \textbf{dividimos por su desviación estándar}.

\[Z=\frac{\bar{X}-E(\bar{X})}{\sqrt{V(\bar{X})}} =\frac{\bar{X}-\mu}{ \frac{\sigma}{\sqrt{n}}} \rightarrow N(0,1)\]

\includegraphics{./figures/phi.JPG}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Sustituyendo la media de \(\bar{X}\) y su desviación estándar en la ecuación del margen de error, tenemos:
\end{enumerate}

\(P(\mu-m \leq \bar{X} \leq\mu + m)=P(-\frac{m}{\sigma/\sqrt{n}} \leq \frac{\bar{X} -\mu}{\frac{\sigma}{\sqrt{n}}}\leq\frac{m}{\sigma/\sqrt{n}})\)
\[=P(-\frac{m}{\sigma/\sqrt{n}} \leq Z \leq\frac{m}{\sigma/\sqrt{n}})=0.95\]

Compáralo con el gráfico anterior: \(\frac{m}{\sigma/\sqrt{n}}\) es la distancia alrededor de \(0\) que captura \(95\%\) de la variable normal estándar de distribución. La distancia deja una probabilidad de \(2.5\%\) en cada extremo de la distribución. Para la parte superior de la cola, esto es

\[\frac{m}{\sigma/\sqrt{n}}=\phi^{-1}(0.975)=1.96\]

donde \(\phi^{-1}\) es la inversa de la distribución normal estándar (qnorm(0.975)). Por lo tanto

\[m=1.96 \frac{\sigma}{\sqrt{n}}\]
\textbf{Ejemplo (cables)}

La media muestral \(\bar{X}\) de una muestra de cables de \(8\) sigue una distribución normal con:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  media \(E(\bar{X})=\mu\)
\end{enumerate}

y

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  error estándar \(se=\sqrt{V(\bar{X})}=\frac{\sigma}{\sqrt{n}}=\frac{0.35}{\sqrt{8}}\)
\end{enumerate}

Entonces el margen de error en \(5\%\) es:

\[m=1.96\frac{0.35}{\sqrt{8}}=0.24\]

Podemos esperar que \(95\%\) de los promedios (\(\bar{x}\)) para la carga de rotura de los cables de \(8\) caigan entre \((13-0.24, 13+0.24)=(12.76, 13.24)\)

\hypertarget{teorema-central-del-luxedmite-1}{%
\section{Teorema central del límite}\label{teorema-central-del-luxedmite-1}}

Pudimos resolver el margen de error porque asumimos que esa variable \(X\) era normal. ¿Qué pasa si \(X\) sigue cualquier otra distribución de probabilidad?

\textbf{Teorema:} Para cualquier variable aleatoria \(X\) con cualquier tipo de distribución

\[X \rightarrow f(x; \theta)\]
la estadística estandarizada

\[Z=\frac{\bar{X}-E(\bar{X})}{\sqrt{V(\bar{X})}}\]

se aproxima a una distribución estándar

\[Z \rightarrow_d N(0,1)\] cuando \(n\rightarrow \infty\)

\textbf{Consecuencia:} Podemos calcular las probabilidades de \(\bar{X}\) si \(n\) es grande, usando la distribución normal:

\[\bar{X} \sim_{aprox} N(\mu, \frac{\sigma^2}{n})\]

\textbf{Ejemplo (fármaco en concentración sanguínea):}

Considera un experimento en el que queremos medir la concentración en sangre de un fármaco después de \(10\) horas de administración en \(30\) pacientes.

Si \textbf{sabemos} que los niveles siguen una distribución exponencial \[X \rightarrow exp(\lambda=2)\]

\includegraphics{_main_files/figure-latex/unnamed-chunk-79-1.pdf}

La media y la varianza son:

\begin{itemize}
\tightlist
\item
  \(\mu=\frac{1}{\lambda}=0.5\)
\item
  \(\sigma^2=\frac{1}{\lambda^2}=0.25\)
\end{itemize}

Por lo tanto, la media y el error estándar de \(\bar{X}\) son:

\begin{itemize}
\tightlist
\item
  \(E(\bar{X})=\frac{1}{\lambda}=0.5\)
\item
  \(se=\sqrt{\frac{\sigma^2}{n}}=\sqrt{\frac{1}{n\lambda^2}}=0.091\)
\end{itemize}

Como \(n \geq 30\)

\[Z=\frac{\bar{X}-\lambda}{\sqrt{\frac{1}{n\lambda^2}}}\]

es una variable normal estándar y: \(\bar{X} \sim_{aprox} N(\lambda, \frac{1}{n\lambda^2})\)

El margen de error al nivel de \(5\%\) se puede calcular de nuevo con la distribución estándar

\[m=\phi^{-1}(0.975) \frac{\sigma}{\sqrt{n}}=1.96\frac{0.25}{\sqrt{30}}=0.1789227\]

Podemos esperar que \(95\%\) de los promedios de muestras de pacientes de \(30\) caigan entre
\((0.5-0.178, 0.5+0.178)= (0.322, 0.678)\)

\includegraphics{_main_files/figure-latex/unnamed-chunk-80-1.pdf}

\hypertarget{suma-muestral-y-clt}{%
\section{Suma muestral y CLT}\label{suma-muestral-y-clt}}

La \textbf{suma muestral} es la \textbf{estadística}

\[Y=X_1+X_2+...X_n=\sum_{i=1}^n X_i=n \bar{X}\]

con

\begin{enumerate}
\def\labelenumi{\arabic{enumi})}
\tightlist
\item
  media \[E(Y)=n\mu\]
\item
  variancia \[V(Y)=nV(X)=n^2V(\bar{X})\]
\end{enumerate}

El TCL nos dice que para cualquier variable aleatoria \(X\) con distribución \textbf{desconocida} (cualquier tipo de)

\[X \rightarrow f(x; \theta)\]

la estadística estandarizada

\[Z=\frac{\bar{X}-E(\bar{X})}{\sqrt{V(\bar{X})}}\]

se aproxima a una distribución estándar

\[Z \rightarrow_d N(0,1)\] cuando \(n\rightarrow \infty\). \(Z\) tembién se puede escribir como

\[Z=\frac{n\bar{X}-nE(\bar{X})}{\sqrt{n^2V(\bar{X})}}=\frac{Y-E(Y)}{\sqrt{V(Y)}}\]

\textbf{Consecuencia:} Podemos calcular probabilidades para la suma muestral \(Y=n\bar{X}\) si \(n\) es grande, usando la distribución normal:

\[Y \sim_{aprox}  N(nE(X), nV(X))\]

\textbf{Ejemplo (Ensayo de Bernoulli)}

Para el ensayo de Bernoulli \(X \rightarrow Bernoulli(p)\), el promedio de una muestra \(n\) de ensayos de Bernoulli es \(\bar{X}=\sum_i^n X_i\). Por lo tanto

\[Z=\frac{\bar{X}-p}{\sqrt{\frac{p(1-p)}{n}}}\]
es normal estándar, porque \(E(\bar{X})=p\) y \(V(\bar{X})=\frac{p(1-p)}{n}\).

Ahora, la suma muestral \(Y=n\bar{X}\) es una variable aleatoria que cuenta el número de eventos con probabilidad \(p\) en una repetición de \(n\) intentos, por lo tanto
\[Y \rightarrow Binom(n, p)\]
con media \(E(Y)=np\) y viarianza \(V(Y)=np(1-p)\). Como podemos escribir
\[Z=\frac{Y-np}{\sqrt{np(1-p)}}\]
entonces usando el TCL, podemos aproximar la función de masa de probabilidad binomial con la densidad de probabilidad normal cuando \(n\) es grande

\[Y \rightarrow Binom(n, p) \sim_{aprox} N(np, np(1-p))\]

Esta aproximación es buena cuando tanto \(np\) como \(n(1-p)\) son mayores que \(5\).

\hypertarget{preguntas-8}{%
\section{Preguntas}\label{preguntas-8}}

\textbf{1)} La importancia del Teorema central del límite es que se aplica a la estandarización de

\textbf{\(\qquad\)a:} Una variable aleatoria;
\textbf{\(\qquad\)b:} La media muestral de una variable normal;
\textbf{\(\qquad\)c:} La media muestral de una variable aleatoria;
\textbf{\(\qquad\)d:} Una variable normal;

\textbf{2)} Cuando \(n>30\), la media muestral de una variable aleatoria (\(\frac{1}{n}\sum_i Xi\)) y su suma muestral (\(\sum_i Xi\)) se pueden aproximar a

\textbf{\(\qquad\)a:} \(N(\frac{\mu}{n}, \frac{\sigma^2}{n})\) y \(N(\mu, \sigma^2)\);
\textbf{\(\qquad\)b:} \(N(\mu, n\sigma^2)\) y \(N(\mu, \frac{\sigma^2}{n})\);
\textbf{\(\qquad\)c:} \(N(\mu, \frac{\sigma^2}{n})\) y \(N(\mu, \frac{\sigma^2}{n})\);
\textbf{\(\qquad\)d:} \(N(\mu, \frac{\sigma^2}{n})\) y \(N(n\mu, n\sigma^2)\)

\textbf{3)} Para una variable normal estándar, si ponemos el número \(z_{0.025}\) en la definición del margen de error \(m=z_{0.025} \frac{\sigma}{\sqrt{n}}\), entonces se referirá a

\textbf{\(\qquad\)a:} El primer cuartil; \textbf{\(\qquad\)b:} El número en el que la distribución ha acumulado \(0.975\) de probabilidad; \textbf{\(\qquad\)c:} El número en el que la distribución ha acumulado una probabilidad de \(0.025\); \textbf{\(\qquad\)d:} El tercer cuartil;

\textbf{4)} La probabilidad de que la media muestral de \(50\) observaciones esté una distancia de un error estandar (\(se=\frac{\sigma}{\sqrt{n}}\)) de de la media poblacional \(\mu\) es:

\textbf{\(\qquad\)a:}2*(1-pnorm(1))= 0.3173105; \textbf{\(\qquad\)c:}2*(1-pnorm(2))=0.04550026;
\textbf{\(\qquad\)b:}-1+2*pnorm(1)=0.6826895;
\textbf{\(\qquad\)d:}-1+2*pnorm(2)=0.9544997

\textbf{5)} Una resonancia magnética del hipocampo del cerebro tiene \(100\) píxeles. Esperamos que \(90\%\) de los píxeles sean blancos (tejido cerebral). Según el Teorema central del límite , ¿cuál es la probabilidad de que el escaneo de un paciente tenga como máximo \(85\%\) de píxeles blancos?

\textbf{\(\qquad\)a:}pnorm(0.9, 0.85, sqrt(0.85*0.15)/10); \textbf{\(\qquad\)b:}dnorm(0.85, 0.9,
sqrt(0.9*0.1)/10); \textbf{\(\qquad\)c:}pnorm(0.85, 0.9, sqrt(0.9*0.1)/10); \textbf{\(\qquad\)d:}dnorm(0.9, 0.85, sqrt(0.85*0.15)/10)

\hypertarget{ejercicios-9}{%
\section{Ejercicios}\label{ejercicios-9}}

\hypertarget{ejercicio-1-8}{%
\subsubsection{Ejercicio 1}\label{ejercicio-1-8}}

Se necesita un componente electrónico para el correcto funcionamiento de un telescopio. Necesita ser reemplazado inmediatamente cuando se desgasta.

La vida media del componente (\(\mu\)) es de \(100\) horas y su desviación estándar \(\sigma\) es de \(30\) horas.

\begin{itemize}
\item
  ¿Cuál es la probabilidad de que el promedio de la vida media de \(50\) componentes esté dentro de \(1\) hora de la vida media de un solo componente? (R:0.1863)
\item
  ¿Cuántos componentes necesitamos para que el telescopio esté operativo \(2750\) horas consecutivas con al menos \(0.95\) de probabilidad? (R:31)
\end{itemize}

\hypertarget{ejercicio-2-8}{%
\subsubsection{Ejercicio 2}\label{ejercicio-2-8}}

La probabilidad de que se encuentre una mutación particular en la población es de \(0.4\). Si testamos \(2000\) personas por la mutación:

\begin{itemize}
\tightlist
\item
  ¿Cuál es la probabilidad de que el número total de personas con la mutación esté entre \(791\) y \(809\)? (R:0.31)
\end{itemize}

sugerencia: usa el CLT con una muestra de ensayos de Bernoulli de \(2000\). Esto se conoce como la \textbf{aproximación normal de la distribución binomial} que es buena cuando \(p\) y \(1-p\) son ambis mayor que \(5\).

\hypertarget{ejercicio-3-5}{%
\subsubsection{Ejercicio 3}\label{ejercicio-3-5}}

Una máquina automática llena tubos de ensayo con muestras biológicas con una media de \(\mu=130\)mg y una desviación estándar de \(\sigma=5\)mg.

\begin{itemize}
\item
  para una muestra aleatoria de tamaño \(50\). ¿Cuál es la probabilidad de que
  la media muestral (promedio) esté entre \(128\)mg y \(132\)mg? (R:0.995)
\item
  ¿Cuál debería ser el tamaño de la muestra (\(n\)) tal que la media muestral \(\bar{X}\) sea superior a \(131\)gr con una probabilidad menor o igual a \(0.025\)?(R:97)
\end{itemize}

\hypertarget{ejercicio-4-3}{%
\subsubsection{Ejercicio 4}\label{ejercicio-4-3}}

En el Caribe, parece haber un promedio de huracanes de \(6\) por año. Teniendo en cuenta que la formación de huracanes es un proceso de Poisson, los meteorólogos planean estimar el tiempo medio entre la formación de dos huracanes. Planean recolectar una muestra de tamaño \(36\) para los tiempos entre dos huracanes.

\begin{itemize}
\item
  ¿Cuál es la probabilidad de que su promedio muestral esté entre \(45\) y \(60\) días? (R:0.39)
\item
  ¿Cuál debe ser el tamaño de la muestra para que tengan una probabilidad de \(0.025\) de que la media muestral sea mayor a \(70\) días? (R:169)
\end{itemize}

\hypertarget{muxe1xima-verosimilitud-y-muxe9todo-de-los-momentos}{%
\chapter{Máxima verosimilitud y Método de los Momentos}\label{muxe1xima-verosimilitud-y-muxe9todo-de-los-momentos}}

\hypertarget{objetivo-8}{%
\section{Objetivo}\label{objetivo-8}}

En este capítulo discutiremos qué es un \textbf{estimador} y daremos algunos ejemplos. Luego introduciremos dos métodos para obtener \textbf{estimadores} de los parámetros de los modelos de probabilidad.

Estos son la \textbf{máxima verosimilitud} y el \textbf{método de los momentos}.

\hypertarget{estaduxedstica-1}{%
\section{Estadística}\label{estaduxedstica-1}}

\textbf{Definición}

Una \textbf{estadística} es cualquier función de una \textbf{muestra aleatoria}
\[T(X_1,X_2, ..., X_n)\]

Por lo general, devuelve un número.

Las estadísticas son \textbf{variables aleatorias} y sus \textbf{distribuciones de probabilidad} se llaman \textbf{distribuciones de muestreo}

Las estadísticas tienen diferentes funciones:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \textbf{Descripción} de los datos de una muestra
\end{enumerate}

\begin{itemize}
\tightlist
\item
  ubicación: \(\bar{X}\)
\item
  Mínimo: \(\min\{X_i\}\)
\item
  Máximo: \(\max\{X_i\}\)
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \textbf{Estimación} de los \textbf{parámetros} de un modelo de probabilidad
\end{enumerate}

\begin{itemize}
\tightlist
\item
  media: \(\bar{X}\) para \(\mu\)
\item
  varianza: \(S^2\) para \(\sigma^2\)
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \textbf{Inferencia} para decir algo sobre los parámetros dados los datos
\end{enumerate}

\begin{itemize}
\tightlist
\item
  media: \(Z\), \(T\)
\item
  varianza: \(\chi^2\)
\end{itemize}

Recuerda: Todas son variables aleatorias. Cada vez que tomamos otra muestra cambian su valor.

\textbf{Definición de estimadores}

Un \textbf{estimador} es un estadístico cuyos valores observados se utilizan para estimar los \textbf{parámetros} de la distribución de la población sobre la que se define la muestra.

Si escribimos la distribución de la población como

\[X \rightarrow f(x; \theta)\]

entonces \(\theta\) es un parámetro y \(\Theta\) es una variable aleatoria cuyas observaciones \(\hat{\theta}\) tomamos como estimaciones de \(\theta\)

\[\hat{\theta} \sim \theta\]

Por lo tanto hay tres cantidades diferentes que debemos considerar:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\theta\) es un \textbf{parámetro} de la distribución de la población \(f(x; \theta)\)
\item
  \(\Theta\) es un \textbf{estimador} de \(\theta\): Una variable aleatoria
\item
  \(\hat{\theta}\) es la \textbf{estimación} de \(\theta\): un valor realizado de \(\Theta\)
\end{enumerate}

\includegraphics{./figures/estimator.JPG}

\textbf{Ejemplo (media de la muestra)}

Cuando tenemos una variable aleatoria normal

\[X \rightarrow N(\mu, \sigma^2)\]

identificamos las tres cantidades diferentes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\mu\) es un \textbf{parámetro} de la distribución de la \textbf{población}: \(N(\mu, \sigma^2)\)
\item
  \(\bar{X}=\frac{1}{n} \sum_{i=1}^n X_i\) es un \textbf{estimador} de \(\mu\)
\item
  \(\bar{x}=\hat{\mu}\) es la \textbf{estimación} de \(\mu\)
\end{enumerate}

\textbf{Ejemplo (varianza de la muestra)}

Cuando tenemos una variable aleatoria normal

\[X \rightarrow N(\mu, \sigma^2)\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(\sigma^2\) es un \textbf{parámetro} de la distribución de la población
\item
  \(S^2=\frac{1}{n-1} \sum_{i=1}^n (X_i-\bar{X})^2\) es un \textbf{estimador} de \(\sigma^2\)
\item
  \(s^2=\hat{\sigma}^2\) es la \textbf{estimación} de \(\sigma^2\)
\end{enumerate}

\hypertarget{propiedades}{%
\section{Propiedades}\label{propiedades}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Un estimador es \textbf{insesgado} si su valor esperado es el parámetro
\end{enumerate}

\[E(\Theta)=\theta\]

Por ejemplo:

\begin{itemize}
\item
  \(\bar{X}\) es un estimador \textbf{insesgado} de \(\mu\) porque \(E(\bar{X})=\mu\)
\item
  \(S^2\) es un estimador \textbf{insesgado} de \(\sigma^2\) porque \(E(S^2)=\sigma^2\)
\end{itemize}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Un estimador es \textbf{consistente} cuando sus valores observados están cada vez menos dispersos al rededor de la medida a medida que el tamaño de la muestra crece
\end{enumerate}

\[lim_{n\rightarrow \infty} V(\Theta) = 0\]

Por ejemplo:

\begin{itemize}
\tightlist
\item
  \(\bar{X}\) es \textbf{consistente} porque \(V(\bar{X})=\frac{\sigma^2}{n}\rightarrow 0\) cuando \(n \rightarrow \infty\).
\end{itemize}

\hypertarget{muxe1xima-verosimilitud}{%
\section{Máxima verosimilitud}\label{muxe1xima-verosimilitud}}

¿Cómo se pueden obtener \textbf{estimadores} de los parámetros de \textbf{cualquier} modelo de probabilidad?

\textbf{Ejemplo (Láser)}

Imagina que diseñamos un láser con un diámetro de \(1 mm\) que queremos usar para aplicaciones clínicas.

Queremos caracterizar el diámetro de un piercing en un tejido realizado con láser y tomar una muestra aleatoria de \(30\) cortes realizados con láser. Aquí están los resultados

\begin{verbatim}
##  [1] 1.11 1.64 1.20 1.79 1.89 1.01 1.31 1.81 1.34 1.25 1.92 1.24 1.49 1.36 1.03
## [16] 1.82 1.09 1.01 1.14 1.91 1.80 1.51 1.44 1.98 1.46 1.53 1.33 1.39 1.12 1.04
\end{verbatim}

y el histograma

\includegraphics{_main_files/figure-latex/unnamed-chunk-82-1.pdf}

¿Cuál sería una función de probabilidad que podría describir los datos?

Para ello seguimos el siguiente proceso:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Proponemos \textbf{un modelo} que depende de parámetros
\item
  Derivamos los \textbf{estimadores} para los parámetros, por máxima verosimilitud o el método de momentos.
\item
  Finalmente usamos el estimador para \textbf{estimar los parámetros} con los datos.
\end{enumerate}

\emph{Proponiendo una densidad de probabilidad}

En muchas aplicaciones, podemos proponer la forma de una densidad de probabilidad que depende de algunos parámetros. Proponer un modelo de probabilidad se hace siguiendo \textbf{propiedades generales} de las observaciones, o lo que esperamos observar. El modelado requiere experiencia, habilidad y conocimiento de varias funciones matemáticas. Sin embargo, en la mayoría de los casos se suelen aplicar \textbf{modelos bien conocidos}.

\textbf{Ejemplo (Láser)}

En nuestro ejemplo, podemos considerar, por ejemplo, que se debe dar la máxima probabilidad a los diámetros de \(x=1 mm\), y que los diámetros deben disminuir como la potencia inversa de algún parámetro \textbf{desconocido} \(\alpha\), con un límite de \(2mm\) más allá del cual la probabilidad es de \(0\).

Una distribución de densidad de probabilidad adecuada es

\[
    f(x)= 
\begin{cases}
\frac{1}{\alpha}(x-1)^{\frac{1}{\alpha}-1},& \text{if } x \in (1,2)\\
    0,& x \notin (1,2)\\
\end{cases}
\]

Donde \(\alpha\) es un parámetro. Esta es una densidad de probabilidad porque se integra a uno y es positiva. En particular, para \(\alpha=2\) podemos graficarlo

\includegraphics{_main_files/figure-latex/unnamed-chunk-83-1.pdf}

\emph{Derivar los estimadores}

Si realizamos una muestra de tamaño \(n\): \((X_1,...X_n)\), ¿Cómo debemos combinar los datos para obtener el mejor valor de \(\alpha\)?

Muchos valores de para el parámetro podrían explicar los datos. Nos interesa \textbf{un criterio} para elegir un valor en particular.

\includegraphics{_main_files/figure-latex/unnamed-chunk-84-1.pdf}

El método de \textbf{máxima verosimilitud} nos da un estimador para \(\alpha\)

\[\hat{\alpha}_{ml}\]

\hypertarget{muxe1xima-verosimilitud-1}{%
\section{Máxima verosimilitud}\label{muxe1xima-verosimilitud-1}}

El objetivo es encontrar el valor del parámetro que \textbf{creemos} es el que \textbf{mejor} representa los datos.

El método de máxima verosimilitud se basa en la búsqueda del valor del parámetro que hace más \textbf{probable} la \textbf{observación} de la muestra.

\textbf{Máxima verosimilitud paso 1}

Calculamos la probabilidad de haber observado la muestra \(n\): \(x_1,...x_n\). Es el producto de probabilidades porque las observaciones son independientes entre sí:

\(P(M=x_1,...x_n)=P(X=x_1)P(X=x_2)...P(X=x_n)\)
\[=f(x_1;\alpha)f(x_2;\alpha) ...f(x_n;\alpha)\]

A esta función la llamamos \textbf{función de verosimilitud} y consideramos que:

\begin{itemize}
\tightlist
\item
  Una vez observados los datos estos son \textbf{fijos}
\item
  La incógnita es \(\alpha\)
\end{itemize}

\[L(\alpha)= \Pi_{i=1..n} f(x_i; \alpha)\]

\textbf{Ejemplo (Láser)}

Para el experimento con láser la función de verosimilitud es

\(L(\alpha;x_1,..x_n)= \frac{1}{\alpha^n} \Pi_{i=1..n} (x_i-1)^{\frac{1-\alpha}{ \alpha}}= \frac{1}{\alpha^n} \{(x_1-1)(x_2-1)...(x_n-1)\}^{\frac{1-\alpha}{\alpha}}\)

\textbf{Máxima verosimilitud paso 2}

Entonces nos preguntamos: ¿cuál es el valor de \(\alpha\) que hace que la muestra observada sea el evento más probable? Por lo tanto, queremos maximizar \(L(\alpha)\) con respecto a \(\alpha\). Como tenemos la multiplicación de muchos factores es más fácil maximizar el logaritmo de \(L(\alpha)\). Esto se llama la función logaritmo de verosimilitud:

\[\ln L(\alpha;x_1,..x_n)\]

\textbf{Ejemplo (Láser)}

En el ejemplo del láser, tomamos el logaritmo y obtenemos la \textbf{Logaritmo de verosimilitud}

\[\ln L(\alpha;x_1,..x_n)= -n \ln(\alpha) + {\frac{1-\alpha}{\alpha}} \Sigma_{i=1...n} \ln (x_i-1)\]

\textbf{Máxima verosimilitud paso 3}

Finalmente \textbf{maximizamos} el logaritmo de verosimilitud con respecto al parámetro. Por lo tanto, diferenciamos el log-verosimilitud con respecto al parámetro \(\alpha\), igualamos a cero y resolvemos para el máximo.

\[\frac{d \ln L(\alpha)}{d \alpha} \big|_{\hat{\alpha}}=0 \]
El valor máximo del parámetro se denomina \textbf{estimación de máxima verosimilitud} para el parámetro y se escribe con un sombrero \(\hat{\alpha}\).

\textbf{Ejemplo (Láser)}

Derivamos la función log-verosimilitud

\[\frac{d \ln L(\alpha)}{d \alpha}= -\frac{n}{\alpha} - \frac{1}{\alpha^2} \Sigma_{i=1.. .n} \ln (x_i-1)\]
El máximo es donde la derivada es \(0\). Este máximo es el valor de nuestro estimador \(\hat{\alpha}_{ml}\).

\[\hat{\alpha}_{ml}=-\frac{1}{n}\sum_{i=1}^n \ln (x_i-1)\]

El estimador del parámetro es por lo tanto (nótese las letras mayúsculas)

\[A=-\frac{1}{n}\sum_{i=1}^n \ln (X_i-1)\]

Que es una variable aleatoria, función de la muestra aleatoria

\[(X_1, X_2, ... X_n)\]

\emph{Estimando los parámetros con los datos}

En nuestro ejemplo, tenemos entonces la observación de la muestra aleatoria como un conjunto de 30 números \((x_1, x_2, ...x_{30})\), por lo tanto sustituimos los números en el estimador y esto nos dará su valor observado.

\(\hat{\alpha}_{ml}=-\frac{1}{30}\{ \ln (1.11-1)+ \ln (1.64-1)+...\ln (1.04-1)\}=1.320\)

Por lo tanto, la estimación de máxima verosimilitud del parámetro es \(1.320\). Si sustituimos este valor en la función de probabilidad y lo superponemos con el histograma, podemos ver que nos da una descripción adecuada de los datos.

\includegraphics{_main_files/figure-latex/unnamed-chunk-85-1.pdf}

Veamos la función del logaritmo de la verosimilitud para nuestros \(30\) cortes láser. Recuerda, los datos son fijos para nuestro experimento y \(\alpha\) varía. La función tiene un máximo. Sin embargo, si tomamos otra muestra, esta función cambia y también su lo hará su máximo.

\includegraphics{_main_files/figure-latex/unnamed-chunk-86-1.pdf}

\textbf{Máxima verosimilitud: Historia}

Para inferir la verdadera posición de Ceres en un momento dado, Gauss derivó la función de error

\[f(x; \mu, \sigma^2)= \frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{1}{2\sigma^2} (x- \mu)^2}\]

Donde la posición \textbf{verdadera} de Ceres era la media \(\mu\). ¿Cómo podemos combinar los datos para tener la mejor estimación de la posición de Ceres?

¿Cuál es la estadística que mejor puede describir su posición?

\includegraphics{./figures/cerestime.JPG}

Esta pregunta se puede formular como: ¿Cuál es la estimación de máxima verosimilitud de \(\mu\) para una variable aleatoria normal?

\textbf{Máxima verosimilitud de la distribución normal}

Para una variable aleatoria normal

\[X \rightarrow N(\mu, \sigma^2)\].

¿Cuáles son los estimadores de \(\mu\) y \(\sigma^2\) que maximizan la probabilidad de los datos observados?

\includegraphics{./figures/normpar.JPG}

Seguimos el método de máxima verosimilitud:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  La función de verosimilitud, o la probabilidad de haber observado la muestra \((x_1, ....x_n)\) es
\end{enumerate}

\(L(\mu, \sigma^2)=\Pi_{i=1..n} f(x_i;\mu,\sigma)\)

\[=\big( \frac{1}{\sigma \sqrt{2 \pi}}\big)^ne^{-\frac{1}{2\sigma^2} \sum_i(x_i-\mu) ^2}\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Tomamos el logaritmo de \(L\) y calculamos la función \textbf{log-verosimilitud}
\end{enumerate}

\[\ln L(\mu, \sigma^2)=-n \ln(\sigma \sqrt{2 \pi})-\frac{1}{2\sigma^2} \Sigma_i(x_i-\mu )^2\]

Las estimaciones de \(\mu\) y \(\sigma^2\) son donde la probabilidad es máxima. Dan la probabilidad más alta para los datos de la muestra.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Diferenciamos con respecto a \(\mu\) y \(\sigma^2\). Estas dos derivadas nos dan dos ecuaciones, una para cada uno de los parámetros. Para derivar con respecto a \(\sigma^2\), es más fácil hacer una sustitución \(t=\sigma^2\).
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\item
  \(\frac{d \ln L(\mu, \sigma^2)}{d\mu}=\frac{1}{\sigma^2} \sum_i(x_i-\mu)\)
\item
  \(\frac{d \ln L(\mu, \sigma^2)}{d\sigma^2}=-\frac{n}{2 \sigma^2}+\frac{1}{2\sigma^4} \sum_i(x_i-\mu)^2\)
\end{enumerate}

Las derivadas son \(0\) en el máximo

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  \(\frac{1}{\hat{\sigma}^2} \sum_i(x_i-\hat{\mu})=0\)
\item
  \(-\frac{n}{2 \hat{\sigma}^2}+\frac{1}{2\hat{\sigma}^4} \sum_i(x_i-\hat{\mu})^ 2=0\)
\end{enumerate}

resolviendo ambas ecuaciones para los parámetros, encontramos para \(\mu\)

\[\hat{\mu}_{ml}=\frac{1}{n}\sum_i x_i=\bar{x}\]

y para \(\sigma^2\)

\[\hat{\sigma}^2_{ml}=\frac{1}{n}\sum_i(x_i-\bar{x})^2\]

Por lo tanto la \textbf{media mestral} o promedio \(\bar{X}\) es el estimador de máxima verosimilitud de la media \(\mu\) de la población. Gauss demostró que la estadística en la que más deberíamos confiar (la que tienen la mayor verosimilitud) para la posición real de Ceres era el \textbf{promedio}. Gauss, al resolvier la posición de Ceres, no solo descubrió la distribución normal, sino que también creó el análisis de regresión y mostró la importancia del promedio. Es debido a él que usamos el promedio para muchas cosas, y no otro tipo de estadísticas.

Además, el estimador de máxima verosimilitud de \(\sigma^2\) es un estimador \textbf{sesgado} porque se puede demostrar que \[E(\hat{\sigma}^2_{ml})=\sigma^2+ \frac{\sigma^2}{n}\neq\sigma^2\]

Fue Fisher quien demostró que a pesar de ser sesgado este estimador es importante, ya que lo usó para generalizar el teorema del límite central, donde pierde su sesgo en \(n\rightarrow \infty\).

\hypertarget{muxe9todo-de-los-momentos}{%
\section{Método de los Momentos}\label{muxe9todo-de-los-momentos}}

El método de máxima verosimilitud tiene como objetivo producir los estimadores de distribuciones de probabilidad a partir de datos. Sin embargo, existe otra forma de producir esos estimadores, que se basa en la idea frecuentista de las probabilidades.

Hbíamos visto que las frecuancias relativas tienden a las probabilidades cuando \(n\) es grande \(f_i \rightarrow f(x_i)\), y como consequencia

\[\bar{x} \rightarrow \mu\]
El centro de gravedad de los datos tiende al centro de gravedad de la probabilidad.
El método de los momentos dice que podemos tomar el valor \textbf{observado} de la media meustral \(\bar{X}\) como estimador de \(E(X)=\mu\)

\[E(X)\sim \bar{x}=\hat{\mu}\]

Es decir que la variable aleatoria que estima la media de la población es el promedio:

\[\bar{X}= \frac{1}{n}\sum_i X_i\]

que también se denomina el primer \textbf{momento de muestra}

En general, si \(X \rightarrow f(x, \theta)\) el estimador del parámetro \(\theta\) se obtiene entonces de la ecuación:

\[E(X; \hat{\theta})=\bar{x}\]

debido a que el valor esperado de la variable aletoria siempre es función del parámetro \(\theta\).

\textbf{Ejemplo (exponencial)}

Si una variable aleatoria sigue una distribución exponencial

\[X \hookrightarrow exp(\lambda)\]

entonces podemos usar el método de los momentos para estimar \(\lambda\). El método consta de tres pasos:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Calcular el valor esperado de la variable \[E(X; \lambda)=\mu\]
\item
  Escribir la ecuación donde el valor esperado es igual al primer momento muestral \[\frac{1}{\hat{\lambda}}=\bar{x}\]
\item
  Resolver para el parámetro
\end{enumerate}

\[\hat{\lambda}=\frac{1}{\bar{x}}\]
En términos de datos, esto es \(\hat{\lambda}=(\frac{1}{n}\sum_i x_i)^{-1}\). Es decir que si queremos estimar el parámetro \(\lambda\) de una variable exponencial de un experimento aleatorio, debemos tomar una muestra aleatoria, sacar su promedio y tomar su inversa. El resultado es el estimador de parámetro que después, junto al modelo, lo podemos usar para calcular las probabilidades de observaciones futuras.

\textbf{Ejemplo (Baterías)}

Supongamos que tenemos varias baterías (nuevas y viejas) que cargamos durante el período de 1 hora. Medimos el estado de carga de la batería, siendo 1 un 100\% de carga.

El estado de carga de una batería es una variable aleatoria que puede tener una distribución uniforme, donde no sabemos el valor mínimo que puede tomar \(x\), pero sabemos que el máximo es 1 (\(100\%\) de carga)

\[
f(x)=
\begin{cases}
    \frac{1}{1-a},& \text{if } x\in (a,1)\\
    0,& x\notin (a,1)
\end{cases}
\]

¿Cuál es el estimador de \(a\) (la carga mínima después de una hora)?

Si ejecutamos un experimento y obtenemos \(x_1,...x_n\), nos preguntamos ¿cómo podemos estimar \(a\) a partir de los datos?

Seguimos los tres pasos del método de los momentos:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Calculamos el valor esperado de la variable aleatoria
\end{enumerate}

\[E(X)=\frac{a+1}{2}\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Obtenemos la ecuación para \(\hat{a}\) donde igualamos el valor esperado al primer momento muestral
\end{enumerate}

\[\frac{\hat{a}+1}{2}=\bar{x}\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Resolvemos para el estimador \(\hat{a}\)
\end{enumerate}

\[\hat{a}=2\bar{x}-1\]

Este es el estimador de la carga mínima que podemos observar.

Ten en cuenta si tomaramos el mínimo de las observaciones esto sería claramente subóptimo. El método nos dio una respuesta inteligente que también se puede resumir en los siguientes pasos

\begin{enumerate}
\def\labelenumi{\alph{enumi})}
\tightlist
\item
  Podemos calcular \(\bar{x}\) con precisión creciente dada por \(n\)
\item
  Sabemos que ninguna medida supera \(b=1\)
\item
  Luego calculamos la distancia entre \(\bar{x}\) y \(b\) que es \(1-\bar{x}\)
\item
  Esta distancia la restamos al promedio \(\bar{x}\) para estimar el valor mínimo de carga:
\end{enumerate}

\[\bar{x}-(1-\bar{x})=2\bar{x}-1\]

Esta debería ser nuestra mejor suposición para \(\hat{a}\). Como tal llegamos a la misma estimación dada por el método de los momentos.

\hypertarget{muxe9todo-de-momentos-para-varios-paruxe1metros}{%
\section{Método de Momentos para varios parámetros}\label{muxe9todo-de-momentos-para-varios-paruxe1metros}}

El método dice que se puede encontrar un estimador para el parámetro \(\theta\) de \(f(x;\theta)\) a partir de la ecuación:

\[E(X)=\frac{1}{n}\sum_i x_i\]

Si hay más parámetros, usamos los \textbf{momentos de muestra} más altos. Consideremos que el segundo momento muestral es

\[\frac{1}{n}\sum_i X^2_i\]

Por lo tanto, una observación de este momento es cercana a \(E(X^2)\)

\[E(X ^ 2)=\frac{1}{n}\sum_i x^2_i\]

El método para dos parámetros dice que se puede encontrar una estimación para los parámetros \(\theta_1\) y \(\theta_2\) de \(f(x;\theta_1,\theta_2)\) a partir de las ecuaciones:

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  \(E(X)= \frac{1}{n}\sum_i x_i\)
\item
  \(E(X^2)=\frac{1}{n}\sum_i x^2_i\)
\end{enumerate}

Podemos tener tantas ecuaciones como parámetros necesitemos calcular, incrementando el grado de los momentos, es decir las potencias de \(X\).

\textbf{Ejemplo (Distribución normal)}

Si \(X\) se distribuye normalmente, tenemos dos parámetros para estimar
\[X \rightarrow N(\mu, \sigma^2)\]

Seguimos los pasos del método de los momentos para dos parámetros:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Calculamos el valor esperado de la variable
\end{enumerate}

\[E(X)=\mu\]
y el valor esperado de \(X^2\)

\[E(X^2)=\sigma^2+\mu^2\]

\(E(X^2)\) se sigue de la propiedad: \(E(X^2) = V(X)+\mu^2\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Obtenemos las ecuaciones para los parámetros donde hacemos (a) el valor esperado de la variable igual al primer momento muestral, y (b) el valor esperado del segundo momento igual al segundo momento muestral
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  \(E(X)\) se estima por \[\hat{\mu}=\frac{1}{n}\sum_i x_i\]
\item
  \(E(X^2)\) se estima por \[\hat{\sigma}^2+\hat{\mu}^2=\frac{1}{n}\sum_i x^2_i\]
\end{enumerate}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  Resolvemos los parámetros
\end{enumerate}

La primera ecuación da directamente el estimador de la media \(\mu\).

\[\hat{\mu}=\frac{1}{n}\sum_i x_i\]

Que de nuevo es el promedio. De la segunda ecuación obtenemos

\[\hat{\sigma}^2= \frac{1}{n} \sum_i x^2_i-\hat{\mu}^2\]

que también se puede escribir como:
\[\hat{\sigma}^2=\frac{1}{n} \sum_i(x_i-\hat{\mu})^2\]
Encontramos que el método de los momentos y las estimaciones de máxima verosimilitud para la distribución normal son iguales. Sin embargo, este no siempre es el caso.

\textbf{Ejemplo (láser)}

¿Cuál es el estimador del parámetro \(\alpha\) para el corte láser dado por el método de los momentos?

\[
    f(x; \alpha)= 
\begin{cases}
\frac{1}{\alpha}(x-1)^{\frac{1}{\alpha}-1},& \text{if } x \in (1,2)\\
    0,& x \notin (1,2)\\
\end{cases}
\]

Donde \(\alpha\) es un parámetro.

El método dice que se puede encontrar un estimador para el parámetro \(\alpha\) de \(f(x;\alpha)\) a partir de la ecuación:

\[E(X)=\frac{1}{n}\sum_i x_i\]
por \(\hat{\alpha}\)

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Calculamos el valor esperado \(E(X)\)
\end{enumerate}

\[E(X)=\int_{-\infty}^{\infty} xf(x;\alpha)dx\]

Considera un cambio de variables \(Z=X-1\) entonces \(E(X)=E(Z)+1\) y

\(E(Z)= \frac{1}{\alpha} \int_0^1 zz^{\frac{1-\alpha}{\alpha}}dz= \frac{1}{\alpha} \int_0^1 z^{1+\frac{1-\alpha}{\alpha}}dz\)

\(= \frac{1}{\alpha} \frac{z^{2+\frac{1-\alpha}{\alpha}}}{{2+\frac{1-\alpha}{\alpha}} } |_0^1=\frac{1}{1+\alpha}\)

Por lo tanto,

\[E(X)=E(Z+1)=\frac{1}{1+\alpha}+1\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Obtenemos la ecuación para \(\hat{\alpha}_m\) donde igualamos el valor esperado al primer momento muestral. Sustituyendo \(\hat{\alpha}_m\), el método de los momentos nos da la ecuación
\end{enumerate}

\[\frac{1}{1+\hat{\alpha}}+1=\bar{x}\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\item
  Resolvemos para \(\hat{\alpha}\) \[\hat{\alpha}_m=\frac{1}{\bar{x}-1}-1\]
\item
  Calculamos el valor de nuestros datos
\end{enumerate}

\[\hat{\alpha}_m=1.314\]

Tenga en cuenta que este es un ejemplo para el cual las estimaciones por máxima verosimilitud y el método de momentos son \textbf{diferentes}.

La estimación de máxima verosimilitud fue:

\[\hat{\alpha}_{ml}=-\frac{1}{n}\sum_{i=1}^n \ln (x_i-1)=1.320\]

El método de estimación de momentos fue:

\[\hat{\alpha}_m=\frac{1}{\bar{x}-1}-1=1.314\]

Necesitamos estudios de \textbf{simulación}, donde \textbf{sabemos} el verdadero valor del parámetro \(\alpha\), para encontrar cuál de estas estadísticas tiene menos error.

Nota: los datos para perforaciones con láser de \(30\) se simularon con \(\alpha=2\), por lo tanto, debemos preferir la estimación de máxima verosimilitud. Para obtener mejores estimaciones de \(\alpha\) necesitamos aumentar el tamaño de la muestra.

\hypertarget{preguntas-9}{%
\section{Preguntas}\label{preguntas-9}}

\textbf{1)} Un estimador no es

\textbf{\(\qquad\)a:} una estadística;
\textbf{\(\qquad\)b:} una variable aleatoria;
\textbf{\(\qquad\)c:} discreto;
\textbf{\(\qquad\)d:} Una observación de un parámetro;

\textbf{2)} Un estimador es insesgado si

\textbf{\(\qquad\)a:} es el parámetro que estima;
\textbf{\(\qquad\)b:} depende de \(1/n\);
\textbf{\(\qquad\)c:} varianza es pequeña;
\textbf{\(\qquad\)d:} su valor esperado es el parámetro que estima;

\textbf{3)} Un estimador es consistente si

\textbf{\(\qquad\)a:} es el parámetro que estima;
\textbf{\(\qquad\)b:} depende de \(1/n\);
\textbf{\(\qquad\)c:} varianza es pequeña;
\textbf{\(\qquad\)d:} su valor esperado es el parámetro que estima;

\textbf{4)} El método de máxima verosimilitud

\textbf{\(\qquad\)a:} Produce estimadores basados en la probabilidad de las observaciones;
\textbf{\(\qquad\)b:} produce estimadores insesgados;
\textbf{\(\qquad\)c:} produce estimadores consistentes;
\textbf{\(\qquad\)d:} produce estimadores iguales a los del métoodo de los momentos;

\textbf{5)} El primer momento muestral es

\textbf{\(\qquad\)a:} la media;
\textbf{\(\qquad\)b:} la varianza;
\textbf{\(\qquad\)c:} el valor esperado;
\textbf{\(\qquad\)d:} el promedio;

\hypertarget{ejercicios-10}{%
\section{Ejercicios}\label{ejercicios-10}}

\hypertarget{ejercicio-1-9}{%
\subsubsection{Ejercicio 1}\label{ejercicio-1-9}}

Toma una variable aleatoria con la siguiente función de densidad de probabilidad

\[
f(x)=
\begin{cases}
    (1+\theta)x^\theta,& \text{if } x\in (0,1)\\
    0,&  x\notin (0,1)
\end{cases}
\]

\begin{itemize}
\item
  ¿Cuál es la estimación de máxima verosimilitud para \(\theta\)? (R:\(\hat{\theta}=-n/\sum_{i=1..n} \log(x_i)-1\))
\item
  Si tomamos una muestra de \(5\) obsevaciones
  \(x_1 = 0.92; \qquad x_2 = 0.79; \qquad x_3 = 0.90; \qquad x_4 = 0.65; \qquad x_5 = 0.86\)
\end{itemize}

¿Cuál es el valor estimado del parámetro \(\theta\)? (R: \(\hat{\theta}=3.96\))

\begin{itemize}
\tightlist
\item
  Calcula \(E(X)=\mu\) en función de \(\theta\). ¿Cuál es la estimación de máxima verosimilitud para \(\mu\)? (R:\(\hat{\mu}=(1+\hat{\theta})/(2+\hat{\theta})=0.832\))
\end{itemize}

\hypertarget{ejercicio-2-9}{%
\subsubsection{Ejercicio 2}\label{ejercicio-2-9}}

Para una variable aleatoria con una función de probabilidad binomial

\[f(x; p)=\binom nxp^x(1-p)^{n-x}\]

\begin{itemize}
\item
  ¿Cuál es el estimador de máxima verosimilitud de \(p\) para una muestra de tamaño \(1\) de esta variable aleatoria? (R:\(\hat{p}=x_1/n\))
\item
  ¿Es el estimador insesgado y/o consistente?
\item
  En \textbf{un} examen de \(100\) estudiantes observamos \(x_1=68\) estudiantes que aprobaron el examen. ¿Cuál es la estimación de máxima verosimilitud para la probabilidad de pasar el examen? (R:0.68)
\end{itemize}

\hypertarget{ejercicio-3-6}{%
\subsubsection{Ejercicio 3}\label{ejercicio-3-6}}

Toma una variable aleatoria con la siguiente función de densidad de probabilidad

\[
    f(x)= 
\begin{cases}
    \lambda e^{-\lambda x},&  x > 0 \\
    0,& x\leq 0  
\end{cases}
\]

\begin{itemize}
\item
  ¿Cuál es la estimación de máxima verosimilitud para \(\lambda\)? (R: \(1/\bar{x}\))
\item
  Si tomamos una muestra de \(5\) observaciones
  \(x_1 = 0.223 \qquad x_2 = 0.681; \qquad x_3 = 0.117; \qquad x_4 = 0.150; \qquad x_5 = 0.520\)
\end{itemize}

¿Cuál es el valor estimado del parámetro \(\alpha=\frac{n}{\lambda}\)? (R:2.95)

\begin{itemize}
\item
  ¿Cuál es la estimación de máxima verosimilitud de la varianza de la variable exponencial \(\sigma^2=\frac{1}{\lambda^2}\)? (R:1.694)
\item
  ¿Es \(\alpha\) un estimador insesgado y consistente de \(E(Y)\), donde \(Y=\sum_1^n X_i\)? (R: Es insesgado, no es consistente)
\end{itemize}

\hypertarget{muxe9todo-de-los-momentos-1}{%
\section{Método de los momentos}\label{muxe9todo-de-los-momentos-1}}

\hypertarget{ejercicio-1-10}{%
\subsubsection{Ejercicio 1}\label{ejercicio-1-10}}

¿Cuáles son los estimadores de los siguientes modelos paramétricos dados por el método de los momentos?

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.5500}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2500}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 4\tabcolsep) * \real{0.2000}}@{}}
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
Model
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
f(x)
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
E(X)
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Bernoulli & \(p^x(1-p)^{1-x}\) & \(p\) \\
Binomial & \(\binom n x p^x(1-p)^{n-x}\) & \(np\) \\
Geometrica & \(p(1-p)^{x-1}\) & \(\frac{1}{p}\) \\
Binomial Negativa & \(\binom {x+r-1} x p^r(1-p)^x\) & \(r\frac{1-p}{p}\) \\
Poisson & \(\frac{e^{-\lambda}\lambda^x}{x!}\) & \(\lambda\) \\
Exponencial & \(\lambda e^{-\lambda x}\) & \(\frac{1}{\lambda}\) \\
Normal & \(\frac{1}{\sqrt{2\pi}\sigma}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\) & \(\mu\) \\
\end{longtable}

(R: \(\hat{p}=\bar{x}\),
\(\hat{p}=\bar{x}/n\),
\(\hat{p}=1/\bar{x}\)
\(\hat{p}=r/(\bar{x}+1)\),
\(\hat{\lambda}=\bar{x}\),
\(\hat{\lambda}=1/\bar{x}\),
\(\hat{\mu}=\bar{x}\))

\hypertarget{ejercicio-2-10}{%
\subsubsection{Ejercicio 2}\label{ejercicio-2-10}}

Toma una variable aleatoria con la siguiente función de densidad de probabilidad

\[
f(x)=
\begin{cases}
    (1+\theta)x^\theta,& \text{if } x\in (0,1)\\
    0,& x\notin (0,1)
\end{cases}
\]

\begin{itemize}
\tightlist
\item
  Calcula \(E(X)\) como una función de \(\theta\) (R:\((1+\theta)/(2+\theta)\))
\item
  ¿Cuál es la estimación de \(\theta\) utilizando el método de los momentos? (R:\(\hat{\theta}=(2\bar{x}-1)/(1-\bar{x})\))
\item
  Si tomamos una muestra de \(5\) observaciones
  \(x_1 = 0.92; \qquad x_2 = 0.79; \qquad x_3 = 0.90; \qquad x_4 = 0.65; \qquad x_5 = 0.86\)
\end{itemize}

¿Cuál es el valor estimado del parámetro \(\theta\)? (R:3.681)

\hypertarget{ejercicio-3-7}{%
\subsubsection{Ejercicio 3}\label{ejercicio-3-7}}

Considera una variable aleatoria discreta \(X\) que sigue una distribución binomial negativa con función de masa de probabilidad:

\[f(x) = \binom{x+r-1}{x}p^r(1-p)^x\]

Dado que

\begin{itemize}
\tightlist
\item
  \(E(X)=\dfrac{r(1-p)}{p}\)
\item
  \(V(X) =\dfrac{r(1-p)}{p^2}\)
\end{itemize}

calcular:

\begin{itemize}
\item
  Una estimación del parámetro \(r\) y una estimación del parámetro \(p\) obtenidas a partir de una muestra aleatoria de tamaño \(n\) por el método de los momentos. (R: \(\hat{p}=\bar{x}/({1/n \sum x^2}-\bar{x}^2)\), \(\hat{r}=\bar{x}\hat{p}/(1-\hat{p})\))
\item
  Los valores de las estimaciones de \(r\) y \(p\) para la siguiente muestra aleatoria:
\end{itemize}

\[x_1 = 27; \qquad   x_2 = 8; \qquad   x_3 = 22; \qquad   x_4 = 29; \qquad   x_5 = 19; \qquad   x_5 = 32\]

(R: 13.152, 0.365)

\hypertarget{intervalos-de-confianza}{%
\chapter{Intervalos de confianza}\label{intervalos-de-confianza}}

\hypertarget{objetivo-9}{%
\section{Objetivo}\label{objetivo-9}}

En este capítulo, presentaremos el concepto de \textbf{intervalos de confianza} para medias, proporciones y varianzas.

Derivaremos las fórmulas para los intervalos de confianza bajo diferentes condiciones, como normalidad con varianza conocida y desconocida, y \(n\) grande.

\hypertarget{estimaciuxf3n-de-la-media}{%
\section{Estimación de la media}\label{estimaciuxf3n-de-la-media}}

Hemos visto que siempre que tomamos una muestra aleatoria \((X_1, X_2, ... X_n)\), la media muestral
\[\bar{X}=\frac{1}{n}\sum_{i=1}^n X_i\]

es un estimador de la media \(\mu\) de la variable aleatoria \(X\). El estimador es \textbf{insesgado}

\begin{itemize}
\tightlist
\item
  \(E(\bar{X})=\mu\)
\end{itemize}

y \textbf{consistente}

\begin{itemize}
\tightlist
\item
  \(V(\bar{X})=\frac{\sigma^2}{n}\)
\end{itemize}

donde \(\sigma^2\) es la varianza de \(X\). Llamamos a \(se=\frac{\sigma}{\sqrt{n}}\) el \textbf{error estándar}.

cuando tomamos los valores de la muestra aleatoria, tomamos el valor de \(\bar{x}\) como el valor de la media. Eso es

\[\bar{x}=\hat{\mu}\]

Como \(\bar{X}\) es una variable aleatoria, la estimación de la media \textbf{cambia} cuando tomamos \textbf{otra muestra}.

\hypertarget{margen-de-error-1}{%
\section{Margen de error}\label{margen-de-error-1}}

Al decidir si el \textbf{error} en la estimación \[\bar{X}-\mu\] es grande o no, generalmente lo comparamos con una tolerancia predefinida. \textbf{Si sabemos} que la distribución de \(X\) es normal \(X \rightarrow N(\mu, \sigma^2)\) y el valor de \(\mu\), podemos calcular qué tan lejos cae la estimación de \(\bar{x}\) de \(\mu\).

Definimos el \textbf{margen de error} al nivel de \(5\%\) como la distancia \(m\) tal que la distribución de \(\bar{X}\) captura \(95\%\) de las estimaciones:

\[P(-m \leq \bar{X}-\mu \leq m)=P(\mu-m \leq \bar{X} \leq\mu + m)=0.95\]

Si \(\bar{X}\) se distribuye normalmente, entonces el margen de error es

\[m=z_{0.025} \frac{\sigma}{\sqrt{n}}=1.96\times se\]
donde \(z_{0.025}=\phi^{-1}(0.975)=\) qnorm(0.975)

\textbf{Ejemplo (cables):}

Tomamos una muestra aleatoria de tamaño \(8\): Cargamos un cable hasta que se rompan y registramos la carga de rotura.

\textbf{Si sabemos} que la rotura de los cables realmente se distribuyen normalmente \[X \rightarrow N(\mu=13, \sigma^2=0.35^2)\] entonces la media muestral es normal

\[\bar{X} \rightarrow N(13, \frac{0.35^2}{8})\]

Con media \(E(\bar{X})=13\) y error estándar \(se=\frac{0.35}{\sqrt{8}}=0.1237\)

Por lo tanto, el margen de error en \(95\%\) es

\[m=z_{0.025} \frac{\sigma}{\sqrt{n}}=1.96\times se=1.96\frac{0.35}{\sqrt{8}}=0.24\]
Ahora, tomamos la muestra aleatoria y encontramos los resultados.

\begin{verbatim}
## [1] 13.34642 13.32620 13.01459 13.10811 12.96999 13.55309 13.75557 12.62747
\end{verbatim}

El promedio observado es \(\bar{x}=13.21\), y el error que cometeríamos si reemplazamos \(\mu\) por \(\bar{x}\), sería

\[\bar{x}-\mu=13.21-13=0.21\]
El \textbf{error observado} está dentro del margen de error

\[\bar{x}-\mu <m\]

\includegraphics{_main_files/figure-latex/unnamed-chunk-88-1.pdf}

\includegraphics{_main_files/figure-latex/unnamed-chunk-89-1.pdf}

\hypertarget{estimaciuxf3n-de-intervalo-para-la-media}{%
\section{Estimación de intervalo para la media}\label{estimaciuxf3n-de-intervalo-para-la-media}}

El problema es que en la vida real \textbf{no sabemos} los valores reales de \(\mu\) o \(\sigma\) para

\[X \rightarrow N(\mu, \sigma^2)\]
Empezamos tomando la muestra

\includegraphics{_main_files/figure-latex/unnamed-chunk-90-1.pdf}

y luego calcular la media

\includegraphics{_main_files/figure-latex/unnamed-chunk-91-1.pdf}

¿Cuál es el valor de \(\mu\)?

Nuestros datos sugieren que es \(\bar{x}=13.21\). Reemplazar \(\mu\) por \(\bar{x}\) se denomina \textbf{estimación puntual} del parámetro. Pero ¿qué tan \textbf{seguros} estamos al hacer este remplazo? después de todo, sabemos que estamos cometiendo un error, pero no sabemos qué tan grande es.

Definimos el intervalo de confianza para \(\mu\). De la ecuación del margen de error

\[P(-m \leq \bar{X} - \mu \leq m)=0.95\]
resolvamos para \(\mu\) que es \textbf{la verdadera incógnita}

\[P(\bar{X} - m \leq \mu \leq \bar{X} + m)=0.95\]

Los límites izquierdo y derecho de la desigualdad son variables aleatorias que motivan la definición del \textbf{intervalo de confianza aleatorio en \(95\%\):}

\[(L,U)=(\bar{X} - m,\bar{X} + m)\]

Este intervalo es una nueva \textbf{variable aleatoria} y tiene por definición una probabilidad de \(0.95\) de contener \(\mu\).

El \textbf{intervalo observado} que obtenemos del experimento es (en minúsculas)

\[(l,u)=(\bar{x} - m,\bar{x} + m)\]

Este intervalo contiene o no el parámetro \(\mu\): ¡\textbf{nunca lo sabremos}!

Decimos que tenemos una confianza de \(95\%\) en que el intervalo \((l,u)\) capturará el verdadero parámetro desconocido \(\mu\). Piensa en comprar un billete de lotería del raspa y gana pero que no podemos raspar para ver el premio. El billete tiene o no el premio sólo que no lo sabemos.

\hypertarget{caso-1-varianza-conocida}{%
\subsection{Caso 1 (varianza conocida)}\label{caso-1-varianza-conocida}}

Los intervalos de confianza se pueden estimar en diferentes casos. El primer caso es cuando

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(X\) es una variable normal
\item
  y conocemos el valor de \(\sigma\)
\end{enumerate}

el intervalo de confianza en \(95\%\) es

\[(l,u)=(\bar{x} - m, \bar{x} + m)\]
donde \[m=z_{0.025} \frac{\sigma}{\sqrt{n}}\]

Eso es:

\[(l,u)=(\bar{x} - z_{0.025} \frac{\sigma}{\sqrt{n}}, \bar{x} + z_{0.025} \frac{\sigma}{ \sqrt{n}})\]

\textbf{Ejemplo (cables):}

En nuestro ejemplo, asumimos que \(X\) se distribuye normalmente y que sabemos \(\sigma^2=0.35^2\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Dado que \(\bar{X}\) es normal, el margen de error es
\end{enumerate}

\[m=z_{0.025} \frac{\sigma}{\sqrt{n}}\]
2. Como sabemos \(\sigma^2=0.35^2\), entonces el intervalo de confianza de \(95\%\) es

\((l,u)=(\bar{x} - m, \bar{x} + m)=\) \[(\bar{x}-z_{0.025} \frac{\sigma}{\sqrt{n }}, \bar{x}+z_{0.025} \frac{\sigma}{\sqrt{n}})= (12.97,13.45)\]

o también podemos escribirlo como

\[\hat{\mu}=\bar{x} \pm m = 13.21 \pm 0.24\]
Esto significa que, al estimar la media por el promedio, confiamos en las unidades pero no tanto en los lugares decimales.

\includegraphics{_main_files/figure-latex/unnamed-chunk-92-1.pdf}

Recuerda que el intervalo de confianza \((l,u)\) es una observación del intervalo de confianza aleatorio \((L,U)\). Por lo tanto, cada vez que obtenemos una nueva muestra entonces \((l,u)\) cambia. Si realizamos muestras de \(100\) de tamaño \(n\) entonces \(95%
\) de los intervalos de confianza contendrán \(\mu\), ¡pero no sabemos cuál!

\includegraphics{_main_files/figure-latex/unnamed-chunk-93-1.pdf}

\hypertarget{nivel-de-confianza}{%
\subsection{Nivel de confianza}\label{nivel-de-confianza}}

Podemos cambiar nuestra confianza de \(95\%\) a \(99\%\). Cuando calculamos el margen de error en \(95\%\), dejamos por fuera \(\alpha=0.05\) de probabilidad, \(0.025\) a cada lado.

Ahora, podemos dejar fuera \(\alpha=0.01\) de probabilidad, \(0.005\) a cada lado. Por lo tanto, el intervalo de confianza de \(99\%\) es

\((l,u) = (\bar{x} - z_{0.005}\frac{\sigma}{\sqrt{n}},\bar{x} + z_{0.005}\frac{\sigma}{\sqrt{n}})\)

\[= (\bar{x} - 2.58\frac{\sigma}{\sqrt{n}},\bar{x} + 2.58\frac{\sigma}{\sqrt{n}})\]

\includegraphics{./figures/phi.JPG}

donde \(z_{0.005}=\phi^{-1}(0.995)=\) qnorm(0.995). También podemos escribirlo como

\[\hat{\mu}=\bar{x} \pm 2.58\frac{\sigma}{\sqrt{n}}\]
Para nuestros cables, el intervalo de confianza de \(99\%\) es

\[\hat{\mu}= 13.21 \pm 0.31\]

Si queremos tener más confianza, ¡necesitamos intervalos de confianza más grandes!

\textbf{Ejemplo (Energía de impacto):}

Un material metálico se prueba por impacto para medir la energía requerida para cortarlo a una temperatura dada. Se cortaron diez probetas de acero A238 a 60ºC con las siguientes energías de impacto (J):

\(64.1, 64.7, 64.5, 64.6, 64.5, 64.3, 64.6, 64.8, 64.2, 64.3\)

Si \textbf{suponemos} que la energía del impacto se distribuye normalmente con \(\sigma=1J\), ¿cuál es el intervalo de confianza de \(95\%\) para la media de estos datos?

Sabemos

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(X \rightarrow N(\mu, \sigma^2)\)
\item
  \(\sigma=1J\)
\item
  \(\alpha=0.05\) (el límite de confianza)
\end{enumerate}

El intervalo de confianza de \(95\%\) es entonces

\((l,u)=(\bar{x}-1.96 \frac{\sigma}{\sqrt{n}}, \bar{x}+1.96 \frac{\sigma}{\sqrt{n}})\)
\[=(64.46-1.96 \frac{1}{\sqrt{10}}, 64.46+1.96 \frac{1}{\sqrt{10}})=(63.84,65.08)\]

o

\[\hat{\mu}=64.46 \pm 0.61\]

esto nos dice que podemos estar seguros del primer dígito (6), algo seguros del segundo (4) e inseguros de los decimales (46).

En R:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(BSDA) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## Loading required package: lattice
\end{verbatim}

\begin{verbatim}
## 
## Attaching package: 'BSDA'
\end{verbatim}

\begin{verbatim}
## The following object is masked from 'package:datasets':
## 
##     Orange
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{z.test}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FloatTok{64.1}\NormalTok{, }\FloatTok{64.7}\NormalTok{, }\FloatTok{64.5}\NormalTok{, }\FloatTok{64.6}\NormalTok{, }\FloatTok{64.5}\NormalTok{, }\FloatTok{64.3}\NormalTok{, }\FloatTok{64.6}\NormalTok{, }\FloatTok{64.8}\NormalTok{, }\FloatTok{64.2}\NormalTok{, }\FloatTok{64.3}\NormalTok{), }
       \AttributeTok{sigma.x=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  One-sample z-Test
## 
## data:  c(64.1, 64.7, 64.5, 64.6, 64.5, 64.3, 64.6, 64.8, 64.2, 64.3)
## z = 203.84, p-value < 2.2e-16
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  63.8402 65.0798
## sample estimates:
## mean of x 
##     64.46
\end{verbatim}

¿Qué pasa si \(\sigma^2\) es \textbf{desconocido}?

\hypertarget{margen-de-error-para-varianza-desconocida}{%
\section{Margen de error para varianza desconocida}\label{margen-de-error-para-varianza-desconocida}}

Pudimos calcular el intervalo de confianza \((l,u)=(\bar{x} -m, \bar{x} -m)\) porque pudimos encontrar el margen de error

\[m=1.96 \frac{\sigma}{\sqrt{n}}\]
desde que \textbf{sabíamos} \(\sigma\). \(\sigma\) es un parámetro de la distribución que normalmente \textbf{no conocemos}, así cmo \(\mu\). Para encontrar el margen de error con varianza \textbf{desconocida}, necesitamos el siguiente teorema, debido a Gosset

\hypertarget{teorema-estaduxedstica-t}{%
\subsection{Teorema (estadística T)}\label{teorema-estaduxedstica-t}}

Cuando \(X\) es normal, entonces la estadística estandarizada

\[T=\frac{\bar{X}-\mu}{\frac{S}{\sqrt{n}}}\]
Sigue una distribución \(t\) con \(n-1\) grados de libertad, donde \(S^2=\frac{1}{n-1} \sum_{i=1}^n (X_i-\bar{X})^2\). Por lo tanto, podemos calcular probabilidades para \(\bar{X}\), incluso si no conocemos \(\sigma\).

Veamos algunas densidades de probabilidad en la familia de las distribuciones \(T\).

\includegraphics{_main_files/figure-latex/unnamed-chunk-95-1.pdf}

Ahora necesitamos volver a calcular el margen de error \(m\) al nivel de \(5\%\) cuando usamos la distribución \(t\)

\(P(\mu-m \leq \bar{X} \leq\mu + m)\)
\[=P(-\frac{m}{s/\sqrt{n}} \leq T \leq\frac{m}{s/\sqrt{n}})=0.95\]

\[m=t_{0.025, n-1} \frac{s}{\sqrt{n}}\]
donde \(t_{0.025, n-1}\) es el valor \(T\) que deja \(2.5\%\) de probabilidad en el lado derecho de la distribución \(t\) con \(n-1\) grados de libertad.

\hypertarget{caso-2-varianza-desconocida}{%
\subsection{Caso 2 (varianza desconocida)}\label{caso-2-varianza-desconocida}}

El segundo caso para calcular los intervalos de confianza es más realista. Si

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(X\) es una variable normal
\end{enumerate}

el intervalo de confianza en \(95\%\) es

\[(l,u)=(\bar{x} - m, \bar{x} + m)\]
donde \[m=t_{0.025, n-1} \frac{s}{\sqrt{n}}\]

Eso es:

\[(l,u)=(\bar{x} - t_{0.025, n-1} \frac{s}{\sqrt{n}}, \bar{x} + t_{0.025, n-1} \frac{s}{\sqrt{n}})\]
donde \(t_{0.025, n-1}=F^{-1}(0.975)\)=qt(0.975, n-1)

\textbf{Ejemplo (Energía de impacto):}

Un material metálico se prueba por impacto para medir la energía requerida para cortarlo a una temperatura dada. Se cortaron diez probetas de acero A238 a 60ºC con las siguientes energías de impacto (J):

\(64.1, 64.7, 64.5, 64.6, 64.5, 64.3, 64.6, 64.8, 64.2, 64.3\)

Si \textbf{suponemos} que la energía del impacto se distribuye normalmente pero \textbf{no conocemos} la varianza, ¿cuál es el intervalo de confianza de \(95\%\) para la media de estos datos?

Sabemos

\begin{itemize}
\tightlist
\item
  \(\bar{x}=64.46\)
\item
  \(s=0.227\)
\item
  \(\alpha=0.05\)
\item
  \(t_{0.025,9}=2.26\) obtenido de \(t_{0.025,9}=\) qt(0.975, 9)
\end{itemize}

El intervalo de confianza es entonces

\((l,u)=(\bar{x}- t_{0.025,9}\frac{s}{\sqrt{n}},\bar{x}+t_{0.025,9} \frac{s} {\sqrt{n}})\)

\[=(64.46-2.26 \frac{0.227}{\sqrt{10}},64.46+2.26 \frac{0.227}{\sqrt{10}})\] \[=(64.29,64.62)\]

Tenga en cuenta que cuando asumimos \(\sigma=1\) el intervalo de confianza \((63.84,65.08)\) era mayor. Por lo tanto, los datos sugieren que \(\sigma<1\).

En R, podemos calcular el intervalo de confianza con:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FloatTok{64.1}\NormalTok{,}\FloatTok{64.7}\NormalTok{,}\FloatTok{64.5}\NormalTok{,}\FloatTok{64.6}\NormalTok{,}\FloatTok{64.5}\NormalTok{,}\FloatTok{64.3}\NormalTok{,}\FloatTok{64.6}\NormalTok{,}\FloatTok{64.8}\NormalTok{,}\FloatTok{64.2}\NormalTok{,}\FloatTok{64.3}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  One Sample t-test
## 
## data:  c(64.1, 64.7, 64.5, 64.6, 64.5, 64.3, 64.6, 64.8, 64.2, 64.3)
## t = 897.74, df = 9, p-value < 2.2e-16
## alternative hypothesis: true mean is not equal to 0
## 95 percent confidence interval:
##  64.29757 64.62243
## sample estimates:
## mean of x 
##     64.46
\end{verbatim}

\hypertarget{estimaciuxf3n-de-proporciones}{%
\section{Estimación de proporciones}\label{estimaciuxf3n-de-proporciones}}

\textbf{Ejemplo (vacuna):}

Se seleccionó una muestra aleatoria de \(400\) pacientes para probar una nueva vacuna contra el virus de la influenza, después de \(6\) meses de vacunación, \(134\) estaban enfermos. ¿Cuál es la eficacia esperada de la vacuna?

Dado que cada vacunación \(X_i\) es un ensayo de Bernoulli

\[X \rightarrow Bernoulli(p)\]
Con media \(\mu=p\) y varianza \(\sigma^2=p(1-p)\).

La muestra es algo como
\[(x_1,x_2, x_3, ...x_n)=(0,1,0,.. 1, 0)_{400}\] con \(134\) unos y en un total de \(400\) repeticiones. La muestra tiene un promedio de \(\bar{x}=\frac{1}{400}\sum_i^{400} x_i=134/400=0.34\). Dado que la media muestral es un estimador insesgado de \(\mu\), entonces podemos tener una estimación puntual para \(p\)

\[\hat{p}=\bar{x}=134/400=0.34\]

Esto tiene sentido porque \(\bar{x}\) es la frecuencia relativa observada para el número de \textbf{unos} en la muestra (\(f_1\)). Y como tal, es un estimador de la probabilidad de observar un uno en un ensayo de Bernoulli.

\[f_1 =\hat{P}(X=1)\]
Esto es consistente con la definición frecuentista de probabilidad que vimos en el capítulo 2. Pero, ¿qué confianza tenemos en esta estimación? Queremos un intervalo de confianza para \(p\)

\hypertarget{caso-3-proporciones}{%
\subsection{Caso 3 (proporciones)}\label{caso-3-proporciones}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Cuando \(\hat{p}n>5\) y \((\hat{p}-1)n>5\), la \textbf{estadística estandarizada} de \(\bar{X}\) se puede aproximar mediante un estándar distribución (TCL)
\end{enumerate}

\[Z=\frac{\bar{X}-\mu}{\sigma/\sqrt{n}}= \frac{\bar{X}-p}{\big[\frac{p(1-p)}{n} \big]^{1/2}}\rightarrow N(0,1)\]
y el intervalo de CI al \(95\%\) de \(p\) es:

\[CI=(l,u)=(\bar{x}-z_{0.025}\big[\frac{\bar{x}(1-\bar{x})}{n} \big]^{ 1/2}, \bar{x}+z_{0.025}\big[\frac{\bar{x}(1-\bar{x})}{n} \big]^{1/2})\]
Donde estimamos la varianza de Bernoulli \(\sigma^2=p(1-p)\) por \(\hat{\sigma}^2=\bar{x}(1-\bar{x})\). Es decir \(\hat{\sigma}=\sqrt{\bar{x}(1-\bar{x})}\).

\textbf{Ejemplo (vacuna):}

En nuestro caso, estamos contando \(134\) fallos de inmunización de \(400\) inoculaciones.

sabemos

\begin{itemize}
\tightlist
\item
  \(\bar{x}=134/400=0.34\)
\item
  \(z_{0.025}=1.96\)
\end{itemize}

Por lo tanto, el intervalo de confianza de \(95\%\) para \(p\) es

\((l,u)=(\bar{x}-1.96 \big[\frac{\bar{x}(1-\bar{x})}{n} \big]^{1/2}, \bar{x}+1.96 \big[\frac{\bar{x}(1-\bar{x})}{n} \big]^{1/2})\)

\[=(0.29,0.38)\]

La probabilidad de fracaso de la vacuna es

\[\hat{p}=0.34 \pm 0.05\]

en R

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{prop.test}\NormalTok{(}\DecValTok{134}\NormalTok{, }\DecValTok{400}\NormalTok{, }\AttributeTok{correct=}\ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  1-sample proportions test without continuity correction
## 
## data:  134 out of 400, null probability 0.5
## X-squared = 43.56, df = 1, p-value = 4.112e-11
## alternative hypothesis: true p is not equal to 0.5
## 95 percent confidence interval:
##  0.2905091 0.3826300
## sample estimates:
##     p 
## 0.335
\end{verbatim}

Nota: Las encuestas de intención de voto (ensayo de Bernoulli) en una muestra de \(n\) individuos reportan este tipo de estimación con su \textbf{margen de error}. No significa que el \textbf{valor verdadero} de \(p\) esté dentro de este intervalo con una probabilidad de \(95\%\). Significa que tenemos una confianza del \(95\%\) de haber atrapado al \(p\) que representa esta muestra en particular.

\hypertarget{estimaciuxf3n-de-la-varianza}{%
\section{Estimación de la varianza}\label{estimaciuxf3n-de-la-varianza}}

Hemos visto que siempre que tomamos una muestra aleatoria \((X_1, X_2, ... X_n)\), la varianza muestral
\[S^2=\frac{1}{n-1}\sum_{i=1}^n (X_i-\bar{X})^2\]
es un estimador de la media \(\sigma^2\) de la variable aleatoria \(X\). El estimador es \textbf{insesgado}

\begin{itemize}
\tightlist
\item
  \(E(S^2)=\sigma^2\)
\end{itemize}

y también es \textbf{consistente}. Cuando tomamos los valores de la muestra aleatoria, tomamos el valor de \(S^2\) como el valor de la varianza; eso es

\[s^2=\hat{\sigma}^2\]

Dado que \(S^2\) es una variable aleatoria, la estimación de la varianza cambia cuando tomamos otra muestra.

\textbf{Ejemplo (energía de impacto)}

Un material metálico se prueba por impacto para medir la energía requerida para cortarlo a una temperatura dada. Se cortaron diez probetas de acero A238 a 60ºC con las siguientes energías de impacto (J):

\(64.1, 64.7, 64.5, 64.6, 64.5, 64.3, 64.6, 64.8, 64.2, 64.3\)

¿Cuál es la estimación de la varianza de estos datos?

\[s^2=0.05155556\]
En R: sd(c(64.1, 64.7, 64.5, 64.6, 64.5, 64.3, 64.6, 64.8, 64.2, 64.3))\^{}2

¿Cuánta confianza tenemos en los decimales de la estimación?

\hypertarget{intervalo-de-confianza-para-la-varianza}{%
\section{Intervalo de confianza para la varianza}\label{intervalo-de-confianza-para-la-varianza}}

Para calcular un intervalo de confianza para la varianza, necesitamos una estadística que sea una función de \(S^2\) y nos permita calcular probabilidades. Usaremos el siguiente teorema

\hypertarget{teorema-chi2}{%
\subsection{\texorpdfstring{Teorema (\(\chi^2\)):}{Teorema (\textbackslash chi\^{}2):}}\label{teorema-chi2}}

Cuando \(X\) es normal, entonces la estadística estandarizada

\[W=\frac{S^2(n-1)}{\sigma^2}\]
sigue una distribución \(\chi^2\) con \(n-1\) grados de libertad

\[\frac{S^2}{\sigma^2}(n-1)\rightarrow \chi^2_{n-1}\]

Por lo tanto, podemos calcular probabilidades para \(W\).

Veamos algunas densidades de probabilidad en la familia de las distribuciones \(\chi^2\).

\includegraphics{_main_files/figure-latex/unnamed-chunk-98-1.pdf}

\hypertarget{intervalo-de-confianza-para-la-varianza-1}{%
\subsection{Intervalo de confianza para la varianza}\label{intervalo-de-confianza-para-la-varianza-1}}

Buscamos el intervalo de confianza de \(\sigma^2\) con confianza \(95\%\) \((L,U)\) tal que \[P(L \leq \sigma^2 \leq U)=0.95\]

Entonces podemos usar el \(\chi^2\) para determinar el \(95\%\) de la distribución alrededor de \(W\). Comencemos definiendo los valores que capturan los \(95\%\) de la distribución

\[P(\chi^2_{0.975,n-1} \leq W \leq \chi^2_{0.025,n-1})=0.95\]
Reemplazando el valor de \(W\)

\[P(\chi^2_{0.975,n-1} \leq \frac{S^2}{\sigma^2}(n-1) \leq \chi^2_{0.025,n-1})= 0.95\]

y resolviendo para \(\sigma^2\)

\[P(\frac{S^2 (n-1)}{\chi^2_{0.025,n-1}}\leq \sigma^2 \leq \frac{S^2(n-1)}{ \chi^2_{0.975,n-1}})=0.95\]

Encontramos un intervalo aleatorio que captura \(\sigma^2\)
con \(95\%\) de confianza

\[(L,U) = (\frac{S^2 (n-1)}{\chi^2_{0.025,n-1}},\frac{S^2(n-1)}{\chi ^2_{0.975,n-1}})\]

\hypertarget{caso-4-varianza}{%
\subsection{Caso 4 (varianza)}\label{caso-4-varianza}}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Cuando \(X\) es una variable normal
\end{enumerate}

El intervalo de confianza al \(95\%\) \textbf{observado} (minúsculas) es

\[(l,u) = (\frac{s^2 (n-1)}{\chi^2_{0.025,n-1}},\frac{s^2(n-1)}{\chi ^2_{0.975,n-1}})\]

dónde

\begin{itemize}
\item
  \(\chi^2_{0.975,n-1}=F^{-1}(0.025)=\) qchisq(0.025, df=n-1)
\item
  \(\chi^2_{0.025, n-1}=F^{-1}(0,975)=\)qchisq(0,975, df=n-1)
  para \(n=10\) o \(df=n-1=9\)
\end{itemize}

\textbf{Ejemplo (energía de impacto)}

Un material metálico se prueba por impacto para medir la energía requerida para cortarlo a una temperatura dada. Se cortaron diez probetas de acero A238 a 60ºC con las siguientes energías de impacto (J):

\(64.1, 64.7, 64.5, 64.6, 64.5, 64.3, 64.6, 64.8, 64.2, 64.3\)

¿Cuál es el intervalo de confianza para la varianza de estos datos?

\[(l,u) = (\frac{s^2 (n-1)}{\chi^2_{0.025,n-1}},\frac{s^2(n-1)}{\chi ^2_{0.975,n-1}})\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  La desviación estándar de los datos es \(s=0.2270585\)
\item
  \(n=10\)
\item
  Luego calculamos \(\chi^2_{0.025,n-1}\) y \(\chi^2_{0.975,n-1}\)
\end{enumerate}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{chi0}\FloatTok{.975} \OtherTok{\textless{}{-}} \FunctionTok{qchisq}\NormalTok{(}\FloatTok{0.025}\NormalTok{, }\AttributeTok{df=}\DecValTok{9}\NormalTok{)}
\NormalTok{chi0}\FloatTok{.975}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 2.700389
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{chi0}\FloatTok{.025} \OtherTok{\textless{}{-}} \FunctionTok{qchisq}\NormalTok{(}\FloatTok{0.975}\NormalTok{, }\AttributeTok{df=}\DecValTok{9}\NormalTok{)}
\NormalTok{chi0}\FloatTok{.025}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 19.02277
\end{verbatim}

\includegraphics{_main_files/figure-latex/unnamed-chunk-99-1.pdf}

Por lo tanto

\[(l,u)= (\frac{0.2270585^2 (10-1)}{19.02277},\frac{0.2270585^2(10-1)}{2.700389})=(0.02,0.17)\]

Recuerda que cuando habíamos calculado el intervalo de confianza para la media, asumimos \(\sigma^2=1\) (caso 1). Ahora podemos decir que esta elección no fue consistente con los datos porque vemos que el intervalo de confianza no contiene el valor \(\sigma^2=1\) .

Según los datos, \(\sigma^2 \neq 1\) con una confianza de \(95\%\).

en R:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(Ecfun)}
\FunctionTok{confint.var}\NormalTok{(}\FloatTok{0.05155556}\NormalTok{, }\DecValTok{9}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##           lower     upper
## [1,] 0.02439183 0.1718271
## attr(,"level")
## [1] 0.95
\end{verbatim}

El intervalo para la varianza \textbf{no es simétrico} y no podemos formularlo como un margen de error con \(\pm\).

\includegraphics{_main_files/figure-latex/unnamed-chunk-101-1.pdf}

\hypertarget{preguntas-10}{%
\section{Preguntas}\label{preguntas-10}}

\textbf{1)} El margen de error a \(95\%\) de confianza de una variable normal es

\textbf{\(\qquad\)a:} \(\frac{s}{\sqrt{n}}\);
\textbf{\(\qquad\)b:} \(1.96\times se\);
\textbf{\(\qquad\)c:} \(\frac{\sigma}{\sqrt{n}}\);
\textbf{\(\qquad\)d:} \(\sigma\)

\textbf{2)} cuando hablamos de \(z_{0.025}\) queremos encontrar:

\textbf{\(\qquad\)a:} El valor de una variable normal estándar que acumula hasta \(99.75\%\) de probabilidad;
\textbf{\(\qquad\)b:} El valor de una variable normal estándar que acumula hasta \(0.25\%\) de probabilidad;
\textbf{\(\qquad\)c:} La probabilidad de una variable estándar hasta \(99.75\%\);
\textbf{\(\qquad\)d:} La probabilidad de una variable estándar hasta \(0.25\%\)

\textbf{3)} El intervalo de confianza aleatorio \((L,U)\) para la media al \(95\%\)

\textbf{\(\qquad\)a:} es un parámetro bidimensional de la distribución de la muestra;
\textbf{\(\qquad\)b:} da los límites donde \(\mu\) tiene una probabilidad de ocurrir el \(95\%\) de las veces;
\textbf{\(\qquad\)c:} es una estimación del promedio;
\textbf{\(\qquad\)d:} captura \(\mu\) \(95\%\) de las veces

\textbf{4)} Un intervalo de confianza para la media escrito como \(\hat{\mu}=56.99 \pm 0.01\)

\textbf{\(\qquad\)a:} indica que estamos \(\%99\) seguros de que la media es \(56.99\);
\textbf{\(\qquad\)b:} indica que no podemos confiar en el último decimal en la estimación de la media;
\textbf{\(\qquad\)c:} indica que la media de la población es en \(56.99\) con un error de \(0.01\);
\textbf{\(\qquad\)d:} indica que podemos confiar en la cifra unitaria (\(6\)) en la estimación de la media

\textbf{5)}Si conocemos el valor de \(\mu\) y encontramos que el intervalo de confianza no lo atrapó, entonces

\textbf{\(\qquad\)a:} el intervalo de confianza no está bien calculado;
\textbf{\(\qquad\)b:} tenemos una observación rara del intervalo de confianza;
\textbf{\(\qquad\)c:} el intervalo de confianza no estima la media;
\textbf{\(\qquad\)f:} hay poca probabilidad de encontrar la media en el intervalo de confianza

\hypertarget{ejercicios-11}{%
\section{Ejercicios}\label{ejercicios-11}}

\hypertarget{ejercicio-1-11}{%
\subsubsection{Ejercicio 1}\label{ejercicio-1-11}}

En un artículo científico, los autores reportan un intervalo de confianza al \(95\%\) de \((228, 232)\) para la frecuencia natural (Hz) de un haz metálico. Utilizaron una muestra de tamaño \(25\) y consideraron que las medidas estaban distribuidas normalmente.

\begin{itemize}
\item
  ¿Cuál es la media y la desviación estándar de las medidas? (R:230, 4.85)
\item
  Calcula el intervalo de confianza de \(99\%\). (R:(227.51, 232.48))
\end{itemize}

\hypertarget{ejercicio-2-11}{%
\subsubsection{Ejercicio 2}\label{ejercicio-2-11}}

calcula el intervalo de confianza al \(95\%\) de la media de una variable normal con varianza conocida \(\sigma^2=9\) y \(\bar{x}=22\), usando una muestra de tamaño \(36\). (R:(21.02, 22.97))

\hypertarget{ejercicio-3-8}{%
\subsubsection{Ejercicio 3}\label{ejercicio-3-8}}

Este año, \(17\) de \(1000\) de pacientes con influenza desarrollaron complicaciones.

\begin{itemize}
\item
  Calcular el intervalo de confianza al \(99\%\) para la proporción de complicaciones. (R:(0.009, 0.031))
\item
  El año anterior \(2\%\) presentó complicaciones. ¿Podemos decir con \(99\%\) de confianza que este año hay una caída significativa en las complicaciones de la influenza? (R:No)
\end{itemize}

\hypertarget{ejercicio-4-4}{%
\subsubsection{Ejercicio 4}\label{ejercicio-4-4}}

¿Cuál es el intervalo de confianza para la varianza poblacional de una variable normal si tomamos una muestra aleatoria de tamaño \(n=10\) y observamos una varianza muestral de \(0.5\)? (R:(0.236, 1.666))

\hypertarget{pruxe1ctica}{%
\section{Práctica}\label{pruxe1ctica}}

Carga datos de misofonía \url{https://alejandro-isglobal.github.io/SDA/data/data_0.txt}

\begin{itemize}
\item
  Calcula el intervalo de confianza para la media de las medidas cefalométricas. (``Angulo\_convexidad'', ``protusion.mandibular'', ``Angulo\_cuelloYtercio'', ``Subnasal\_H'')
\item
  Calcula el intervalo de confianza para la proporción de misofonía (``Misofonia.dic'') y depresión (``depresion.dic'').
\item
  Calcula el intervalo de confianza para la varianza de la edad (``Edad''). ¿Cuál es el intervalo de confianza para la desviación estándar de la población?
\end{itemize}

\hypertarget{contraste-de-hipuxf3tesis}{%
\chapter{Contraste de hipótesis}\label{contraste-de-hipuxf3tesis}}

\hypertarget{objetivo-10}{%
\section{Objetivo}\label{objetivo-10}}

En este capítulo estudiaremos \textbf{pruebas de hipótesis} de medias y proporciones. Definiremos cuál es la hipótesis nula y la alternativa y cómo utilizar los datos para elegir entre ambas.

También presentaremos la prueba de hipótesis de varianzas y los errores que se cometen cuando se prueba una hipótesis. Estos errores se conocen como falsos positivos y falsos negativos.

\hypertarget{hipuxf3tesis}{%
\section{Hipótesis}\label{hipuxf3tesis}}

Cuando llevamos a cabo experimentos aleatorios, a menudo queremos probar si los cambios que realizamos sobre el experimento tienen un efecto real. Queremos, por ejemplo, saber si hemos podido influenciar el experimento. O, sihemos sometido el experimento bajo una nueva condición, queremos saber si esa condición affecta el desarrollo del experimento. Usualmente tenemos una idea de cómo deberían ser los datos cuando estos cambios no están presente. Dado que los resultatos del experimento son aleatorios con y sin el cambio ¿cómo podemos diferenciar entre aplicar el cambio o no?

La estrategia es formular el cambio o la nueva condición en términos de los valores que pueden tomar los \textbf{parámetros} de las distribuciones de probabilidad asociadas al experimento aleatorio. Después, usamos las observaciones del experimento aleatorio bajo la nueva condición para propocionar \textbf{evidencia} sobre la posible influencia en los parámetros.

\textbf{Ejemplos (Neumáticos)}

Los fabricantes de neumáticos quieren saber si la vida media de los neumáticos que producen es de al menos 20000 km. Intentemos traducir su interés en términos estadísticos. Imaginemos un experimento alatorio que consiste en medir cuanto dura la vida útil de un neumático en particular. Por lo tanto a los fabricantes les interesa saber si la media de la vida útil de un neumático es de al menos 20000 km.

\newpage

Formulemos dos declaraciones dicotómicas, es decir dos situaciones excluyentes:

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  La vida media de los neumáticos puede ser \textbf{menos} de 20 000 km
\item
  La vida media de los neumáticos puede ser \textbf{superior} a 20000 km
\end{enumerate}

Esto significa que sólo una puede ser verdadera. La pregunta es entonces cómo podemos usar los datos para \textbf{decidir} entre la situación a. o situación b. Consideremos que \(\mu\) es la media de la distribución de la población. Por lo tanto, las afirmaciones a. y B. también se puede escribir como

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  \(H_0: \mu \leq 20000km\)
\item
  \(H_1: \mu > 20000km\)
\end{enumerate}

Donde la declaración \(H_0\) es para la cual los autos \textbf{no recorren} los 20000 km deseados mientras que la declaración \(H_1\) es \textbf{el caso deseado}. \(H_0\) y \(H_1\) se llaman hipótesis.

\textbf{Definición}

En estadística, una afirmación (conjetura) sobre la distribución de una variable aleatoria se denomina \textbf{hipótesis}.

Las hipótesis generalmente se escriben en dos declaraciones dicotómicas.

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\item
  La hipótesis \textbf{nula}: \(H_0\) cuando la conjetura es falsa generalmente se refiere al \textbf{statu quo}. Los datos pueden ser explicados por el satus quo.
\item
  La \textbf{hipótesis alternativa}: \(H_1\) cuando la conjetura es verdadera generalmente se refiere a la \textbf{hipótesis de investigación}. Los datos pueden ser explicados por la alternativa deseada.
\end{enumerate}

\textbf{Ejemplo (Fertilizante)}

Los desarrolladores de fertilizantes quieren probar si su nuevo producto tiene un efecto real en el crecimiento de las plantas. ¿Cuáles son la hipótesis nula y la alternativa?

Siendo \(\mu_0\) el crecimiento medio de las plantas \textbf{sin} fertilizante (conocido) y \(\mu\) el crecimiento medio de las plantas con el fertilizante (desconocido)

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  \(H_0:\mu \leq \mu_0\) (El fertilizante puede que no haga nada: status quo)
\item
  \(H_1:\mu > \mu_0\) (El fertilizante puede tener el efecto deseado: interés de investigación)
\end{enumerate}

\textbf{Ejemplo (quimioterapia)}

Las farmacéuticas necesitan saber si una nueva quimioterapia puede curar al 90\% de los pacientes con cáncer. Siendo \(p_0\) la proporción de pacientes que se curan \textbf{sin} la quimioterapia (conocido) y \(p\) la proporción que se curan \textbf{con} la quimioterapia (desconocido) podemos formular las hipótesis

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  \(H_0:p \leq p_0\) (La quimioterapia puede que no cambie la proporción de curados: status quo)
\item
  \(H_1: p > p_0\) (La quimioterapia puede tener el efecto deseado: interés de investigación)
\end{enumerate}

Ten en cuenta que nuestro nuevo experimento mejorado tiene el parámetro \(p\) y queremos saber cómo se compara con el experimento sin \textbf{ningúna mejora} que tiene el parámetro \(p_0\).

Queremos decidir entre \(H_0\) y \(H_1\). Hay dos opciones:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  Rechazamos la hipótesis alternativa \(H_1\); es decir, aceptamos la hipótesis nula \(H_0\).
\item
  Aceptamos la hipótesis alternativa \(H_1\) (nuestro interés); es decir, rechazamos la hipótesis nula \(H_0\).
\end{enumerate}

\hypertarget{contraste-de-hipuxf3tesis-1}{%
\section{Contraste de hipótesis}\label{contraste-de-hipuxf3tesis-1}}

Resumamos los diferentes casos, formas y tipos de las pruebas de hipótesis. Después discutiremos cada caso con un ejemplo particular.

Las hipótesis se pueden probar o decidir utilizando intervalos de confianza. Por lo tanto, vamos a probar hipótesis en los cuatro \textbf{casos} que vimos para los intervalos de confianza, a saber:

\begin{itemize}
\item
  \textbf{Caso 1}: Prueba de hipótesis para la media \(\mu\), cuando \(X \rightarrow N(\mu, \sigma^2)\) y sabemos \(\sigma\)
\item
  \textbf{Caso 2}: Prueba de hipótesis para la media \(\mu\), cuando \(X \rightarrow N(\mu, \sigma^2)\) y no sabemos \(\sigma\)
\item
  \textbf{Caso 3}: Prueba de hipótesis para la proporción \(p\) cuando \(X \rightarrow Bernoulli(p)\) y tanto \(np\) como \(n(1-p)\) \(> 5\).
\item
  \textbf{Caso 4}: Prueba de hipótesis para la varianza \(\sigma^2\), cuando \(X \rightarrow N(\mu, \sigma^2)\)
\end{itemize}

Hay tres \textbf{maneras} de probar las hipótesis:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Por medio de \textbf{intervalos de confianza}
\item
  usando una \textbf{zona de rechazo}
\item
  Con un \(pvalor\).
\end{enumerate}

Las tres opciones son equivalentes. Finalmente, hay tres \textbf{tipos} de hipótesis que podemos probar:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  de \textbf{dos} colas
\item
  de cola \textbf{superior}
\item
  de cola \textbf{inferior}
\end{enumerate}

\hypertarget{caso-1-para-la-media-con-varianza-conocida}{%
\section{Caso 1 (para la media con varianza conocida)}\label{caso-1-para-la-media-con-varianza-conocida}}

Un contraste de hipótesis de \textbf{cola de dos colas} es de la forma

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  \(H_0:\mu = \mu_0\) (status quo)
\item
  \(H_1:\mu \neq \mu_0\) (interés de investigación)
\end{enumerate}

Este contraste se llama de dos colas porque la hipótesis alternativa \(H_1\) requiere que la media \(\mu\) sea menor o mayor que \(\mu_0\). Esta hipótesis se puede probar en diferentes casos. El \textbf{caso 1} es cuando

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(X\) es una variable normal, y
\item
  conocemos el valor de \(\sigma^2\)
\end{enumerate}

\hypertarget{prueba-de-hipuxf3tesis-con-un-intervalo-de-confianza}{%
\subsection{Prueba de hipótesis con un intervalo de confianza}\label{prueba-de-hipuxf3tesis-con-un-intervalo-de-confianza}}

Para el \textbf{caso 1} el intervalo de confianza en \(95\%\) es

\[(l,u)=(\bar{x}-z_{0.025} \frac{\sigma}{\sqrt{n}}, \bar{x}+z_{0.025} \frac{\sigma}{ \sqrt{n}})\]

\textbf{Criterios de decisión:}

\begin{itemize}
\tightlist
\item
  Si el intervalo de confianza \textbf{contiene} la hipótesis nula
\end{itemize}

\[\mu_0\in (l,u)\] entonces \textbf{aceptamos} \(H_0\) con una confianza de \(95\%\).

\begin{itemize}
\tightlist
\item
  Si el intervalo de confianza \textbf{no contiene} la hipótesis nula\[\mu_0\notin (l,u)\] entonces \textbf{rechazamos} \(H_0\) con \(95\%\) de confianza.
\end{itemize}

\textbf{Ejemplo (Cables)}

Compramos \(8\) cables a una empresa fabricante que afirma que se rompen con \textbf{media} de \(\mu_0=13\) Toneladas. No estamos seguros y tal vez queramos decidir si los cables se rompen \textbf{en promedio} a \(13\) Toneladas o no. Formulamos el contraste de hipótesis

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  \(H_0:\mu = 13\) (Los cables \textbf{pueden} romperse como afirma el fabricante: status quo)
\item
  \(H_1:\mu \neq 13\) (Los cables \textbf{pueden} no romperse como afirma el fabricante: interés de investigación)
\end{enumerate}

Como no sabemos qué es cierto, empecemos por \textbf{suponer} que \textbf{el fabricante tiene razón} y que los cables realmente satisfacen la hipótesis nula y, por lo tanto,

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(X \rightarrow N(\mu=13, \sigma^2=0.35^2)\)
\item
  Sabemos \(\sigma^2=0.35^2\)
\end{enumerate}

Para decidir entre \(H_0\) o \(H_1\), realizamos una muestra de \(8\) experimentos aleatorios: Cargamos un cable hasta que se rompe y registramos la carga de rotura. Estos son los resultados.

\begin{verbatim}
## [1] 13.34642 13.32620 13.01459 13.10811 12.96999 13.55309 13.75557 12.62747
\end{verbatim}

El intervalo de confianza \textbf{si} el fabricante tiene razón, es decir, si la hipótesis nula es verdadera, es

\[(l,u)=(\bar{x}-z_{0.025} \frac{\sigma}{\sqrt{n}}, \bar{x}+z_{0.025} \frac{\sigma}{ \sqrt{n}})= (12.97,13.45)\]
El intervalo de confianza nos dice que podmeos tener un \(95\%\) de confianza en que la media de la carga de rotura \(\mu\) de los cables que promabos está en el intervalo. No sabemos el valor real de \(\mu\) pero vemos un valor podría ser \(\mu=13\) Toneladas, ya que el intervalo atrapó \(\mu_0\)

\[\mu_0\in (12.97,13.45)\]

Nuestra conclusión es aceptar que \(H_0\) podría haber producido nuestro \textbf{intervalo observado}. También decimos que los datos respaldan la afirmación del fabricante. Más técnicamente, decimos que \textbf{no rechazamos} la hipótesis nula \(H_0\).

\includegraphics{_main_files/figure-latex/unnamed-chunk-103-1.pdf}

\hypertarget{prueba-de-hipuxf3tesis-con-zonas-de-aceptaciuxf3nrechazo}{%
\subsection{Prueba de hipótesis con zonas de aceptación/rechazo}\label{prueba-de-hipuxf3tesis-con-zonas-de-aceptaciuxf3nrechazo}}

Una forma equivalente de probar la hipótesis es ver si nuestro conjunto de observaciones es raro o común si la hipótesis nula fuera verdadera. Recordemos el contraste de hipótesis

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  \(H_0:\mu = \mu_0\) (status quo)
\item
  \(H_1:\mu \neq \mu_0\) (interés de investigación)
\end{enumerate}

Para probar la hipótesis con una \textbf{zona de rechazo} calculamos la estadística estandarizada

\[Z=\frac{\bar{X}-\mu_0}{\frac{\sigma}{\sqrt{n}}}\]
Cuando la hipótesis nula es verdadera. Ten en cuenta que estamos estandarizando con \(\mu_0\) (la hipótesis nula). Este es el error estandarizado que cometemos al estimar \(\mu_0\) con \(\bar{X}\). Luego vemos si el valor observado de \(Z\) está dentro del intervalo

\[(-z_{0.025}, z_{0.025})\]
Recuerda que este intervalo define los valores más comunes de \(Z\) ya que \(P(-z_{0.025} \leq Z \leq z_{0.025})=0.95\).

El intervalo \((-z_{0.025}, z_{0.025})\) se denomina \textbf{intervalo de aceptación} de \(H_0\) con un nivel de confianza de \(95\%\).

\includegraphics{_main_files/figure-latex/unnamed-chunk-104-1.pdf}

\textbf{Criterios de decisión:}

\begin{itemize}
\tightlist
\item
  Si la estadística observada \(z_{obs}\) bajo la hipótesis nula \textbf{está} en la región de aceptación
\end{itemize}

\[z_{obs} \in (-z_{0.025}, z_{0.025})\]

entonces \textbf{aceptamos} \(H_0\) con una confianza de \(95\%\).

\begin{itemize}
\tightlist
\item
  Si la estadística observada \(z_{obs}\) bajo la hipótesis nula \textbf{no} está en la región de aceptación
\end{itemize}

\[z_{obs} \notin (-z_{0.025}, z_{0.025})\] entonces \textbf{rechazamos} \(H_0\) con una confianza de \(95\%\).

La región \((-z_{0.025}] \cup[z_{0.025})\) se denomina \textbf{zona de rechazo}.

Este criterio de decición nos dice que tan común es nuestra muestra aleatoria si la hipótesis nula es verdad.

\textbf{Ejemplo (Cables)}

Si \(H_0\) es verdadera entonces \(\bar{X}\) es el estimador de \(\mu_0\) y la estadística estandarizada

\[Z=\frac{\bar{X}-13}{\frac{0.35}{\sqrt{8}}} \rightarrow N(0,1)\]
es el error en estimación de \(\mu_0\) que cometemos cuando realizamos la estimación. Debido a que estamos en \textbf{caso 1}, \(Z\) es estándar normal.

Para \textbf{nuestros datos}, el \textbf{error observado} estandarizado está en la región de aceptación

\[z_{obs}=\frac{\bar{x}-13}{\frac{0.35}{\sqrt{8}}}=1.7187 \in (-z_{0.025}, z_{0.025})\]
Concluimos que nuestro error observado es típico al \(95\%\) cuando la hipótesis nula \(\mu_0\) es verdadera. Por lo tanto, nuevamente aceptamos que los datos son consistentes con la afirmación del fabricante. También decimos que \textbf{no rechazamos} \(H_0\).

\includegraphics{_main_files/figure-latex/unnamed-chunk-105-1.pdf}

\hypertarget{prueba-de-hipuxf3tesis-con-un-p-valor}{%
\subsection{Prueba de hipótesis con un P valor}\label{prueba-de-hipuxf3tesis-con-un-p-valor}}

También podemos contrastar la hipótesis de \textbf{dos colas} calculando la probabilidad de que el promedio de una nueva muestra aleatoria sea aún más raro que el promedio que acabamos de observar. Debido a que estamos en el **caso 1*, sabemos que la estadística estandarizada \(Z\) es una variable normal estándar, entonces definimos el \(pvalor\) como

\[pvalor = P(Z \leq -z_{obs}) + P(z_{obs} \leq Z) = 2 (1-\phi(|z_{obs}|))\]

Esa es la probabilidad de que cuando tomamos otra muestra del mismo tamaño podamos obtener una observación aún más extrema. Si nuestra observación ya es rara, entonces este valor será pequeño.

\textbf{Criterios de decisión:}

\begin{itemize}
\tightlist
\item
  Si el \(pvalor\) observado es
\end{itemize}

\[pvalor \geq \alpha =1-0.95=0.05\]

entonces \textbf{aceptamos} \(H_0\) con una confianza de \(95\%\).

\begin{itemize}
\tightlist
\item
  Si el \(pvalor\) observado es
\end{itemize}

\[pvalor < \alpha =1-0.95=0.05\]
entonces \textbf{rechazamos} \(H_0\) con una confianza de \(95\%\).

\(\alpha\) es el nivel de significancia. Nos dice cuánto de la distribución estamos omitiendo y define la región que consideramos como observaciones raras.

Recuerda: siempre confiamos en nuestros datos. Si la hipótesis nula dice que nuestros datos son una observación \textbf{rara} entonces desconfiamos de la hipótesis nula y la rechazamos.

\includegraphics{_main_files/figure-latex/unnamed-chunk-106-1.pdf}

\textbf{Ejemplo (Cables)}

Para nuestros datos, la estadística observada \(z_{obs}=1.718714\) y su \textbf{P valor} es entonces

\[pvalor=2 (1-\phi(1.718714))=0.08567\]
R: 2*(1-pnorm(1.718714))

Concluimos que si realizamos una nueva muestra es probable que podamos obtener un resultado más extremo que el que obtuvimos. La hipótesis nula puede tolerar el error observado con una confianza de \(95\%\). Por lo tanto, aceptamos que \(H_0\) podría haber producido nuestros datos y decimos nuevamente que es consistente con la afirmación del fabricante.

En R todo el contraste de hipótesis se puede realizar con la función z.test de la librería BSDA (que es necesario instalar previamente)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(BSDA) }
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(BSDA) }
\FunctionTok{z.test}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FloatTok{13.34642}\NormalTok{, }\FloatTok{13.32620}\NormalTok{, }\FloatTok{13.01459}\NormalTok{, }\FloatTok{13.10811}\NormalTok{, }
         \FloatTok{12.96999}\NormalTok{, }\FloatTok{13.55309}\NormalTok{, }\FloatTok{13.75557}\NormalTok{, }\FloatTok{12.62747}\NormalTok{), }
       \AttributeTok{mu=}\DecValTok{13}\NormalTok{, }
       \AttributeTok{sigma.x=}\FloatTok{0.35}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  One-sample z-Test
## 
## data:  c(13.34642, 13.3262, 13.01459, 13.10811, 12.96999, 13.55309,     13.75557, 12.62747)
## z = 1.7187, p-value = 0.08567
## alternative hypothesis: true mean is not equal to 13
## 95 percent confidence interval:
##  12.97015 13.45521
## sample estimates:
## mean of x 
##  13.21268
\end{verbatim}

\hypertarget{hipuxf3tesis-de-la-cola-superior}{%
\subsection{Hipótesis de la cola superior}\label{hipuxf3tesis-de-la-cola-superior}}

Es posible que nos interese probar solo el hecho de que la media de nuestro experimento es una media más alta que la media nula.

Prueba de cola superior:

\begin{itemize}
\tightlist
\item
  \(H_0:\mu \leq 13\) (\textbf{como mucho} los cables se rompen como siempre)
\item
  \(H_1:\mu > 13\) (los cables se rompen con una carga \textbf{mayor})
\end{itemize}

Esto se llama \textbf{de cola superior} porque la hipótesis alternativa \(H_1\) requiere que la media \(\mu\) sea \textbf{mayor} que \(\mu_0\). Esta hipótesis se puede probar en diferentes casos. El \textbf{caso 1} es cuando

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(X\) es una variable normal, y
\item
  conocemos el valor de \(\sigma\)
\end{enumerate}

\textbf{Criterios de decisión:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{Intervalo de confianza:} Si el \textbf{intervalo de confianza de cola superior} \textbf{contiene} la hipótesis nula
\end{enumerate}

\[\mu_0\in (l,u)=(\bar{x}-z_{0.05} \frac{\sigma}{\sqrt{n}}, \infty)\]
donde \(z_{0.05}=\phi^{-1}(0.95)=\)qnorm(0.95), entonces \textbf{aceptamos} \(H_0\) con una confianza de \(95\%\). Ten en cuenta que esta prueba es desde el punto de vista de los \textbf{datos} y que no estamos centrando el intervalo de confianza alrededor de \(\bar{x}\), sino que estamos dejando todo el \(5\%\) que corresponde a los casos raros a la izquierda del promedio. Por lo tanto, nos estamos preguntando si la hipótesis nula es menor que el promedio.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \emph{Región de rechazo/aceptación:} Si la estadística observada \(z_{obs}\) bajo la hipótesis nula \textbf{está} en la región de aceptación
\end{enumerate}

\[z_{obs}=\frac{\bar{x}-\mu_0}{\frac{\sigma}{\sqrt{n}}} \in (-\infty, z_{0.05})\]

entonces \textbf{aceptamos} \(H_0\) con una confianza de \(95\%\). Ten en cuenta que esta prueba es desde el punto de vista de la \textbf{hipótesis nula}. Dejamos todo el \(5\%\) que corresponde a los promedios raros a la derecha de la hipótesis nula y, por lo tanto, nos preguntamos si el promedio es claramente mayor que la hipótesis nula.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \(pvalor\): Si el P valor de \textbf{cola superior} \[pvalor= 1-\phi(z_{obs})\]
\end{enumerate}

1-pnorm(zobs) es mayor que \(\alpha=1-0.95=0.05\)

\[pvalor \geq \alpha =0.05\]

entonces \textbf{aceptamos} \(H_0\) con una confianza del \(95\%\). Ten en cuenta que esta prueba es nuevamente desde el punto de vista de la \textbf{hipótesis nula}. Nos estamos preguntando: si tuviéramos que tomar otro promedio, ¿cuál es la probabilidad de que sea mayor que el observado?

\textbf{Ejemplo (Cables)}

En el ejemplo de los cables, nos puede interesar solo en el caso de que los cables sean una versión mejorada de lo que afirma el fabricante. Por lo tanto, la hipótesis de cola superior es

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  \(H_0:\mu \leq 13\) (Los cables pueden romperse \textbf{como máximo} como afirma el fabricante: status quo)
\item
  \(H_1:\mu > 13\) (Los cables pueden romperse \textbf{al menos} como afirma el fabricante: interés de investigación)
\end{enumerate}

Probaremos la cola superior de la distribución.
Para los datos que discutimos antes, de tal forma que \textbf{rechazamos} \(H_0\) a \(95\%\) de confianza debido a cualquiera de los tres contrastes equivalentes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  El intervalo de confianza \textbf{de cola superior} no contiene la hipótesis nula \(\mu_0=13\)
\end{enumerate}

\[\mu_0=13 \notin (\bar{x}-z_{0.05} \frac{\sigma}{\sqrt{n}}, \infty)=(13.00914, \infty)\]
donde \(z_{0.05}=\)qnorm(0.95)=1.644854

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  Tenemos que la región de aceptación para \(H_0\) es:
\end{enumerate}

\[(-\infty, z_{0.05})=( -\infty, 1.644854)\]

y que el error estandarizado observado no está en la región
\[z_{obs} = \frac{13.21268-13}{\frac{0.35}{\sqrt{8}}}=1.7187 \notin ( -\infty, 1.644854)\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  El \(pvalor\) de cola superior es menor que \(\alpha=0.05\)
  \[pvalor=1-\phi(1.7187)=0.04283451 <0.05\]
\end{enumerate}

donde \(pvalor=\)1-pnorm(1.7187).

La prueba de hipótesis se puede realizar en R, especificando el parámetro ``alternative'' como ``greater'':

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{z.test}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FloatTok{13.34642}\NormalTok{, }\FloatTok{13.32620}\NormalTok{, }\FloatTok{13.01459}\NormalTok{, }\FloatTok{13.10811}\NormalTok{,}
         \FloatTok{12.96999}\NormalTok{, }\FloatTok{13.55309}\NormalTok{, }\FloatTok{13.75557}\NormalTok{, }\FloatTok{12.62747}\NormalTok{), }
       \AttributeTok{mu=}\DecValTok{13}\NormalTok{, }\AttributeTok{alternative=}\StringTok{"greater"}\NormalTok{, }\AttributeTok{sigma.x=}\FloatTok{0.35}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  One-sample z-Test
## 
## data:  c(13.34642, 13.3262, 13.01459, 13.10811, 12.96999, 13.55309,     13.75557, 12.62747)
## z = 1.7187, p-value = 0.04283
## alternative hypothesis: true mean is greater than 13
## 95 percent confidence interval:
##  13.00914       NA
## sample estimates:
## mean of x 
##  13.21268
\end{verbatim}

\includegraphics{_main_files/figure-latex/unnamed-chunk-111-1.pdf}

\hypertarget{caso-2-para-la-media-con-varianza-desconocida}{%
\section{Caso 2 (para la media con varianza desconocida)}\label{caso-2-para-la-media-con-varianza-desconocida}}

Un contraste de hipótesis de \textbf{dos colas} de la forma

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  \(H_0:\mu = \mu_0\) (status quo)
\item
  \(H_1:\mu \neq \mu_0\) (interés de investigación)
\end{enumerate}

se puede probar cuando no sabemos \(\sigma^2\) a partir del \textbf{caso 2}, es decir, cuando

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(X\) es una variable normal, \(X \rightarrow N(\mu, \sigma^2)\), y
\item
  \textbf{no} sabemos el valor de \(\sigma^2\)
\end{enumerate}

Recordemos que en este caso el \textbf{error estandarizado} con respecto a la \textbf{desviación estándar de la muestra} \(S\)

\[T=\frac{\bar{X}-\mu}{\frac{S}{\sqrt{n}}}\]

Sigue una distribución \(t\) con \(n-1\) grados de libertad. Por lo tanto, podemos aplicar \textbf{los tres criterios} como en el \textbf{caso 1} pero reemplazando \(s\) por \(\sigma\) y \(Z\) por \(T\).

\textbf{Criterios de decisión:}

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \emph{Intervalo de confianza:} Si el intervalo de confianza \textbf{contiene} la hipótesis nula
\end{enumerate}

\[\mu_0\in (l,u)=(\bar{x}-t_{0.025,n-1} \frac{s}{\sqrt{n}}, \bar{x}+t_{0.025, n-1} \frac{s}{\sqrt{n}})\] entonces \textbf{aceptamos} \(H_0\) con una confianza de \(95\%\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  \emph{Región de rechazo/aceptación:} Si la estadística observada \(t_{obs}\) bajo la hipótesis nula \textbf{está} en la región de aceptación
\end{enumerate}

\[t_{obs}=\frac{\bar{x}-\mu_0}{\frac{s}{\sqrt{n}}} \in (-t_{0.025}, t_{0.025})\]

donde \(t_{0.025}=F_t^{-1}(0.975, n-1)=\)qt(0.975, n-1), entonces \textbf{aceptamos} \(H_0\) con \(95 \%\) confianza.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  \(pvalor\): Si el \[pvalor= 2 (1-F_t(|t_{obs}|))\]
\end{enumerate}

2*(1-pt(abs(tobs), n-1)) es

\(pvalor \geq \alpha =1-0.95=0.05\)

entonces \textbf{aceptamos} \(H_0\) con una confianza de \(95\%\). Si se cumple un criterio se cumplen los otros. En el caso de no se cumplan entonces no aceptamos \(H_0\) y la rechazamos.

\textbf{Ejemplo (Cables)}

Para el contraste de hipótesis para la carga de rotura de los cables

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  \(H_0:\mu = 13\)
\item
  \(H_1:\mu\neq 13\)
\end{enumerate}

Supondremos que la rotura de los cables se distribuye normalmente

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(X \rightarrow N(\mu=13, \sigma^2=?)\)
\item
  No sabemos \(\sigma^2\)
\end{enumerate}

Habiendo obtenido la muestra

\begin{verbatim}
## [1] 13.34642 13.32620 13.01459 13.10811 12.96999 13.55309 13.75557 12.62747
\end{verbatim}

\textbf{aceptamos} \(H_0\) con confianza de \(95\%\) debido a cualquiera de los siguientes contrastes:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  El intervalo de confianza
\end{enumerate}

\[(\bar{x}-t_{0.025, n-1} \frac{s}{\sqrt{n}}, \bar{x}+t_{0.025, n-1} \frac{s}{ \sqrt{n}})=(12.91409, 13.51127)\]

contiene \(H_0:\mu=13\).

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  La región de aceptación para \(H_0\) es:
\end{enumerate}

\[(-t_{0.025,7}, t_{0.025,7})=( -2.36, 2.36)\]

y el error estandarizado observado de \(H_0\) es
\[t_{obs} = \frac{13.21268-13}{\frac{0.3571565}{\sqrt{8}}}=1.6843\]

el cual está dentro de la región de aceptación.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  El \[pvalor=2(1-F_{t,7}(1.6843))=0.136\]
\end{enumerate}

es mayor que \(\alpha=0.05\). El \(pvalor\) se calcula R como 2*(1-pt(1.6843,7))

En R estos contrastes se realizan con la función t.test:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FloatTok{13.34642}\NormalTok{, }\FloatTok{13.32620}\NormalTok{, }\FloatTok{13.01459}\NormalTok{, }\FloatTok{13.10811}\NormalTok{,}
         \FloatTok{12.96999}\NormalTok{, }\FloatTok{13.55309}\NormalTok{, }\FloatTok{13.75557}\NormalTok{, }\FloatTok{12.62747}\NormalTok{), }
       \AttributeTok{mu=}\DecValTok{13}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  One Sample t-test
## 
## data:  c(13.34642, 13.3262, 13.01459, 13.10811, 12.96999, 13.55309, 13.75557, 12.62747)
## t = 1.6843, df = 7, p-value = 0.136
## alternative hypothesis: true mean is not equal to 13
## 95 percent confidence interval:
##  12.91409 13.51127
## sample estimates:
## mean of x 
##  13.21268
\end{verbatim}

\includegraphics{_main_files/figure-latex/unnamed-chunk-114-1.pdf}

\textbf{Ejemplo (NaCl)}

\(11.6 g\) de NaCl se disuelven en \(100 g\) de agua, correpondiendo a una concentración molar de \(1.92 mol/L\).

Diseñamos un proceso para eliminar la sal de esta concentración y obtenemos los siguientes resultados

\begin{verbatim}
## [1] 1.716 1.889 1.783 1.849 1.891
\end{verbatim}

Queremos probar con una confianza del \(95º%
\) si el proceso cambia la concentración de sal en cualquier dirección. Por lo tanto, proponemos una hipótesis de dos colas:

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  \(H_0:\mu=1.92\)
\item
  \(H_1:\mu\neq 1.92\)
\end{enumerate}

Supondremos que \(X\) es normal y que no conocemos la varianza \(\sigma^2\). Por lo tanto, estamos en el \textbf{caso 2} que probamos con una prueba t.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FloatTok{1.716}\NormalTok{, }\FloatTok{1.889}\NormalTok{, }\FloatTok{1.783}\NormalTok{, }\FloatTok{1.849}\NormalTok{, }\FloatTok{1.891}\NormalTok{), }
       \AttributeTok{mu=}\FloatTok{1.92}\NormalTok{, }\AttributeTok{alternative =} \StringTok{"two.sided"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  One Sample t-test
## 
## data:  c(1.716, 1.889, 1.783, 1.849, 1.891)
## t = -2.8038, df = 4, p-value = 0.04862
## alternative hypothesis: true mean is not equal to 1.92
## 95 percent confidence interval:
##  1.732122 1.919078
## sample estimates:
## mean of x 
##    1.8256
\end{verbatim}

De tal forma que rechazamos la hipótesis nula: el \(pvalor\) es menor que \(0.05\) y el intervalo de confianza no contiene a \(\mu_0=1.92\). Concluimos pues que el proceso \textbf{altera} la concentración de sal.

\hypertarget{hipuxf3tesis-la-cola-inferior}{%
\subsection{Hipótesis la cola inferior}\label{hipuxf3tesis-la-cola-inferior}}

Si solo estamos interesados en el caso de que podamos eliminar la sal de la concentración, entonces proponemos una hipótesis de \textbf{cola inferior}:

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  \(H_0:\mu \geq 1.92\) (Después del proceso de desalinización la concentración de sal es al menos la inicial: status quo)
\item
  \(H_1:\mu < 1.92\) (Después del proceso de desalinización la concentración es menor a la inicial: interés de investigación)
\end{enumerate}

Ten en cuenta que la cola inferior viene dada por la alternativa \(H_1\). Queremos probar que la concentración promedio después del proceso es menor que la concentración inicial. Los criterios de contraste son los mismos que para los otros tipos de hipótesis. Para este tipo de hipótesis, \textbf{aceptaremos} la hipótesis nula si

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\item
  \(\mu_0\) está en el intervalo de confianza:
  \[\mu_0\in (l,u)=(-\infty, \bar{x}+t_{0.05,n-1} \frac{s}{\sqrt{n}})\]
\item
  o \(t_{obs}\) está en la región de aceptación:
\end{enumerate}

\[t_{obs}\in (t_{0.05,n-1}, \infty)\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  o el \(pvalor\) de la cola inferior
  \[pvalor=F_t(t_{obs},n-1)\]
  es superior a \(\alpha=0.05\)
\end{enumerate}

Si no se complen estos criterios, rechazamos \(H_0\) y aceptamos la hipótesis alternativa \(H_1\).

\textbf{Ejemplo (NaCl)}

Para el contraste inferior de la cola

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  \(H_0:\mu\geq 1.92\)
\item
  \(H_1:\mu < 1.92\)
\end{enumerate}

Podemos suponer que la concentración es normal y que no sabemos \(\sigma^2\). Por lo tanto, estamos en el \textbf{caso 2} para el cual solo necesitamos cambiar el argumento ``alternative'' en la función t.test. Así pues rechazamos la hipótesis nula.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FloatTok{1.716}\NormalTok{, }\FloatTok{1.889}\NormalTok{, }\FloatTok{1.783}\NormalTok{, }\FloatTok{1.849}\NormalTok{, }\FloatTok{1.891}\NormalTok{), }
       \AttributeTok{mu=}\FloatTok{1.92}\NormalTok{, }\AttributeTok{alternative =} \StringTok{"less"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  One Sample t-test
## 
## data:  c(1.716, 1.889, 1.783, 1.849, 1.891)
## t = -2.8038, df = 4, p-value = 0.02431
## alternative hypothesis: true mean is less than 1.92
## 95 percent confidence interval:
##      -Inf 1.897376
## sample estimates:
## mean of x 
##    1.8256
\end{verbatim}

El resultado es mas significativo que el de dos colas, ya que el \(pvalor\) es menor que antes. Concluimos con mas confianza que el proceso \textbf{reduce} la concentración de sal.

\textbf{Ejemplo 2 (soporífero)}

En algunos casos, no estamos seguros del valor numérico de la hipótesis a contrastar, pero sabemos que queremos mejorar el valor de un parámetro en una nueva condición.

En su artículo original, Gosset analizó el efecto de dos medicamentos soporíferos.

\begin{itemize}
\tightlist
\item
  A 10 individuos se les dio el \textbf{soporífero 1} y se anotaron las horas adicionales dormidas bajo tratamiento, con una media de \(0.75\)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{medicine1 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{0.7}\NormalTok{,}\SpecialCharTok{{-}}\FloatTok{1.6}\NormalTok{,}\SpecialCharTok{{-}}\FloatTok{0.2}\NormalTok{,}\SpecialCharTok{{-}}\FloatTok{1.2}\NormalTok{,}\SpecialCharTok{{-}}\FloatTok{0.1}\NormalTok{,}\FloatTok{3.4}\NormalTok{,}\FloatTok{3.7}\NormalTok{,}\FloatTok{0.8}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{2}\NormalTok{)}
\NormalTok{medicine1}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  0.7 -1.6 -0.2 -1.2 -0.1  3.4  3.7  0.8  0.0  2.0
\end{verbatim}

\begin{itemize}
\tightlist
\item
  Los mismos 10 individuos recibieron el \textbf{soporífero 2} y anotaron las horas adicionales dormidas bajo tratamiento, con una media de \(2.33\)
\end{itemize}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{medicine2 }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\FloatTok{1.9}\NormalTok{,}\FloatTok{0.8}\NormalTok{,}\FloatTok{1.1}\NormalTok{,}\FloatTok{0.1}\NormalTok{,}\SpecialCharTok{{-}}\FloatTok{0.1}\NormalTok{,}\FloatTok{4.4}\NormalTok{,}\FloatTok{5.5}\NormalTok{,}\FloatTok{1.6}\NormalTok{,}\FloatTok{4.6}\NormalTok{,}\FloatTok{3.4}\NormalTok{)}
\NormalTok{medicine2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1]  1.9  0.8  1.1  0.1 -0.1  4.4  5.5  1.6  4.6  3.4
\end{verbatim}

La hipótesis científica era que el soporífero 2 era mejor que el soporífero 1. Para cada individuo, Gosset calculó la diferencia entre los tratamientos. Tomando \(X\) como la \textbf{diferencia} entre tratamientos, esta fue la muestra observada para \(X\)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}}\NormalTok{ medicine2}\SpecialCharTok{{-}}\NormalTok{medicine1}
\NormalTok{x}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
##  [1] 1.2 2.4 1.3 1.3 0.0 1.0 1.8 0.8 4.6 1.4
\end{verbatim}

encontrando un promedio de ganancia de tratamiento del soporífero 2 con respecto al soporífero 1 de \(1.58\), y \(s=1.229995\)

La pregunta científica se puede establecer como prueba t pareada \textbf{de cola superior}:

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  \(H_0:\mu \leq \mu_0=0\) (sin diferencia de tratamiento: \(\mu_2-\mu_1=0\))
\item
  \(H_1:\mu > \mu_0= 0\) (tratamiento 2 superior al tratamiento 1: \(\mu_2-\mu_1>0\))
\end{enumerate}

Donde \(\mu\) es la media de las \textbf{diferencias} entre tratamientos, y la hipótesis nula dice que no hay diferencia \(\mu_0=0\).

Si suponemos que \(X\) es normal y no sabemos \(\sigma^2\) entonces estamos en el \textbf{caso 2}. El \textbf{error estandarizado} es:

\[T=\frac{\bar{X}}{\frac{S}{\sqrt{n}}}\]

y su observación

\[t_{obs}=\frac{\bar{x}}{\frac{s}{\sqrt{n}}}\]
que también se conoce como la relación \textbf{señal} a \textbf{ruido}.

Podemos probar la hipotesis sobre la diferencia \(X=medicina_1-medicina_2\)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(x,}\AttributeTok{alternative=}\StringTok{"greater"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  One Sample t-test
## 
## data:  x
## t = 4.0621, df = 9, p-value = 0.001416
## alternative hypothesis: true mean is greater than 0
## 95 percent confidence interval:
##  0.8669947       Inf
## sample estimates:
## mean of x 
##      1.58
\end{verbatim}

Esto también se conoce como una prueba t pareada, donde introducimos cada condición por separado y afirmamos que las observaciones están pareadas

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{t.test}\NormalTok{(medicine2, medicine1,}
       \AttributeTok{paired =} \ConstantTok{TRUE}\NormalTok{,}
       \AttributeTok{alternative=}\StringTok{"greater"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  Paired t-test
## 
## data:  medicine2 and medicine1
## t = 4.0621, df = 9, p-value = 0.001416
## alternative hypothesis: true mean difference is greater than 0
## 95 percent confidence interval:
##  0.8669947       Inf
## sample estimates:
## mean difference 
##            1.58
\end{verbatim}

\includegraphics{_main_files/figure-latex/unnamed-chunk-123-1.pdf}

\hypertarget{prueba-de-hipuxf3tesis-con-n-grande-y-cualquier-distribuciuxf3n}{%
\subsection{Prueba de hipótesis con n grande y cualquier distribución}\label{prueba-de-hipuxf3tesis-con-n-grande-y-cualquier-distribuciuxf3n}}

En muchas ocasiones, \(X\) no se distribuye normalmente pero si podemos tomar muestras grandes \(n \ge 30\) entonces podemos usar el CLT:

De tal forma que el \textbf{error estandarizado} de la hipótesis nula se puede aproximar a una distribución estándar

\[Z=\frac{\bar{X}-\mu}{\frac{\sigma}{\sqrt{n}}} \rightarrow N(0,1)\]

Por lo tando procedemos como en el \textbf{caso 1}. Si no se desconoce \(\sigma\), lo reemplazamos por su estimación \(s\) y procedemos como en el \textbf{caso 2} usando la estadística t

\[T=\frac{\bar{X}-\mu_0}{\frac{S}{\sqrt{n}}}\]

\hypertarget{caso-3-para-proporciones}{%
\section{Caso 3 (para proporciones)}\label{caso-3-para-proporciones}}

Si nuestro experimento aleatorio es un ensayo de Bernoulli \(X \rightarrow Bernoulli(p)\), podemos formular contrastes de hipótesis para la probabilidad \(p\) de un evento en el ensayo. Considera una hipótesis de cola superior

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  \(H_0: p \leq p_0\) (status quo)
\item
  \(H_1: p> p_0\) (interés de investigación)
\end{enumerate}

En este \textbf{caso 3}, podemos probar el valor de la proporción si

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(X\) es un ensayo de Bernoulli, y
\item
  \(np\), \(n(1-p)\) son ambos mayores que \(5\), lo que nos permite aplicar el teorema central del límite.
\end{enumerate}

Recuerda que si tomamos una muestra de \(n\) ensayos de Bernoulli \((1,0,1,...0)\), \(\bar{X}=\frac{1}{n}\sum_{i=1 }^n X_i\) es la frecuencia relativa de ``unos'' en la muestra. Este es un estimador de \(p\).

Si asumimos que la hipótesis nula es verdadera entonces \(X \rightarrow Bernoulli(p_0)\) y el error estandarizado que cometemos cuando estimamos \(p_0\) con \(\bar{X}\) es

\[Z=\frac{\bar{X}-p_0}{\frac{\sqrt{p_0(1-p_0)}}{\sqrt{n}}} \rightarrow N(0,1)\]

\(\sigma=\sqrt{p_0(1-p_0)}\) es la desviación estándar de \(X\), cuando la hipótesis nula es verdadera: \(V(X)=\sigma^2=p_0(1-p_0)\). Con esta estadística \(Z\), podemos aceptar o rechazar la hipótesis nula usando cualquiera de los tres riterios de decisión.

\textbf{Ejemplo (mejora de procesos)}

Podemos estar satisfechos con un nuevo proceso si el \(90\%\) de las veces mejoramos el proceso anterior.

Si tomamos una muestra de \(200\) nuevos procesos y encontramos que \(188\) veces mejoramos el proceso anterior, ¿podemos estar satisfechos con el nuevo proceso con una confianza de \(95\%\)?

Para esto formulamos un contraste de hipótesis de cola superior para la hipótesis nula \(p_0=0.9\). Por lo tanto, las hipótesis nula y alternativa son

\begin{itemize}
\tightlist
\item
  \(H_0: p \leq p_0=0.9\) (No satisfactorio)
\item
  \(H_1: p> p_0=0.9\) (Satisfactorio)
\end{itemize}

Suponemos que si la hipótesis nula es verdadera entonces

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  la distribución de un experimento aleatorio es
\end{enumerate}

\[X \rightarrow Bernoulli (p_0)\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  además \(p_0n=180>5\) y \((1-p_0)=n=20>5\)
\end{enumerate}

Y por lo tanto podemos aplicar \textbf{caso 3}.

Podemos usar cualquiera de los tres criterios para probar la hipótesis. En cualquier caso, \textbf{rechazaremos} \(H_0\) con una confianza de \(95\%\) porque:

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  El intervalo de confianza \textbf{de cola superior} para \(p\) no incluye \(p_0\)
\end{enumerate}

\[p_0=0.9 \notin (\bar{x}-z_{0.05}\big[\frac{\bar{x}(1-\bar{x})}{n} \big]^{1/2},1)= (0.912,1)\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\tightlist
\item
  El error estandarizado observado bajo la hipótesis nula no está en la región de aceptación
\end{enumerate}

\[z_{obs}= \frac{\bar{X}-p_0}{\big[\frac{p_0(1-p_0)}{n} \big]^{1/2}} =\frac{0.94 -0.90}{\sqrt{0.00045}}=1.88563 \notin (-\infty, z_{0.05})=(-\infty, 1.644)\]
Nota que para este caso usamos \(p_0\) para calcular \(z_{obs}\) porque estamos suponiendo que la hipótesis nula es verdad. Por lo tanto conocemos exactamente la media y la varianza de las observaciones.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{2}
\tightlist
\item
  El \(pvalor\) de cola superior es menor que \(\alpha=0.05\):
\end{enumerate}

\[pvalor=1-\phi(1.885618)=0.02967323<0.05\]

en R: 1-pnorm(1.885618)

\includegraphics{_main_files/figure-latex/unnamed-chunk-124-1.pdf}

La prueba se puede realizar en R usando la función prop.test. Sin embargo nota que los intervalos de confianza no son idénticos a los dados en el criterio 1, porque ahí suponemos que \(\bar{X}\) es exactamente normal mientras que prop.test usa una aproximación mas adecuada

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{prop.test}\NormalTok{(}\DecValTok{188}\NormalTok{, }\DecValTok{200}\NormalTok{, }\AttributeTok{p=}\FloatTok{0.9}\NormalTok{, }\AttributeTok{alternative =} \StringTok{"greater"}\NormalTok{ , }\AttributeTok{correct=}\ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
##  1-sample proportions test without continuity correction
## 
## data:  188 out of 200, null probability 0.9
## X-squared = 3.5556, df = 1, p-value = 0.02967
## alternative hypothesis: true p is greater than 0.9
## 95 percent confidence interval:
##  0.9060689 1.0000000
## sample estimates:
##    p 
## 0.94
\end{verbatim}

\hypertarget{caso-4-para-la-varianza}{%
\section{Caso 4 (para la varianza)}\label{caso-4-para-la-varianza}}

En muchos casos, se realizan experimentos para probar valores específicos de la dispersión de datos.

Como

\begin{itemize}
\item
  al cumplir con estándares de diseño donde las medidas deben estar entre ciertos valores.
\item
  cuando se aplican diferentes tratamientos a diferentes grupos, queremos ver la dispersión de los resultados entre los grupos.
\end{itemize}

Un contraste de hipótesis \textbf{de dos colas} para la varianza es de la forma

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  \(H_0:\sigma^2 = \sigma^2_0\) (status quo)
\item
  \(H_1:\sigma^2 \neq \sigma^2_0\) (interés de investigación)
\end{enumerate}

Esta hipótesis para \(\sigma^2\) (\textbf{caso 4}) y se puede probar cuando

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  \(X\) es una variable normal
\end{enumerate}

Recuerda que si tomamos una muestra de \(n\) ensayos de Bernoulli \((1,0,1,...0)\), \(S^2=\frac{1}{n-1}\sum_{i=1 }^n (X_i-\bar{X})^2\) es la varianza de la muestra. Este es un estimador de \(\sigma^2\).

Si asumimos que la hipótesis nula es verdadera, entonces \(X \rightarrow N(\mu, \sigma_0)\) y la \textbf{proporción de error} que cometemos cuando estimamos \(\sigma^2\) con \(s^2\) es

\[W=\frac{(n-1)S^2}{\sigma_0^2}\]

cuando \(W=1\) no cometemos ningún error. \(W\) tiene una distribución \(\chi^2\) (chi-cuadrado) con n-1 grados de libertad.

\[W \rightarrow \chi^2(n-1)\]

Con \(W\), podemos aceptar o rechazar la hipótesis nula usando cualquiera de los tres criterios de decisión.

\textbf{Ejemplo (semiconductor)}

La producción de un chip semiconductor está regulada por un proceso que requiere que el espesor de una capa en particular no varíe en más de \(\sigma_0=0.6mm\), de su media de \(25mm\).

Para llevar el control del proceso cada cierto tiempo se toma una muestra de \(20\) especímenes.

En una ocasión se toma una muestra del espesor de 20 semiconductores.

\begin{verbatim}
##  [1] 24.51239 24.79975 26.35608 25.06134 25.11248 26.49211 25.40100 23.89940
##  [9] 24.40244 24.61227 26.06495 25.31304 25.34867 25.09629 24.51642 26.55461
## [17] 25.43313 23.28904 25.61018 24.58867
\end{verbatim}

La desviación estándar estimada para estos datos es \(s=0.8462188\). ¿Estaba el proceso fuera de control con una confianza de \(99\%\) y debería detenerse?

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{sd}\NormalTok{(x)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## [1] 0.8462188
\end{verbatim}

Por lo tanto, queremos contrastar las hipótesis de la cola superior

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  \(H_0:\sigma^2 \leq \sigma^2_0=0.6^2\) (El proceso está bajo control)
\item
  \(H_1:\sigma^2 > \sigma^2_0=0.6^2\) (El proceso está fuera de control)
\end{enumerate}

Probemos la hipótesis usando la \textbf{región de aceptación}.

La estadística de contraste son \[W=\frac{(n-1)S^2}{\sigma_0^2} \rightarrow \chi^2(n-1)\]

y el límite de umbral \(\alpha=0.01=0-0.99\). Por lo tanto, la región de aceptación \(P(W\leq \chi^2_{0.01,19})=0.99\) es

\[(0, \chi^2_{0.01,19})=(0,36.19)\]

En R: \(\chi^2_{0.01,19}=\)qchisq(0.99,19)\(= 36.19\)

Para nuestros datos, la \textbf{proporción de error estandarizado} observada es:

\[w_{obs}=\frac{19 (0.8462188)^2}{0.60^2}=37.79344\]

Que cae fuera de la región de aceptación.

\[w_{obs}=37.79344\notin (0,36.19)\]

Por lo tanto, rechazamos la hipótesis nula y concluimos que sí! el proceso está fuera de control.

Si nosotros, alternativamente, calculamos el \(pvalor\) de cola superior

\[pvalor=1-F_{\chi^2,19}(37.79344)= 0.006\]
vemos que es menor que \(\alpha=0.01\) y rechazamos la hipótesis nula.

R: 1-pchisq(37.79344, 19)

\includegraphics{_main_files/figure-latex/unnamed-chunk-128-1.pdf}

Para probar la hipótesis, podemos usar la función varTest de la biblioteca EnvStats. Si la biblioteca no está instalada, primero ejecuta

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{install.packages}\NormalTok{(EnvStats)}
\end{Highlighting}
\end{Shaded}

y después

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(EnvStats);}
\FunctionTok{varTest}\NormalTok{(x, }\AttributeTok{sigma.squared =} \FloatTok{0.6}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{, }\AttributeTok{alternative =} \StringTok{"greater"}\NormalTok{, }\AttributeTok{conf.level =} \FloatTok{0.99}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
## 
## Results of Hypothesis Test
## --------------------------
## 
## Null Hypothesis:                 variance = 0.36
## 
## Alternative Hypothesis:          True variance is greater than 0.36
## 
## Test Name:                       Chi-Squared Test on Variance
## 
## Estimated Parameter(s):          variance = 0.7160863
## 
## Data:                            x
## 
## Test Statistic:                  Chi-Squared = 37.79344
## 
## Test Statistic Parameter:        df = 19
## 
## P-value:                         0.006304231
## 
## 99% Confidence Interval:         LCL = 0.3759412
##                                  UCL =       Inf
\end{verbatim}

También vemos que \(\sigma_0^2=0.6^2=0.36\) no está en el intervalo de confianza, por lo que se rechaza la hipótesis nula.

\hypertarget{errores-en-la-prueba-de-hipuxf3tesis}{%
\section{Errores en la prueba de hipótesis}\label{errores-en-la-prueba-de-hipuxf3tesis}}

El resultado de una prueba de hipótesis de cola superior puede ser \textbf{rechazar} la hipótesis nula:

\[H_0: \mu\leq\mu_0\]

cuando \(H_0\) realmente \textbf{es verdad}. Debemos tener en cuenta que la decisión se toma con base en los datos. Bien puede ser que el estadístico observado haya caido, por aleatoridad, lejos de la hipótesis nula, en la zona de rechazo de \(H_0\) aún cuando esta sea verdad. Cuando realizamos la prueba de hipótesis, no sabemos si \(H_0\) es verdad, por lo que si ahora lo sabemos es porque asumimos que lo hemos averiguado de alguna otra forma. Aún así, la probabilidad de rechazar \(H_0\) cuando es verdad es precisamente el nivel de significación estadística \(\alpha\). Llamamos a esta probabilidad la probabilidad de cometer un error de \textbf{tipo 1}. Tomando el ejemplo para el \textbf{caso 1}, un test de cola superior, y una confianza del \(95\%\) tenemos que

\[\alpha = P(Z> z_{0.05})=0.05\]

donde \(z_{0.05}=\phi^{-1}(0.95)=\) qnorm(0.95)=1.644

\includegraphics{_main_files/figure-latex/unnamed-chunk-131-1.pdf}

Un error del tipo 1 también se llama un \textbf{falso positivo} porque nuestro interés de investigación está en \(H_1\). Cuando rechazamos \(H_0\), aceptamos \(H_1\) y decimos que nuestro test es \textbf{positivo}. Aceptar \(H_1\) se traduce en anunciar un descubrimiento, por lo que el error de tipo 1 es anunciar un descubrimiento cuando este no existe: lo hemos hecho porque los datos nos lo han sugerido.

Existe otro tipo de error. El resultado de una prueba de hipótesis de cola superior puede ser \textbf{aceptar} la hipótesis nula:

\[H_0: \mu\leq\mu_0\]

cuando \(H_0\) realmente \textbf{no es verdad}. En este caso, puede ser que el estadístico observado haya caido, por aleatoridad, cerca de la hipótesis nula, en la zona de aceptación de \(H_0\), cuando realmente \(H_1\) es verdad. Si averiguaramos de alguna forma que, por ejemplo, \(\mu\) realmente tiene un valor \(\mu_1\) entonces la hipóteisis alternativa sería exactamente:

\[H_1: \mu=\mu_1\]

\includegraphics{_main_files/figure-latex/unnamed-chunk-132-1.pdf}

Si \(H_1\) es realemente verdadera (línea roja, que no sabemos cuando realizamos la prueba de hipótesis) entonces los estadísticos observados son \textbf{realmente} variables aleatorias \(Y\) que se distribuyen con media (caso 1)

\[E(Y)=\frac{\mu_1-\mu_0}{\frac{\sigma}{\sqrt{n}}}\]

y en su mayoría caerán cerca de este valor, por lo tanto, en la zona de rechazo de \(H_0\), dando validez a la prueba de hipótesis. Sin embargo existen casos en que el estadístico observado cae en la zona de acepación de \(H_0\) por aleatoreidad, apesar de que los estadísticos los produce \(H_1\). En estos casos aceptamos \(H_0\) cuando no es verdad. Este error se llama \textbf{un error de tipo 2} o un \textbf{falso negativo}. Para el caso 1, con un test de cola superior y nivel de confianza del \(95\%\) este es

\[\beta= P(Y < z_{0.05})\]
Donde \(Y \rightarrow N(\frac{\mu_1-\mu_0}{\sigma/\sqrt{n}},1)\) es la \textbf{verdadera distribución} de los estadísticos observados.

\textbf{Ejemplo (Bombilla)}

La eficiencia energética de una nueva bombilla es una variable aleatoria normal con desviación estandar de \(5\) vátios. Consideramos que las bombillas que producimos son eficientes si su media no supera los \(80\) vátios, por lo que planteamos el contraste de hipótesis

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  \(H_0 : \mu \geq 80\) (no eficientes)
\item
  \(H_1 : \mu < 80\) (eficientes)
\end{enumerate}

Queremos probar que producimos bombillas eficientes y planteamos realizar una muestra aleatoria de tamaño 100, con un nivel de significación estadística del \(5\%\). Si estudios previos han sugerído que las bombillas puedne tener una media de \(\mu=\mu_1=79\) vátios ¿Qué error del tipo 2 esperamos?

El contraste es para el \textbf{caso 1} con una \textbf{cola inferior}. Por lo tanto la probabilidad de aceptar la hipótesis nula (no prodicimos bombillas eficientes) es

\[\alpha = P(Z< z_{0.95})=0.05\]
y \(z_{0.95}=\)qnorm(0.05)\(=-1.644\).

El error de tipo 2 es por lo tanto

\[\beta= P(Y > -1.644)\]

es decir, la probabilidad de aceptar que no producimos bombillas eficientes cuando en realidad sí lo hacemos. Al tener el \textbf{caso 1} porque conocemos \(\sigma\) y la variable es normal, entonces los estadísticos observados realmente se distribuyten como

\[Y \rightarrow N(\frac{79-80}{5/\sqrt{100}}=-2,1)\] y el error de tipo 2 es

\[\beta = 1-F(-1.644)=0.36\]

calculado en R como 1-pnorm(-1.644,-2,1)=0.36. De tal forma, que sólo un \(\alpha=5\%\) de las veces anunciaríamos que producimos bombillas eficientes cuando realmente no lo son, mientras que un \(\beta=36\%\) de las veces anunciaríamos tener una producción que no sirve cuando realmente sí sirve.

Cuando realizamos una prueba de hipótesis tenemos dos posibilidades para cada condición

\begin{itemize}
\tightlist
\item
  \(H_1\) es en realidad : \textbf{verdadera} (\(\mu=\mu_1\)) o \textbf{falsa} (\(\mu=\mu_0\))
\item
  La prueba para \(H_1\) es: \textbf{positiva} (\(z_{obs}\) en zona de aceptación de \(H_1\)) o \textbf{negativa} (\(z_{obs}\) en zona de aceptación de \(H_0\))
\end{itemize}

\textbf{Ejemplo (PCR)}

Hacemos \textbf{una} PCR para probar una infección. El contraste de hipótesis es

\begin{enumerate}
\def\labelenumi{\alph{enumi}.}
\tightlist
\item
  \(H_0\) no hay infección
\item
  \(H_1\) hay infección
\end{enumerate}

Hacemos la prueba PCR y nos da

\begin{enumerate}
\def\labelenumi{\roman{enumi}.}
\tightlist
\item
  negativa: rechazamos la infección (\(H_1\))
\item
  positiva: aceptamos la infección (\(H_1\))
\end{enumerate}

Podemos escribir la tabla de contingencia para las probabilidades de los resultados de la prueba de hipótesis como

\begin{longtable}[]{@{}ccc@{}}
\toprule\noalign{}
& \(H_1\) es verdadera & \(H_0\) es verdadera \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
\textbf{La prueba en \(H_1\) es positiva} & \(1-\beta\) & \(\alpha\) \\
\textbf{La prueba en \(H_1\) es negativa} & \(\beta\) & \(1-\alpha\) \\
\textbf{suma} & 1 & 1 \\
\end{longtable}

De tal forma que tenemos

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  La tasa de \textbf{error de tipo 2}: probabilidad de un falso negativo (ignorar un descubrimiento cuando es verdadero)
\end{enumerate}

\[\beta=P(negativa|H_1)\]

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\setcounter{enumi}{1}
\item
  Tasa de \textbf{verdaderos positivos}: Este es el poder o la sensibilidad de una prueba (afirmar un descubrimiento cuando es verdadero, el objetivo principal)
  \[1-\beta=P(positiva|H_1)\]
\item
  Tasa de \textbf{error de tipo 1}: probabilidad de un falso positivo (afirmar un descubrimiento cuando es falso)
  \[\alpha=P(positiva|H_0)\]
\item
  Tasa de \textbf{verdaderos negativos}: Esta es la especificidad de una prueba (ignorar un descubrimiento cuando es falso)
  \[1-\alpha=P(negativa|H_0)\]
\end{enumerate}

\hypertarget{ejercicios-12}{%
\section{Ejercicios}\label{ejercicios-12}}

\hypertarget{ejercicio-1-12}{%
\subsubsection{Ejercicio 1}\label{ejercicio-1-12}}

Imagina que tomamos una muestra aleatoria de tamaño \(n = 41\) de una variable aleatoria normal \(X\) y encontramos que el promedio de la muestra es de \(10\) y la varianza de la muestra es de \(1.5\).

\begin{itemize}
\item
  ¿Cuál es entonces el intervalo de confianza para la media de \(X\) con un nivel de confianza de \(95\%\)? (R:(9.61, 10.38))
\item
  Probar la hipótesis de que la media de \(X\) es \textbf{diferente} de \(10.5\), utilizando un umbral de significancia de \(5\%\). (R: Reject the null)
\item
  Escriba el código para calcular el P valor para probar la hipótesis de que la media de \(\mu\) es \textbf{inferior} a \(10.5\), utilizando un umbral de significancia de \(5\%\).
\end{itemize}

Considera que el código para la distribución de probabilidad T con \(n-1\) grados de libertad es pt(tobs, n-1). (R: pt((10-10.5)/sqrt(1.5/41), 40))

\hypertarget{ejercicio-2-12}{%
\subsubsection{Ejercicio 2}\label{ejercicio-2-12}}

Una muestra de \(10\) condensados de gas mostraron las siguientes concentraciones de mercurio (en \(ng/ml\)):

\(23.3\), \(22.5\), \(21.9\), \(21.5\), \(19.9\), \(21.3\), \(21.7\), \(23.8\), \(22.6\), \(24.7\)

Suponiendo que la concentración de mercurio se distribuye normalmente entre los condensados de gas, prueba la hipótesis de que un condensado no supera el límite de toxicidad establecido en \(24 ng/ml\). (R: p-value = 0.001, Reject the null)

\hypertarget{ejercicio-3-9}{%
\subsubsection{Ejercicio 3}\label{ejercicio-3-9}}

El fabricante de microarrays de expresión génica garantiza que al menos el \(97\%\) de los microarrays que producen tienen señales de alta calidad. Un cliente recibe un lote de piezas de \(200\) y descubre que \(8\) no son buenas.

¿Debe el cliente devolver el lote por mala calidad? (R:No, p-value = 0.20, Accept the null)

\hypertarget{soluciones-a-las-preguntas}{%
\chapter{Soluciones a las preguntas}\label{soluciones-a-las-preguntas}}

\hypertarget{capuxedtulo-2}{%
\section{Capítulo 2}\label{capuxedtulo-2}}

\(\qquad\) 1.c; \(\qquad\) 2.a; \(\qquad\) 3.d; \(\qquad\) 4.d; \(\qquad\) 5.b

\hypertarget{capuxedtulo-3}{%
\section{Capítulo 3}\label{capuxedtulo-3}}

\(\qquad\) 1.a; \(\qquad\) 2.b; \(\qquad\) 3.b; \(\qquad\) 4.b; \(\qquad\) 5.a

\hypertarget{capuxedtulo-4}{%
\section{Capítulo 4}\label{capuxedtulo-4}}

\(\qquad\) 1.c; \(\qquad\) 2.b; \(\qquad\) 3.d; \(\qquad\) 4.b; \(\qquad\) 5.b

\hypertarget{capuxedtulo-5}{%
\section{Capítulo 5}\label{capuxedtulo-5}}

\(\qquad\) 1.d; \(\qquad\) 2.c; \(\qquad\) 3.b; \(\qquad\) 4.c; \(\qquad\) 5.b

\hypertarget{capuxedtulo-7}{%
\section{Capítulo 7}\label{capuxedtulo-7}}

\(\qquad\) 1.d; \(\qquad\) 2.a; \(\qquad\) 3.d; \(\qquad\) 4.a; \(\qquad\) 5.d

\hypertarget{capuxedtulo-8}{%
\section{Capítulo 8}\label{capuxedtulo-8}}

\(\qquad\) 1.d; \(\qquad\) 2.b; \(\qquad\) 3.a

\hypertarget{capuxedtulo-9}{%
\section{Capítulo 9}\label{capuxedtulo-9}}

\(\qquad\) 1.c; \(\qquad\) 2.a; \(\qquad\) 3.c; \(\qquad\) 4.d; \(\qquad\) 5.b

\hypertarget{capuxedtulo-10}{%
\section{Capítulo 10}\label{capuxedtulo-10}}

\(\qquad\) 1.a; \(\qquad\) 2.c; \(\qquad\) 3.d; \(\qquad\) 4.d; \(\qquad\) 5.c

\hypertarget{capuxedtulo-11}{%
\section{Capítulo 11}\label{capuxedtulo-11}}

\(\qquad\) 1.c; \(\qquad\) 2.b; \(\qquad\) 3.c

\hypertarget{capuxedtulo-12}{%
\section{Capítulo 12}\label{capuxedtulo-12}}

\(\qquad\) 1.d; \(\qquad\) 2.d; \(\qquad\) 3.b; \(\qquad\) 4.a

\hypertarget{capuxedtulo-13}{%
\section{Capítulo 13}\label{capuxedtulo-13}}

\(\qquad\) 1.b; \(\qquad\) 2.a; \(\qquad\) 3.d; \(\qquad\) 4.b; \(\qquad\) 5.b

  \bibliography{book.bib,packages.bib}

\end{document}
