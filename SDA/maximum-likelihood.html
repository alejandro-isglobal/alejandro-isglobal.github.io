<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 12 Maximum likelihood | Statistical Data Analysis for Experimental Sciences</title>
  <meta name="description" content="This is a markdown book titled Statistical Data Analysis for Experimental Sciences by Alejandro Caceres" />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 12 Maximum likelihood | Statistical Data Analysis for Experimental Sciences" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="This is a markdown book titled Statistical Data Analysis for Experimental Sciences by Alejandro Caceres" />
  <meta name="github-repo" content="alejandro-isglobal/master" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 12 Maximum likelihood | Statistical Data Analysis for Experimental Sciences" />
  
  <meta name="twitter:description" content="This is a markdown book titled Statistical Data Analysis for Experimental Sciences by Alejandro Caceres" />
  

<meta name="author" content="Alejandro CÃ¡ceres" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="central-limit-theorem.html"/>
<link rel="next" href="interval-estimation.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>



<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">SDA</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#how-to-read-the-book"><i class="fa fa-check"></i><b>1.1</b> How to read the book</a></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i><b>1.2</b> Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="data-description.html"><a href="data-description.html"><i class="fa fa-check"></i><b>2</b> Data description</a>
<ul>
<li class="chapter" data-level="2.1" data-path="data-description.html"><a href="data-description.html#scientific-method"><i class="fa fa-check"></i><b>2.1</b> Scientific method</a></li>
<li class="chapter" data-level="2.2" data-path="data-description.html"><a href="data-description.html#data"><i class="fa fa-check"></i><b>2.2</b> Data</a></li>
<li class="chapter" data-level="2.3" data-path="data-description.html"><a href="data-description.html#types-of-outcomes"><i class="fa fa-check"></i><b>2.3</b> Types of outcomes</a></li>
<li class="chapter" data-level="2.4" data-path="data-description.html"><a href="data-description.html#random-experiments"><i class="fa fa-check"></i><b>2.4</b> Random experiments</a></li>
<li class="chapter" data-level="2.5" data-path="data-description.html"><a href="data-description.html#absolute-frequencies"><i class="fa fa-check"></i><b>2.5</b> Absolute frequencies</a></li>
<li class="chapter" data-level="2.6" data-path="data-description.html"><a href="data-description.html#relative-frequencies"><i class="fa fa-check"></i><b>2.6</b> Relative frequencies</a></li>
<li class="chapter" data-level="2.7" data-path="data-description.html"><a href="data-description.html#bar-chart"><i class="fa fa-check"></i><b>2.7</b> Bar chart</a></li>
<li class="chapter" data-level="2.8" data-path="data-description.html"><a href="data-description.html#pie-chart"><i class="fa fa-check"></i><b>2.8</b> Pie chart</a></li>
<li class="chapter" data-level="2.9" data-path="data-description.html"><a href="data-description.html#ordinal-categorical-outcomes"><i class="fa fa-check"></i><b>2.9</b> Ordinal categorical outcomes</a></li>
<li class="chapter" data-level="2.10" data-path="data-description.html"><a href="data-description.html#absolute-and-relative-cumulative-frequencies"><i class="fa fa-check"></i><b>2.10</b> Absolute and relative cumulative frequencies</a></li>
<li class="chapter" data-level="2.11" data-path="data-description.html"><a href="data-description.html#cumulative-frequency-graph"><i class="fa fa-check"></i><b>2.11</b> Cumulative frequency graph</a></li>
<li class="chapter" data-level="2.12" data-path="data-description.html"><a href="data-description.html#numerical-outcomes"><i class="fa fa-check"></i><b>2.12</b> Numerical outcomes</a></li>
<li class="chapter" data-level="2.13" data-path="data-description.html"><a href="data-description.html#transforming-continuous-data"><i class="fa fa-check"></i><b>2.13</b> Transforming continuous data</a></li>
<li class="chapter" data-level="2.14" data-path="data-description.html"><a href="data-description.html#frequency-table-for-a-continuous-variable"><i class="fa fa-check"></i><b>2.14</b> Frequency table for a continuous variable</a></li>
<li class="chapter" data-level="2.15" data-path="data-description.html"><a href="data-description.html#histogram"><i class="fa fa-check"></i><b>2.15</b> Histogram</a></li>
<li class="chapter" data-level="2.16" data-path="data-description.html"><a href="data-description.html#cumulative-frequency-graph-1"><i class="fa fa-check"></i><b>2.16</b> Cumulative frequency graph</a></li>
<li class="chapter" data-level="2.17" data-path="data-description.html"><a href="data-description.html#summary-statistics"><i class="fa fa-check"></i><b>2.17</b> Summary Statistics</a></li>
<li class="chapter" data-level="2.18" data-path="data-description.html"><a href="data-description.html#average-sample-mean"><i class="fa fa-check"></i><b>2.18</b> Average (sample mean)</a></li>
<li class="chapter" data-level="2.19" data-path="data-description.html"><a href="data-description.html#median"><i class="fa fa-check"></i><b>2.19</b> Median</a></li>
<li class="chapter" data-level="2.20" data-path="data-description.html"><a href="data-description.html#dispersion"><i class="fa fa-check"></i><b>2.20</b> Dispersion</a></li>
<li class="chapter" data-level="2.21" data-path="data-description.html"><a href="data-description.html#sample-variance"><i class="fa fa-check"></i><b>2.21</b> Sample variance</a></li>
<li class="chapter" data-level="2.22" data-path="data-description.html"><a href="data-description.html#interquartile-range-iqr"><i class="fa fa-check"></i><b>2.22</b> Interquartile range (IQR)</a></li>
<li class="chapter" data-level="2.23" data-path="data-description.html"><a href="data-description.html#boxplot"><i class="fa fa-check"></i><b>2.23</b> Boxplot</a></li>
<li class="chapter" data-level="2.24" data-path="data-description.html"><a href="data-description.html#questions"><i class="fa fa-check"></i><b>2.24</b> Questions</a></li>
<li class="chapter" data-level="2.25" data-path="data-description.html"><a href="data-description.html#exercises"><i class="fa fa-check"></i><b>2.25</b> Exercises</a></li>
<li class="chapter" data-level="2.26" data-path="data-description.html"><a href="data-description.html#practice"><i class="fa fa-check"></i><b>2.26</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>3</b> Probability</a>
<ul>
<li class="chapter" data-level="3.1" data-path="probability.html"><a href="probability.html#probability-mesurement"><i class="fa fa-check"></i><b>3.1</b> Probability mesurement</a></li>
<li class="chapter" data-level="3.2" data-path="probability.html"><a href="probability.html#classical-probability"><i class="fa fa-check"></i><b>3.2</b> Classical probability</a></li>
<li class="chapter" data-level="3.3" data-path="probability.html"><a href="probability.html#relative-frequencies-1"><i class="fa fa-check"></i><b>3.3</b> Relative frequencies</a></li>
<li class="chapter" data-level="3.4" data-path="probability.html"><a href="probability.html#frequentist-probability"><i class="fa fa-check"></i><b>3.4</b> Frequentist probability</a></li>
<li class="chapter" data-level="3.5" data-path="probability.html"><a href="probability.html#classical-and-frequentist-probabilities"><i class="fa fa-check"></i><b>3.5</b> Classical and frequentist probabilities</a></li>
<li class="chapter" data-level="3.6" data-path="probability.html"><a href="probability.html#sample-space"><i class="fa fa-check"></i><b>3.6</b> Sample space</a></li>
<li class="chapter" data-level="3.7" data-path="probability.html"><a href="probability.html#events"><i class="fa fa-check"></i><b>3.7</b> Events</a></li>
<li class="chapter" data-level="3.8" data-path="probability.html"><a href="probability.html#algebra-of-events"><i class="fa fa-check"></i><b>3.8</b> Algebra of events</a></li>
<li class="chapter" data-level="3.9" data-path="probability.html"><a href="probability.html#mutually-exclusive-events"><i class="fa fa-check"></i><b>3.9</b> Mutually exclusive events</a></li>
<li class="chapter" data-level="3.10" data-path="probability.html"><a href="probability.html#definition-of-probability"><i class="fa fa-check"></i><b>3.10</b> Definition of probability</a></li>
<li class="chapter" data-level="3.11" data-path="probability.html"><a href="probability.html#probability-table"><i class="fa fa-check"></i><b>3.11</b> Probability table</a></li>
<li class="chapter" data-level="3.12" data-path="probability.html"><a href="probability.html#joint-probabilities"><i class="fa fa-check"></i><b>3.12</b> Joint probabilities</a></li>
<li class="chapter" data-level="3.13" data-path="probability.html"><a href="probability.html#contingency-table"><i class="fa fa-check"></i><b>3.13</b> Contingency table</a></li>
<li class="chapter" data-level="3.14" data-path="probability.html"><a href="probability.html#the-addition-rule"><i class="fa fa-check"></i><b>3.14</b> The addition rule</a></li>
<li class="chapter" data-level="3.15" data-path="probability.html"><a href="probability.html#questions-1"><i class="fa fa-check"></i><b>3.15</b> Questions</a></li>
<li class="chapter" data-level="3.16" data-path="probability.html"><a href="probability.html#exercises-1"><i class="fa fa-check"></i><b>3.16</b> Exercises</a></li>
<li class="chapter" data-level="3.17" data-path="probability.html"><a href="probability.html#practice-1"><i class="fa fa-check"></i><b>3.17</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="conditional-probability.html"><a href="conditional-probability.html"><i class="fa fa-check"></i><b>4</b> Conditional probability</a>
<ul>
<li class="chapter" data-level="4.1" data-path="conditional-probability.html"><a href="conditional-probability.html#joint-probability"><i class="fa fa-check"></i><b>4.1</b> Joint probability</a></li>
<li class="chapter" data-level="4.2" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-independence-and-correlation"><i class="fa fa-check"></i><b>4.2</b> Statistical independence and correlation</a></li>
<li class="chapter" data-level="4.3" data-path="conditional-probability.html"><a href="conditional-probability.html#conditional-probability-1"><i class="fa fa-check"></i><b>4.3</b> Conditional probability</a></li>
<li class="chapter" data-level="4.4" data-path="conditional-probability.html"><a href="conditional-probability.html#conditional-contingency-table"><i class="fa fa-check"></i><b>4.4</b> Conditional contingency table</a></li>
<li class="chapter" data-level="4.5" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-independence"><i class="fa fa-check"></i><b>4.5</b> Statistical independence</a></li>
<li class="chapter" data-level="4.6" data-path="conditional-probability.html"><a href="conditional-probability.html#statistical-dependency"><i class="fa fa-check"></i><b>4.6</b> Statistical dependency</a></li>
<li class="chapter" data-level="4.7" data-path="conditional-probability.html"><a href="conditional-probability.html#diagnostic-test"><i class="fa fa-check"></i><b>4.7</b> Diagnostic test</a></li>
<li class="chapter" data-level="4.8" data-path="conditional-probability.html"><a href="conditional-probability.html#inverse-probabilities"><i class="fa fa-check"></i><b>4.8</b> Inverse probabilities</a></li>
<li class="chapter" data-level="4.9" data-path="conditional-probability.html"><a href="conditional-probability.html#bayes-theorem"><i class="fa fa-check"></i><b>4.9</b> Bayesâ Theorem</a></li>
<li class="chapter" data-level="4.10" data-path="conditional-probability.html"><a href="conditional-probability.html#questions-2"><i class="fa fa-check"></i><b>4.10</b> Questions</a></li>
<li class="chapter" data-level="4.11" data-path="conditional-probability.html"><a href="conditional-probability.html#exercises-2"><i class="fa fa-check"></i><b>4.11</b> Exercises</a></li>
<li class="chapter" data-level="4.12" data-path="conditional-probability.html"><a href="conditional-probability.html#practice-2"><i class="fa fa-check"></i><b>4.12</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html"><i class="fa fa-check"></i><b>5</b> Discrete Random Variables</a>
<ul>
<li class="chapter" data-level="5.1" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#definition-of-a-random-variable"><i class="fa fa-check"></i><b>5.1</b> Definition of a Random Variable</a></li>
<li class="chapter" data-level="5.2" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#the-value-of-a-random-variable"><i class="fa fa-check"></i><b>5.2</b> The value of a random variable</a></li>
<li class="chapter" data-level="5.3" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-of-random-variables"><i class="fa fa-check"></i><b>5.3</b> Probability of random variables</a></li>
<li class="chapter" data-level="5.4" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-functions"><i class="fa fa-check"></i><b>5.4</b> Probability functions</a></li>
<li class="chapter" data-level="5.5" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-mass-functions"><i class="fa fa-check"></i><b>5.5</b> Probability mass functions</a></li>
<li class="chapter" data-level="5.6" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#mean-or-expected-value"><i class="fa fa-check"></i><b>5.6</b> Mean or expected value</a></li>
<li class="chapter" data-level="5.7" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#variance"><i class="fa fa-check"></i><b>5.7</b> Variance</a></li>
<li class="chapter" data-level="5.8" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-functions-for-functions-of-x"><i class="fa fa-check"></i><b>5.8</b> Probability functions for functions of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="5.9" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-distribution"><i class="fa fa-check"></i><b>5.9</b> Probability distribution</a></li>
<li class="chapter" data-level="5.10" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#probability-function-and-probability-distribution"><i class="fa fa-check"></i><b>5.10</b> Probability function and probability distribution</a></li>
<li class="chapter" data-level="5.11" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#quantiles"><i class="fa fa-check"></i><b>5.11</b> Quantiles</a></li>
<li class="chapter" data-level="5.12" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#summary"><i class="fa fa-check"></i><b>5.12</b> Summary</a></li>
<li class="chapter" data-level="5.13" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#questions-3"><i class="fa fa-check"></i><b>5.13</b> Questions</a></li>
<li class="chapter" data-level="5.14" data-path="discrete-random-variables.html"><a href="discrete-random-variables.html#exercises-3"><i class="fa fa-check"></i><b>5.14</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="continous-random-variables.html"><a href="continous-random-variables.html"><i class="fa fa-check"></i><b>6</b> Continous Random Variables</a>
<ul>
<li class="chapter" data-level="6.1" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probabilities-of-continuous-random-variables"><i class="fa fa-check"></i><b>6.1</b> Probabilities of continuous random variables</a></li>
<li class="chapter" data-level="6.2" data-path="continous-random-variables.html"><a href="continous-random-variables.html#relative-frequencies-2"><i class="fa fa-check"></i><b>6.2</b> Relative frequencies</a></li>
<li class="chapter" data-level="6.3" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-density-function"><i class="fa fa-check"></i><b>6.3</b> Probability Density Function</a></li>
<li class="chapter" data-level="6.4" data-path="continous-random-variables.html"><a href="continous-random-variables.html#total-area-under-the-curve"><i class="fa fa-check"></i><b>6.4</b> Total area under the curve</a></li>
<li class="chapter" data-level="6.5" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probabilities-of-continous-variables"><i class="fa fa-check"></i><b>6.5</b> Probabilities of continous variables</a></li>
<li class="chapter" data-level="6.6" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-distribution-1"><i class="fa fa-check"></i><b>6.6</b> Probability distribution</a></li>
<li class="chapter" data-level="6.7" data-path="continous-random-variables.html"><a href="continous-random-variables.html#probability-plots"><i class="fa fa-check"></i><b>6.7</b> Probability plots</a></li>
<li class="chapter" data-level="6.8" data-path="continous-random-variables.html"><a href="continous-random-variables.html#mean"><i class="fa fa-check"></i><b>6.8</b> Mean</a></li>
<li class="chapter" data-level="6.9" data-path="continous-random-variables.html"><a href="continous-random-variables.html#variance-1"><i class="fa fa-check"></i><b>6.9</b> Variance</a></li>
<li class="chapter" data-level="6.10" data-path="continous-random-variables.html"><a href="continous-random-variables.html#functions-of-x"><i class="fa fa-check"></i><b>6.10</b> Functions of <span class="math inline">\(X\)</span></a></li>
<li class="chapter" data-level="6.11" data-path="continous-random-variables.html"><a href="continous-random-variables.html#exercises-4"><i class="fa fa-check"></i><b>6.11</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html"><i class="fa fa-check"></i><b>7</b> Discrete Probability Models</a>
<ul>
<li class="chapter" data-level="7.1" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#probability-model"><i class="fa fa-check"></i><b>7.1</b> Probability model</a></li>
<li class="chapter" data-level="7.2" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#parametric-models"><i class="fa fa-check"></i><b>7.2</b> Parametric models</a></li>
<li class="chapter" data-level="7.3" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#uniform-probability-mass-function-one-parameter"><i class="fa fa-check"></i><b>7.3</b> Uniform probability mass function (one parameter)</a></li>
<li class="chapter" data-level="7.4" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#uniform-probability-mass-function-two-parameters"><i class="fa fa-check"></i><b>7.4</b> Uniform probability mass function (two parameters)</a></li>
<li class="chapter" data-level="7.5" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#bernoulli-trial"><i class="fa fa-check"></i><b>7.5</b> Bernoulli trial</a></li>
<li class="chapter" data-level="7.6" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#binomial-experiment"><i class="fa fa-check"></i><b>7.6</b> Binomial experiment</a></li>
<li class="chapter" data-level="7.7" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#binomial-probability-function"><i class="fa fa-check"></i><b>7.7</b> Binomial probability function</a></li>
<li class="chapter" data-level="7.8" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#negative-binomial"><i class="fa fa-check"></i><b>7.8</b> Negative binomial</a></li>
<li class="chapter" data-level="7.9" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#geometric-distribution"><i class="fa fa-check"></i><b>7.9</b> Geometric distribution</a></li>
<li class="chapter" data-level="7.10" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#hypergeometric-model"><i class="fa fa-check"></i><b>7.10</b> Hypergeometric model</a></li>
<li class="chapter" data-level="7.11" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#questions-4"><i class="fa fa-check"></i><b>7.11</b> Questions</a></li>
<li class="chapter" data-level="7.12" data-path="discrete-probability-models.html"><a href="discrete-probability-models.html#exercises-5"><i class="fa fa-check"></i><b>7.12</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html"><i class="fa fa-check"></i><b>8</b> Poisson and Exponential Models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#discrete-probability-models-1"><i class="fa fa-check"></i><b>8.1</b> Discrete probability models</a></li>
<li class="chapter" data-level="8.2" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#poissson-experiment"><i class="fa fa-check"></i><b>8.2</b> Poissson experiment</a></li>
<li class="chapter" data-level="8.3" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#poisson-probability-mass-function"><i class="fa fa-check"></i><b>8.3</b> Poisson probability mass function</a></li>
<li class="chapter" data-level="8.4" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#continuous-probability-models"><i class="fa fa-check"></i><b>8.4</b> Continuous probability models</a></li>
<li class="chapter" data-level="8.5" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-process"><i class="fa fa-check"></i><b>8.5</b> Exponential process</a></li>
<li class="chapter" data-level="8.6" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-probability-density"><i class="fa fa-check"></i><b>8.6</b> Exponential probability density</a></li>
<li class="chapter" data-level="8.7" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exponential-distribution"><i class="fa fa-check"></i><b>8.7</b> Exponential Distribution</a></li>
<li class="chapter" data-level="8.8" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#questions-5"><i class="fa fa-check"></i><b>8.8</b> Questions</a></li>
<li class="chapter" data-level="8.9" data-path="poisson-and-exponential-models.html"><a href="poisson-and-exponential-models.html#exercises-6"><i class="fa fa-check"></i><b>8.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="normal-distribution.html"><a href="normal-distribution.html"><i class="fa fa-check"></i><b>9</b> Normal Distribution</a>
<ul>
<li class="chapter" data-level="9.1" data-path="normal-distribution.html"><a href="normal-distribution.html#history"><i class="fa fa-check"></i><b>9.1</b> History</a></li>
<li class="chapter" data-level="9.2" data-path="normal-distribution.html"><a href="normal-distribution.html#normal-density"><i class="fa fa-check"></i><b>9.2</b> normal density</a></li>
<li class="chapter" data-level="9.3" data-path="normal-distribution.html"><a href="normal-distribution.html#definition"><i class="fa fa-check"></i><b>9.3</b> Definition</a></li>
<li class="chapter" data-level="9.4" data-path="normal-distribution.html"><a href="normal-distribution.html#probability-distribution-2"><i class="fa fa-check"></i><b>9.4</b> Probability distribution</a></li>
<li class="chapter" data-level="9.5" data-path="normal-distribution.html"><a href="normal-distribution.html#standard-normal-density"><i class="fa fa-check"></i><b>9.5</b> Standard normal density</a></li>
<li class="chapter" data-level="9.6" data-path="normal-distribution.html"><a href="normal-distribution.html#standard-distribution"><i class="fa fa-check"></i><b>9.6</b> Standard distribution</a></li>
<li class="chapter" data-level="9.7" data-path="normal-distribution.html"><a href="normal-distribution.html#standardization"><i class="fa fa-check"></i><b>9.7</b> Standardization</a></li>
<li class="chapter" data-level="9.8" data-path="normal-distribution.html"><a href="normal-distribution.html#questions-6"><i class="fa fa-check"></i><b>9.8</b> Questions</a></li>
<li class="chapter" data-level="9.9" data-path="normal-distribution.html"><a href="normal-distribution.html#exercises-7"><i class="fa fa-check"></i><b>9.9</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="sampling-distributions.html"><a href="sampling-distributions.html"><i class="fa fa-check"></i><b>10</b> Sampling distributions</a>
<ul>
<li class="chapter" data-level="10.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#random-sample"><i class="fa fa-check"></i><b>10.1</b> Random sample</a></li>
<li class="chapter" data-level="10.2" data-path="sampling-distributions.html"><a href="sampling-distributions.html#parameter-estimation"><i class="fa fa-check"></i><b>10.2</b> Parameter estimation</a></li>
<li class="chapter" data-level="10.3" data-path="sampling-distributions.html"><a href="sampling-distributions.html#law-of-large-numbers"><i class="fa fa-check"></i><b>10.3</b> Law of Large Numbers</a></li>
<li class="chapter" data-level="10.4" data-path="sampling-distributions.html"><a href="sampling-distributions.html#inference"><i class="fa fa-check"></i><b>10.4</b> Inference</a></li>
<li class="chapter" data-level="10.5" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-mean"><i class="fa fa-check"></i><b>10.5</b> Sample mean</a></li>
<li class="chapter" data-level="10.6" data-path="sampling-distributions.html"><a href="sampling-distributions.html#prediction"><i class="fa fa-check"></i><b>10.6</b> Prediction</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#example-pacemaker-prediction"><i class="fa fa-check"></i><b>10.6.1</b> <strong>Example: Pacemaker Prediction</strong></a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="sampling-distributions.html"><a href="sampling-distributions.html#validation"><i class="fa fa-check"></i><b>10.7</b> Validation</a></li>
<li class="chapter" data-level="10.8" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-sum"><i class="fa fa-check"></i><b>10.8</b> Sample Sum</a>
<ul>
<li class="chapter" data-level="10.8.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#example-cables"><i class="fa fa-check"></i><b>10.8.1</b> Example (Cables)</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="sampling-distributions.html"><a href="sampling-distributions.html#sample-variance-1"><i class="fa fa-check"></i><b>10.9</b> Sample Variance</a>
<ul>
<li class="chapter" data-level="10.9.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#example-cables-1"><i class="fa fa-check"></i><b>10.9.1</b> Example (Cables)</a></li>
</ul></li>
<li class="chapter" data-level="10.10" data-path="sampling-distributions.html"><a href="sampling-distributions.html#distribution-of-the-sample-variance"><i class="fa fa-check"></i><b>10.10</b> Distribution of the Sample Variance</a></li>
<li class="chapter" data-level="10.11" data-path="sampling-distributions.html"><a href="sampling-distributions.html#the-chi2-distribution"><i class="fa fa-check"></i><b>10.11</b> The <span class="math inline">\(\chi^2\)</span> Distribution</a></li>
<li class="chapter" data-level="10.12" data-path="sampling-distributions.html"><a href="sampling-distributions.html#questions-7"><i class="fa fa-check"></i><b>10.12</b> Questions</a></li>
<li class="chapter" data-level="10.13" data-path="sampling-distributions.html"><a href="sampling-distributions.html#exercises-8"><i class="fa fa-check"></i><b>10.13</b> Exercises</a>
<ul>
<li class="chapter" data-level="10.13.1" data-path="sampling-distributions.html"><a href="sampling-distributions.html#from-estimation-to-inference"><i class="fa fa-check"></i><b>10.13.1</b> From Estimation to Inference</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html"><i class="fa fa-check"></i><b>11</b> Central limit theorem</a>
<ul>
<li class="chapter" data-level="11.1" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#margin-of-error"><i class="fa fa-check"></i><b>11.1</b> Margin of error</a></li>
<li class="chapter" data-level="11.2" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#averages-of-normal-variables"><i class="fa fa-check"></i><b>11.2</b> Averages of normal variables</a></li>
<li class="chapter" data-level="11.3" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#central-limit-theorem-1"><i class="fa fa-check"></i><b>11.3</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="11.4" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#sample-sum-and-clt"><i class="fa fa-check"></i><b>11.4</b> Sample sum and CLT</a></li>
<li class="chapter" data-level="11.5" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#unknown-sigma"><i class="fa fa-check"></i><b>11.5</b> Unknown <span class="math inline">\(\sigma\)</span></a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#example-pacemaker-prediction-1"><i class="fa fa-check"></i><b>11.5.1</b> <strong>Example: Pacemaker Prediction</strong></a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#t-statistic"><i class="fa fa-check"></i><b>11.6</b> T-statistic</a></li>
<li class="chapter" data-level="11.7" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#questions-8"><i class="fa fa-check"></i><b>11.7</b> Questions</a></li>
<li class="chapter" data-level="11.8" data-path="central-limit-theorem.html"><a href="central-limit-theorem.html#exercises-9"><i class="fa fa-check"></i><b>11.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html"><i class="fa fa-check"></i><b>12</b> Maximum likelihood</a>
<ul>
<li class="chapter" data-level="12.1" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#statistic"><i class="fa fa-check"></i><b>12.1</b> Statistic</a></li>
<li class="chapter" data-level="12.2" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#properties"><i class="fa fa-check"></i><b>12.2</b> Properties</a></li>
<li class="chapter" data-level="12.3" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#maximum-likelihood-1"><i class="fa fa-check"></i><b>12.3</b> Maximum likelihood</a></li>
<li class="chapter" data-level="12.4" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#maximum-likelihood-2"><i class="fa fa-check"></i><b>12.4</b> Maximum likelihood</a></li>
<li class="chapter" data-level="12.5" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#questions-9"><i class="fa fa-check"></i><b>12.5</b> Questions</a></li>
<li class="chapter" data-level="12.6" data-path="maximum-likelihood.html"><a href="maximum-likelihood.html#exercises-10"><i class="fa fa-check"></i><b>12.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="interval-estimation.html"><a href="interval-estimation.html"><i class="fa fa-check"></i><b>13</b> Interval estimation</a>
<ul>
<li class="chapter" data-level="13.1" data-path="interval-estimation.html"><a href="interval-estimation.html#revisiting-parameter-estimation-and-marging-of-error"><i class="fa fa-check"></i><b>13.1</b> Revisiting parameter estimation and marging of error</a></li>
<li class="chapter" data-level="13.2" data-path="interval-estimation.html"><a href="interval-estimation.html#interval-estimation-for-the-mean"><i class="fa fa-check"></i><b>13.2</b> Interval estimation for the mean</a></li>
<li class="chapter" data-level="13.3" data-path="interval-estimation.html"><a href="interval-estimation.html#confidence-interval-estimation"><i class="fa fa-check"></i><b>13.3</b> Confidence Interval Estimation</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="interval-estimation.html"><a href="interval-estimation.html#estimation-of-the-mean-for-normal-variables"><i class="fa fa-check"></i><b>13.3.1</b> Estimation of the mean for normal variables</a></li>
<li class="chapter" data-level="13.3.2" data-path="interval-estimation.html"><a href="interval-estimation.html#estimation-of-the-proportion-for-dichotomic-variables"><i class="fa fa-check"></i><b>13.3.2</b> Estimation of the proportion for dichotomic variables</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="interval-estimation.html"><a href="interval-estimation.html#estimation-of-the-variance"><i class="fa fa-check"></i><b>13.4</b> Estimation of the variance</a></li>
<li class="chapter" data-level="13.5" data-path="interval-estimation.html"><a href="interval-estimation.html#confidence-interval-for-the-variance"><i class="fa fa-check"></i><b>13.5</b> Confidence interval for the variance</a></li>
<li class="chapter" data-level="13.6" data-path="interval-estimation.html"><a href="interval-estimation.html#questions-10"><i class="fa fa-check"></i><b>13.6</b> Questions</a></li>
<li class="chapter" data-level="13.7" data-path="interval-estimation.html"><a href="interval-estimation.html#exercises-11"><i class="fa fa-check"></i><b>13.7</b> Exercises</a></li>
<li class="chapter" data-level="13.8" data-path="interval-estimation.html"><a href="interval-estimation.html#practice-3"><i class="fa fa-check"></i><b>13.8</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html"><i class="fa fa-check"></i><b>14</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="14.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-formulation"><i class="fa fa-check"></i><b>14.1</b> Hypothesis formulation</a></li>
<li class="chapter" data-level="14.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-1"><i class="fa fa-check"></i><b>14.2</b> Hypothesis Testing</a></li>
<li class="chapter" data-level="14.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-for-the-mean"><i class="fa fa-check"></i><b>14.3</b> Hypothesis testing for the mean</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-with-a-confidence-interval"><i class="fa fa-check"></i><b>14.3.1</b> Hypothesis test with a confidence interval</a></li>
<li class="chapter" data-level="14.3.2" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-with-acceptancerejection-zones"><i class="fa fa-check"></i><b>14.3.2</b> Hypothesis test with acceptance/rejection zones</a></li>
<li class="chapter" data-level="14.3.3" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-test-with-a-p-value"><i class="fa fa-check"></i><b>14.3.3</b> Hypothesis test with a P-value</a></li>
<li class="chapter" data-level="14.3.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#upper-tail-hypothesis"><i class="fa fa-check"></i><b>14.3.4</b> Upper tail hypothesis</a></li>
<li class="chapter" data-level="14.3.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#paired-t-test"><i class="fa fa-check"></i><b>14.3.5</b> Paired t-test</a></li>
<li class="chapter" data-level="14.3.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#lower-tail-hypothesis"><i class="fa fa-check"></i><b>14.3.6</b> Lower tail hypothesis</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-for-the-proportion"><i class="fa fa-check"></i><b>14.4</b> Hypothesis testing for the proportion</a></li>
<li class="chapter" data-level="14.5" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#hypothesis-testing-for-the-variance"><i class="fa fa-check"></i><b>14.5</b> Hypothesis Testing for the Variance</a></li>
<li class="chapter" data-level="14.6" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#errors-in-hypothesis-testing"><i class="fa fa-check"></i><b>14.6</b> Errors in hypothesis testing</a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#sensitivity-and-specificity"><i class="fa fa-check"></i><b>14.6.1</b> Sensitivity and Specificity</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#exercises-12"><i class="fa fa-check"></i><b>14.7</b> Exercises</a></li>
<li class="chapter" data-level="14.8" data-path="hypothesis-testing.html"><a href="hypothesis-testing.html#practice-4"><i class="fa fa-check"></i><b>14.8</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="contingency-tables.html"><a href="contingency-tables.html"><i class="fa fa-check"></i><b>15</b> Contingency tables</a>
<ul>
<li class="chapter" data-level="15.1" data-path="contingency-tables.html"><a href="contingency-tables.html#difference-between-proportions"><i class="fa fa-check"></i><b>15.1</b> Difference between proportions</a></li>
<li class="chapter" data-level="15.2" data-path="contingency-tables.html"><a href="contingency-tables.html#difference-between-proportions-1"><i class="fa fa-check"></i><b>15.2</b> Difference between proportions</a></li>
<li class="chapter" data-level="15.3" data-path="contingency-tables.html"><a href="contingency-tables.html#contingency-table-of-conditional-probabilities"><i class="fa fa-check"></i><b>15.3</b> Contingency table of conditional probabilities</a></li>
<li class="chapter" data-level="15.4" data-path="contingency-tables.html"><a href="contingency-tables.html#test-for-the-difference-between-proportions"><i class="fa fa-check"></i><b>15.4</b> Test for the difference between proportions</a></li>
<li class="chapter" data-level="15.5" data-path="contingency-tables.html"><a href="contingency-tables.html#chi2-test"><i class="fa fa-check"></i><b>15.5</b> <span class="math inline">\(\chi^2\)</span> test</a></li>
<li class="chapter" data-level="15.6" data-path="contingency-tables.html"><a href="contingency-tables.html#fishers-exact-test"><i class="fa fa-check"></i><b>15.6</b> Fisherâs exact test</a></li>
<li class="chapter" data-level="15.7" data-path="contingency-tables.html"><a href="contingency-tables.html#hypergeometric-distribution"><i class="fa fa-check"></i><b>15.7</b> Hypergeometric distribution</a></li>
<li class="chapter" data-level="15.8" data-path="contingency-tables.html"><a href="contingency-tables.html#difference-between-several-proportions"><i class="fa fa-check"></i><b>15.8</b> Difference between several proportions</a></li>
<li class="chapter" data-level="15.9" data-path="contingency-tables.html"><a href="contingency-tables.html#goodness-of-fit"><i class="fa fa-check"></i><b>15.9</b> Goodness of fit</a></li>
<li class="chapter" data-level="15.10" data-path="contingency-tables.html"><a href="contingency-tables.html#questions-11"><i class="fa fa-check"></i><b>15.10</b> Questions</a></li>
<li class="chapter" data-level="15.11" data-path="contingency-tables.html"><a href="contingency-tables.html#practice-5"><i class="fa fa-check"></i><b>15.11</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html"><i class="fa fa-check"></i><b>16</b> Mean differences between two samples</a>
<ul>
<li class="chapter" data-level="16.1" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#difference-in-means-between-two-groups"><i class="fa fa-check"></i><b>16.1</b> Difference in means between two groups</a></li>
<li class="chapter" data-level="16.2" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#data-1"><i class="fa fa-check"></i><b>16.2</b> Data</a></li>
<li class="chapter" data-level="16.3" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#difference-between-means"><i class="fa fa-check"></i><b>16.3</b> Difference between means</a></li>
<li class="chapter" data-level="16.4" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#hypothesis-test"><i class="fa fa-check"></i><b>16.4</b> Hypothesis test</a></li>
<li class="chapter" data-level="16.5" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#estiamtor-of-the-mean-difference"><i class="fa fa-check"></i><b>16.5</b> Estiamtor of the mean difference</a></li>
<li class="chapter" data-level="16.6" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#standardized-error"><i class="fa fa-check"></i><b>16.6</b> Standardized error</a></li>
<li class="chapter" data-level="16.7" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#standardized-error-for-the-null"><i class="fa fa-check"></i><b>16.7</b> Standardized error for the null</a></li>
<li class="chapter" data-level="16.8" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#mean-differences-when-n-is-small"><i class="fa fa-check"></i><b>16.8</b> Mean differences when <span class="math inline">\(n\)</span> is small</a></li>
<li class="chapter" data-level="16.9" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#data-2"><i class="fa fa-check"></i><b>16.9</b> Data</a></li>
<li class="chapter" data-level="16.10" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#difference-between-means-1"><i class="fa fa-check"></i><b>16.10</b> Difference between means</a></li>
<li class="chapter" data-level="16.11" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#hypothesis-test-1"><i class="fa fa-check"></i><b>16.11</b> Hypothesis test</a></li>
<li class="chapter" data-level="16.12" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#estimator-of-the-mean-difference"><i class="fa fa-check"></i><b>16.12</b> Estimator of the mean difference</a></li>
<li class="chapter" data-level="16.13" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#standardized-error-for-the-null-1"><i class="fa fa-check"></i><b>16.13</b> Standardized error for the null</a></li>
<li class="chapter" data-level="16.14" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#mean-differences-with-unequall-variances"><i class="fa fa-check"></i><b>16.14</b> Mean differences with unequall variances</a></li>
<li class="chapter" data-level="16.15" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#data-3"><i class="fa fa-check"></i><b>16.15</b> Data</a></li>
<li class="chapter" data-level="16.16" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#questions-12"><i class="fa fa-check"></i><b>16.16</b> Questions</a></li>
<li class="chapter" data-level="16.17" data-path="mean-differences-between-two-samples.html"><a href="mean-differences-between-two-samples.html#practice-6"><i class="fa fa-check"></i><b>16.17</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html"><i class="fa fa-check"></i><b>17</b> Mean differences across several groups</a>
<ul>
<li class="chapter" data-level="17.1" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#different-means-among-several-conditions"><i class="fa fa-check"></i><b>17.1</b> Different means among several conditions</a></li>
<li class="chapter" data-level="17.2" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#data-4"><i class="fa fa-check"></i><b>17.2</b> Data</a></li>
<li class="chapter" data-level="17.3" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#difference-between-means-2"><i class="fa fa-check"></i><b>17.3</b> Difference between means</a></li>
<li class="chapter" data-level="17.4" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#hypothesis-test-2"><i class="fa fa-check"></i><b>17.4</b> Hypothesis test</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#distribution-of-group-means-under-h_0"><i class="fa fa-check"></i><b>17.4.1</b> Distribution of group means under <span class="math inline">\(H_0\)</span></a></li>
<li class="chapter" data-level="17.4.2" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#sources-of-variation"><i class="fa fa-check"></i><b>17.4.2</b> Sources of variation</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#variance-components-estimators"><i class="fa fa-check"></i><b>17.5</b> Variance components estimators</a></li>
<li class="chapter" data-level="17.6" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#analysis-of-variance-anova"><i class="fa fa-check"></i><b>17.6</b> Analysis of variance (ANOVA)</a></li>
<li class="chapter" data-level="17.7" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#anova-for-two-groups"><i class="fa fa-check"></i><b>17.7</b> ANOVA for Two Groups</a></li>
<li class="chapter" data-level="17.8" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#linear-model"><i class="fa fa-check"></i><b>17.8</b> Linear model</a></li>
<li class="chapter" data-level="17.9" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#way-anova"><i class="fa fa-check"></i><b>17.9</b> 2-way ANOVA</a></li>
<li class="chapter" data-level="17.10" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#data-5"><i class="fa fa-check"></i><b>17.10</b> Data</a></li>
<li class="chapter" data-level="17.11" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#modeling-residuals"><i class="fa fa-check"></i><b>17.11</b> Modeling residuals</a></li>
<li class="chapter" data-level="17.12" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#way-anova-linear-model"><i class="fa fa-check"></i><b>17.12</b> 2-way ANOVA linear model</a></li>
<li class="chapter" data-level="17.13" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#hypothesis-tests"><i class="fa fa-check"></i><b>17.13</b> Hypothesis tests</a></li>
<li class="chapter" data-level="17.14" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#variance-components"><i class="fa fa-check"></i><b>17.14</b> Variance components</a></li>
<li class="chapter" data-level="17.15" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#way-anova-with-interaction"><i class="fa fa-check"></i><b>17.15</b> 2-way ANOVA with interaction</a></li>
<li class="chapter" data-level="17.16" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#linear-model-1"><i class="fa fa-check"></i><b>17.16</b> Linear model</a></li>
<li class="chapter" data-level="17.17" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#hypothesis-tests-1"><i class="fa fa-check"></i><b>17.17</b> Hypothesis tests</a></li>
<li class="chapter" data-level="17.18" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#variance-components-1"><i class="fa fa-check"></i><b>17.18</b> Variance components</a></li>
<li class="chapter" data-level="17.19" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#questions-13"><i class="fa fa-check"></i><b>17.19</b> Questions</a></li>
<li class="chapter" data-level="17.20" data-path="mean-differences-across-several-groups.html"><a href="mean-differences-across-several-groups.html#practice-7"><i class="fa fa-check"></i><b>17.20</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html"><i class="fa fa-check"></i><b>18</b> Regression and Correlation</a>
<ul>
<li class="chapter" data-level="18.1" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#correlations"><i class="fa fa-check"></i><b>18.1</b> Correlations</a></li>
<li class="chapter" data-level="18.2" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#data-6"><i class="fa fa-check"></i><b>18.2</b> Data</a></li>
<li class="chapter" data-level="18.3" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#normal-bivariate"><i class="fa fa-check"></i><b>18.3</b> Normal bivariate</a></li>
<li class="chapter" data-level="18.4" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#estimators"><i class="fa fa-check"></i><b>18.4</b> Estimators</a></li>
<li class="chapter" data-level="18.5" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#correlation-coefficient"><i class="fa fa-check"></i><b>18.5</b> Correlation coefficient</a></li>
<li class="chapter" data-level="18.6" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#hypothesis-contrast"><i class="fa fa-check"></i><b>18.6</b> Hypothesis contrast</a></li>
<li class="chapter" data-level="18.7" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#regression-analysis"><i class="fa fa-check"></i><b>18.7</b> Regression analysis</a></li>
<li class="chapter" data-level="18.8" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#linear-model-2"><i class="fa fa-check"></i><b>18.8</b> Linear model</a></li>
<li class="chapter" data-level="18.9" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#hypothesis-contrast-1"><i class="fa fa-check"></i><b>18.9</b> Hypothesis contrast</a></li>
<li class="chapter" data-level="18.10" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#estimators-1"><i class="fa fa-check"></i><b>18.10</b> Estimators</a></li>
<li class="chapter" data-level="18.11" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#hypothesis-testing-2"><i class="fa fa-check"></i><b>18.11</b> Hypothesis testing</a></li>
<li class="chapter" data-level="18.12" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#stratified-analysis"><i class="fa fa-check"></i><b>18.12</b> Stratified analysis</a></li>
<li class="chapter" data-level="18.13" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#multiple-regression"><i class="fa fa-check"></i><b>18.13</b> Multiple Regression</a></li>
<li class="chapter" data-level="18.14" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#multiple-regression-interaction"><i class="fa fa-check"></i><b>18.14</b> Multiple Regression interaction</a></li>
<li class="chapter" data-level="18.15" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#model-diagnostics"><i class="fa fa-check"></i><b>18.15</b> Model diagnostics</a></li>
<li class="chapter" data-level="18.16" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#questions-14"><i class="fa fa-check"></i><b>18.16</b> Questions</a></li>
<li class="chapter" data-level="18.17" data-path="regression-and-correlation.html"><a href="regression-and-correlation.html#practice-8"><i class="fa fa-check"></i><b>18.17</b> Practice</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="apendix.html"><a href="apendix.html"><i class="fa fa-check"></i><b>19</b> Apendix</a>
<ul>
<li class="chapter" data-level="19.1" data-path="apendix.html"><a href="apendix.html#solutions-to-questions"><i class="fa fa-check"></i><b>19.1</b> Solutions to Questions</a></li>
<li class="chapter" data-level="19.2" data-path="apendix.html"><a href="apendix.html#summary-tables-python-and-r-code"><i class="fa fa-check"></i><b>19.2</b> Summary tables, Python and R code</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="apendix.html"><a href="apendix.html#creating-data-frames-and-loading-text-files"><i class="fa fa-check"></i><b>19.2.1</b> Creating Data Frames and Loading Text Files</a></li>
<li class="chapter" data-level="19.2.2" data-path="apendix.html"><a href="apendix.html#python-and-r-functions-for-data-description"><i class="fa fa-check"></i><b>19.2.2</b> Python and R Functions for Data Description</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="apendix.html"><a href="apendix.html#summary-of-common-probability-models"><i class="fa fa-check"></i><b>19.3</b> Summary of common probability models</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="apendix.html"><a href="apendix.html#python-and-r-functions-for-probability-models"><i class="fa fa-check"></i><b>19.3.1</b> Python and R Functions for Probability Models</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="apendix.html"><a href="apendix.html#summary-of-hypothesis"><i class="fa fa-check"></i><b>19.4</b> Summary of hypothesis</a>
<ul>
<li class="chapter" data-level="19.4.1" data-path="apendix.html"><a href="apendix.html#python-and-r-functions-for-hypothesis-tesing"><i class="fa fa-check"></i><b>19.4.1</b> Python and R Functions for Hypothesis tesing</a></li>
<li class="chapter" data-level="19.4.2" data-path="apendix.html"><a href="apendix.html#python-libraries-required"><i class="fa fa-check"></i><b>19.4.2</b> Python Libraries Required</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Statistical Data Analysis
for
Experimental Sciences</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="maximum-likelihood" class="section level1 hasAnchor" number="12">
<h1><span class="header-section-number">Chapter 12</span> Maximum likelihood<a href="maximum-likelihood.html#maximum-likelihood" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>n 1922, R.A. Fisher published a seminal paper that laid the foundations of modern mathematical statistics <span class="citation">(<a href="#ref-Fisher1922">R. âA. Fisher 1922</a>)</span>. While important statistical techniquesâsuch as regression analysis and tests of goodness-of-fitâhad already been developed, their mathematical underpinnings had remained largely unformalized. This lack of rigor, Fisher argued, was partly due to the nature of the field, which deals with uncertainty and error, and where precise definitions were often not considered practically necessary.</p>
<p>Another major source of confusion was linguistic: the same terms were often used to refer both to the unknown quantities that researchers sought to estimate (parameters) and to the values computed from data (estimates). For example, think of the distinction between <span class="math inline">\(\mu\)</span>, the expected value of a normal random variable, and <span class="math inline">\(\bar{x}\)</span>, the sample mean used to estimate it. Clarifying such distinctions was a crucial step in the formalization of statistical inference, enabling the generalization of estimation methods to a wide variety of models.</p>
<p>In this chapter, we will explore what an estimator is and illustrate its use in general applications such as radioactive detection, biodiversity estimation, and the analysis of system complexity. We will introduce a general framework for obtaining estimators of model parameters, focusing in particular on the method of maximum likelihood, first introduced by Fisher. Fisherâs key insight was to treat the likelihood of the observed values of random samples as a function of the unknown parameters, allowing for a principled method to derive estimates.</p>
<div id="statistic" class="section level2 hasAnchor" number="12.1">
<h2><span class="header-section-number">12.1</span> Statistic<a href="maximum-likelihood.html#statistic" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>It is time to formalize some of the notions that we have already dealt with. The intention of using a more precise language is to be able to generalize the basic concepts to any type of probability models. In particular, we need to formalize the notion of statistics, estimator and their properties, such as the error we can make when estimating a parameter with the observed value of an estimator.</p>
<p>To extract useful information of a random experiment from the sample we use statistics.</p>
<p><strong>Definition</strong></p>
<p>A <strong>statistic</strong> is any function of a random sample
<span class="math display">\[T(X_1,X_2, ..., X_n)\]</span></p>
<p>It usually returns a number, but frequency tables and plots like histograms can also be considered statistics. Statistics are random variables and their probability distributions are called <strong>sampling distributions</strong>.</p>
<p>Statistics have different functions:</p>
<ol style="list-style-type: decimal">
<li><strong>Description</strong> of a sampleâs data</li>
</ol>
<ul>
<li>location: <span class="math inline">\(\bar{X}\)</span></li>
<li>Minimum: <span class="math inline">\(\min\{X_i\}\)</span></li>
<li>Maximum: <span class="math inline">\(\max\{X_i\}\)</span></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li><strong>Estimation</strong> of a probability modelâs <strong>parameters</strong></li>
</ol>
<ul>
<li>We use <span class="math inline">\(\bar{X}\)</span> to estimate <span class="math inline">\(\mu\)</span></li>
<li>We use <span class="math inline">\(S^2\)</span> to estimate <span class="math inline">\(\sigma^2\)</span></li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li><strong>Inference</strong> for predicting the outcomes of the estimators</li>
</ol>
<ul>
<li>for the mean we will use the statistics <span class="math inline">\(Z\)</span>, <span class="math inline">\(T\)</span></li>
<li>for the variance we will use <span class="math inline">\(\chi^2\)</span></li>
</ul>
<p>This last point will be developed in the following chapters.</p>
<p>The key fact is that statistics are random variables whose observed values we take as information about the experiment. However, every time we take a new sample their value change.</p>
<p><strong>Definition of estimators</strong></p>
<p>An <strong>estimator</strong> is a statistic whose observed values are used to estimate the <strong>parameters</strong> of the probability model used to describe the outcome of the random experiments under study. When we use an estimator, the information that we are interested in extracting is the properties of the random experiment encoded in the parameters.</p>
<p>If we write the probability model of the random experiment as the probability function</p>
<p><span class="math display">\[X \rightarrow f(x; \theta)\]</span></p>
<p>then <span class="math inline">\(\theta\)</span> is a parameter and the statistics <span class="math inline">\(\Theta\)</span> is a random variable whose observations <span class="math inline">\(\hat{\theta}\)</span> we take as estimations of <span class="math inline">\(\theta\)</span>. The estimate <span class="math inline">\(\hat{\theta}\)</span> is a numerical value obtained by evaluating the estimator <span class="math inline">\(\Theta\)</span> on the data and is used as an approximation of the unknown parameter <span class="math inline">\(\theta\)</span>.</p>
<p><span class="math display">\[\hat{\theta} \approx \theta\]</span></p>
<p>Let us unpack this statement. There are three different quantities that we must consider:</p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\theta\)</span> is a <strong>parameter</strong> of the probability model that describes the experiment <span class="math inline">\(f(x; \theta)\)</span>.</li>
<li><span class="math inline">\(\Theta\)</span> is an <strong>estimator</strong> of <span class="math inline">\(\theta\)</span>: A random variable.</li>
<li><span class="math inline">\(\hat{\theta}\)</span> is the point <strong>estimate</strong> of <span class="math inline">\(\theta\)</span>: An outcome or a realized value of <span class="math inline">\(\Theta\)</span>.</li>
</ol>
<p><img src="figures/estimator.JPG" /></p>
<p><strong>Example (Sample mean)</strong></p>
<p>When the probability density function for the outcomes of a random experiment is modeled by a normal density</p>
<p><span class="math display">\[X \rightarrow N(\mu, \sigma^2)\]</span></p>
<p>we can identify the three different quantities:</p>
<ol style="list-style-type: decimal">
<li>The mean: <span class="math inline">\(\mu\)</span> is a <strong>parameter</strong> of the <strong>population</strong> distribution <span class="math inline">\(N(\mu, \sigma^2)\)</span>.</li>
<li>The average: <span class="math inline">\(\bar{X}\)</span> is an <strong>estimator</strong> of <span class="math inline">\(\mu\)</span>.</li>
<li>The point estimate of the mean: <span class="math inline">\(\bar{x}=\hat{\mu}\)</span> is the <strong>estimate</strong> of <span class="math inline">\(\mu\)</span>.</li>
</ol>
<p><strong>Example (Sample variance)</strong></p>
<p>When we have a normal random variable</p>
<p><span class="math display">\[X \rightarrow N(\mu, \sigma^2)\]</span></p>
<ol style="list-style-type: decimal">
<li><span class="math inline">\(\sigma^2\)</span> is a <strong>parameter</strong> of the population distribution</li>
<li><span class="math inline">\(S^2\)</span> is an <strong>estimator</strong> of <span class="math inline">\(\sigma^2\)</span></li>
<li><span class="math inline">\(s^2=\hat{\sigma}^2\)</span> is the <strong>estimate</strong> of <span class="math inline">\(\sigma^2\)</span></li>
</ol>
</div>
<div id="properties" class="section level2 hasAnchor" number="12.2">
<h2><span class="header-section-number">12.2</span> Properties<a href="maximum-likelihood.html#properties" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The estimators have important properties that allow us to determine the type of errors we can make when using them to estimate parameters. There are two types of error: the systematic error measured by the bias, and the random error measured by the variability of the sample. When there is low systematic error we say that the estimate is <strong>accurate</strong> (low bias) and if the observations from the sample do no vary much between then we say that the estimate is <strong>precise</strong>.</p>
<ol style="list-style-type: decimal">
<li>An estimator <span class="math inline">\(\Theta\)</span> is <strong>unbiased</strong> if its expected value is the parameter</li>
</ol>
<p><span class="math display">\[E(\Theta)=\theta\]</span></p>
<p>Therefore, the estimator is accurate and does not have systemic error.</p>
<p>For example:</p>
<ul>
<li><p><span class="math inline">\(\bar{X}\)</span> is an <strong>unbiased</strong> estimator of <span class="math inline">\(\mu\)</span> because <span class="math inline">\(E(\bar{X})=\mu\)</span></p></li>
<li><p><span class="math inline">\(S^2\)</span> is an <strong>unbiased</strong> estimator of <span class="math inline">\(\sigma^2\)</span> because <span class="math inline">\(E(S^2)=\sigma^2\)</span></p></li>
</ul>
<ol start="2" style="list-style-type: decimal">
<li>An estimator is <strong>consistent</strong> when its observed values get closer and closer as the sample size is increased</li>
</ol>
<p><span class="math display">\[lim_{n\rightarrow \infty} V(\Theta) = 0\]</span></p>
<p>Therefore the estimator is increases precision when the sample size increases.</p>
<p>For example:</p>
<ul>
<li><span class="math inline">\(\bar{X}\)</span> is <strong>consistent</strong> because <span class="math inline">\(V(\bar{X})=\frac{\sigma^2}{n}\rightarrow 0\)</span> when <span class="math inline">\(n \rightarrow \infty\)</span>.</li>
</ul>
<ol start="3" style="list-style-type: decimal">
<li>The mean squared error <span class="math inline">\(mse\)</span> of <span class="math inline">\(\Theta\)</span> is its expected squared difference from the parameter</li>
</ol>
<p><span class="math display">\[mse(\Theta)=E([\Theta - \theta]^2)\]</span></p>
<p>or equivalently is the sum of the errors in consistency and bias</p>
<p><span class="math display">\[mse(\Theta)=se^2 + bias^2\]</span></p>
<p>where <span class="math inline">\(se=\sqrt{V(\Theta)}\)</span> is the standard error.
<strong>Efficient estimators</strong> are those with the lowest variance among unbiased estimators.</p>
</div>
<div id="maximum-likelihood-1" class="section level2 hasAnchor" number="12.3">
<h2><span class="header-section-number">12.3</span> Maximum likelihood<a href="maximum-likelihood.html#maximum-likelihood-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Now that we know what estimators are and what makes them good, we need a method to derive them from data. The method of maximum likelihood does this by choosing an observed value of the estimator as a likely value of a parameter that which makes the observed data most probable. Remember that the parameter is un-observable and, if we do not know its theoretical value, we are trying to learn its most likely value using experimental data.</p>
<p>How can then we obtain <strong>estimators</strong> of the parameters of <strong>any</strong> probability model? The method of maximum likelihood offers a strategy to propose estimators.</p>
<p><strong>Example (Alpha particles)</strong></p>
<p>In 1910, Rutherford y Geiger counted the number of <span class="math inline">\(\alpha\)</span> particles that a specimen of polonium would emit each <span class="math inline">\(7.5\)</span> seconds. The absolute frequencies that they reported for the number of particles each <span class="math inline">\(7.5\)</span> seconds from a total of <span class="math inline">\(2608\)</span> observations were</p>
<p><span class="math display">\[
\begin{array}{cc}
\mathbf{outcome} &amp; \mathbf{n_i}  \\
0 &amp; 57 \\
1 &amp; 203 \\
2 &amp; 383 \\
3 &amp; 525 \\
4 &amp; 532 \\
5 &amp; 408 \\
6 &amp; 273 \\
7 &amp; 139 \\
8 &amp; 45 \\
9 &amp; 27 \\
10 &amp;  10 \\
11 &amp;   4 \\
12 &amp;   0 \\
13 &amp;   1 \\
14 &amp;   1 \\ \hline
\mathbf{sum} &amp; 2608 \\
\end{array}
\]</span></p>
<p><img src="_main_files/figure-html/unnamed-chunk-141-1.png" width="672" /></p>
<p>They observed, for instance, that <span class="math inline">\(57\)</span> of the times they did not observed any particle within <span class="math inline">\(7.5\)</span> seconds, <span class="math inline">\(203\)</span> of the times they counted one particles within <span class="math inline">\(7.5\)</span> seconds, etc. They wanted to show that particles were emitted from independent sources (atoms) and find a probabilistic model for the counts.</p>
<p>What is a probability function that can describe the data?</p>
<p><strong>Proposing a probability model</strong></p>
<p>To answer the question on how to select a probabilistic model when we have some data, we follow the steps:</p>
<p><strong>Step 1.</strong> we propose <strong>probability function</strong> on the nature of the random variable (continuous or discrete) that depends on parameters,</p>
<p><strong>Step 2.</strong> we derive the <strong>estimators</strong> for the parameters, by maximum likelihood,</p>
<p><strong>Step 3.</strong> finally, we use the estimator to <strong>estimate the parameters</strong> with the data.</p>
<p>In many applications, we can propose parametric models that is a model that belongs to a family of a probability functions that depends on some parameters. Proposing a probability model is done by following the <strong>general properties</strong> of the observations, or by what we expect to observe. Modelling requires experience, skill and knowledge of several mathematical functions. However, in most cases <strong>well known models</strong> are typically applied.</p>
<p><strong>Example (Alpha particles)</strong></p>
<p>In the appendix of Rutherford and Geigerâs paper, Bateman showed that if there were independent sources alpha particles, the number of particles detected in a time interval would follow a Poisson distribution. That is</p>
<p><span class="math display">\[X \sim Poisson (\lambda)\]</span></p>
<p>Therefore, once selected the theoretical model, they needed to find the value of the parameter <span class="math inline">\(\lambda\)</span> for their data.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-142-1.png" width="672" /></p>
<p>Many values of the parameters could explain the data. We are interested in <strong>one criterion</strong> to choose one particular value.</p>
<p>The <strong>maximum likelihood</strong> method will gives us the estimator for <span class="math inline">\(\lambda\)</span></p>
<p><span class="math display">\[\hat{\lambda}_{ml}\]</span>
using an optimal probabilistic argument.</p>
</div>
<div id="maximum-likelihood-2" class="section level2 hasAnchor" number="12.4">
<h2><span class="header-section-number">12.4</span> Maximum likelihood<a href="maximum-likelihood.html#maximum-likelihood-2" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The objective is to find the value of the parameter that we <strong>believe</strong> can <strong>best</strong> represent the data.</p>
<p>The method of maximum likelihood is based on the search for the parameter value that makes the <strong>observation</strong> of the sample the most <strong>probable</strong>.</p>
<p>Remember, a random sample is a random variable
<span class="math display">\[M=(X_1,...X_n)\]</span>
an observed sample is an outcome of <span class="math inline">\(M\)</span>, a set of numerical values that we actually obtained when we repeated the random experiment</p>
<p><span class="math display">\[m=(x_1,...x_{n=2608})=c(10, 14, ... 0, 4)\]</span></p>
<p><strong>Maximum likelihood step 1</strong></p>
<p>First, we calculate the probability of having observed the particular <span class="math inline">\(n\)</span>-sample: <span class="math inline">\(x_1,...x_n\)</span>. This is the product of probabilities for each observation because the repetitions of the random experiment are independent of one another. If the probabilistic model of is</p>
<p><span class="math display">\[X \sim f(x, \theta)\]</span>
Then the probability of observing the data is</p>
<p><span class="math inline">\(P(M=x_1,...x_n)=P(X=x_1)P(X=x_2)...P(X=x_n)\)</span>
<span class="math display">\[=f(x_1;\theta)f(x_2;\theta) ...f(x_n;\theta)\]</span>
We call this function the <strong>likelihood function</strong> and we consider that:</p>
<ul>
<li>Once the data are observed, they are <strong>fixed</strong></li>
<li>The unknown is the parameter <span class="math inline">\(\theta\)</span></li>
</ul>
<p><span class="math display">\[L(\theta)= \Pi_{i=1..n} f(x_i; \theta)\]</span></p>
<p><strong>Example (Alpha particles)</strong></p>
<p>For the alpha particle experiment the model in Poisson</p>
<p><span class="math display">\[X \sim  f(x; \lambda)= \frac{e^{-\lambda}\lambda^x}{x!}\]</span>
and the unknown the parameter <span class="math inline">\(\lambda\)</span>. Therefore, the likelihood is</p>
<p><span class="math inline">\(L(\lambda;x_1,..x_n)= \frac{e^{-\lambda}\lambda^{x_1}}{x_1!}\frac{e^{-\lambda}\lambda^{x_2}}{x_2!}...\frac{e^{-\lambda}\lambda^{x_n}}{x_1!}=\)</span></p>
<p><span class="math display">\[\frac{e^{-n\lambda}\lambda^{\sum {x_i}}}{x_1!x_2!..x_n!}\]</span></p>
<p><strong>Maximum likelihood step 2</strong></p>
<p>We then ask: what is the value of <span class="math inline">\(\theta\)</span> that makes the observed sample the most probable event? We thus want to maximize <span class="math inline">\(L(\theta)\)</span> with respect to <span class="math inline">\(\theta\)</span>. Since we have the multiplication of many factors, it is easier to maximize the logarithm of <span class="math inline">\(L(\theta)\)</span>. This is called the log-likelihood function:</p>
<p><span class="math display">\[\ln L(\theta;x_1,..x_n)\]</span></p>
<p><strong>Example (Alpha particles)</strong></p>
<p>In the alpha particles example, we therefore take the logarithm and obtain the <strong>Log-likelihood</strong></p>
<p><span class="math display">\[\ln L(\alpha;x_1,..x_n)= -n\lambda - \sum{x_i}\ln(\lambda)-\ln(x_1!x_2!...x_3!)\]</span></p>
<p><strong>Maximum likelihood step 3</strong></p>
<p>Finally we <strong>maximize</strong> the log-likelihood with respect to the parameter. Therefore, we differentiate the log-likelihood with respect to the parameter <span class="math inline">\(\theta\)</span>, equate to zero and solve for the maximum.</p>
<p><span class="math display">\[\frac{d \ln L(\theta)}{d \theta} \big|_{\hat{\theta}}=0 \]</span>
The value of the parameter at the maximum is called the <strong>maximum likelihood estimate</strong> for the parameter and it is written with a hat <span class="math inline">\(\hat{\theta}\)</span>.</p>
<p><strong>Example (Alpha particles)</strong></p>
<p>We derive the log-likelihood</p>
<p><span class="math display">\[\frac{d \ln L(\lambda)}{d \lambda}= -n + \frac{\sum{x_i}}{\lambda}\]</span>
The maximum is where the derivative is <span class="math inline">\(0\)</span>. This maximum is the value of our estimator <span class="math inline">\(\hat{\lambda}_{ml}\)</span>.</p>
<p><span class="math display">\[\hat{\lambda}_{ml}=\frac{1}{n}\sum_{i=1}^{n}\]</span></p>
<p>The estimator of the parameter is therefore (note the capital letters)</p>
<p><span class="math display">\[\Lambda=\frac{1}{n}\sum_{i=1}^{n}\]</span></p>
<p>Which is a the sample mean, a random variable function of the random sample</p>
<p><span class="math display">\[(X_1, X_2, ... X_n)\]</span></p>
<p>We then have the fact that the <strong>sample mean</strong> is the <strong>maximum likelihood</strong> estimator of the parameter <span class="math inline">\(\lambda\)</span> of a Poisson model.</p>
<p><em>Estimating the parameters with the data</em></p>
<p>In our example, we then have the observation of the random sample as a set of 2608 numbers <span class="math inline">\((x_1, x_2, ...x_{2608})\)</span>, we therefore substitute the numbers in the estimator and this will give us its observed value.</p>
<p><span class="math display">\[\hat{\lambda}_{ml}=-\frac{1}{n}\sum_{i=1}^{n} =\sum_{i=1}^{n} x_if_i =3.871549\]</span></p>
<p>Using the relative frequency table. Therefore, the maximum likelihood estimate of the parameter is <span class="math inline">\(3.871549\)</span>, as reported by Rutherford and Gaiger. If we substitute this value in the probability function, and overlay it with the bar plot, we can see that it gives us a suitable description of the data.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-143-1.png" width="672" /></p>
<p>Let us look at the log-likelihood function for the <span class="math inline">\(2608\)</span> observations. Remember, data is fixed the data of the experiment and that <span class="math inline">\(\lambda\)</span> varies. The function has a maximum. However, if we take another sample this function changes and so does its maximum.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-144-1.png" width="672" /></p>
<p><strong>Example (Number of Individuals per Species)</strong></p>
<p>In another influential work, Fisher and colleagues analysed the number of individuals for each moth species that was captured over 4 years at Rothamsted Experimental Station <span class="citation">(<a href="#ref-fisher1943species">R. A. Fisher, Corbet, and Williams 1943</a>)</span>. This is their data aggregated in absolute frequencies</p>
<p><span class="math display">\[
\begin{array}{cc}
\mathbf{outcome} &amp; \mathbf{n_i}  \\
  1 &amp; 102 \\
  2 &amp; 41 \\
  3 &amp; 18 \\
  4 &amp; 12 \\
  5 &amp; 8 \\
  6 &amp; 5 \\
  7 &amp; 1 \\
  8 &amp; 2 \\
  9 &amp; 1 \\
  10 &amp; 2 \\
  12 &amp; 1 \\
  13 &amp; 1 \\
  16 &amp; 1 \\
\hline
\mathbf{sum} &amp; 195\\
\end{array}
\]</span></p>
<p>that represents the number of individuals observed for a species during the four years campaign. This is <span class="math inline">\(102\)</span> species were observed only once, <span class="math inline">\(42\)</span> species twice and so on. The random variable <span class="math inline">\(X\)</span> is then the number of events in a period of time on a particular species. Here the species is the observation unit or the repetition of the random experiment. The random experiment was repeated 195 times, and Fisher proposed that the random variable <span class="math inline">\(X\)</span> followed a log-series distribution</p>
<p><span class="math display">\[X \sim \frac{-\theta^x}{x\ln(1-\theta)}\]</span></p>
<p>where <span class="math inline">\(\theta \in (0,1)\)</span>, rather than a Poisson distribution.</p>
<p>To find the value of <span class="math inline">\(\theta\)</span> we can use the method of Maximum Likelihood, where we first propose the likelihood of the data</p>
<p><span class="math display">\[
L(\theta) = \prod_{i=1}^{n} \left( -\frac{\theta^{x_i}}{x_i \log(1 - \theta)} \right)
\]</span></p>
<p>Where <span class="math inline">\(x\)</span> is the dis-aggregated data, one observation (number of counts in 4 years) per species <span class="math inline">\((1, 1, ...1_{102}, 2, ...2_{41}, ..., 12, 13, 16)\)</span>. We can then optimize the logarithm of <span class="math inline">\(L(\theta)\)</span>.</p>
<p><span class="math display">\[
\ln L(\theta)
= \sum_{i=1}^{n} \ln\left( -\frac{\theta^{x_i}}{x_i \ln(1 - \theta)} \right)
\]</span></p>
<p>While the solution cannot be written in terms of known functions, we can solve it numerically, giving the maximum at</p>
<p><span class="math display">\[\hat{\theta}=0.77\]</span></p>
<p>As reported by Fisher.</p>
<p><img src="_main_files/figure-html/unnamed-chunk-145-1.png" width="672" /></p>
<p>He also defined the biodiversity index <span class="math display">\[\alpha=N \frac{1-\theta}{\theta}\sim 134.1\]</span>
Were <span class="math inline">\(N=449\)</span> is the total number of individuals observed. This value represents a system of high richness-many species are present- and high evenness-individuals are fairly well distributed among species.</p>
<p><strong>Example (The Normal Distribution)</strong></p>
<p>Gauss used astronomical data from Giuseppe Piazzi to infer the true position of Ceres at a given time, Gauss derived the error function</p>
<p><span class="math display">\[f(x; \mu, \sigma^2)= \frac{1}{\sigma \sqrt{2 \pi}} e^{-\frac{1}{2\sigma^2} (x-\mu)^2}\]</span></p>
<p>Where the <strong>true</strong> position of Ceres was the mean <span class="math inline">\(\mu\)</span>, or the expected value of the outcomes. How did Gauss combined the data for having the best estimate for the position of Ceres?</p>
<p>What is the statistic that can describe best its position?</p>
<p><img src="figures/cerestime.JPG" /></p>
<p>In modern times, this question can be formulated as: What is the maximum likelihood estimator of <span class="math inline">\(\mu\)</span> for a random normal variable?</p>
<p><strong>Maximum likelihood of the normal distribution</strong></p>
<p>For a random normal variable</p>
<p><span class="math display">\[X \rightarrow N(\mu, \sigma^2)\]</span>.</p>
<p>What are the estimators of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> that maximize the probability of the observed data?</p>
<p>We follow the maximum likelihood method:</p>
<p><strong>Step 1.</strong> The likelihood function, or the probability of having observed the sample <span class="math inline">\((x_1, ....x_n)\)</span> is</p>
<p><span class="math inline">\(L(\mu, \sigma^2)=\Pi_{i=1..n} f(x_i;\mu,\sigma)\)</span></p>
<p><span class="math display">\[=\big( \frac{1}{\sigma \sqrt{2 \pi}}\big)^n e^{-\frac{1}{2\sigma^2} \sum_i(x_i-\mu)^2}\]</span></p>
<p><strong>Step 2.</strong> We take the log of <span class="math inline">\(L\)</span>, and compute the <strong>log-likelihood</strong></p>
<p><span class="math display">\[\ln L(\mu, \sigma^2)=-n \ln(\sigma \sqrt{2 \pi})-\frac{1}{2\sigma^2} \Sigma_i(x_i-\mu)^2\]</span></p>
<p>The estimates of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> are where the likelihood is maximum. They give the highest probability for the data.</p>
<p><strong>Step 3.</strong> We differentiate with respect to <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span>. These two derivatives give us two equations, one for each of the parameters. For deriving respect to <span class="math inline">\(\sigma^2\)</span>, it is easier to make a substitution <span class="math inline">\(t=\sigma^2\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li><p><span class="math inline">\(\frac{d \ln L(\mu, \sigma^2)}{d\mu}=\frac{1}{\sigma^2} \sum_i(x_i-\mu)\)</span></p></li>
<li><p><span class="math inline">\(\frac{d \ln L(\mu, \sigma^2)}{d\sigma^2}=-\frac{n}{2 \sigma^2}+\frac{1}{2\sigma^4} \sum_i(x_i-\mu)^2\)</span></p></li>
</ol>
<p>The derivatives are <span class="math inline">\(0\)</span> at the maxima</p>
<ol style="list-style-type: lower-alpha">
<li><span class="math inline">\(\frac{1}{\hat{\sigma}^2} \sum_i(x_i-\hat{\mu})=0\)</span></li>
<li><span class="math inline">\(-\frac{n}{2 \hat{\sigma}^2}+\frac{1}{2\hat{\sigma}^4} \sum_i(x_i-\hat{\mu})^2=0\)</span></li>
</ol>
<p>solving both equations for the parameters we find for <span class="math inline">\(\mu\)</span></p>
<p><span class="math display">\[\hat{\mu}_{ml}=\frac{1}{n}\sum_i x_i=\bar{x}\]</span></p>
<p>and for <span class="math inline">\(\sigma^2\)</span></p>
<p><span class="math display">\[\hat{\sigma}^2_{ml}=\frac{1}{n}\sum_i(x_i-\bar{x})^2\]</span></p>
<p>Therefore, the sample mean (average) <span class="math inline">\(\bar{X}\)</span> is the maximum likelihood estimator of the mean <span class="math inline">\(\mu\)</span>. Gauss showed that the statistics that we should trust most (that with highest likelihood) for the real position of the Ceres was the <strong>average</strong>. Gauss solving the position of Ceres, not only discovered the normal distribution, but also created the regression analysis and showed the importance of the average. It is due to him that we often use the average as a preferred statistics, assuming that the observations follow a normal distribution.</p>
<p>In addition, the maximum likelihood estimator of <span class="math inline">\(\sigma^2\)</span> is a <strong>biased</strong> estimator because it can be shown that <span class="math display">\[E(\hat{\sigma}^2_{ml})=\sigma^2-\frac{\sigma^2}{n}\neq \sigma^2\]</span></p>
<p>It was Fisher who showed that this estimator was important, as he used it to generalize the central limit theorem.</p>
</div>
<div id="questions-9" class="section level2 hasAnchor" number="12.5">
<h2><span class="header-section-number">12.5</span> Questions<a href="maximum-likelihood.html#questions-9" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>1)</strong> An estimator is not</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> a statistic;
<strong><span class="math inline">\(\qquad\)</span>b:</strong> a random variable;
<strong><span class="math inline">\(\qquad\)</span>c:</strong> discrete;
<strong><span class="math inline">\(\qquad\)</span>d:</strong> an observation of the parameter;</p>
<p><strong>2)</strong> An estimator is unbiased if</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> it is the parameter that it estimates;
<strong><span class="math inline">\(\qquad\)</span>b:</strong> depends on <span class="math inline">\(1/n\)</span>;
<strong><span class="math inline">\(\qquad\)</span>c:</strong> its variance is small;
<strong><span class="math inline">\(\qquad\)</span>d:</strong> its expected value is the parameter it estimates;</p>
<p><strong>3)</strong> An estimator is consistent if</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> it is the parameter that it estimates;
<strong><span class="math inline">\(\qquad\)</span>b:</strong> depends on <span class="math inline">\(1/n\)</span>;
<strong><span class="math inline">\(\qquad\)</span>c:</strong> its variance is small;
<strong><span class="math inline">\(\qquad\)</span>d:</strong> its expected value is the parameter it estimates;</p>
<p><strong>4)</strong> The maximum likelihood method</p>
<p><strong><span class="math inline">\(\qquad\)</span>a:</strong> Produces estimators based on the probability of the observations;
<strong><span class="math inline">\(\qquad\)</span>b:</strong> produces unbiased estimators;
<strong><span class="math inline">\(\qquad\)</span>c:</strong> produces consistent estimators;
<strong><span class="math inline">\(\qquad\)</span>d:</strong> produces estimators equal to those of the method of moments;</p>
</div>
<div id="exercises-10" class="section level2 hasAnchor" number="12.6">
<h2><span class="header-section-number">12.6</span> Exercises<a href="maximum-likelihood.html#exercises-10" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="exercise-1-9" class="section level4 hasAnchor" number="12.6.0.1">
<h4><span class="header-section-number">12.6.0.1</span> Exercise 1<a href="maximum-likelihood.html#exercise-1-9" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Take a random variable with the following probability density function</p>
<p><span class="math display">\[
f(x)=
\begin{cases}
    (1+\theta)x^\theta,&amp; \text{if } x\in (0,1)\\
    0,&amp;  x\notin (0,1)
\end{cases}
\]</span></p>
<ul>
<li><p>What is the maximum likelihood estimator for <span class="math inline">\(\theta\)</span>?</p></li>
<li><p>If we take a <span class="math inline">\(5\)</span>-sample with observations
<span class="math inline">\(x_1 = 0.92; \qquad x_2 = 0.79; \qquad x_3 = 0.90; \qquad x_4 = 0.65; \qquad x_5 = 0.86\)</span></p></li>
</ul>
<p>What is the estimated value of the parameter <span class="math inline">\(\theta\)</span>?</p>
<ul>
<li>Compute <span class="math inline">\(E(X)=\mu\)</span> as a function of <span class="math inline">\(\theta\)</span>. What is the maximum likelihood estimator for <span class="math inline">\(\mu\)</span>?</li>
</ul>
</div>
<div id="exercise-2-9" class="section level4 hasAnchor" number="12.6.0.2">
<h4><span class="header-section-number">12.6.0.2</span> Exercise 2<a href="maximum-likelihood.html#exercise-2-9" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>For a random variable with a binomial probability function</p>
<p><span class="math display">\[f(x; p)=\binom n x p^x(1-p)^{n-x}\]</span></p>
<ul>
<li><p>What is the maximum-likelihood estimator of <span class="math inline">\(p\)</span> for a sample of size <span class="math inline">\(1\)</span> of this random variable?</p></li>
<li><p>In <strong>one</strong> exam of <span class="math inline">\(100\)</span> students we observed <span class="math inline">\(x_1=68\)</span> students that passed the exam. What is the estimate of the <span class="math inline">\(p\)</span>?</p></li>
</ul>
</div>
<div id="exercise-3-7" class="section level4 hasAnchor" number="12.6.0.3">
<h4><span class="header-section-number">12.6.0.3</span> Exercise 3<a href="maximum-likelihood.html#exercise-3-7" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Take a random variable with the following probability density function</p>
<p><span class="math display">\[
    f(x)=
\begin{cases}
    \lambda e^{-\lambda x},&amp; \text{if } 0 \leq x\\
    0,&amp; otherwise
\end{cases}
\]</span></p>
<ul>
<li><p>What is the maximum likelihood estimator for <span class="math inline">\(\lambda\)</span>?</p></li>
<li><p>If we take a <span class="math inline">\(5\)</span>-sample with observations
<span class="math inline">\(x_1 = 0.223 \qquad x_2 = 0.681; \qquad x_3 = 0.117; \qquad x_4 = 0.150; \qquad x_5 = 0.520\)</span></p></li>
</ul>
<p>What is the estimated value of the parameter <span class="math inline">\(\lambda\)</span>?</p>
<ul>
<li><p>What is the maximum likelihood estimator of the parameter <span class="math inline">\(\alpha=\frac{n}{\lambda}\)</span></p></li>
<li><p>Is <span class="math inline">\(\alpha\)</span> an unbiased and consistent estimator of the mean of the sample sum <span class="math inline">\(E(Y)\)</span>, where <span class="math inline">\(Y=\sum_1^n X_i\)</span>?</p></li>
</ul>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Fisher1922" class="csl-entry">
Fisher, R.âA. 1922. <span>âOn the Mathematical Foundations of Theoretical Statistics.â</span> <em>Philosophical Transactions of the Royal Society of London. Series A, Containing Papers of a Mathematical or Physical Character</em> 222 (594â604): 309â68. <a href="https://doi.org/10.1098/rsta.1922.0009">https://doi.org/10.1098/rsta.1922.0009</a>.
</div>
<div id="ref-fisher1943species" class="csl-entry">
Fisher, Ronald A., A. S. Corbet, and C. B. Williams. 1943. <span>âThe Relation Between the Number of Species and the Number of Individuals in a Random Sample of an Animal Population.â</span> <em>The Journal of Animal Ecology</em> 12 (1): 42â58. <a href="https://doi.org/10.2307/1411">https://doi.org/10.2307/1411</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="central-limit-theorem.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="interval-estimation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/12-MaximumLikelihood.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf", "_main.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
